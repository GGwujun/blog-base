<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog/umi.css" />
    <script>
      window.routerBase = "/blog";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>18 | 爬虫和反爬虫：如何防止黑产爬取我的数据？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/计算机网络通关29讲/05.模块四web技术/05" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>计算机基础<ul><li><a href="/blog/编译原理之美">编译原理之美</a></li><li><a href="/blog/编译原理实战">编译原理实战</a></li><li><a href="/blog/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog/详解http">详解http</a></li><li><a aria-current="page" class="active" href="/blog/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog/网络排查案例课">网络排查案例课</a></li><li><a href="/blog/linux操作系统">linux操作系统</a></li><li><a href="/blog/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog/程序员数学基础">程序员数学基础</a></li><li><a href="/blog/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog/操作系统实战">操作系统实战</a></li><li><a href="/blog/软件工程之美">软件工程之美</a></li><li><a href="/blog/sql必知必会">sql必知必会</a></li><li><a href="/blog/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog/网络编程实战">网络编程实战</a></li><li><a href="/blog/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></span><span>算法<ul><li><a href="/blog/常用算法25讲">常用算法25讲</a></li><li><a href="/blog/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog/动态规划面试宝典">动态规划面试宝典</a></li></ul></span><span>前端开发<ul><li><a href="/blog/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog/正则表达式入门">正则表达式入门</a></li></ul></span><span>前端工程化</span><span>前端性能优化</span><span>移动端开发</span><span>软件测试</span><span>产品与用户体验</span><span>面试</span><span>杂谈<ul><li><a href="/blog/代码之丑">代码之丑</a></li><li><a href="/blog/代码精进之路">代码精进之路</a></li><li><a href="/blog/数据分析思维课">数据分析思维课</a></li><li><a href="/blog/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog/重学线性代数">重学线性代数</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>计算机基础<ul><li><a href="/blog/编译原理之美">编译原理之美</a></li><li><a href="/blog/编译原理实战">编译原理实战</a></li><li><a href="/blog/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog/详解http">详解http</a></li><li><a aria-current="page" class="active" href="/blog/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog/网络排查案例课">网络排查案例课</a></li><li><a href="/blog/linux操作系统">linux操作系统</a></li><li><a href="/blog/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog/程序员数学基础">程序员数学基础</a></li><li><a href="/blog/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog/操作系统实战">操作系统实战</a></li><li><a href="/blog/软件工程之美">软件工程之美</a></li><li><a href="/blog/sql必知必会">sql必知必会</a></li><li><a href="/blog/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog/网络编程实战">网络编程实战</a></li><li><a href="/blog/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></li><li>算法<ul><li><a href="/blog/常用算法25讲">常用算法25讲</a></li><li><a href="/blog/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog/动态规划面试宝典">动态规划面试宝典</a></li></ul></li><li>前端开发<ul><li><a href="/blog/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog/正则表达式入门">正则表达式入门</a></li></ul></li><li>前端工程化</li><li>前端性能优化</li><li>移动端开发</li><li>软件测试</li><li>产品与用户体验</li><li>面试</li><li>杂谈<ul><li><a href="/blog/代码之丑">代码之丑</a></li><li><a href="/blog/代码精进之路">代码精进之路</a></li><li><a href="/blog/数据分析思维课">数据分析思维课</a></li><li><a href="/blog/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog/重学线性代数">重学线性代数</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog/计算机网络通关29讲/01.开篇词">01.开篇词</a><ul><li><a href="/blog/计算机网络通关29讲/01.开篇词/01"><span>开篇词 | 一次搞定计算机网络，高效修炼程序员内功</span></a></li><li><a href="/blog/计算机网络通关29讲/01.开篇词/02"><span>课前导读 | 程序员如何打好计算机领域的基础？</span></a></li></ul></li><li><a href="/blog/计算机网络通关29讲/02.模块一互联网和传输层协议">02.模块一互联网和传输层协议</a><ul><li><a href="/blog/计算机网络通关29讲/02.模块一互联网和传输层协议/01"><span>01 | 漫游互联网：什么是蜂窝移动网络？</span></a></li><li><a href="/blog/计算机网络通关29讲/02.模块一互联网和传输层协议/02"><span>02 | 传输层协议 TCP：TCP 为什么握手是 3 次、挥手是 4 次？</span></a></li><li><a href="/blog/计算机网络通关29讲/02.模块一互联网和传输层协议/03"><span>03 | TCP 的封包格式：TCP 为什么要粘包和拆包？</span></a></li><li><a href="/blog/计算机网络通关29讲/02.模块一互联网和传输层协议/04"><span>04 | TCP 的稳定性：滑动窗口和流速控制是怎么回事？</span></a></li><li><a href="/blog/计算机网络通关29讲/02.模块一互联网和传输层协议/05"><span>05 | UDP 协议：TCP 协议和 UDP 协议的优势和劣势？</span></a></li><li><a href="/blog/计算机网络通关29讲/02.模块一互联网和传输层协议/06"><span>加餐 | 模块一思考题解答</span></a></li></ul></li><li><a href="/blog/计算机网络通关29讲/03.模块二网络层协议">03.模块二网络层协议</a><ul><li><a href="/blog/计算机网络通关29讲/03.模块二网络层协议/01"><span>06 | IPv4 协议：路由和寻址的区别是什么？</span></a></li><li><a href="/blog/计算机网络通关29讲/03.模块二网络层协议/02"><span>07 | IPv6 协议：Tunnel 技术是什么？</span></a></li><li><a href="/blog/计算机网络通关29讲/03.模块二网络层协议/03"><span>08 | 局域网：NAT 是如何工作的？</span></a></li><li><a href="/blog/计算机网络通关29讲/03.模块二网络层协议/04"><span>09 | TCP 实战：如何进行 TCP 抓包调试？</span></a></li><li><a href="/blog/计算机网络通关29讲/03.模块二网络层协议/05"><span>加餐 | 模块二思考题解答</span></a></li></ul></li><li><a href="/blog/计算机网络通关29讲/04.模块三网络编程">04.模块三网络编程</a><ul><li><a href="/blog/计算机网络通关29讲/04.模块三网络编程/01"><span>10 | Socket 编程：epoll 为什么用红黑树？</span></a></li><li><a href="/blog/计算机网络通关29讲/04.模块三网络编程/02"><span>11 | 流和缓冲区：缓冲区的 flip 是怎么回事？</span></a></li><li><a href="/blog/计算机网络通关29讲/04.模块三网络编程/03"><span>12 | 网络 I/O 模型：BIO、NIO 和 AIO 有什么区别？</span></a></li><li><a href="/blog/计算机网络通关29讲/04.模块三网络编程/04"><span>13 | 面试中如何回答“怎样实现 RPC 框架”的问题？</span></a></li><li><a href="/blog/计算机网络通关29讲/04.模块三网络编程/05"><span>加餐 | 模块三思考题解答</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog/计算机网络通关29讲/05.模块四web技术">05.模块四Web技术</a><ul><li><a href="/blog/计算机网络通关29讲/05.模块四web技术/01"><span>14 | DNS 域名解析系统：CNAME 记录的作用是？</span></a></li><li><a href="/blog/计算机网络通关29讲/05.模块四web技术/02"><span>15 | 内容分发网络：请简述 CDN 回源如何工作？</span></a></li><li><a href="/blog/计算机网络通关29讲/05.模块四web技术/03"><span>16 | HTTP 协议面试通关：强制缓存和协商缓存的区别是？</span></a></li><li><a href="/blog/计算机网络通关29讲/05.模块四web技术/04"><span>17 | 流媒体技术：直播网站是如何实现的？</span></a></li><li><a aria-current="page" class="active" href="/blog/计算机网络通关29讲/05.模块四web技术/05"><span>18 | 爬虫和反爬虫：如何防止黑产爬取我的数据？</span></a></li><li><a href="/blog/计算机网络通关29讲/05.模块四web技术/06"><span>加餐 | 模块四思考题解答</span></a></li></ul></li><li><a href="/blog/计算机网络通关29讲/06.模块五网络安全">06.模块五网络安全</a><ul><li><a href="/blog/计算机网络通关29讲/06.模块五网络安全/01"><span>19 | 网络安全概述：对称、非对称加密的区别是？</span></a></li><li><a href="/blog/计算机网络通关29讲/06.模块五网络安全/02"><span>20 | 信任链：为什么可以相信一个 HTTPS 网站？</span></a></li><li><a href="/blog/计算机网络通关29讲/06.模块五网络安全/03"><span>21 | 攻防手段介绍：如何抵御 SYN 拒绝攻击？</span></a></li><li><a href="/blog/计算机网络通关29讲/06.模块五网络安全/04"><span>加餐 | 模块五思考题解答</span></a></li></ul></li><li><a href="/blog/计算机网络通关29讲/07.结束语">07.结束语</a><ul><li><a href="/blog/计算机网络通关29讲/07.结束语/01"><span>结束语 | 未来需要怎样的工程师</span></a></li></ul></li><li><a href="/blog/计算机网络通关29讲/summary">计算机网络通关29讲</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="爬取数据违法吗？" data-depth="3"><a href="/blog/计算机网络通关29讲/05.模块四web技术/05#爬取数据违法吗"><span>爬取数据违法吗？</span></a></li><li title="爬虫的原理" data-depth="3"><a href="/blog/计算机网络通关29讲/05.模块四web技术/05#爬虫的原理"><span>爬虫的原理</span></a></li><li title="反爬虫" data-depth="3"><a href="/blog/计算机网络通关29讲/05.模块四web技术/05#反爬虫"><span>反爬虫</span></a></li><li title="总结" data-depth="3"><a href="/blog/计算机网络通关29讲/05.模块四web技术/05#总结"><span>总结</span></a></li><li title="思考题" data-depth="3"><a href="/blog/计算机网络通关29讲/05.模块四web技术/05#思考题"><span>思考题</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="18--爬虫和反爬虫如何防止黑产爬取我的数据"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#18--爬虫和反爬虫如何防止黑产爬取我的数据"><span class="icon icon-link"></span></a>18 | 爬虫和反爬虫：如何防止黑产爬取我的数据？</h1><p>爬虫在当今的互联网中被大量地使用已经是约定俗成的潜规则，虽说内容的提供者都千方百计地防止自己的数据被竞品拿走，但是如果你去看一看某些百科中的文章和维基百科的相似程度，就知道很多不良的行为正在被默许着。</p><p>记得早期一些购票网站起家的时候，就大量使用爬虫技术爬取航空公司的数据，为了不让航空公司屏蔽，特意用了很多个人电脑做爬虫端，让航空公司无法分清哪些是爬虫、哪些是用户。这样，用户订票的时候，客服经理就有足够的票务数据提供给用户。</p><p>另外，一些相互竞争的电商、外卖公司，内部甚至会设立专门的数据爬取小组，用于监控竞品的数据，并且实时地调整业务的竞争策略——如补贴、签约等。还有一些爬虫的黑产利用招聘网站的漏洞，爬取并出售简历数据。对一个 HR 而言，花几千块钱的年费，才可以看上万份简历。而一个黑产，只需要多购买几个这样的账号，就可以从招聘网站中拿走大量的数据，再销售给不法分子，一年获得上千万的利润。</p><p>因此，这一讲我们就聊一聊这个的话题——<strong>如何防止黑产爬取我的数据</strong>，以此加深你对数据安全的重视。</p><h3 id="爬取数据违法吗"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#爬取数据违法吗"><span class="icon icon-link"></span></a>爬取数据违法吗？</h3><p>首先，爬取一个网站的数据，很可能是违法行为。通常一个网站，会在自己根路径下的 robots.txt 中定义自己网页中哪些数据是可以用来爬取的。从理论上讲，如果你想爬取一个网站的数据，应该先获取它根目录下的 robots.txt 文件，查阅文件内容，看自己要爬取的数据是否被允许。</p><p>下面是 bilibili 的 robots.txt 的内容：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">User-agent: Yisouspider</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: Applebot</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: bingbot</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: Sogou inst spider</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: Sogou web spider</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: 360Spider</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: Googlebot</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: Baiduspider</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: Bytespider</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: PetalBot</span></div><div class="token-line"><span class="token plain">    Allow: /</span></div><div class="token-line"><span class="token plain">    User-agent: *</span></div><div class="token-line"><span class="token plain">    Disallow: /</span></div></pre></div><p>可以看到，如果你是谷歌、苹果、360、百度等搜索引擎，那么 B 站是欢迎你爬取内容的。如果你是其他的个人或者组织，比如说你想爬取 B 站上所有大 V 的数据，然后将分析结果出售给其他人（比如某个 MCN 平台），实际上是触犯法律的。依据我国的刑法，你可能会被判处非法获取计算机信息系统数据罪，情节严重的可能会被判处 3 年以上的有期徒刑并处罚金。</p><p>我之所以说这件事情，是希望你对网络信息安全有清晰的认识。互联网不是法外之地，做任何事情之前都请三思而行。</p><h4 id="助点机器人"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#助点机器人"><span class="icon icon-link"></span></a>助点机器人</h4><p>在没有允许的情况下爬取对方的数据是违法行为。但是这里衍生出一个问题，比如说，你是一个拉勾的付费用户，你觉得拉勾的界面不够智能，于是你自己写了一个程序，只针对自己的账号范围实现某个功能，对拉勾的简历进行筛选，从而找到合适的求职者，这是违法行为吗？</p><p>这个行为不是违法行为。这个行为可以归结成你自己做的一个辅助自己工作的机器人，但是如果你将这个工具提供给其他人，这是违法行为吗？其实也不是违法行为。但是如果其他人将这个工具用作黑产，比如说爬取用户的数据然后进行简历信息的买卖，这就构成了违法行为，构成犯罪的是买卖简历信息。如果你是拉勾的竞品，你使用大量账号这样做，还会构成非法竞争。</p><p>换一个例子，有人觉得 Github 不够智能，然后做了一个插件，帮助大家浏览 Github 中文件代码的目录树，本质上这个工具也需要用到爬虫的部分技术——需要爬取这个目录树。但这不是违法行为，但若有人利用类似的工具，将 Github 全部代码都拿走，在淘宝上打包售卖，这就是违法行为了。</p><h3 id="爬虫的原理"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#爬虫的原理"><span class="icon icon-link"></span></a>爬虫的原理</h3><p>讨论完法律，我们讨论下爬虫是怎么实现的。爬虫的原理非常简单，本质上就是一次网络请求，然后将返回的数据保存下来。</p><p>对于搜索引擎的爬虫而言，通常会在请求头中加上自己的标识，比如百度会加上 baidu 字符串，这样方便网站服务器识别。</p><p>爬虫如果是非法的，往往就需要伪装成浏览器。通常会用到浏览器内核去模拟发出网络请求，比如用 Chromium（Chrome 的开源内核）就可以提供这样的能力。</p><p>当你用 Chromium 发起请求的时候，对于服务提供方的反爬虫系统，你的请求就变成了一次标准的用户行为。如果对方网站需要登录才能爬取数据，这个时候，不法分子还会模拟登陆行为。如果仅仅是输入用户名和密码，那这个网站登录行为会非常容易模拟，只需要找到对方对应的接口，把用户名和密码传过去，就可以拿到访问资源的令牌。这就是大部分网站登录时需要你用手机验证码登录、微信扫描、或填写图片验证码的原因。</p><p>对于一些获取数据还需要付费的网站，比如说视频网站或拉勾这样的招聘网站，用户需要付费才能获取核心的数据，这个时候不法分子可能会购买大量的账号。为了防止不法分子获得大量的账号，现在国家已经在严打销售手机卡号的行为。所以请你记住，使用其他人的身份去注册账号，这也是一种违法行为。</p><h4 id="关于验证码"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#关于验证码"><span class="icon icon-link"></span></a>关于验证码</h4><p>当被爬取的网站登录接口有验证码时，爬虫的设计者通常会有两种手段。一种是破解验证码，在现在这个人工智能的时代，想要破解验证码只需要获得足够多的验证码图片样本，然后用 tensorflow 分析一下，基本上都可以做到一定的识别率，可以高于 80% 以上。所以现在的网站往往不会使用简单的图片验证码，比如说要拖动一个滑块、选中几张图片、算一道数学题等来增加破解成本。我见过最变态的网站验证码是一道化学题，我花了两个小时才注册成功。</p><p>所以你的网站如果还在使用普通的图形验证码，而你网站被攻克的代价也很高的话，请你务必早点更换验证码——更换成更难破解的，甚至多种验证码的混合。</p><h4 id="模拟用户动作"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#模拟用户动作"><span class="icon icon-link"></span></a>模拟用户动作</h4><p>对于一个爬取数据用的浏览器内核，往往还提供了模拟用户行为的功能。比如说点击按钮，滚动一下页面，输入一行文字。所以千万不要觉得，爬虫模拟不了这些用户行为，对于爬虫的设计者，这些都是基础操作。</p><h4 id="数据的提取"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#数据的提取"><span class="icon icon-link"></span></a>数据的提取</h4><p>当数据被下载下来之后，爬虫会尝试将原始数据存储，然后再进行离线分析。当然有的爬虫爬取了数据之后就马上进行分析。如果要爬取网页数据，后续会用到 HTML 的解析器（Parser），这个在 Github上 可以找到很多的开源实现。如果是爬取的接口数据，通常就是分析 Json。有的网页数据是由 JavaScript 渲染的，这种网页，通常爬虫会模拟浏览器的行为，在页面加载完成几秒之后才开始下载网页内容。</p><h4 id="反追踪"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#反追踪"><span class="icon icon-link"></span></a>反追踪</h4><p>对于黑产的爬虫，还会进行 IP 的反追踪。所谓 IP 的反追踪，就是利用代理，增加追踪的成本。比如黑客在从事犯罪活动时通过多次代理，跨了多个国家，那么一个国家的警方力量就很难追踪到他。在爬虫领域有很多人会购买 IP 代理，比如说一个非法的去 B 站收集统计数据的爬虫，为了防止 B 站的追诉以及防止 B 站安全策略的屏蔽，可能会购买大量的 IP，然后模拟成几百个用户在使用 B 站。你要注意，临时租用大量 IP 地址的价格低廉，这也大大降低了犯罪的成本。</p><h3 id="反爬虫"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#反爬虫"><span class="icon icon-link"></span></a>反爬虫</h3><p>接下来，我们说说有关反爬虫的一些基本的操作。</p><h4 id="robotstxt"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#robotstxt"><span class="icon icon-link"></span></a>robots.txt</h4><p><strong>在反爬虫的时候，第一步我们要先从法律上告诉爬虫哪些页面是不可以爬取的</strong>。所以我们要先写好自己的 robots.txt，并放到网站的根目录。</p><h4 id="用户的识别"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#用户的识别"><span class="icon icon-link"></span></a>用户的识别</h4><p>接下来我们对于高频访问的 IP 要予以关注。当然，仅仅通过 IP 来判断是不可取的。因为有的时候一家公司会共用一个 IP 出口地址。举个例子：一家猎头公司下面的几百个猎头，可能会每天疯狂的使用拉勾，因此从拉勾的数据上，你会看到大量的重复 IP 访问。这个时候我问你个问题，你禁不禁用这些 IP？当然不能禁用，这些都是付费用户。</p><p>那么这个时候有一件非常值得做的事情，就是使用设备的指纹。对于一个设备，它的 CPU 数量、CPU 序列号、屏幕的分辨率、手机的厂商等，通常是固定的。这样可以结合 IP 地址做精细去重。这项技术被称为<strong>设备指纹</strong>，就是利用设备上的信息，生成一个具有唯一性的字符串，因为这种生成算法是非标准化的，因此不同的数据安全团队会有自己的算法。</p><p>有了对用户的识别，就可以根据唯一用户设置数据安全策略，比如访问频次、黑名单等。</p><h4 id="字体加密"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#字体加密"><span class="icon icon-link"></span></a>字体加密</h4><p>再介绍一种方法是<strong>自己实现字符编码和字体文件，增加爬虫爬取数据的成本</strong>。</p><p>爬虫爬取的通常就是用户本身可以看到的内容。如果自己实现一套自己的字符编码。比如将 UTF8 编码中的汉字打乱顺序，然后再将字体文件中对应的数据换序，得到字体文件。显示简历的时候，使用自己根据这个字符集生成的字体文件。</p><p>这样，爬虫下载到网页数据后，中文会乱码，这是因为爬虫无法理解我们创造的非标准字符集编码。当用户看到网页的时候，可以看到正确的内容，这是因为字体文件起了作用。即便爬虫将字体文件打开，和编码对应上，也是非常复杂的一个体力劳动。然后我们每天更换一次顺序，就可以给黑产增加相当大的爬取成本。</p><h4 id="加密传输"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#加密传输"><span class="icon icon-link"></span></a>加密传输</h4><p>对于移动端 App 中的数据，如果可以加密传输，也能大大增加爬取成本。因为 App 不是浏览器，想要模拟一个 App 是非常困难的。那么 App 的数据抓取就依赖于 App 数据传输使用的标准协议，比如一个用 HTTPS 协议传输数据的 App，爬虫可以在 App 端安装证书，然后再利用代理实现中间人抓包。但如果数据用自己的协议加密，那么爬虫抓包的同时，还必须能够破解这个加密协议。</p><h3 id="总结"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#总结"><span class="icon icon-link"></span></a>总结</h3><p>非法爬取数据是不可能完全杜绝的，我们只能提高非法爬取数据的成本。但是一定要有数据安全的意识。在互联网的世界里，数据是第一生产力，也是生命线。在完成开发工作之余，利用自己的专业知识适当提高爬取数据的成本是非常有必要的。</p><p><strong>如果自己被公司要求写一个爬虫爬取竞品数据，请你先阅读下竞品的 robots.txt 文件，看看允不允许你这样做</strong>。如果这是一个违法行为，那么也可以适当提醒下有这样想法的决策者。 国家对网络信息安全犯罪的打击，只会越来越严。爬取数据看似简单，其实做到毫无证据保留是很难的。当然，利用爬虫技术，让自己在使用互联网产品的时候，可以消耗更少的时间，属于辅助机器人，这个是法律允许的。比如我就用爬虫技术监控拉勾教育中我自己专栏的订阅情况，当有同学订阅的时候我会收到邮件。</p><h3 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog/计算机网络通关29讲/05.模块四web技术/05#思考题"><span class="icon icon-link"></span></a>思考题</h3><p>最后再给你提一个问题：用最熟悉的语言写一段程序，模拟成浏览器访问拉勾教育的首页获取首页数据。</p><p>这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲是《模块四思考题解答》，希望你自己完成题目后再来看答案和分析。再见！</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/docs/计算机网络通关29讲/05.模块四Web技术/05.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 13:36:35</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog/umi.js"></script>
  </body>
</html>
