<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog/umi.css" />
    <script>
      window.routerBase = "/blog";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>
      06 | 案例篇：系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？ - 大师兄
    </title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/linux性能优化实战/02.cpu性能篇/05" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>计算机基础<ul><li><a href="/blog/编译原理之美">编译原理之美</a></li><li><a href="/blog/编译原理实战">编译原理实战</a></li><li><a href="/blog/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog/详解http">详解http</a></li><li><a href="/blog/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog/网络排查案例课">网络排查案例课</a></li><li><a href="/blog/linux操作系统">linux操作系统</a></li><li><a href="/blog/linux内核技术实战课">linux内核技术实战课</a></li><li><a aria-current="page" class="active" href="/blog/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog/程序员数学基础">程序员数学基础</a></li><li><a href="/blog/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog/操作系统实战">操作系统实战</a></li><li><a href="/blog/软件工程之美">软件工程之美</a></li><li><a href="/blog/sql必知必会">sql必知必会</a></li><li><a href="/blog/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog/网络编程实战">网络编程实战</a></li><li><a href="/blog/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></span><span>算法<ul><li><a href="/blog/常用算法25讲">常用算法25讲</a></li><li><a href="/blog/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog/动态规划面试宝典">动态规划面试宝典</a></li></ul></span><span>前端开发<ul><li><a href="/blog/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog/正则表达式入门">正则表达式入门</a></li></ul></span><span>前端工程化</span><span>前端性能优化</span><span>移动端开发</span><span>软件测试</span><span>产品与用户体验</span><span>面试</span><span>杂谈<ul><li><a href="/blog/代码之丑">代码之丑</a></li><li><a href="/blog/代码精进之路">代码精进之路</a></li><li><a href="/blog/数据分析思维课">数据分析思维课</a></li><li><a href="/blog/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog/重学线性代数">重学线性代数</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>计算机基础<ul><li><a href="/blog/编译原理之美">编译原理之美</a></li><li><a href="/blog/编译原理实战">编译原理实战</a></li><li><a href="/blog/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog/详解http">详解http</a></li><li><a href="/blog/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog/网络排查案例课">网络排查案例课</a></li><li><a href="/blog/linux操作系统">linux操作系统</a></li><li><a href="/blog/linux内核技术实战课">linux内核技术实战课</a></li><li><a aria-current="page" class="active" href="/blog/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog/程序员数学基础">程序员数学基础</a></li><li><a href="/blog/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog/操作系统实战">操作系统实战</a></li><li><a href="/blog/软件工程之美">软件工程之美</a></li><li><a href="/blog/sql必知必会">sql必知必会</a></li><li><a href="/blog/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog/网络编程实战">网络编程实战</a></li><li><a href="/blog/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></li><li>算法<ul><li><a href="/blog/常用算法25讲">常用算法25讲</a></li><li><a href="/blog/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog/动态规划面试宝典">动态规划面试宝典</a></li></ul></li><li>前端开发<ul><li><a href="/blog/全栈工程师修炼指南">全栈工程师修炼指南</a></li><li><a href="/blog/正则表达式入门">正则表达式入门</a></li></ul></li><li>前端工程化</li><li>前端性能优化</li><li>移动端开发</li><li>软件测试</li><li>产品与用户体验</li><li>面试</li><li>杂谈<ul><li><a href="/blog/代码之丑">代码之丑</a></li><li><a href="/blog/代码精进之路">代码精进之路</a></li><li><a href="/blog/数据分析思维课">数据分析思维课</a></li><li><a href="/blog/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog/重学线性代数">重学线性代数</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog/linux性能优化实战/01.开篇词">01.开篇词</a><ul><li><a href="/blog/linux性能优化实战/01.开篇词/01"><span>开篇词 | 别再让Linux性能问题成为你的绊脚石</span></a></li><li><a href="/blog/linux性能优化实战/01.开篇词/02"><span>01 | 如何学习Linux性能优化？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog/linux性能优化实战/02.cpu性能篇">02.CPU性能篇</a><ul><li><a href="/blog/linux性能优化实战/02.cpu性能篇/01"><span>02 | 基础篇：到底应该怎么理解“平均负载”？</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/02"><span>03 | 基础篇：经常说的 CPU 上下文切换是什么意思？（上）</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/03"><span>04 | 基础篇：经常说的 CPU 上下文切换是什么意思？（下）</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/04"><span>05 | 基础篇：某个应用的CPU使用率居然达到100%，我该怎么办？</span></a></li><li><a aria-current="page" class="active" href="/blog/linux性能优化实战/02.cpu性能篇/05"><span>06 | 案例篇：系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/06"><span>07 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（上）</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/07"><span>08 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（下）</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/08"><span>09 | 基础篇：怎么理解Linux软中断？</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/09"><span>10 | 案例篇：系统的软中断CPU使用率升高，我该怎么办？</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/10"><span>11 | 套路篇：如何迅速分析出系统CPU的瓶颈在哪里？</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/11"><span>12 | 套路篇：CPU 性能优化的几个思路</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/12"><span>13 | 答疑（一）：无法模拟出 RES 中断的问题，怎么办？</span></a></li><li><a href="/blog/linux性能优化实战/02.cpu性能篇/13"><span>14 | 答疑（二）：如何用perf工具分析Java程序？</span></a></li></ul></li><li><a href="/blog/linux性能优化实战/03.内存性能篇">03.内存性能篇</a><ul><li><a href="/blog/linux性能优化实战/03.内存性能篇/01"><span>15 | 基础篇：Linux内存是怎么工作的？</span></a></li><li><a href="/blog/linux性能优化实战/03.内存性能篇/02"><span>16 | 基础篇：怎么理解内存中的Buffer和Cache？</span></a></li><li><a href="/blog/linux性能优化实战/03.内存性能篇/03"><span>17 | 案例篇：如何利用系统缓存优化程序的运行效率？</span></a></li><li><a href="/blog/linux性能优化实战/03.内存性能篇/04"><span>18 | 案例篇：内存泄漏了，我该如何定位和处理？</span></a></li><li><a href="/blog/linux性能优化实战/03.内存性能篇/05"><span>19 | 案例篇：为什么系统的Swap变高了（上）</span></a></li><li><a href="/blog/linux性能优化实战/03.内存性能篇/06"><span>20 | 案例篇：为什么系统的Swap变高了？（下）</span></a></li><li><a href="/blog/linux性能优化实战/03.内存性能篇/07"><span>21 | 套路篇：如何“快准狠”找到系统内存的问题？</span></a></li><li><a href="/blog/linux性能优化实战/03.内存性能篇/08"><span>22 | 答疑（三）：文件系统与磁盘的区别是什么？</span></a></li></ul></li><li><a href="/blog/linux性能优化实战/04.io性能篇">04.IO性能篇</a><ul><li><a href="/blog/linux性能优化实战/04.io性能篇/01"><span>23 | 基础篇：Linux 文件系统是怎么工作的？</span></a></li><li><a href="/blog/linux性能优化实战/04.io性能篇/02"><span>24 | 基础篇：Linux 磁盘I/O是怎么工作的（上）</span></a></li><li><a href="/blog/linux性能优化实战/04.io性能篇/03"><span>25 | 基础篇：Linux 磁盘I/O是怎么工作的（下）</span></a></li><li><a href="/blog/linux性能优化实战/04.io性能篇/04"><span>26 | 案例篇：如何找出狂打日志的“内鬼”？</span></a></li><li><a href="/blog/linux性能优化实战/04.io性能篇/05"><span>27 | 案例篇：为什么我的磁盘I/O延迟很高？</span></a></li><li><a href="/blog/linux性能优化实战/04.io性能篇/06"><span>28 | 案例篇：一个SQL查询要15秒，这是怎么回事？</span></a></li><li><a href="/blog/linux性能优化实战/04.io性能篇/07"><span>29 | 案例篇：Redis响应严重延迟，如何解决？</span></a></li><li><a href="/blog/linux性能优化实战/04.io性能篇/08"><span>30 | 套路篇：如何迅速分析出系统I/O的瓶颈在哪里？</span></a></li><li><a href="/blog/linux性能优化实战/04.io性能篇/09"><span>31 | 套路篇：磁盘 I/O 性能优化的几个思路</span></a></li><li><a href="/blog/linux性能优化实战/04.io性能篇/10"><span>32 | 答疑（四）：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系</span></a></li></ul></li><li><a href="/blog/linux性能优化实战/05.网络性能篇">05.网络性能篇</a><ul><li><a href="/blog/linux性能优化实战/05.网络性能篇/01"><span>33 | 关于 Linux 网络，你必须知道这些（上）</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/02"><span>34 | 关于 Linux 网络，你必须知道这些（下）</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/03"><span>35 | 基础篇：C10K 和 C1000K 回顾</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/04"><span>36 | 套路篇：怎么评估系统的网络性能？</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/05"><span>37 | 案例篇：DNS 解析时快时慢，我该怎么办？</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/06"><span>38 | 案例篇：怎么使用 tcpdump 和 Wireshark 分析网络流量？</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/07"><span>39 | 案例篇：怎么缓解 DDoS 攻击带来的性能下降问题？</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/08"><span>40 | 案例篇：网络请求延迟变大了，我该怎么办？</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/09"><span>41 | 案例篇：如何优化 NAT 性能？（上）</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/10"><span>42 | 案例篇：如何优化 NAT 性能？（下）</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/11"><span>43 | 套路篇：网络性能优化的几个思路（上）</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/12"><span>44 | 套路篇：网络性能优化的几个思路（下）</span></a></li><li><a href="/blog/linux性能优化实战/05.网络性能篇/13"><span>45 | 答疑（五）：网络收发过程中，缓冲区位置在哪里？</span></a></li></ul></li><li><a href="/blog/linux性能优化实战/06.综合实战篇">06.综合实战篇</a><ul><li><a href="/blog/linux性能优化实战/06.综合实战篇/01"><span>46 | 案例篇：为什么应用容器化后，启动慢了很多？</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/02"><span>47 | 案例篇：服务器总是时不时丢包，我该怎么办？（上）</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/03"><span>48 | 案例篇：服务器总是时不时丢包，我该怎么办？（下）</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/04"><span>49 | 案例篇：内核线程 CPU 利用率太高，我该怎么办？</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/05"><span>50 | 案例篇：动态追踪怎么用？（上）</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/06"><span>51 | 案例篇：动态追踪怎么用？（下）</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/07"><span>52 | 案例篇：服务吞吐量下降很厉害，怎么分析？</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/08"><span>53 | 套路篇：系统监控的综合思路</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/09"><span>54 | 套路篇：应用监控的一般思路</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/10"><span>55 | 套路篇：分析性能问题的一般步骤</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/11"><span>56 | 套路篇：优化性能问题的一般方法</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/12"><span>57 | 套路篇：Linux 性能工具速查</span></a></li><li><a href="/blog/linux性能优化实战/06.综合实战篇/13"><span>58 | 答疑（六）：容器冷启动如何性能分析？</span></a></li></ul></li><li><a href="/blog/linux性能优化实战/07.加餐篇">07.加餐篇</a><ul><li><a href="/blog/linux性能优化实战/07.加餐篇/01"><span>加餐（一） | 书单推荐：性能优化和Linux 系统原理</span></a></li><li><a href="/blog/linux性能优化实战/07.加餐篇/02"><span>加餐（二） | 书单推荐：网络原理和 Linux 内核实现</span></a></li><li><a href="/blog/linux性能优化实战/07.加餐篇/03"><span>用户故事 | “半路出家 ”，也要顺利拿下性能优化！</span></a></li><li><a href="/blog/linux性能优化实战/07.加餐篇/04"><span>用户故事 | 运维和开发工程师们怎么说？</span></a></li></ul></li><li><a href="/blog/linux性能优化实战/08.结束语">08.结束语</a><ul><li><a href="/blog/linux性能优化实战/08.结束语/01"><span>结束语 | 愿你攻克性能难关</span></a></li></ul></li><li><a href="/blog/linux性能优化实战/09.结课测试">09.结课测试</a><ul><li><a href="/blog/linux性能优化实战/09.结课测试/01"><span>结课测试｜这些Linux性能知识你都掌握了吗？</span></a></li></ul></li><li><a href="/blog/linux性能优化实战/summary">linux性能优化实战</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="案例分析" data-depth="2"><a href="/blog/linux性能优化实战/02.cpu性能篇/05#案例分析"><span>案例分析</span></a></li><li title="你的准备" data-depth="3"><a href="/blog/linux性能优化实战/02.cpu性能篇/05#你的准备"><span>你的准备</span></a></li><li title="操作和分析" data-depth="3"><a href="/blog/linux性能优化实战/02.cpu性能篇/05#操作和分析"><span>操作和分析</span></a></li><li title="execsnoop" data-depth="2"><a href="/blog/linux性能优化实战/02.cpu性能篇/05#execsnoop"><span>execsnoop</span></a></li><li title="小结" data-depth="2"><a href="/blog/linux性能优化实战/02.cpu性能篇/05#小结"><span>小结</span></a></li><li title="思考" data-depth="2"><a href="/blog/linux性能优化实战/02.cpu性能篇/05#思考"><span>思考</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="06--案例篇系统的-cpu-使用率很高但为啥却找不到高-cpu-的应用"><a aria-hidden="true" tabindex="-1" href="/blog/linux性能优化实战/02.cpu性能篇/05#06--案例篇系统的-cpu-使用率很高但为啥却找不到高-cpu-的应用"><span class="icon icon-link"></span></a>06 | 案例篇：系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？</h1><p>你好，我是倪朋飞。</p><p>上一节我讲了 CPU 使用率是什么，并通过一个案例教你使用 top、vmstat、pidstat 等工具，排查高 CPU 使用率的进程，然后再使用 perf top 工具，定位应用内部函数的问题。不过就有人留言了，说似乎感觉高 CPU 使用率的问题，还是挺容易排查的。</p><p>那是不是所有 CPU 使用率高的问题，都可以这么分析呢？我想，你的答案应该是否定的。</p><p>回顾前面的内容，我们知道，系统的 CPU 使用率，不仅包括进程用户态和内核态的运行，还包括中断处理、等待 I/O 以及内核线程等。所以，<strong>当你发现系统的 CPU 使用率很高的时候，不一定能找到相对应的高 CPU 使用率的进程</strong>。</p><p>今天，我就用一个 Nginx + PHP 的 Web 服务的案例，带你来分析这种情况。</p><h2 id="案例分析"><a aria-hidden="true" tabindex="-1" href="/blog/linux性能优化实战/02.cpu性能篇/05#案例分析"><span class="icon icon-link"></span></a>案例分析</h2><h3 id="你的准备"><a aria-hidden="true" tabindex="-1" href="/blog/linux性能优化实战/02.cpu性能篇/05#你的准备"><span class="icon icon-link"></span></a>你的准备</h3><p>今天依旧探究系统CPU使用率高的情况，所以这次实验的准备工作，与上节课的准备工作基本相同，差别在于案例所用的 Docker 镜像不同。</p><p>本次案例还是基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。我使用的案例环境如下所示：</p><ul><li><p>机器配置：2 CPU，8GB 内存</p></li><li><p>预先安装 docker、sysstat、perf、ab 等工具，如 apt install <a target="_blank" rel="noopener noreferrer" href="http://docker.io/">docker.io<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> sysstat linux-tools-common apache2-utils</p></li></ul><p>前面我们讲到过，ab（apache bench）是一个常用的 HTTP 服务性能测试工具，这里同样用来模拟 Nginx 的客户端。由于 Nginx 和 PHP 的配置比较麻烦，我把它们打包成了两个 <a target="_blank" rel="noopener noreferrer" href="https://github.com/feiskyer/linux-perf-examples/tree/master/nginx-short-process">Docker 镜像<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，这样只需要运行两个容器，就可以得到模拟环境。</p><p>注意，这个案例要用到两台虚拟机，如下图所示：</p><p><img src="/images/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/02.CPU%E6%80%A7%E8%83%BD%E7%AF%87/resourceimage903d90c30b4f555218f77241bfe2ac27723d.png" alt=""/></p><p>你可以看到，其中一台用作 Web 服务器，来模拟性能问题；另一台用作 Web 服务器的客户端，来给 Web 服务增加压力请求。使用两台虚拟机是为了相互隔离，避免“交叉感染”。</p><p>接下来，我们打开两个终端，分别 SSH 登录到两台机器上，并安装上述工具。</p><p>同样注意，下面所有命令都默认以 root 用户运行，如果你是用普通用户身份登陆系统，请运行 sudo su root 命令切换到 root 用户。</p><p>走到这一步，准备工作就完成了。接下来，我们正式进入操作环节。</p><blockquote><p>温馨提示：案例中 PHP 应用的核心逻辑比较简单，你可能一眼就能看出问题，但实际生产环境中的源码就复杂多了。所以，我依旧建议，<strong>操作之前别看源码</strong>，避免先入为主，而要把它当成一个黑盒来分析。这样，你可以更好把握，怎么从系统的资源使用问题出发，分析出瓶颈所在的应用，以及瓶颈在应用中大概的位置。</p></blockquote><h3 id="操作和分析"><a aria-hidden="true" tabindex="-1" href="/blog/linux性能优化实战/02.cpu性能篇/05#操作和分析"><span class="icon icon-link"></span></a>操作和分析</h3><p>首先，我们在第一个终端，执行下面的命令运行 Nginx 和 PHP 应用：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ docker run --name nginx -p 10000:80 -itd feisky/nginx:sp</span></div><div class="token-line"><span class="token plain">    $ docker run --name phpfpm -itd --network container:nginx feisky/php-fpm:sp</span></div></pre></div><p>然后，在第二个终端，使用 curl 访问 http://[VM1的IP]:10000，确认 Nginx 已正常启动。你应该可以看到 It works! 的响应。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 192.168.0.10是第一台虚拟机的IP地址</span></div><div class="token-line"><span class="token plain">    $ curl http://192.168.0.10:10000/</span></div><div class="token-line"><span class="token plain">    It works!</span></div></pre></div><p>接着，我们来测试一下这个 Nginx 服务的性能。在第二个终端运行下面的 ab 命令。要注意，与上次操作不同的是，这次我们需要并发100个请求测试Nginx性能，总共测试1000个请求。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 并发100个请求测试Nginx性能，总共测试1000个请求</span></div><div class="token-line"><span class="token plain">    $ ab -c 100 -n 1000 http://192.168.0.10:10000/</span></div><div class="token-line"><span class="token plain">    This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt;</span></div><div class="token-line"><span class="token plain">    Copyright 1996 Adam Twiss, Zeus Technology Ltd, </span></div><div class="token-line"><span class="token plain">    ...</span></div><div class="token-line"><span class="token plain">    Requests per second:    87.86 [#/sec] (mean)</span></div><div class="token-line"><span class="token plain">    Time per request:       1138.229 [ms] (mean)</span></div><div class="token-line"><span class="token plain">    ...</span></div></pre></div><p>从ab的输出结果我们可以看到，Nginx能承受的每秒平均请求数，只有 87 多一点，是不是感觉它的性能有点差呀。那么，到底是哪里出了问题呢？我们再用 top 和 pidstat 来观察一下。</p><p>这次，我们在第二个终端，将测试的并发请求数改成5，同时把请求时长设置为10分钟（-t 600）。这样，当你在第一个终端使用性能分析工具时， Nginx 的压力还是继续的。</p><p>继续在第二个终端运行 ab 命令：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ ab -c 5 -t 600 http://192.168.0.10:10000/</span></div></pre></div><p>然后，我们在第一个终端运行 top 命令，观察系统的 CPU 使用情况：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ top</span></div><div class="token-line"><span class="token plain">    ...</span></div><div class="token-line"><span class="token plain">    %Cpu(s): 80.8 us, 15.1 sy,  0.0 ni,  2.8 id,  0.0 wa,  0.0 hi,  1.3 si,  0.0 st</span></div><div class="token-line"><span class="token plain">    ...</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">      PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span></div><div class="token-line"><span class="token plain">     6882 root      20   0    8456   5052   3884 S   2.7  0.1   0:04.78 docker-containe</span></div><div class="token-line"><span class="token plain">     6947 systemd+  20   0   33104   3716   2340 S   2.7  0.0   0:04.92 nginx</span></div><div class="token-line"><span class="token plain">     7494 daemon    20   0  336696  15012   7332 S   2.0  0.2   0:03.55 php-fpm</span></div><div class="token-line"><span class="token plain">     7495 daemon    20   0  336696  15160   7480 S   2.0  0.2   0:03.55 php-fpm</span></div><div class="token-line"><span class="token plain">    10547 daemon    20   0  336696  16200   8520 S   2.0  0.2   0:03.13 php-fpm</span></div><div class="token-line"><span class="token plain">    10155 daemon    20   0  336696  16200   8520 S   1.7  0.2   0:03.12 php-fpm</span></div><div class="token-line"><span class="token plain">    10552 daemon    20   0  336696  16200   8520 S   1.7  0.2   0:03.12 php-fpm</span></div><div class="token-line"><span class="token plain">    15006 root      20   0 1168608  66264  37536 S   1.0  0.8   9:39.51 dockerd</span></div><div class="token-line"><span class="token plain">     4323 root      20   0       0      0      0 I   0.3  0.0   0:00.87 kworker/u4:1</span></div><div class="token-line"><span class="token plain">    ...</span></div></pre></div><p>观察 top 输出的进程列表可以发现，CPU 使用率最高的进程也只不过才 2.7%，看起来并不高。</p><p>然而，再看系统 CPU 使用率（ %Cpu ）这一行，你会发现，系统的整体 CPU 使用率是比较高的：用户 CPU 使用率（us）已经到了 80%，系统 CPU 为 15.1%，而空闲 CPU （id）则只有 2.8%。</p><p>为什么用户 CPU 使用率这么高呢？我们再重新分析一下进程列表，看看有没有可疑进程：</p><ul><li><p>docker-containerd 进程是用来运行容器的，2.7% 的 CPU 使用率看起来正常；</p></li><li><p>Nginx 和 php-fpm 是运行 Web 服务的，它们会占用一些 CPU 也不意外，并且 2% 的 CPU 使用率也不算高；</p></li><li><p>再往下看，后面的进程呢，只有 0.3% 的 CPU 使用率，看起来不太像会导致用户 CPU 使用率达到 80%。</p></li></ul><p>那就奇怪了，明明用户 CPU 使用率都80%了，可我们挨个分析了一遍进程列表，还是找不到高 CPU 使用率的进程。看来top是不管用了，那还有其他工具可以查看进程 CPU 使用情况吗？不知道你记不记得我们的老朋友 pidstat，它可以用来分析进程的 CPU 使用情况。</p><p>接下来，我们还是在第一个终端，运行 pidstat 命令：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 间隔1秒输出一组数据（按Ctrl+C结束）</span></div><div class="token-line"><span class="token plain">    $ pidstat 1</span></div><div class="token-line"><span class="token plain">    ...</span></div><div class="token-line"><span class="token plain">    04:36:24      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command</span></div><div class="token-line"><span class="token plain">    04:36:25        0      6882    1.00    3.00    0.00    0.00    4.00     0  docker-containe</span></div><div class="token-line"><span class="token plain">    04:36:25      101      6947    1.00    2.00    0.00    1.00    3.00     1  nginx</span></div><div class="token-line"><span class="token plain">    04:36:25        1     14834    1.00    1.00    0.00    1.00    2.00     0  php-fpm</span></div><div class="token-line"><span class="token plain">    04:36:25        1     14835    1.00    1.00    0.00    1.00    2.00     0  php-fpm</span></div><div class="token-line"><span class="token plain">    04:36:25        1     14845    0.00    2.00    0.00    2.00    2.00     1  php-fpm</span></div><div class="token-line"><span class="token plain">    04:36:25        1     14855    0.00    1.00    0.00    1.00    1.00     1  php-fpm</span></div><div class="token-line"><span class="token plain">    04:36:25        1     14857    1.00    2.00    0.00    1.00    3.00     0  php-fpm</span></div><div class="token-line"><span class="token plain">    04:36:25        0     15006    0.00    1.00    0.00    0.00    1.00     0  dockerd</span></div><div class="token-line"><span class="token plain">    04:36:25        0     15801    0.00    1.00    0.00    0.00    1.00     1  pidstat</span></div><div class="token-line"><span class="token plain">    04:36:25        1     17084    1.00    0.00    0.00    2.00    1.00     0  stress</span></div><div class="token-line"><span class="token plain">    04:36:25        0     31116    0.00    1.00    0.00    0.00    1.00     0  atopacctd</span></div><div class="token-line"><span class="token plain">    ...</span></div></pre></div><p>观察一会儿，你是不是发现，所有进程的 CPU 使用率也都不高啊，最高的 Docker 和 Nginx 也只有 4% 和 3%，即使所有进程的 CPU 使用率都加起来，也不过是 21%，离 80% 还差得远呢！</p><p>最早的时候，我碰到这种问题就完全懵了：明明用户 CPU 使用率已经高达 80%，但我却怎么都找不到是哪个进程的问题。到这里，你也可以想想，你是不是也遇到过这种情况？还能不能再做进一步的分析呢？</p><p>后来我发现，会出现这种情况，很可能是因为前面的分析漏了一些关键信息。你可以先暂停一下，自己往上翻，重新操作检查一遍。或者，我们一起返回去分析 top 的输出，看看能不能有新发现。</p><p>现在，我们回到第一个终端，重新运行 top 命令，并观察一会儿：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ top</span></div><div class="token-line"><span class="token plain">    top - 04:58:24 up 14 days, 15:47,  1 user,  load average: 3.39, 3.82, 2.74</span></div><div class="token-line"><span class="token plain">    Tasks: 149 total,   6 running,  93 sleeping,   0 stopped,   0 zombie</span></div><div class="token-line"><span class="token plain">    %Cpu(s): 77.7 us, 19.3 sy,  0.0 ni,  2.0 id,  0.0 wa,  0.0 hi,  1.0 si,  0.0 st</span></div><div class="token-line"><span class="token plain">    KiB Mem :  8169348 total,  2543916 free,   457976 used,  5167456 buff/cache</span></div><div class="token-line"><span class="token plain">    KiB Swap:        0 total,        0 free,        0 used.  7363908 avail Mem</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">      PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span></div><div class="token-line"><span class="token plain">     6947 systemd+  20   0   33104   3764   2340 S   4.0  0.0   0:32.69 nginx</span></div><div class="token-line"><span class="token plain">     6882 root      20   0   12108   8360   3884 S   2.0  0.1   0:31.40 docker-containe</span></div><div class="token-line"><span class="token plain">    15465 daemon    20   0  336696  15256   7576 S   2.0  0.2   0:00.62 php-fpm</span></div><div class="token-line"><span class="token plain">    15466 daemon    20   0  336696  15196   7516 S   2.0  0.2   0:00.62 php-fpm</span></div><div class="token-line"><span class="token plain">    15489 daemon    20   0  336696  16200   8520 S   2.0  0.2   0:00.62 php-fpm</span></div><div class="token-line"><span class="token plain">     6948 systemd+  20   0   33104   3764   2340 S   1.0  0.0   0:00.95 nginx</span></div><div class="token-line"><span class="token plain">    15006 root      20   0 1168608  65632  37536 S   1.0  0.8   9:51.09 dockerd</span></div><div class="token-line"><span class="token plain">    15476 daemon    20   0  336696  16200   8520 S   1.0  0.2   0:00.61 php-fpm</span></div><div class="token-line"><span class="token plain">    15477 daemon    20   0  336696  16200   8520 S   1.0  0.2   0:00.61 php-fpm</span></div><div class="token-line"><span class="token plain">    24340 daemon    20   0    8184   1616    536 R   1.0  0.0   0:00.01 stress</span></div><div class="token-line"><span class="token plain">    24342 daemon    20   0    8196   1580    492 R   1.0  0.0   0:00.01 stress</span></div><div class="token-line"><span class="token plain">    24344 daemon    20   0    8188   1056    492 R   1.0  0.0   0:00.01 stress</span></div><div class="token-line"><span class="token plain">    24347 daemon    20   0    8184   1356    540 R   1.0  0.0   0:00.01 stress</span></div><div class="token-line"><span class="token plain">    ...</span></div></pre></div><p>这次从头开始看 top 的每行输出，咦？Tasks 这一行看起来有点奇怪，就绪队列中居然有 6 个 Running 状态的进程（6 running），是不是有点多呢？</p><p>回想一下 ab 测试的参数，并发请求数是 5。再看进程列表里， php-fpm 的数量也是 5，再加上 Nginx，好像同时有 6 个进程也并不奇怪。但真的是这样吗？</p><p>再仔细看进程列表，这次主要看 Running（R） 状态的进程。你有没有发现， Nginx 和所有的 php-fpm 都处于Sleep（S）状态，而真正处于 Running（R）状态的，却是几个 stress 进程。这几个 stress 进程就比较奇怪了，需要我们做进一步的分析。</p><p>我们还是使用 pidstat 来分析这几个进程，并且使用 -p 选项指定进程的 PID。首先，从上面 top 的结果中，找到这几个进程的 PID。比如，先随便找一个 24344，然后用 pidstat 命令看一下它的 CPU 使用情况：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ pidstat -p 24344</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    16:14:55      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command</span></div></pre></div><p>奇怪，居然没有任何输出。难道是pidstat 命令出问题了吗？之前我说过，<strong>在怀疑性能工具出问题前，最好还是先用其他工具交叉确认一下</strong>。那用什么工具呢？ ps 应该是最简单易用的。我们在终端里运行下面的命令，看看 24344 进程的状态：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 从所有进程中查找PID是24344的进程</span></div><div class="token-line"><span class="token plain">    $ ps aux | grep 24344</span></div><div class="token-line"><span class="token plain">    root      9628  0.0  0.0  14856  1096 pts/0    S+   16:15   0:00 grep --color=auto 24344</span></div></pre></div><p>还是没有输出。现在终于发现问题，原来这个进程已经不存在了，所以 pidstat 就没有任何输出。既然进程都没了，那性能问题应该也跟着没了吧。我们再用 top 命令确认一下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ top</span></div><div class="token-line"><span class="token plain">    ...</span></div><div class="token-line"><span class="token plain">    %Cpu(s): 80.9 us, 14.9 sy,  0.0 ni,  2.8 id,  0.0 wa,  0.0 hi,  1.3 si,  0.0 st</span></div><div class="token-line"><span class="token plain">    ...</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">      PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span></div><div class="token-line"><span class="token plain">     6882 root      20   0   12108   8360   3884 S   2.7  0.1   0:45.63 docker-containe</span></div><div class="token-line"><span class="token plain">     6947 systemd+  20   0   33104   3764   2340 R   2.7  0.0   0:47.79 nginx</span></div><div class="token-line"><span class="token plain">     3865 daemon    20   0  336696  15056   7376 S   2.0  0.2   0:00.15 php-fpm</span></div><div class="token-line"><span class="token plain">      6779 daemon    20   0    8184   1112    556 R   0.3  0.0   0:00.01 stress</span></div><div class="token-line"><span class="token plain">    ...</span></div></pre></div><p>好像又错了。结果还跟原来一样，用户 CPU 使用率还是高达 80.9%，系统 CPU 接近 15%，而空闲 CPU 只有 2.8%，Running 状态的进程有 Nginx、stress等。</p><p>可是，刚刚我们看到stress 进程不存在了，怎么现在还在运行呢？再细看一下 top 的输出，原来，这次 stress 进程的 PID 跟前面不一样了，原来的 PID 24344 不见了，现在的是 6779。</p><p>进程的 PID 在变，这说明什么呢？在我看来，要么是这些进程在不停地重启，要么就是全新的进程，这无非也就两个原因：</p><ul><li><p>第一个原因，进程在不停地崩溃重启，比如因为段错误、配置错误等等，这时，进程在退出后可能又被监控系统自动重启了。</p></li><li><p>第二个原因，这些进程都是短时进程，也就是在其他应用内部通过 exec 调用的外面命令。这些命令一般都只运行很短的时间就会结束，你很难用 top 这种间隔时间比较长的工具发现（上面的案例，我们碰巧发现了）。</p></li></ul><p>至于 stress，我们前面提到过，它是一个常用的压力测试工具。它的 PID 在不断变化中，看起来像是被其他进程调用的短时进程。要想继续分析下去，还得找到它们的父进程。</p><p>要怎么查找一个进程的父进程呢？没错，用 pstree 就可以用树状形式显示所有进程之间的关系：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ pstree | grep stress</span></div><div class="token-line"><span class="token plain">            |-docker-containe-+-php-fpm-+-php-fpm---sh---stress</span></div><div class="token-line"><span class="token plain">            |         |-3*[php-fpm---sh---stress---stress]</span></div></pre></div><p>从这里可以看到，stress 是被 php-fpm 调用的子进程，并且进程数量不止一个（这里是3个）。找到父进程后，我们能进入 app 的内部分析了。</p><p>首先，当然应该去看看它的源码。运行下面的命令，把案例应用的源码拷贝到 app 目录，然后再执行 grep 查找是不是有代码再调用 stress 命令：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 拷贝源码到本地</span></div><div class="token-line"><span class="token plain">    $ docker cp phpfpm:/app .</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    # grep 查找看看是不是有代码在调用stress命令</span></div><div class="token-line"><span class="token plain">    $ grep stress -r app</span></div><div class="token-line"><span class="token plain">    app/index.php:// fake I/O with stress (via write()/unlink()).</span></div><div class="token-line"><span class="token plain">    app/index.php:$result = exec(&quot;/usr/local/bin/stress -t 1 -d 1 2&gt;&amp;1&quot;, $output, $status);</span></div></pre></div><p>找到了，果然是 app/index.php 文件中直接调用了 stress 命令。</p><p>再来看看 <a target="_blank" rel="noopener noreferrer" href="https://github.com/feiskyer/linux-perf-examples/blob/master/nginx-short-process/app/index.php">app/index.php<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> 的源代码：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ cat app/index.php</span></div><div class="token-line"><span class="token plain">    &lt;?php</span></div><div class="token-line"><span class="token plain">    // fake I/O with stress (via write()/unlink()).</span></div><div class="token-line"><span class="token plain">    $result = exec(&quot;/usr/local/bin/stress -t 1 -d 1 2&gt;&amp;1&quot;, $output, $status);</span></div><div class="token-line"><span class="token plain">    if (isset($_GET[&quot;verbose&quot;]) &amp;&amp; $_GET[&quot;verbose&quot;]==1 &amp;&amp; $status != 0) {</span></div><div class="token-line"><span class="token plain">      echo &quot;Server internal error: &quot;;</span></div><div class="token-line"><span class="token plain">      print_r($output);</span></div><div class="token-line"><span class="token plain">    } else {</span></div><div class="token-line"><span class="token plain">      echo &quot;It works!&quot;;</span></div><div class="token-line"><span class="token plain">    }</span></div><div class="token-line"><span class="token plain">    ?&gt;</span></div></pre></div><p>可以看到，源码里对每个请求都会调用一个 stress 命令，模拟 I/O 压力。从注释上看，stress 会通过 write() 和 unlink() 对 I/O 进程进行压测，看来，这应该就是系统 CPU 使用率升高的根源了。</p><p>不过，stress 模拟的是 I/O 压力，而之前在 top 的输出中看到的，却一直是用户 CPU 和系统 CPU 升高，并没见到 iowait 升高。这又是怎么回事呢？stress 到底是不是 CPU 使用率升高的原因呢？</p><p>我们还得继续往下走。从代码中可以看到，给请求加入 verbose=1 参数后，就可以查看 stress 的输出。你先试试看，在第二个终端运行：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ curl http://192.168.0.10:10000?verbose=1</span></div><div class="token-line"><span class="token plain">    Server internal error: Array</span></div><div class="token-line"><span class="token plain">    (</span></div><div class="token-line"><span class="token plain">        [0] =&gt; stress: info: [19607] dispatching hogs: 0 cpu, 0 io, 0 vm, 1 hdd</span></div><div class="token-line"><span class="token plain">        [1] =&gt; stress: FAIL: [19608] (563) mkstemp failed: Permission denied</span></div><div class="token-line"><span class="token plain">        [2] =&gt; stress: FAIL: [19607] (394) &lt;-- worker 19608 returned error 1</span></div><div class="token-line"><span class="token plain">        [3] =&gt; stress: WARN: [19607] (396) now reaping child worker processes</span></div><div class="token-line"><span class="token plain">        [4] =&gt; stress: FAIL: [19607] (400) kill error: No such process</span></div><div class="token-line"><span class="token plain">        [5] =&gt; stress: FAIL: [19607] (451) failed run completed in 0s</span></div><div class="token-line"><span class="token plain">    )</span></div></pre></div><p>看错误消息 mkstemp failed: Permission denied ，以及 failed run completed in 0s。原来 stress 命令并没有成功，它因为权限问题失败退出了。看来，我们发现了一个 PHP 调用外部 stress 命令的 bug：没有权限创建临时文件。</p><p>从这里我们可以猜测，正是由于权限错误，大量的 stress 进程在启动时初始化失败，进而导致用户 CPU 使用率的升高。</p><p>分析出问题来源，下一步是不是就要开始优化了呢？当然不是！既然只是猜测，那就需要再确认一下，这个猜测到底对不对，是不是真的有大量的 stress 进程。该用什么工具或指标呢？</p><p>我们前面已经用了 top、pidstat、pstree 等工具，没有发现大量的 stress 进程。那么，还有什么其他的工具可以用吗？</p><p>还记得上一期提到的 perf 吗？它可以用来分析 CPU 性能事件，用在这里就很合适。依旧在第一个终端中运行 perf record -g 命令 ，并等待一会儿（比如15秒）后按 Ctrl+C 退出。然后再运行 perf report 查看报告：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 记录性能事件，等待大约15秒后按 Ctrl+C 退出</span></div><div class="token-line"><span class="token plain">    $ perf record -g</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    # 查看报告</span></div><div class="token-line"><span class="token plain">    $ perf report</span></div></pre></div><p>这样，你就可以看到下图这个性能报告：</p><p><img src="/images/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/02.CPU%E6%80%A7%E8%83%BD%E7%AF%87/resourceimagec933c99445b401301147fa41cb2b5739e833.png" alt=""/></p><p>你看，stress 占了所有CPU时钟事件的 77%，而 stress 调用调用栈中比例最高的，是随机数生成函数 random()，看来它的确就是 CPU 使用率升高的元凶了。随后的优化就很简单了，只要修复权限问题，并减少或删除 stress 的调用，就可以减轻系统的 CPU 压力。</p><p>当然，实际生产环境中的问题一般都要比这个案例复杂，在你找到触发瓶颈的命令行后，却可能发现，这个外部命令的调用过程是应用核心逻辑的一部分，并不能轻易减少或者删除。</p><p>这时，你就得继续排查，为什么被调用的命令，会导致 CPU 使用率升高或 I/O 升高等问题。这些复杂场景的案例，我会在后面的综合实战里详细分析。</p><p>最后，在案例结束时，不要忘了清理环境，执行下面的 Docker 命令，停止案例中用到的 Nginx 进程：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ docker rm -f nginx phpfpm</span></div></pre></div><h2 id="execsnoop"><a aria-hidden="true" tabindex="-1" href="/blog/linux性能优化实战/02.cpu性能篇/05#execsnoop"><span class="icon icon-link"></span></a>execsnoop</h2><p>在这个案例中，我们使用了 top、pidstat、pstree 等工具分析了系统 CPU 使用率高的问题，并发现 CPU 升高是短时进程 stress 导致的，但是整个分析过程还是比较复杂的。对于这类问题，有没有更好的方法监控呢？</p><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/brendangregg/perf-tools/blob/master/execsnoop">execsnoop<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> 就是一个专为短时进程设计的工具。它通过 ftrace 实时监控进程的 exec() 行为，并输出短时进程的基本信息，包括进程 PID、父进程 PID、命令行参数以及执行的结果。</p><p>比如，用 execsnoop 监控上述案例，就可以直接得到 stress 进程的父进程 PID 以及它的命令行参数，并可以发现大量的 stress 进程在不停启动：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># 按 Ctrl+C 结束</span></div><div class="token-line"><span class="token plain">    $ execsnoop</span></div><div class="token-line"><span class="token plain">    PCOMM            PID    PPID   RET ARGS</span></div><div class="token-line"><span class="token plain">    sh               30394  30393    0</span></div><div class="token-line"><span class="token plain">    stress           30396  30394    0 /usr/local/bin/stress -t 1 -d 1</span></div><div class="token-line"><span class="token plain">    sh               30398  30393    0</span></div><div class="token-line"><span class="token plain">    stress           30399  30398    0 /usr/local/bin/stress -t 1 -d 1</span></div><div class="token-line"><span class="token plain">    sh               30402  30400    0</span></div><div class="token-line"><span class="token plain">    stress           30403  30402    0 /usr/local/bin/stress -t 1 -d 1</span></div><div class="token-line"><span class="token plain">    sh               30405  30393    0</span></div><div class="token-line"><span class="token plain">    stress           30407  30405    0 /usr/local/bin/stress -t 1 -d 1</span></div><div class="token-line"><span class="token plain">    ...</span></div></pre></div><p>execsnoop 所用的 ftrace 是一种常用的动态追踪技术，一般用于分析 Linux 内核的运行时行为，后面课程我也会详细介绍并带你使用。</p><h2 id="小结"><a aria-hidden="true" tabindex="-1" href="/blog/linux性能优化实战/02.cpu性能篇/05#小结"><span class="icon icon-link"></span></a>小结</h2><p>碰到常规问题无法解释的 CPU 使用率情况时，首先要想到有可能是短时应用导致的问题，比如有可能是下面这两种情况。</p><ul><li><p>第一，<strong>应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现</strong>。</p></li><li><p>第二，<strong>应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU</strong>。</p></li></ul><p>对于这类进程，我们可以用 pstree 或者 execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。</p><h2 id="思考"><a aria-hidden="true" tabindex="-1" href="/blog/linux性能优化实战/02.cpu性能篇/05#思考"><span class="icon icon-link"></span></a>思考</h2><p>最后，我想邀请你一起来聊聊，你所碰到的 CPU 性能问题。有没有哪个印象深刻的经历可以跟我分享呢？或者，在今天的案例操作中，你遇到了什么问题，又解决了哪些呢？你可以结合我的讲述，总结自己的思路。</p><p>欢迎在留言区和我讨论，也欢迎把这篇文章分享给你的同事、朋友。我们一起在实战中演练，在交流中进步。</p><p><img src="/images/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/02.CPU%E6%80%A7%E8%83%BD%E7%AF%87/resourceimage5652565d66d658ad23b2f4997551db153852.jpg" alt=""/></p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/docs/linux性能优化实战/02.CPU性能篇/05.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 13:36:35</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog/umi.js"></script>
  </body>
</html>
