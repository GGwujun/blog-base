<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-base/umi.css" />
    <script>
      window.routerBase = "/blog-base";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>
      03 案例篇 | 如何处理Page Cache难以回收产生的load飙高问题？ - 大师兄
    </title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/linux内核技术实战课/02.page-cache管理问题/03" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-base/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>计算机基础<ul><li><a href="/blog-base/编译原理之美">编译原理之美</a></li><li><a href="/blog-base/编译原理实战">编译原理实战</a></li><li><a href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/详解http">详解http</a></li><li><a href="/blog-base/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog-base/网络排查案例课">网络排查案例课</a></li><li><a href="/blog-base/linux操作系统">linux操作系统</a></li><li><a aria-current="page" class="active" href="/blog-base/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog-base/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog-base/程序员数学基础">程序员数学基础</a></li><li><a href="/blog-base/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog-base/操作系统实战">操作系统实战</a></li><li><a href="/blog-base/软件工程之美">软件工程之美</a></li><li><a href="/blog-base/sql必知必会">sql必知必会</a></li><li><a href="/blog-base/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog-base/网络编程实战">网络编程实战</a></li><li><a href="/blog-base/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></span><span>算法<ul><li><a href="/blog-base/常用算法25讲">常用算法25讲</a></li><li><a href="/blog-base/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog-base/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog-base/动态规划面试宝典">动态规划面试宝典</a></li></ul></span><span>前端开发<ul><li><a href="/blog-base/正则表达式入门">正则表达式入门</a></li></ul></span><span>前端工程化</span><span>前端性能优化</span><span>移动端开发</span><span>软件测试</span><span>产品与用户体验</span><span>面试</span><span>杂谈<ul><li><a href="/blog-base/代码之丑">代码之丑</a></li><li><a href="/blog-base/代码精进之路">代码精进之路</a></li><li><a href="/blog-base/数据分析思维课">数据分析思维课</a></li><li><a href="/blog-base/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog-base/重学线性代数">重学线性代数</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-base/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>计算机基础<ul><li><a href="/blog-base/编译原理之美">编译原理之美</a></li><li><a href="/blog-base/编译原理实战">编译原理实战</a></li><li><a href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/详解http">详解http</a></li><li><a href="/blog-base/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog-base/网络排查案例课">网络排查案例课</a></li><li><a href="/blog-base/linux操作系统">linux操作系统</a></li><li><a aria-current="page" class="active" href="/blog-base/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog-base/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog-base/程序员数学基础">程序员数学基础</a></li><li><a href="/blog-base/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog-base/操作系统实战">操作系统实战</a></li><li><a href="/blog-base/软件工程之美">软件工程之美</a></li><li><a href="/blog-base/sql必知必会">sql必知必会</a></li><li><a href="/blog-base/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog-base/网络编程实战">网络编程实战</a></li><li><a href="/blog-base/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></li><li>算法<ul><li><a href="/blog-base/常用算法25讲">常用算法25讲</a></li><li><a href="/blog-base/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog-base/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog-base/动态规划面试宝典">动态规划面试宝典</a></li></ul></li><li>前端开发<ul><li><a href="/blog-base/正则表达式入门">正则表达式入门</a></li></ul></li><li>前端工程化</li><li>前端性能优化</li><li>移动端开发</li><li>软件测试</li><li>产品与用户体验</li><li>面试</li><li>杂谈<ul><li><a href="/blog-base/代码之丑">代码之丑</a></li><li><a href="/blog-base/代码精进之路">代码精进之路</a></li><li><a href="/blog-base/数据分析思维课">数据分析思维课</a></li><li><a href="/blog-base/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog-base/重学线性代数">重学线性代数</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-base/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog-base/linux内核技术实战课/01.开篇词">01.开篇词</a><ul><li><a href="/blog-base/linux内核技术实战课/01.开篇词/01"><span>开篇词 | 如何让Linux内核更好地服务应用程序？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-base/linux内核技术实战课/02.page-cache管理问题">02.PageCache管理问题</a><ul><li><a href="/blog-base/linux内核技术实战课/02.page-cache管理问题/01"><span>01 基础篇 | 如何用数据观测Page Cache？</span></a></li><li><a href="/blog-base/linux内核技术实战课/02.page-cache管理问题/02"><span>02 基础篇 | Page Cache是怎样产生和释放的？</span></a></li><li><a aria-current="page" class="active" href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03"><span>03 案例篇 | 如何处理Page Cache难以回收产生的load飙高问题？</span></a></li><li><a href="/blog-base/linux内核技术实战课/02.page-cache管理问题/04"><span>04 案例篇 | 如何处理Page Cache容易回收引起的业务性能问题？</span></a></li><li><a href="/blog-base/linux内核技术实战课/02.page-cache管理问题/05"><span>05 分析篇 | 如何判断问题是否由Page Cache产生的？</span></a></li></ul></li><li><a href="/blog-base/linux内核技术实战课/03.内存泄漏问题">03.内存泄漏问题</a><ul><li><a href="/blog-base/linux内核技术实战课/03.内存泄漏问题/01"><span>06  基础篇 | 进程的哪些内存类型容易引起内存泄漏？</span></a></li><li><a href="/blog-base/linux内核技术实战课/03.内存泄漏问题/02"><span>07 案例篇 | 如何预防内存泄漏导致的系统假死？</span></a></li><li><a href="/blog-base/linux内核技术实战课/03.内存泄漏问题/03"><span>08 案例篇 | Shmem：进程没有消耗内存，内存哪去了？</span></a></li><li><a href="/blog-base/linux内核技术实战课/03.内存泄漏问题/04"><span>09 分析篇 | 如何对内核内存泄漏做些基础的分析？</span></a></li><li><a href="/blog-base/linux内核技术实战课/03.内存泄漏问题/05"><span>10 分析篇 | 内存泄漏时，我们该如何一步步找到根因？</span></a></li></ul></li><li><a href="/blog-base/linux内核技术实战课/04.tcp重传问题">04.TCP重传问题</a><ul><li><a href="/blog-base/linux内核技术实战课/04.tcp重传问题/01"><span>11 基础篇 | TCP连接的建立和断开受哪些系统配置影响？</span></a></li><li><a href="/blog-base/linux内核技术实战课/04.tcp重传问题/02"><span>12 基础篇 | TCP收发包过程会受哪些配置项影响？</span></a></li><li><a href="/blog-base/linux内核技术实战课/04.tcp重传问题/03"><span>13 案例篇 | TCP拥塞控制是如何导致业务性能抖动的？</span></a></li><li><a href="/blog-base/linux内核技术实战课/04.tcp重传问题/04"><span>14 案例篇 |  TCP端到端时延变大，怎样判断是哪里出现了问题？</span></a></li><li><a href="/blog-base/linux内核技术实战课/04.tcp重传问题/05"><span>15 分析篇 | 如何高效地分析TCP重传问题？</span></a></li><li><a href="/blog-base/linux内核技术实战课/04.tcp重传问题/06"><span>16 套路篇 | 如何分析常见的TCP问题？</span></a></li></ul></li><li><a href="/blog-base/linux内核技术实战课/05.内核态cpu利用率飙高问题">05.内核态CPU利用率飙高问题</a><ul><li><a href="/blog-base/linux内核技术实战课/05.内核态cpu利用率飙高问题/01"><span>17 基础篇 | CPU是如何执行任务的？</span></a></li><li><a href="/blog-base/linux内核技术实战课/05.内核态cpu利用率飙高问题/02"><span>18 案例篇 | 业务是否需要使用透明大页：水可载舟，亦可覆舟？</span></a></li><li><a href="/blog-base/linux内核技术实战课/05.内核态cpu利用率飙高问题/03"><span>19 案例篇 | 网络吞吐高的业务是否需要开启网卡特性呢？</span></a></li><li><a href="/blog-base/linux内核技术实战课/05.内核态cpu利用率飙高问题/04"><span>20 分析篇 | 如何分析CPU利用率飙高问题 ？</span></a></li></ul></li><li><a href="/blog-base/linux内核技术实战课/06.加餐">06.加餐</a><ul><li><a href="/blog-base/linux内核技术实战课/06.加餐/01"><span>加餐 | 我是如何使用tracepoint来分析内核Bug的？</span></a></li></ul></li><li><a href="/blog-base/linux内核技术实战课/07.结束语">07.结束语</a><ul><li><a href="/blog-base/linux内核技术实战课/07.结束语/01"><span>结束语 | 第一次看内核代码，我也很懵逼</span></a></li><li><a href="/blog-base/linux内核技术实战课/07.结束语/02"><span>来领奖啦！你填写毕业问卷了吗？</span></a></li><li><a href="/blog-base/linux内核技术实战课/07.结束语/03"><span>毕业问卷获奖用户名单</span></a></li></ul></li><li><a href="/blog-base/linux内核技术实战课/08.结课测试">08.结课测试</a><ul><li><a href="/blog-base/linux内核技术实战课/08.结课测试/01"><span>结课测试 | 这些Linux内核技术实战技能你都掌握了吗？</span></a></li></ul></li><li><a href="/blog-base/linux内核技术实战课/summary">linux内核技术实战课</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="直接内存回收引起load飙高或者业务时延抖动" data-depth="2"><a href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#直接内存回收引起load飙高或者业务时延抖动"><span>直接内存回收引起load飙高或者业务时延抖动</span></a></li><li title="系统中脏页过多引起load飙高" data-depth="2"><a href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#系统中脏页过多引起load飙高"><span>系统中脏页过多引起load飙高</span></a></li><li title="系统NUMA策略配置不当引起的load飙高" data-depth="2"><a href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#系统numa策略配置不当引起的load飙高"><span>系统NUMA策略配置不当引起的load飙高</span></a></li><li title="课堂总结" data-depth="2"><a href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#课堂总结"><span>课堂总结</span></a></li><li title="课后作业" data-depth="2"><a href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#课后作业"><span>课后作业</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="03-案例篇--如何处理page-cache难以回收产生的load飙高问题"><a aria-hidden="true" tabindex="-1" href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#03-案例篇--如何处理page-cache难以回收产生的load飙高问题"><span class="icon icon-link"></span></a>03 案例篇 | 如何处理Page Cache难以回收产生的load飙高问题？</h1><p>你好，我是邵亚方。今天这节课，我想跟你聊一聊怎么处理在生产环境中，因为Page Cache管理不当引起的系统load飙高的问题。</p><p>相信你在平时的工作中，应该会或多或少遇到过这些情形：系统很卡顿，敲命令响应非常慢；应用程序的RT变得很高，或者抖动得很厉害。在发生这些问题时，很有可能也伴随着系统load飙得很高。</p><p>那这是什么原因导致的呢？据我观察，大多是有三种情况：</p><ul><li>直接内存回收引起的load飙高；</li><li>系统中脏页积压过多引起的load飙高；</li><li>系统NUMA策略配置不当引起的load飙高。</li></ul><p>这是应用开发者和运维人员向我咨询最多的几种情况。问题看似很简单，但如果对问题产生的原因理解得不深，解决起来就会很棘手，甚至配置得不好，还会带来负面的影响。</p><p>所以这节课，我们一起来分析下这三种情况，可以说，搞清楚了这几种情况，你差不多就能解决掉绝大部分Page Cache引起的load飙高问题了。如果你对问题的原因排查感兴趣，也不要着急，在第5讲，我会带你学习load飙高问题的分析方法。</p><p>接下来，我们就来逐一分析下这几类情况。</p><h2 id="直接内存回收引起load飙高或者业务时延抖动"><a aria-hidden="true" tabindex="-1" href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#直接内存回收引起load飙高或者业务时延抖动"><span class="icon icon-link"></span></a>直接内存回收引起load飙高或者业务时延抖动</h2><p>直接内存回收是指在进程上下文同步进行内存回收，那么它具体是怎么引起load飙高的呢？</p><p>因为直接内存回收是在进程申请内存的过程中同步进行的回收，而这个回收过程可能会消耗很多时间，进而导致进程的后续行为都被迫等待，这样就会造成很长时间的延迟，以及系统的CPU利用率会升高，最终引起load飙高。</p><p>我们详细地描述一下这个过程，为了尽量不涉及太多技术细节，我会用一张图来表示，这样你理解起来会更容易。</p><p><img src="/images/httpsstatic001geekbangorgresourceimagefe00fe84eb2bd4956bbbdd5b0259df8c9400.jpg" alt="" title="内存回收过程"/></p><p>从图里你可以看到，在开始内存回收后，首先进行后台异步回收（上图中蓝色标记的地方），这不会引起进程的延迟；如果后台异步回收跟不上进程内存申请的速度，就会开始同步阻塞回收，导致延迟（上图中红色和粉色标记的地方，这就是引起load高的地址）。</p><p>那么，针对直接内存回收引起load飙高或者业务RT抖动的问题，一个解决方案就是<strong>及早地触发后台回收来避免应用程序进行直接内存回收，那具体要怎么做呢？</strong></p><p>我们先来了解一下后台回收的原理，如图：</p><p><img src="/images/httpsstatic001geekbangorgresourceimage447244d471fdae7376eb13e6e6bfc70b3172.jpg" alt=""/></p><p>它的意思是：当内存水位低于watermark low时，就会唤醒kswapd进行后台回收，然后kswapd会一直回收到watermark high。</p><p>那么，我们可以增大min_free_kbytes这个配置选项来及早地触发后台回收，该选项最终控制的是内存回收水位，不过，内存回收水位是内核里面非常细节性的知识点，我们可以先不去讨论。</p><blockquote><p>vm.min_free_kbytes = 4194304</p></blockquote><p>对于大于等于128G的系统而言，将min_free_kbytes设置为4G比较合理，这是我们在处理很多这种问题时总结出来的一个经验值，既不造成较多的内存浪费，又能避免掉绝大多数的直接内存回收。</p><p>该值的设置和总的物理内存并没有一个严格对应的关系，我们在前面也说过，如果配置不当会引起一些副作用，所以在调整该值之前，我的建议是：你可以渐进式地增大该值，比如先调整为1G，观察sar -B中pgscand是否还有不为0的情况；如果存在不为0的情况，继续增加到2G，再次观察是否还有不为0的情况来决定是否增大，以此类推。</p><p>在这里你需要注意的是，即使将该值增加得很大，还是可能存在pgscand不为0的情况（这个略复杂，涉及到内存碎片和连续内存申请，我们在此先不展开，你知道有这么回事儿就可以了）。那么这个时候你要考虑的是，业务是否可以容忍，如果可以容忍那就没有必要继续增加了，也就是说，增大该值并不是完全避免直接内存回收，而是尽量将直接内存回收行为控制在业务可以容忍的范围内。</p><p>这个方法可以用在3.10.0以后的内核上（对应的操作系统为CentOS-7以及之后更新的操作系统）。</p><p>当然了，这样做也有一些缺陷：提高了内存水位后，应用程序可以直接使用的内存量就会减少，这在一定程度上浪费了内存。所以在调整这一项之前，你需要先思考一下，<strong>应用程序更加关注什么，如果关注延迟那就适当地增大该值，如果关注内存的使用量那就适当地调小该值。</strong></p><p>除此之外，对CentOS-6(对应于2.6.32内核版本)而言，还有另外一种解决方案：</p><blockquote><p>vm.extra_free_kbytes = 4194304</p></blockquote><p>那就是将extra_free_kbytes 配置为4G。extra_free_kbytes在3.10以及以后的内核上都被废弃掉了，不过由于在生产环境中还存在大量的机器运行着较老版本内核，你使用到的也可能会是较老版本的内核，所以在这里还是有必要提一下。它的大致原理如下所示：</p><p><img src="/images/httpsstatic001geekbangorgresourceimage7dd27d9e537e23489cd4f5f34fedcd6f89d2.jpg" alt=""/></p><p>extra_free_kbytes的目的是为了解决min_free_kbyte造成的内存浪费，但是这种做法并没有被内核主线接收，因为这种行为很难维护会带来一些麻烦，感兴趣的可以看一下这个讨论：<a target="_blank" rel="noopener noreferrer" href="https://lkml.org/lkml/2013/2/17/210">add extra free kbytes tunable<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p>总的来说，通过调整内存水位，在一定程度上保障了应用的内存申请，但是同时也带来了一定的内存浪费，因为系统始终要保障有这么多的free内存，这就压缩了Page Cache的空间。调整的效果你可以通过/proc/zoneinfo来观察：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ egrep &quot;min|low|high&quot; /proc/zoneinfo </span></div><div class="token-line"><span class="token plain">    ...</span></div><div class="token-line"><span class="token plain">            min      7019</span></div><div class="token-line"><span class="token plain">            low      8773</span></div><div class="token-line"><span class="token plain">            high     10527</span></div><div class="token-line"><span class="token plain">    ...</span></div></pre></div><p>其中min、low、high分别对应上图中的三个内存水位。你可以观察一下调整前后min、low、high的变化。需要提醒你的是，内存水位是针对每个内存zone进行设置的，所以/proc/zoneinfo里面会有很多zone以及它们的内存水位，你可以不用去关注这些细节。</p><h2 id="系统中脏页过多引起load飙高"><a aria-hidden="true" tabindex="-1" href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#系统中脏页过多引起load飙高"><span class="icon icon-link"></span></a>系统中脏页过多引起load飙高</h2><p>接下来，我们分析下由于系统脏页过多引起load飙高的情况。在前一个案例中我们也提到，直接回收过程中，如果存在较多脏页就可能涉及在回收过程中进行回写，这可能会造成非常大的延迟，而且因为这个过程本身是阻塞式的，所以又可能进一步导致系统中处于D状态的进程数增多，最终的表现就是系统的load值很高。</p><p>我们来看一下这张图，这是一个典型的脏页引起系统load值飙高的问题场景：</p><p><img src="/images/httpsstatic001geekbangorgresourceimage907590c693c95d67cfaf89b86edbd1228d75.jpg" alt=""/></p><p>如图所示，如果系统中既有快速I/O设备，又有慢速I/O设备（比如图中的ceph RBD设备，或者其他慢速存储设备比如HDD），直接内存回收过程中遇到了正在往慢速I/O设备回写的page，就可能导致非常大的延迟。</p><p>这里我多说一点。这类问题其实是不太好去追踪的，为了更好追踪这种慢速I/O设备引起的抖动问题，我也给Linux Kernel提交了一个patch来进行更好的追踪：<a target="_blank" rel="noopener noreferrer" href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=19343b5bdd16ad4ae6b845ef829f68b683c4dfb5">mm/page-writeback: introduce tracepoint for wait_on_page_writeback()<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，这种做法是在原来的基础上增加了回写的设备，这样子用户就能更好地将回写和具体设备关联起来，从而判断问题是否是由慢速I/O设备导致的（具体的分析方法我会在后面第5讲分析篇里重点来讲）。</p><p>那如何解决这类问题呢？一个比较省事的解决方案是控制好系统中积压的脏页数据。很多人知道需要控制脏页，但是往往并不清楚如何来控制好这个度，脏页控制的少了可能会影响系统整体的效率，脏页控制的多了还是会触发问题，所以我们接下来看下如何来衡量好这个“度”。</p><p>首先你可以通过sar -r来观察系统中的脏页个数：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ sar -r 1</span></div><div class="token-line"><span class="token plain">    07:30:01 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty</span></div><div class="token-line"><span class="token plain">    09:20:01 PM   5681588   2137312     27.34         0   1807432    193016      2.47    534416   1310876         4</span></div><div class="token-line"><span class="token plain">    09:30:01 PM   5677564   2141336     27.39         0   1807500    204084      2.61    539192   1310884        20</span></div><div class="token-line"><span class="token plain">    09:40:01 PM   5679516   2139384     27.36         0   1807508    196696      2.52    536528   1310888        20</span></div><div class="token-line"><span class="token plain">    09:50:01 PM   5679548   2139352     27.36         0   1807516    196624      2.51    536152   1310892        24</span></div></pre></div><p>kbdirty就是系统中的脏页大小，它同样也是对/proc/vmstat中nr_dirty的解析。你可以通过调小如下设置来将系统脏页个数控制在一个合理范围:</p><blockquote><p>vm.dirty_background_bytes = 0<br/>vm.dirty_background_ratio = 10<br/>vm.dirty_bytes = 0<br/>vm.dirty_expire_centisecs = 3000<br/>vm.dirty_ratio = 20</p></blockquote><p>调整这些配置项有利有弊，调大这些值会导致脏页的积压，但是同时也可能减少了I/O的次数，从而提升单次刷盘的效率；调小这些值可以减少脏页的积压，但是同时也增加了I/O的次数，降低了I/O的效率。</p><p><strong>至于这些值调整大多少比较合适，也是因系统和业务的不同而异，我的建议也是一边调整一边观察，将这些值调整到业务可以容忍的程度就可以了，即在调整后需要观察业务的服务质量(SLA)，要确保SLA在可接受范围内</strong>。调整的效果你可以通过/proc/vmstat来查看：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ grep &quot;nr_dirty_&quot; /proc/vmstat</span></div><div class="token-line"><span class="token plain">    nr_dirty_threshold 366998</span></div><div class="token-line"><span class="token plain">    nr_dirty_background_threshold 183275</span></div></pre></div><p>你可以观察一下调整前后这两项的变化。<strong>这里我要给你一个避免踩坑的提示</strong>，解决该方案中的设置项如果设置不妥会触发一个内核Bug，这是我在2017年进行性能调优时发现的一个内核Bug，我给社区提交了一个patch将它fix掉了，具体的commit见<a target="_blank" rel="noopener noreferrer" href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=94af584692091347baea4d810b9fc6e0f5483d42">writeback: schedule periodic writeback with sysctl<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a target="_blank" rel="noopener noreferrer" href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=94af584692091347baea4d810b9fc6e0f5483d42"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, commit log清晰地描述了该问题，我建议你有时间看一看。</p><h2 id="系统numa策略配置不当引起的load飙高"><a aria-hidden="true" tabindex="-1" href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#系统numa策略配置不当引起的load飙高"><span class="icon icon-link"></span></a>系统NUMA策略配置不当引起的load飙高</h2><p>除了我前面提到的这两种引起系统load飙高或者业务延迟抖动的场景之外，还有另外一种场景也会引起load飙高，那就是系统NUMA策略配置不当引起的load飙高。</p><p>比如说，我们在生产环境上就曾经遇到这样的问题：系统中还有一半左右的free内存，但还是频频触发direct reclaim，导致业务抖动得比较厉害。后来经过排查发现是由于设置了zone_reclaim_mode，这是NUMA策略的一种。</p><p>设置zone_reclaim_mode的目的是为了增加业务的NUMA亲和性，但是在实际生产环境中很少会有对NUMA特别敏感的业务，这也是为什么内核将该配置从默认配置1修改为了默认配置0: <a target="_blank" rel="noopener noreferrer" href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4f9b16a64753d0bb607454347036dc997fd03b82">mm: disable zone_reclaim_mode by default<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> ，配置为0之后，就避免了在其他node有空闲内存时，不去使用这些空闲内存而是去回收当前node的Page Cache，也就是说，通过减少内存回收发生的可能性从而避免它引发的业务延迟。</p><p>那么如何来有效地衡量业务延迟问题是否由zone reclaim引起的呢？它引起的延迟究竟有多大呢？这个衡量和观察方法也是我贡献给Linux Kernel的：<a target="_blank" rel="noopener noreferrer" href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=132bb8cfc9e081238e7e2fd0c37c8c75ad0d2963">mm/vmscan: add tracepoints for node reclaim<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> ，大致的思路就是利用linux的tracepoint来做这种量化分析，这是性能开销相对较小的一个方案。</p><p>我们可以通过numactl来查看服务器的NUMA信息，如下是两个node的服务器：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">$ numactl --hardware</span></div><div class="token-line"><span class="token plain">    available: 2 nodes (0-1)</span></div><div class="token-line"><span class="token plain">    node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 24 25 26 27 28 29 30 31 32 33 34 35</span></div><div class="token-line"><span class="token plain">    node 0 size: 130950 MB</span></div><div class="token-line"><span class="token plain">    node 0 free: 108256 MB</span></div><div class="token-line"><span class="token plain">    node 1 cpus: 12 13 14 15 16 17 18 19 20 21 22 23 36 37 38 39 40 41 42 43 44 45 46 47</span></div><div class="token-line"><span class="token plain">    node 1 size: 131072 MB</span></div><div class="token-line"><span class="token plain">    node 1 free: 122995 MB</span></div><div class="token-line"><span class="token plain">    node distances:</span></div><div class="token-line"><span class="token plain">    node   0   1 </span></div><div class="token-line"><span class="token plain">      0:  10  21 </span></div><div class="token-line"><span class="token plain">      1:  21  10</span></div></pre></div><p>其中CPU0～11，24～35的local node为node 0；而CPU12～23，36～47的local node为node 1。如下图所示：</p><p><img src="/images/httpsstatic001geekbangorgresourceimage80e280e7c19a8f310d5bf30d368cef86bbe2.jpg" alt=""/></p><p>推荐将zone_reclaim_mode配置为0。</p><blockquote><p>vm.zone_reclaim_mode = 0</p></blockquote><p>因为相比内存回收的危害而言，NUMA带来的性能提升几乎可以忽略，所以配置为0，利远大于弊。</p><p>好了，对于Page Cache管理不当引起的系统load飙高和业务时延抖动问题，我们就分析到这里，希望通过这篇的学习，在下次你遇到直接内存回收引起的load飙高问题时不再束手无策。</p><p>总的来说，这些问题都是Page Cache难以释放而产生的问题，那你是否想过，是不是Page Cache很容易释放就不会产生问题了？这个答案可能会让你有些意料不到：Page Cache容易释放也有容易释放的问题。这到底是怎么回事呢，我们下节课来分析下这方面的案例。</p><h2 id="课堂总结"><a aria-hidden="true" tabindex="-1" href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#课堂总结"><span class="icon icon-link"></span></a>课堂总结</h2><p>这节课我们讲的这几个案例都是内存回收过程中引起的load飙高问题。关于内存回收这事，我们可以做一个形象的类比。我们知道，内存是操作系统中很重要的一个资源，它就像我们在生活过程中很重要的一个资源——钱一样，如果你的钱（内存）足够多，那想买什么就可以买什么，而不用担心钱花完（内存用完）后要吃土（引起load飙高）。</p><p>但是现实情况是我们每个人用来双十一购物的钱（内存）总是有限的，在买东西（运行程序）的时候总需要精打细算，一旦预算快超了（内存快不够了），就得把一些不重要的东西（把一些不活跃的内容）从购物车里删除掉（回收掉），好腾出资金（空闲的内存）来买更想买的东西（运行需要运行的程序）。</p><p>我们讲的这几个案例都可以通过调整系统参数/配置来解决，调整系统参数/配置也是应用开发者和运维人员在发生了内核问题时所能做的改动。比如说，直接内存回收引起load飙高时，就去调整内存水位设置；脏页积压引起load飙高时，就需要去调整脏页的水位；NUMA策略配置不当引起load飙高时，就去检查是否需要关闭该策略。同时我们在做这些调整的时候，一定要边调整边观察业务的服务质量，确保SLA是可以接受的。</p><p>如果你想要你的系统更加稳定，你的业务性能更好，你不妨去研究一下系统中的可配置项，看看哪些配置可以帮助你的业务。</p><h2 id="课后作业"><a aria-hidden="true" tabindex="-1" href="/blog-base/linux内核技术实战课/02.page-cache管理问题/03#课后作业"><span class="icon icon-link"></span></a>课后作业</h2><p>这节课我给你布置的作业是针对直接内存回收的，现在你已经知道直接内存回收容易产生问题，是我们需要尽量避免的，那么我的问题是：请你执行一些模拟程序来构造出直接内存回收的场景（小提示： 你可以通过sar -B中的pgscand来判断是否有了直接内存回收）。欢迎在留言区分享你的看法。</p><p>感谢你的阅读，如果你认为这节课的内容有收获，也欢迎把它分享给你的朋友，我们下一讲见。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/linux内核技术实战课/02.PageCache管理问题/03.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 17:33:13</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-base/umi.js"></script>
  </body>
</html>
