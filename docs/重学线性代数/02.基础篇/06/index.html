<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-base/umi.css" />
    <script>
      window.routerBase = "/blog-base";
    </script>
    <script>
      window.publicPath = window.resourceBaseUrl || "/blog-base/";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>06 | 线性无关：如何理解向量在N维空间的几何意义？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/重学线性代数/02.基础篇/06" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-base/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>计算机基础<ul><li><a href="/blog-base/编译原理之美">编译原理之美</a></li><li><a href="/blog-base/编译原理实战">编译原理实战</a></li><li><a href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/详解http">详解http</a></li><li><a href="/blog-base/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog-base/网络排查案例课">网络排查案例课</a></li><li><a href="/blog-base/linux操作系统">linux操作系统</a></li><li><a href="/blog-base/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog-base/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog-base/程序员数学基础">程序员数学基础</a></li><li><a href="/blog-base/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog-base/操作系统实战">操作系统实战</a></li><li><a href="/blog-base/软件工程之美">软件工程之美</a></li><li><a href="/blog-base/sql必知必会">sql必知必会</a></li><li><a href="/blog-base/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog-base/网络编程实战">网络编程实战</a></li><li><a href="/blog-base/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></span><span>算法<ul><li><a href="/blog-base/常用算法25讲">常用算法25讲</a></li><li><a href="/blog-base/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog-base/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog-base/动态规划面试宝典">动态规划面试宝典</a></li></ul></span><span>前端开发<ul><li><a href="/blog-base/正则表达式入门">正则表达式入门</a></li></ul></span><span>前端工程化</span><span>前端性能优化</span><span>移动端开发</span><span>软件测试</span><span>产品与用户体验</span><span>面试</span><span>杂谈<ul><li><a href="/blog-base/代码之丑">代码之丑</a></li><li><a href="/blog-base/代码精进之路">代码精进之路</a></li><li><a href="/blog-base/数据分析思维课">数据分析思维课</a></li><li><a href="/blog-base/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a aria-current="page" class="active" href="/blog-base/重学线性代数">重学线性代数</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-base/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>计算机基础<ul><li><a href="/blog-base/编译原理之美">编译原理之美</a></li><li><a href="/blog-base/编译原理实战">编译原理实战</a></li><li><a href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/详解http">详解http</a></li><li><a href="/blog-base/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog-base/网络排查案例课">网络排查案例课</a></li><li><a href="/blog-base/linux操作系统">linux操作系统</a></li><li><a href="/blog-base/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog-base/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog-base/程序员数学基础">程序员数学基础</a></li><li><a href="/blog-base/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog-base/操作系统实战">操作系统实战</a></li><li><a href="/blog-base/软件工程之美">软件工程之美</a></li><li><a href="/blog-base/sql必知必会">sql必知必会</a></li><li><a href="/blog-base/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog-base/网络编程实战">网络编程实战</a></li><li><a href="/blog-base/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></li><li>算法<ul><li><a href="/blog-base/常用算法25讲">常用算法25讲</a></li><li><a href="/blog-base/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog-base/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog-base/动态规划面试宝典">动态规划面试宝典</a></li></ul></li><li>前端开发<ul><li><a href="/blog-base/正则表达式入门">正则表达式入门</a></li></ul></li><li>前端工程化</li><li>前端性能优化</li><li>移动端开发</li><li>软件测试</li><li>产品与用户体验</li><li>面试</li><li>杂谈<ul><li><a href="/blog-base/代码之丑">代码之丑</a></li><li><a href="/blog-base/代码精进之路">代码精进之路</a></li><li><a href="/blog-base/数据分析思维课">数据分析思维课</a></li><li><a href="/blog-base/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a aria-current="page" class="active" href="/blog-base/重学线性代数">重学线性代数</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-base/重学线性代数">重学线性代数</a></li><li><a href="/blog-base/重学线性代数/01.开篇词">01.开篇词</a><ul><li><a href="/blog-base/重学线性代数/01.开篇词/01"><span>开篇词 | 从今天起，学会线性代数</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-base/重学线性代数/02.基础篇">02.基础篇</a><ul><li><a href="/blog-base/重学线性代数/02.基础篇/01"><span>01 | 导读：如何在机器学习中运用线性代数工具？</span></a></li><li><a href="/blog-base/重学线性代数/02.基础篇/02"><span>02 | 基本概念：线性代数研究的到底是什么问题？</span></a></li><li><a href="/blog-base/重学线性代数/02.基础篇/03"><span>03 | 矩阵：为什么说矩阵是线性方程组的另一种表达？</span></a></li><li><a href="/blog-base/重学线性代数/02.基础篇/04"><span>04 | 解线性方程组：为什么用矩阵求解的效率这么高？</span></a></li><li><a href="/blog-base/重学线性代数/02.基础篇/05"><span>05 | 线性空间：如何通过向量的结构化空间在机器学习中做降维处理？</span></a></li><li><a aria-current="page" class="active" href="/blog-base/重学线性代数/02.基础篇/06"><span>06 | 线性无关：如何理解向量在N维空间的几何意义？</span></a></li><li><a href="/blog-base/重学线性代数/02.基础篇/07"><span>07 | 基和秩：为什么说它表达了向量空间中“有用”的向量个数？</span></a></li><li><a href="/blog-base/重学线性代数/02.基础篇/08"><span>08 | 线性映射：如何从坐标系角度理解两个向量空间之间的函数？</span></a></li><li><a href="/blog-base/重学线性代数/02.基础篇/09"><span>09 | 仿射空间：如何在图形的平移操作中大显身手？</span></a></li><li><a href="/blog-base/重学线性代数/02.基础篇/10"><span>10 | 解析几何：为什么说它是向量从抽象到具象的表达？</span></a></li><li><a href="/blog-base/重学线性代数/02.基础篇/11"><span>基础通关 | 线性代数5道典型例题及解析</span></a></li></ul></li><li><a href="/blog-base/重学线性代数/03.应用篇">03.应用篇</a><ul><li><a href="/blog-base/重学线性代数/03.应用篇/01"><span>11 | 如何运用线性代数方法解决图论问题？</span></a></li><li><a href="/blog-base/重学线性代数/03.应用篇/02"><span>12 | 如何通过矩阵转换让3D图形显示到二维屏幕上？</span></a></li><li><a href="/blog-base/重学线性代数/03.应用篇/03"><span>13 | 如何通过有限向量空间加持的希尔密码，提高密码被破译的难度？</span></a></li><li><a href="/blog-base/重学线性代数/03.应用篇/04"><span>14 | 如何在深度学习中运用数值代数的迭代法做训练？</span></a></li><li><a href="/blog-base/重学线性代数/03.应用篇/05"><span>15 | 如何从计算机的角度来理解线性代数？</span></a></li><li><a href="/blog-base/重学线性代数/03.应用篇/06"><span>强化通关 | 线性代数水平测试20题</span></a></li></ul></li><li><a href="/blog-base/重学线性代数/04.结束语">04.结束语</a><ul><li><a href="/blog-base/重学线性代数/04.结束语/01"><span>结束语 | 和数学打交道这么多年，我的三点感悟</span></a></li></ul></li><li><a href="/blog-base/重学线性代数/summary">重学线性代数</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="线性组合" data-depth="2"><a href="/blog-base/重学线性代数/02.基础篇/06#线性组合"><span>线性组合</span></a></li><li title="线性无关的判断方式" data-depth="2"><a href="/blog-base/重学线性代数/02.基础篇/06#线性无关的判断方式"><span>线性无关的判断方式</span></a></li><li title="更普遍和复杂的线性无关判断" data-depth="2"><a href="/blog-base/重学线性代数/02.基础篇/06#更普遍和复杂的线性无关判断"><span>更普遍和复杂的线性无关判断</span></a></li><li title="线性组合在机器学习中的应用" data-depth="2"><a href="/blog-base/重学线性代数/02.基础篇/06#线性组合在机器学习中的应用"><span>线性组合在机器学习中的应用</span></a></li><li title="本节小结" data-depth="2"><a href="/blog-base/重学线性代数/02.基础篇/06#本节小结"><span>本节小结</span></a></li><li title="线性代数练习场" data-depth="2"><a href="/blog-base/重学线性代数/02.基础篇/06#线性代数练习场"><span>线性代数练习场</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="06--线性无关如何理解向量在n维空间的几何意义"><a aria-hidden="true" tabindex="-1" href="/blog-base/重学线性代数/02.基础篇/06#06--线性无关如何理解向量在n维空间的几何意义"><span class="icon icon-link"></span></a>06 | 线性无关：如何理解向量在N维空间的几何意义？</h1><p>你好，我是朱维刚。欢迎你继续跟我学习线性代数，今天我们要讲的内容是“线性无关”。</p><p>上一节课中，我讲的是线性空间的基本概念，是立足于宏观角度来讲的。那么今天，我们就要深入线性空间，从微观角度，再来看看线性空间中元素之间的关系，也就是<strong>线性组合</strong>。</p><p>线性组合有<strong>线性相关</strong>和<strong>线性无关</strong>，而线性无关是线性代数中最重要的概念之一，为什么这么说呢？因为线性相关的向量组中存在多余的向量，去掉它们不影响我们所考虑的问题。而线性无关向量集合是没有任何冗余的，也就是说，失去集合中任意一个向量，我们都会失去一些东西。接下来我们就开始把这个“直观上的理解”固化成实实在在的知识体系。</p><p>在正式开始讲解前，我还是一样，先通过一个例子，让你对线性组合有个大致的了解。</p><p>假设，有一家物流运输公司$Y$，$Y$主要靠车辆的货物运输来赚钱，而且$Y$拥有很多直营的运输车辆，设共有$n$辆车，$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->n<!-- -->}<!-- -->｝$，那么，$Y$公司的收入可以表示成：$Y_<!-- -->{<!-- -->i<!-- -->}<!-- -->=a_<!-- -->{<!-- -->0<!-- -->}<!-- -->+a_<!-- -->{<!-- -->1<!-- -->}<!-- --> x_<!-- -->{<!-- -->1<!-- -->}<!-- -->+a_<!-- -->{<!-- -->2<!-- -->}<!-- --> x_<!-- -->{<!-- -->2<!-- -->}<!-- -->+\cdots+a_<!-- -->{<!-- -->n<!-- -->}<!-- --> x_<!-- -->{<!-- -->n<!-- -->}<!-- -->$。</p><p>这是个线性方程，它的系数$a$表示了各辆车对收入的贡献率，$a_<!-- -->{<!-- -->0<!-- -->}<!-- -->$表示企业的日常总支出。这时企业内，任何一辆车对收入的贡献大小和这个企业其他的车都没有关系，所以各车之间就是<strong>线性无关</strong>的。如果这时，我们再聚焦到每辆车本身的利润上，比如我们都知道的这个公式：利润=收入-成本，那每辆车的利润、成本和收入之间就是<strong>线性相关</strong>的。</p><h2 id="线性组合"><a aria-hidden="true" tabindex="-1" href="/blog-base/重学线性代数/02.基础篇/06#线性组合"><span class="icon icon-link"></span></a>线性组合</h2><p>在例子中，我们已经知道了线性组合中的线性相关、线性无关的意思。那么接下来，我们来看线性组合的确切定义：一个向量空间$V$和属于这个向量空间的有限数量的向量$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$，对于属于向量空间$V$的每个向量$v$，都有这样的表达形式：$v=\lambda_<!-- -->{<!-- -->1<!-- -->}<!-- --> x_<!-- -->{<!-- -->1<!-- -->}<!-- -->+\lambda_<!-- -->{<!-- -->2<!-- -->}<!-- --> x_<!-- -->{<!-- -->2<!-- -->}<!-- -->+\cdots+\lambda_<!-- -->{<!-- -->k<!-- -->}<!-- --> x_<!-- -->{<!-- -->k<!-- -->}<!-- -->=\sum_<!-- -->{<!-- -->i=1<!-- -->}<!-- -->^<!-- -->{<!-- -->k<!-- -->}<!-- --> \lambda_<!-- -->{<!-- -->i<!-- -->}<!-- --> x_<!-- -->{<!-- -->i<!-- -->}<!-- -->$。</p><p>那么，$v$就是向量$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$的线性组合。</p><p>我们继续看线性相关和线性无关的定义，一个向量空间$V$和属于这个向量空间的有限数量的向量$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$，有一个非平凡线性组合：$0=\lambda_<!-- -->{<!-- -->1<!-- -->}<!-- --> x_<!-- -->{<!-- -->1<!-- -->}<!-- -->+\lambda_<!-- -->{<!-- -->2<!-- -->}<!-- --> x_<!-- -->{<!-- -->2<!-- -->}<!-- -->+\cdots+\lambda_<!-- -->{<!-- -->k<!-- -->}<!-- --> x_<!-- -->{<!-- -->k<!-- -->}<!-- -->=\sum_<!-- -->{<!-- -->i=1<!-- -->}<!-- -->^<!-- -->{<!-- -->k<!-- -->}<!-- --> \lambda_<!-- -->{<!-- -->i<!-- -->}<!-- --> x_<!-- -->{<!-- -->i<!-- -->}<!-- -->$。如果其中至少有一个$λ$不等于0，这时，向量$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$是<strong>线性相关</strong>的。而如果有平凡解存在，例如：$λ_<!-- -->{<!-- -->1<!-- -->}<!-- -->= \ldots=λ_<!-- -->{<!-- -->k<!-- -->}<!-- -->=0$，则向量$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$是<strong>线性无关</strong>的。</p><blockquote><p>注意：这里有个数学用语“平凡解”，术语“平凡”经常用于结构非常简单的对象，一般来说，$Ax=0$中的零解，即$x=0$，就叫做平凡解。</p></blockquote><p>现在，我们通过一个实际的例子来加深一下理解。</p><p>假如你想从上海去杭州，有两条路线可以供你选择：一条是从上海出发，行驶$84.9$公里后到苏州，再从苏州出发行驶$120.14$公里后到达杭州；另一条是从上海出发行驶$164.7$公里后直接到达杭州。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimage1d3b1dc1a7aa6c762519eff1c6d9cb00343b.03d55efd.png" alt=""/></p><p>我们可以把地理位置坐标系看成是一个二维的向量空间，上海到苏州可以表示成向量$v1$，苏州到杭州可以表示成向量$v2$，上海到杭州可以表示成向量$v3$，这样很明显可以看出，向量$v1$和$v2$是线性无关的，而上海到杭州$v3$却可以被另两个向量$v1$和$v2$表达，于是我们可以说$v1$，$v2$和$v3$之间是线性相关的。</p><h2 id="线性无关的判断方式"><a aria-hidden="true" tabindex="-1" href="/blog-base/重学线性代数/02.基础篇/06#线性无关的判断方式"><span class="icon icon-link"></span></a>线性无关的判断方式</h2><p>线性无关的判断，对于实践中数据冗余的判断非常有用，那有没有一些方法来判断向量之间是线性无关的呢？我们来看一些有用的方法吧：</p><ol><li>k向量要么线性无关，要么线性相关，没有第三个选择。</li><li>已知向量集合 $｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$ 中至少有一个是$0$向量，则它们是线性相关的。</li><li>已知有向量集合 $｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$ ，其中$x_<!-- -->{<!-- -->k<!-- -->}<!-- -->≠0$ ，如果一个向量等于另一向量和一个标量的乘，$x_<!-- -->{<!-- -->i<!-- -->}<!-- -->=λx_<!-- -->{<!-- -->j<!-- -->}<!-- -->$ ，那么，向量集合 $｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$ 是线性相关的。</li></ol><p>之前的方式方法都是偏理论的，而更加实践的方法，就是用高斯消元法来判断向量集合$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$是否是线性无关的。将所有向量组合成矩阵的列，做高斯消元，一直到形成行阶梯型矩阵为止。如果所有的列都是主元列，那矩阵所有列向量是线性无关的，反之，如果有至少一个非主元列，那矩阵所有列向量是线性相关的。</p><p>现在我们来做个小练习，就用高斯消元法来看一下这3个向量是否是线性无关的。</p><p>$$x_<!-- -->{<!-- -->1<!-- -->}<!-- -->=\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->c<!-- -->}<br/>1 \\\<br/>2 \\\<br/>-3 \\\<br/>4<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right], x_<!-- -->{<!-- -->2<!-- -->}<!-- -->=\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->l<!-- -->}<br/>1 \\\<br/>1 \\\<br/>0 \\\<br/>2<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right], x_<!-- -->{<!-- -->3<!-- -->}<!-- -->=\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->c<!-- -->}<br/>-1 \\\<br/>-2 \\\<br/>1 \\\<br/>1<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right]$$</p><p>首先，我们把它表示成一般线性方程形式，或者一个非平凡线性组合。</p><p>$$\lambda_<!-- -->{<!-- -->1<!-- -->}<!-- --> x_<!-- -->{<!-- -->1<!-- -->}<!-- -->+\lambda_<!-- -->{<!-- -->2<!-- -->}<!-- --> x_<!-- -->{<!-- -->2<!-- -->}<!-- -->+\lambda_<!-- -->{<!-- -->3<!-- -->}<!-- --> x_<!-- -->{<!-- -->3<!-- -->}<!-- -->=\lambda_<!-- -->{<!-- -->1<!-- -->}<!-- -->\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->c<!-- -->}<br/>1 \\\<br/>2 \\\<br/>-3 \\\<br/>4<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right]+\lambda_<!-- -->{<!-- -->2<!-- -->}<!-- -->\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->c<!-- -->}<br/>1 \\\<br/>1 \\\<br/>0 \\\<br/>2<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right]+\lambda_<!-- -->{<!-- -->3<!-- -->}<!-- -->\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->c<!-- -->}<br/>-1 \\\<br/>-2 \\\<br/>1 \\\<br/>1<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right]=0$$</p><p>接着，把向量组合成矩阵的列，运用行运算，一直到能够识别出主元列为止。</p><p>$$\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->ccc<!-- -->}<br/>1 &amp; 1 &amp; -1 \\\<br/>2 &amp; 1 &amp; -2 \\\<br/>-3 &amp; 0 &amp; 1 \\\<br/>4 &amp; 2 &amp; 1<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right] \cdots\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->ccc<!-- -->}<br/>1 &amp; 1 &amp; -1 \\\<br/>0 &amp; 1 &amp; 0 \\\<br/>0 &amp; 0 &amp; 1 \\\<br/>0 &amp; 0 &amp; 0<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right]$$</p><p>这里，矩阵每一列都是主元列，所以，它没有非平凡解，只有在$λ_<!-- -->{<!-- -->1<!-- -->}<!-- -->=0$，$λ_<!-- -->{<!-- -->2<!-- -->}<!-- -->=0$，$λ_<!-- -->{<!-- -->3<!-- -->}<!-- -->=0$的情况下，方程才有解。因此，我们能说向量$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$ 是线性无关的。</p><h2 id="更普遍和复杂的线性无关判断"><a aria-hidden="true" tabindex="-1" href="/blog-base/重学线性代数/02.基础篇/06#更普遍和复杂的线性无关判断"><span class="icon icon-link"></span></a>更普遍和复杂的线性无关判断</h2><p>理论是这样的，接下来我们再扩展一下学到的知识，把它用到更普遍和复杂的情况中，也就是有$k$个线性无关的向量$｛b_<!-- -->{<!-- -->1<!-- -->}<!-- -->, b_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, b_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$，以及$m$个线性组合的情况：</p><p>$$<br/>\begin<!-- -->{<!-- -->aligned<!-- -->}<br/>x_<!-- -->{<!-- -->1<!-- -->}<!-- --> &amp;=\sum_<!-- -->{<!-- -->i=1<!-- -->}<!-- -->^<!-- -->{<!-- -->k<!-- -->}<!-- --> \lambda_<!-- -->{<!-- -->i 1<!-- -->}<!-- --> b_<!-- -->{<!-- -->i<!-- -->}<!-- --> \\\<br/>x_<!-- -->{<!-- -->2<!-- -->}<!-- --> &amp;=\sum_<!-- -->{<!-- -->i=1<!-- -->}<!-- -->^<!-- -->{<!-- -->k<!-- -->}<!-- --> \lambda_<!-- -->{<!-- -->i 2<!-- -->}<!-- --> b_<!-- -->{<!-- -->i<!-- -->}<!-- --> \\\<br/>\cdot &amp; \\\<br/>\cdot &amp; \\\<br/>\cdot &amp; \\\<br/>x_<!-- -->{<!-- -->m<!-- -->}<!-- --> &amp;=\sum_<!-- -->{<!-- -->i=1<!-- -->}<!-- -->^<!-- -->{<!-- -->k<!-- -->}<!-- --> \lambda_<!-- -->{<!-- -->i m<!-- -->}<!-- --> b_<!-- -->{<!-- -->i<!-- -->}<br/>\end<!-- -->{<!-- -->aligned<!-- -->}<br/>$$</p><p>如果把这$k$个线性无关的向量组合成矩阵$B$，$B=\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->lll<!-- -->}<!-- -->b_<!-- -->{<!-- -->1<!-- -->}<!-- --> &amp; \ldots &amp; b_<!-- -->{<!-- -->k<!-- -->}<!-- -->\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right]$ ，我们就能用更紧凑的形式来表达：</p><p>$$x_<!-- -->{<!-- -->j<!-- -->}<!-- -->=B \lambda_<!-- -->{<!-- -->i<!-- -->}<!-- -->, \lambda_<!-- -->{<!-- -->j<!-- -->}<!-- -->=\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->c<!-- -->}<br/>\lambda_<!-- -->{<!-- -->1 j<!-- -->}<!-- --> \\\<br/>\cdot \\\<br/>\cdot \\\<br/>\cdot \\\<br/>\lambda_<!-- -->{<!-- -->kj<!-- -->}<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right], j=1, \ldots, m$$</p><p>这时，如何判断$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->m<!-- -->}<!-- -->｝$ 是否是线性无关的呢？首先，我们用一个非平凡线性组合来测试，就和之前的方法一样，把它表示成这样的形式：$\sum_<!-- -->{<!-- -->i=1<!-- -->}<!-- -->^<!-- -->{<!-- -->m<!-- -->}<!-- --> \varphi_<!-- -->{<!-- -->j<!-- -->}<!-- --> x_<!-- -->{<!-- -->j<!-- -->}<!-- -->=\sum_<!-- -->{<!-- -->i=1<!-- -->}<!-- -->^<!-- -->{<!-- -->m<!-- -->}<!-- --> \varphi_<!-- -->{<!-- -->j<!-- -->}<!-- --> B \lambda_<!-- -->{<!-- -->j<!-- -->}<!-- -->=B \sum_<!-- -->{<!-- -->i=1<!-- -->}<!-- -->^<!-- -->{<!-- -->m<!-- -->}<!-- --> \varphi_<!-- -->{<!-- -->j<!-- -->}<!-- --> \lambda_<!-- -->{<!-- -->j<!-- -->}<!-- -->=0$。</p><p>接着，从这样的等式可以很容易看出，只有向量$｛λ_<!-- -->{<!-- -->1<!-- -->}<!-- -->, λ_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, λ_<!-- -->{<!-- -->m<!-- -->}<!-- -->｝$线性无关，$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->m<!-- -->}<!-- -->｝$ 才是线性无关的。</p><p>还是老样子，我们通过一个例子来看下。假设，有一组线性无关的向量 $｛b_<!-- -->{<!-- -->1<!-- -->}<!-- -->, b_<!-- -->{<!-- -->2<!-- -->}<!-- -->, b_<!-- -->{<!-- -->3<!-- -->}<!-- -->, b_<!-- -->{<!-- -->4<!-- -->}<!-- -->｝$，和4个线性组合。</p><p>$$\left\<!-- -->{<!-- -->\begin<!-- -->{<!-- -->aligned<!-- -->}<br/>x_<!-- -->{<!-- -->1<!-- -->}<!-- --> &amp;=b_<!-- -->{<!-- -->1<!-- -->}<!-- -->-2 b_<!-- -->{<!-- -->2<!-- -->}<!-- -->+b_<!-- -->{<!-- -->3<!-- -->}<!-- -->-b_<!-- -->{<!-- -->4<!-- -->}<!-- --> \\\<br/>x_<!-- -->{<!-- -->2<!-- -->}<!-- --> &amp;=-4 b_<!-- -->{<!-- -->1<!-- -->}<!-- -->-2 b_<!-- -->{<!-- -->2<!-- -->}<!-- -->+4 b_<!-- -->{<!-- -->4<!-- -->}<!-- --> \\\<br/>x_<!-- -->{<!-- -->3<!-- -->}<!-- --> &amp;=2 b_<!-- -->{<!-- -->1<!-- -->}<!-- -->+3 b_<!-- -->{<!-- -->2<!-- -->}<!-- -->-b_<!-- -->{<!-- -->3<!-- -->}<!-- -->-3 b_<!-- -->{<!-- -->4<!-- -->}<!-- --> \\\<br/>x_<!-- -->{<!-- -->4<!-- -->}<!-- --> &amp;=17 b_<!-- -->{<!-- -->1<!-- -->}<!-- -->-10 b_<!-- -->{<!-- -->2<!-- -->}<!-- -->+11 b_<!-- -->{<!-- -->3<!-- -->}<!-- -->+b_<!-- -->{<!-- -->4<!-- -->}<br/>\end<!-- -->{<!-- -->aligned<!-- -->}<!-- -->\right.$$</p><p>接下来我们该怎么判断$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, x_<!-- -->{<!-- -->3<!-- -->}<!-- -->, x_<!-- -->{<!-- -->4<!-- -->}<!-- -->｝$是否是线性无关的呢？按刚才说的方法，我们需要首先找到$λ$向量，通过$λ$向量组合成这样的矩阵：</p><p>$$\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->cccc<!-- -->}<br/>1 &amp; -4 &amp; 2 &amp; 17 \\\<br/>-2 &amp; -2 &amp; 3 &amp; -10 \\\<br/>1 &amp; 0 &amp; -1 &amp; 11 \\\<br/>-1 &amp; 4 &amp; -3 &amp; 1<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right]$$</p><p>接着，使用高斯消元法，一直到形成行阶梯型矩阵为止。高斯消元法的用法已经在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/269448">第四节课<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中详细说了，如果你有些记不清，可以回去复习一下。这里我们直接得到了行阶梯型矩阵：</p><p>$$<br/>\left[\begin<!-- -->{<!-- -->array<!-- -->}<!-- -->{<!-- -->cccc<!-- -->}<br/>1 &amp; 0 &amp; 0 &amp; -7 \\\<br/>0 &amp; 1 &amp; 0 &amp; -15 \\\<br/>0 &amp; 0 &amp; 1 &amp; -18 \\\<br/>0 &amp; 0 &amp; 0 &amp; 0<br/>\end<!-- -->{<!-- -->array<!-- -->}<!-- -->\right]<br/>$$</p><p>矩阵的最后一列不是主元列，而且你可以很直观地发现 $x_<!-- -->{<!-- -->4<!-- -->}<!-- -->=-7 x_<!-- -->{<!-- -->1<!-- -->}<!-- -->-15 x_<!-- -->{<!-- -->2<!-- -->}<!-- -->-18 x_<!-- -->{<!-- -->3<!-- -->}<!-- -->$，所以，我们可以判断 $｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, x_<!-- -->{<!-- -->3<!-- -->}<!-- -->, x_<!-- -->{<!-- -->4<!-- -->}<!-- -->｝$是线性相关的，$x_<!-- -->{<!-- -->4<!-- -->}<!-- -->$ 能由 $｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, x_<!-- -->{<!-- -->3<!-- -->}<!-- -->｝$ 的线性组合来表达。</p><p>友情提醒：已知在一个向量空间$V$中，有$k$个向量 $｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$和$m$个线性组合，如果$m&gt;k$，那么我们可以说，这$k$个向量 $｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, \ldots, x_<!-- -->{<!-- -->k<!-- -->}<!-- -->｝$ 的$m$个线性组合是线性相关的。所以，在这样的情况下，就为你省去了计算的时间。</p><h2 id="线性组合在机器学习中的应用"><a aria-hidden="true" tabindex="-1" href="/blog-base/重学线性代数/02.基础篇/06#线性组合在机器学习中的应用"><span class="icon icon-link"></span></a>线性组合在机器学习中的应用</h2><p>在了解了线性组合的概念，以及线性组合中的线性相关，特别是线性无关的判断后，我们来看一个机器学习中的实践例子，来了解一下线性组合是怎么体现在机器学习中的。</p><p>机器学习中，最经典，也是最简单的线性组合应用莫过于<strong>线性回归</strong>了。线性回归是比较常见，也是简单实用的机器学习算法，它是利用数理统计中的回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。</p><p>线性回归假设目标值与特征之间线性相关，也就是说满足一个多元一次方程。它可以通过构建“损失（loss）”函数，来求解损失函数最小时的参数$w$和$b$，也就是说，整个机器学习的过程就是通过样本数据，得到最后的参数$w$和$b$。</p><p>我们通过一个例子来看看线性回归。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimagec200c2a1d35f4175d0ff599eeedd5df2e200.b5ea965e.png" alt=""/></p><p>这是一个典型的一元线性回归模型。图中的空心圆点是真实数据点，而红线是一元线性回归模型，是用来做数据预测的，也就是$y=\omega^<!-- -->{<!-- -->T<!-- -->}<!-- --> x+b$。我们可以根据给定的$x$值通过方程式来计算$y$值。从分布在红色线周围的真实数据点来看，其实我们可以直观的得出结论：这个一元线性回归模型可以被用来很好的做预测。</p><p>线性回归在现实生活中的一个典型的应用场景是健身卡路里的燃烧预测，比如输入数据是年龄、性别、身高、体重、健身心跳、健身持久时间，而输出则是燃烧掉的卡路里。</p><p>怎么样？机器学习是不是很简单？</p><p>其实，机器学习的本质就是用数学来解决现实的问题。而很多看起来简单的数学公式可以解决很多问题，比如这里说的线性组合应用——线性回归。</p><p>我最近发现，有不少同学遇到问题，都想着怎么用复杂的机器学习算法去解决问题，特别是高大上的深度学习、神经网络之类的。但其实对于机器学习来说，算法不是越复杂越好，而是越适用越好。你可以先从简单的算法模型入手，先验证效果后，再做进一步的判断，是否需要用更复杂的算法模型。</p><h2 id="本节小结"><a aria-hidden="true" tabindex="-1" href="/blog-base/重学线性代数/02.基础篇/06#本节小结"><span class="icon icon-link"></span></a>本节小结</h2><p>好了，到这里线性无关这一讲就结束了，最后我再总结一下前面讲解的内容。</p><p>向量空间是实践的基本单位，之前都是从宏观角度出发的，而今天的知识的重点在于，我从微观角度，深入讲解了线性空间中元素之间的关系，也就是线性组合，线性组合有线性相关和线性无关，而线性无关是线性代数中最重要的概念之一。所以，你一定要掌握线性组合的概念，以及它包含的线性相关，特别是线性无关的判断方式，希望你能多练习线性组合中的线性无关的判断，为实践打好坚实的基础。</p><h2 id="线性代数练习场"><a aria-hidden="true" tabindex="-1" href="/blog-base/重学线性代数/02.基础篇/06#线性代数练习场"><span class="icon icon-link"></span></a>线性代数练习场</h2><p>练习时刻到了，今天的练习题简单一些，和之前举过的例子相似，假设我们有一组线性无关的向量$｛b_<!-- -->{<!-- -->1<!-- -->}<!-- -->, b_<!-- -->{<!-- -->2<!-- -->}<!-- -->, b_<!-- -->{<!-- -->3<!-- -->}<!-- -->, b_<!-- -->{<!-- -->4<!-- -->}<!-- -->｝$，和4个线性组合。</p><p>$$\left\<!-- -->{<!-- -->\begin<!-- -->{<!-- -->aligned<!-- -->}<br/>x_<!-- -->{<!-- -->1<!-- -->}<!-- --> &amp;=b_<!-- -->{<!-- -->1<!-- -->}<!-- -->+b_<!-- -->{<!-- -->2<!-- -->}<!-- -->-2 b_<!-- -->{<!-- -->3<!-- -->}<!-- -->-b_<!-- -->{<!-- -->4<!-- -->}<!-- --> \\\<br/>x_<!-- -->{<!-- -->2<!-- -->}<!-- --> &amp;=b_<!-- -->{<!-- -->1<!-- -->}<!-- -->+5 b_<!-- -->{<!-- -->2<!-- -->}<!-- -->-3 b_<!-- -->{<!-- -->3<!-- -->}<!-- -->-2 b_<!-- -->{<!-- -->4<!-- -->}<!-- --> \\\<br/>x_<!-- -->{<!-- -->3<!-- -->}<!-- --> &amp;=3 b_<!-- -->{<!-- -->1<!-- -->}<!-- -->-b_<!-- -->{<!-- -->2<!-- -->}<!-- -->+b_<!-- -->{<!-- -->3<!-- -->}<!-- -->+4 b_<!-- -->{<!-- -->4<!-- -->}<!-- --> \\\<br/>x_<!-- -->{<!-- -->4<!-- -->}<!-- --> &amp;=-2 b_<!-- -->{<!-- -->1<!-- -->}<!-- -->+2 b_<!-- -->{<!-- -->2<!-- -->}<!-- -->+b_<!-- -->{<!-- -->3<!-- -->}<!-- -->-b_<!-- -->{<!-- -->4<!-- -->}<br/>\end<!-- -->{<!-- -->aligned<!-- -->}<!-- -->\right.$$</p><p>请你判断$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, x_<!-- -->{<!-- -->3<!-- -->}<!-- -->, x_<!-- -->{<!-- -->4<!-- -->}<!-- -->｝$是线性无关的吗？</p><blockquote><p>友情提示：通过高斯消元法，我们能得到行阶梯型矩阵，通过行阶梯型矩阵，就可以判断$｛x_<!-- -->{<!-- -->1<!-- -->}<!-- -->, x_<!-- -->{<!-- -->2<!-- -->}<!-- -->, x_<!-- -->{<!-- -->3<!-- -->}<!-- -->, x_<!-- -->{<!-- -->4<!-- -->}<!-- -->｝$是否是线性无关的。</p></blockquote><p>欢迎你在留言区或<a target="_blank" rel="noopener noreferrer" href="https://horde.geekbang.org/channel/list/39">部落<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>里晒出你的运算过程和结果。如果有收获，也欢迎你把这篇文章分享给你的朋友。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/重学线性代数/02.基础篇/06.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 19:21:00</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-base/umi.js"></script>
  </body>
</html>
