<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-base/umi.css" />
    <script>
      window.routerBase = "/blog-base";
    </script>
    <script>
      window.publicPath = window.resourceBaseUrl || "/blog-base/";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>31 | GPU（下）：为什么深度学习需要使用GPU？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/深入浅出计算机组成原理/03.原理篇处理器/15" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-base/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>计算机基础<ul><li><a href="/blog-base/编译原理之美">编译原理之美</a></li><li><a href="/blog-base/编译原理实战">编译原理实战</a></li><li><a aria-current="page" class="active" href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/详解http">详解http</a></li><li><a href="/blog-base/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog-base/网络排查案例课">网络排查案例课</a></li><li><a href="/blog-base/linux操作系统">linux操作系统</a></li><li><a href="/blog-base/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog-base/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog-base/程序员数学基础">程序员数学基础</a></li><li><a href="/blog-base/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog-base/操作系统实战">操作系统实战</a></li><li><a href="/blog-base/软件工程之美">软件工程之美</a></li><li><a href="/blog-base/sql必知必会">sql必知必会</a></li><li><a href="/blog-base/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog-base/网络编程实战">网络编程实战</a></li><li><a href="/blog-base/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></span><span>算法<ul><li><a href="/blog-base/常用算法25讲">常用算法25讲</a></li><li><a href="/blog-base/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog-base/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog-base/动态规划面试宝典">动态规划面试宝典</a></li></ul></span><span>前端开发<ul><li><a href="/blog-base/正则表达式入门">正则表达式入门</a></li></ul></span><span>前端工程化</span><span>前端性能优化</span><span>移动端开发</span><span>软件测试</span><span>产品与用户体验</span><span>面试</span><span>杂谈<ul><li><a href="/blog-base/代码之丑">代码之丑</a></li><li><a href="/blog-base/代码精进之路">代码精进之路</a></li><li><a href="/blog-base/数据分析思维课">数据分析思维课</a></li><li><a href="/blog-base/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog-base/重学线性代数">重学线性代数</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-base/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>计算机基础<ul><li><a href="/blog-base/编译原理之美">编译原理之美</a></li><li><a href="/blog-base/编译原理实战">编译原理实战</a></li><li><a aria-current="page" class="active" href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/详解http">详解http</a></li><li><a href="/blog-base/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog-base/网络排查案例课">网络排查案例课</a></li><li><a href="/blog-base/linux操作系统">linux操作系统</a></li><li><a href="/blog-base/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog-base/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog-base/程序员数学基础">程序员数学基础</a></li><li><a href="/blog-base/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog-base/操作系统实战">操作系统实战</a></li><li><a href="/blog-base/软件工程之美">软件工程之美</a></li><li><a href="/blog-base/sql必知必会">sql必知必会</a></li><li><a href="/blog-base/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog-base/网络编程实战">网络编程实战</a></li><li><a href="/blog-base/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></li><li>算法<ul><li><a href="/blog-base/常用算法25讲">常用算法25讲</a></li><li><a href="/blog-base/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog-base/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog-base/动态规划面试宝典">动态规划面试宝典</a></li></ul></li><li>前端开发<ul><li><a href="/blog-base/正则表达式入门">正则表达式入门</a></li></ul></li><li>前端工程化</li><li>前端性能优化</li><li>移动端开发</li><li>软件测试</li><li>产品与用户体验</li><li>面试</li><li>杂谈<ul><li><a href="/blog-base/代码之丑">代码之丑</a></li><li><a href="/blog-base/代码精进之路">代码精进之路</a></li><li><a href="/blog-base/数据分析思维课">数据分析思维课</a></li><li><a href="/blog-base/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog-base/重学线性代数">重学线性代数</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇">01.入门篇</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/01"><span>开篇词 | 为什么你需要学习计算机组成原理？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/02"><span>01 | 冯·诺依曼体系结构：计算机组成的金字塔</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/03"><span>02 | 给你一张知识地图，计算机组成原理应该这么学</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/04"><span>03 | 通过你的CPU主频，我们来谈谈“性能”究竟是什么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/05"><span>04 | 穿越功耗墙，我们该从哪些方面提升“性能”？</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算">02.原理篇指令和运算</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/01"><span>05 | 计算机指令：让我们试试用纸带编程</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/02"><span>06 | 指令跳转：原来if...else就是goto</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/03"><span>07 | 函数调用：为什么会发生stack overflow？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/04"><span>08 | ELF和静态链接：为什么程序无法同时在Linux和Windows下运行？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/05"><span>09 | 程序装载：“640K内存”真的不够用么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/06"><span>10 | 动态链接：程序内部的“共享单车”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/07"><span>11 | 二进制编码：“手持两把锟斤拷，口中疾呼烫烫烫”？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/08"><span>12 | 理解电路：从电报机到门电路，我们如何做到“千里传信”？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/09"><span>13 | 加法器：如何像搭乐高一样搭电路（上）？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/10"><span>14 | 乘法器：如何像搭乐高一样搭电路（下）？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/11"><span>15 | 浮点数和定点数（上）：怎么用有限的Bit表示尽可能多的信息？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/12"><span>16 | 浮点数和定点数（下）：深入理解浮点数到底有什么用？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器">03.原理篇处理器</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/01"><span>17 | 建立数据通路（上）：指令+运算=CPU</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/02"><span>18 | 建立数据通路（中）：指令+运算=CPU</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/03"><span>19 | 建立数据通路（下）：指令+运算=CPU</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/04"><span>20 | 面向流水线的指令设计（上）：一心多用的现代CPU</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/05"><span>21 | 面向流水线的指令设计（下）：奔腾4是怎么失败的？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/06"><span>22 | 冒险和预测（一）：hazard是“危”也是“机”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/07"><span>23 | 冒险和预测（二）：流水线里的接力赛</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/08"><span>24 | 冒险和预测（三）：CPU里的“线程池”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/09"><span>25 | 冒险和预测（四）：今天下雨了，明天还会下雨么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/10"><span>26 | Superscalar和VLIW：如何让CPU的吞吐率超过1？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/11"><span>27 | SIMD：如何加速矩阵乘法？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/12"><span>28 | 异常和中断：程序出错了怎么办？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/13"><span>29 | CISC和RISC：为什么手机芯片都是ARM？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/14"><span>30 | GPU（上）：为什么玩游戏需要使用GPU？</span></a></li><li><a aria-current="page" class="active" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15"><span>31 | GPU（下）：为什么深度学习需要使用GPU？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/16"><span>32 | FPGA和ASIC：计算机体系结构的黄金时代</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17"><span>33 | 解读TPU：设计和拆解一块ASIC芯片</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/18"><span>34 | 理解虚拟机：你在云上拿到的计算机是什么样的？</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统">04.原理篇存储与IO系统</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/01"><span>35 | 存储器层次结构全景：数据存储的大金字塔长什么样？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/02"><span>36 | 局部性原理：数据库性能跟不上，加个缓存就好了？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/03"><span>37 | 高速缓存（上）：“4毫秒”究竟值多少钱？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/04"><span>38 | 高速缓存（下）：你确定你的数据更新了么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/05"><span>39 | MESI协议：如何让多核CPU的高速缓存保持一致？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/06"><span>40 | 理解内存（上）：虚拟内存和内存保护是什么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/07"><span>41 | 理解内存（下）：解析TLB和内存保护</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/08"><span>42 | 总线：计算机内部的高速公路</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/09"><span>43 | 输入输出设备：我们并不是只能用灯泡显示“0”和“1”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/10"><span>44 | 理解IO_WAIT：I/O性能到底是怎么回事儿？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/11"><span>45 | 机械硬盘：Google早期用过的“黑科技”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/12"><span>46 | SSD硬盘（上）：如何完成性能优化的KPI？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/13"><span>47 | SSD硬盘（下）：如何完成性能优化的KPI？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/14"><span>48 | DMA：为什么Kafka这么快？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/15"><span>49 | 数据完整性（上）：硬件坏了怎么办？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/16"><span>50 | 数据完整性（下）：如何还原犯罪现场？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/17"><span>51 | 分布式计算：如果所有人的大脑都联网会怎样？</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇">05.应用篇</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/01"><span>52 | 设计大型DMP系统（上）：MongoDB并不是什么灵丹妙药</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/02"><span>53 | 设计大型DMP系统（下）：SSD拯救了所有的DBA</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/03"><span>54 | 理解Disruptor（上）：带你体会CPU高速缓存的风驰电掣</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/04"><span>55 | 理解Disruptor（下）：不需要换挡和踩刹车的CPU，有多快？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/05"><span>结束语 | 知也无涯，愿你也享受发现的乐趣</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐">06.答疑与加餐</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/01"><span>特别加餐 | 我在2019年F8大会的两日见闻录</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/02"><span>FAQ第一期 | 学与不学，知识就在那里，不如就先学好了</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/03"><span>用户故事 | 赵文海：怕什么真理无穷，进一寸有一寸的欢喜</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/04"><span>FAQ第二期 | 世界上第一个编程语言是怎么来的？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/05"><span>特别加餐 | 我的一天怎么过？</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/summary">深入浅出计算机组成原理</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="Shader的诞生和可编程图形处理器" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#shader的诞生和可编程图形处理器"><span>Shader的诞生和可编程图形处理器</span></a></li><li title="现代GPU的三个核心创意" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#现代gpu的三个核心创意"><span>现代GPU的三个核心创意</span></a></li><li title="芯片瘦身" data-depth="3"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#芯片瘦身"><span>芯片瘦身</span></a></li><li title="多核并行和SIMT" data-depth="3"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#多核并行和simt"><span>多核并行和SIMT</span></a></li><li title="GPU里的“超线程”" data-depth="3"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#gpu里的超线程"><span>GPU里的“超线程”</span></a></li><li title="GPU在深度学习上的性能差异" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#gpu在深度学习上的性能差异"><span>GPU在深度学习上的性能差异</span></a></li><li title="总结延伸" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#总结延伸"><span>总结延伸</span></a></li><li title="推荐阅读" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#推荐阅读"><span>推荐阅读</span></a></li><li title="课后思考" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#课后思考"><span>课后思考</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="31--gpu下为什么深度学习需要使用gpu"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#31--gpu下为什么深度学习需要使用gpu"><span class="icon icon-link"></span></a>31 | GPU（下）：为什么深度学习需要使用GPU？</h1><p>上一讲，我带你一起看了三维图形在计算机里的渲染过程。这个渲染过程，分成了顶点处理、图元处理、 栅格化、片段处理，以及最后的像素操作。这一连串的过程，也被称之为图形流水线或者渲染管线。</p><p>因为要实时计算渲染的像素特别地多，图形加速卡登上了历史的舞台。通过3dFx的Voodoo或者NVidia的TNT这样的图形加速卡，CPU就不需要再去处理一个个像素点的图元处理、栅格化和片段处理这些操作。而3D游戏也是从这个时代发展起来的。</p><p>你可以看这张图，这是“古墓丽影”游戏的多边形建模的变化。这个变化，则是从1996年到2016年，这20年来显卡的进步带来的。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimage1dc31d098ce5b2c779392c8d3a33636673c3.dbd99857.png" alt=""/></p><p><a target="_blank" rel="noopener noreferrer" href="http://www.gamesgrabr.com/blog/2016/01/07/the-evolution-of-lara-croft/">图片来源<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><h2 id="shader的诞生和可编程图形处理器"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#shader的诞生和可编程图形处理器"><span class="icon icon-link"></span></a>Shader的诞生和可编程图形处理器</h2><p>不知道你有没有发现，在Voodoo和TNT显卡的渲染管线里面，没有“顶点处理“这个步骤。在当时，把多边形的顶点进行线性变化，转化到我们的屏幕的坐标系的工作还是由CPU完成的。所以，CPU的性能越好，能够支持的多边形也就越多，对应的多边形建模的效果自然也就越像真人。而3D游戏的多边形性能也受限于我们CPU的性能。无论你的显卡有多快，如果CPU不行，3D画面一样还是不行。</p><p>所以，1999年NVidia推出的GeForce 256显卡，就把顶点处理的计算能力，也从CPU里挪到了显卡里。不过，这对于想要做好3D游戏的程序员们还不够，即使到了GeForce 256。整个图形渲染过程都是在硬件里面固定的管线来完成的。程序员们在加速卡上能做的事情呢，只有改配置来实现不同的图形渲染效果。如果通过改配置做不到，我们就没有什么办法了。</p><p>这个时候，程序员希望我们的GPU也能有一定的可编程能力。这个编程能力不是像CPU那样，有非常通用的指令，可以进行任何你希望的操作，而是在整个的<strong>渲染管线</strong>（Graphics Pipeline）的一些特别步骤，能够自己去定义处理数据的算法或者操作。于是，从2001年的Direct3D 8.0开始，微软第一次引入了<strong>可编程管线</strong>（Programable Function Pipeline）的概念。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimage276d2724f76ffa4222eae01521cd2dffd16d.78dd0f2a.jpeg" alt=""/></p><p>早期的可编程管线的GPU，提供了单独的顶点处理和片段处理（像素处理）的着色器</p><p>一开始的可编程管线呢，仅限于顶点处理（Vertex Processing）和片段处理（Fragment Processing）部分。比起原来只能通过显卡和Direct3D这样的图形接口提供的固定配置，程序员们终于也可以开始在图形效果上开始大显身手了。</p><p>这些可以编程的接口，我们称之为<strong>Shader</strong>，中文名称就是<strong>着色器</strong>。之所以叫“着色器”，是因为一开始这些“可编程”的接口，只能修改顶点处理和片段处理部分的程序逻辑。我们用这些接口来做的，也主要是光照、亮度、颜色等等的处理，所以叫着色器。</p><p>这个时候的GPU，有两类Shader，也就是Vertex Shader和Fragment Shader。我们在上一讲看到，在进行顶点处理的时候，我们操作的是多边形的顶点；在片段操作的时候，我们操作的是屏幕上的像素点。对于顶点的操作，通常比片段要复杂一些。所以一开始，这两类Shader都是独立的硬件电路，也各自有独立的编程接口。因为这么做，硬件设计起来更加简单，一块GPU上也能容纳下更多的Shader。</p><p>不过呢，大家很快发现，虽然我们在顶点处理和片段处理上的具体逻辑不太一样，但是里面用到的指令集可以用同一套。而且，虽然把Vertex Shader和Fragment Shader分开，可以减少硬件设计的复杂程度，但是也带来了一种浪费，有一半Shader始终没有被使用。在整个渲染管线里，Vertext Shader运行的时候，Fragment Shader停在那里什么也没干。Fragment Shader在运行的时候，Vertext Shader也停在那里发呆。</p><p>本来GPU就不便宜，结果设计的电路有一半时间是闲着的。喜欢精打细算抠出每一分性能的硬件工程师当然受不了了。于是，<strong>统一着色器架构</strong>（Unified Shader Architecture）就应运而生了。</p><p>既然大家用的指令集是一样的，那不如就在GPU里面放很多个一样的Shader硬件电路，然后通过统一调度，把顶点处理、图元处理、片段处理这些任务，都交给这些Shader去处理，让整个GPU尽可能地忙起来。这样的设计，就是我们现代GPU的设计，就是统一着色器架构。</p><p>有意思的是，这样的GPU并不是先在PC里面出现的，而是来自于一台游戏机，就是微软的XBox 360。后来，这个架构才被用到ATI和NVidia的显卡里。这个时候的“着色器”的作用，其实已经和它的名字关系不大了，而是变成了一个通用的抽象计算模块的名字。</p><p>正是因为Shader变成一个“通用”的模块，才有了把GPU拿来做各种通用计算的用法，也就是<strong>GPGPU</strong>（General-Purpose Computing on Graphics Processing Units，通用图形处理器）。而正是因为GPU可以拿来做各种通用的计算，才有了过去10年深度学习的火热。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimageda93dab4ed01f50995d82e6e5d970b54c693.41052e8e.jpeg" alt=""/></p><h2 id="现代gpu的三个核心创意"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#现代gpu的三个核心创意"><span class="icon icon-link"></span></a>现代GPU的三个核心创意</h2><p>讲完了现代GPU的进化史，那么接下来，我们就来看看，为什么现代的GPU在图形渲染、深度学习上能那么快。</p><h3 id="芯片瘦身"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#芯片瘦身"><span class="icon icon-link"></span></a>芯片瘦身</h3><p>我们先来回顾一下，之前花了很多讲仔细讲解的现代CPU。现代CPU里的晶体管变得越来越多，越来越复杂，其实已经不是用来实现“计算”这个核心功能，而是拿来实现处理乱序执行、进行分支预测，以及我们之后要在存储器讲的高速缓存部分。</p><p>而在GPU里，这些电路就显得有点多余了，GPU的整个处理过程是一个<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Stream_processing">流式处理<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>（Stream Processing）的过程。因为没有那么多分支条件，或者复杂的依赖关系，我们可以把GPU里这些对应的电路都可以去掉，做一次小小的瘦身，只留下取指令、指令译码、ALU以及执行这些计算需要的寄存器和缓存就好了。一般来说，我们会把这些电路抽象成三个部分，就是下面图里的取指令和指令译码、ALU和执行上下文。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimage4c9d4c153ac45915fbf3985d24b092894b9d.5faf159c.jpeg" alt=""/></p><h3 id="多核并行和simt"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#多核并行和simt"><span class="icon icon-link"></span></a>多核并行和SIMT</h3><p>这样一来，我们的GPU电路就比CPU简单很多了。于是，我们就可以在一个GPU里面，塞很多个这样并行的GPU电路来实现计算，就好像CPU里面的多核CPU一样。和CPU不同的是，我们不需要单独去实现什么多线程的计算。因为GPU的运算是天然并行的。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimage3dac3d0859652adf9e3c0305e8e8517b47ac.d4aa0166.jpeg" alt=""/></p><p>我们在上一讲里面其实已经看到，无论是对多边形里的顶点进行处理，还是屏幕里面的每一个像素进行处理，每个点的计算都是独立的。所以，简单地添加多核的GPU，就能做到并行加速。不过光这样加速还是不够，工程师们觉得，性能还有进一步被压榨的空间。</p><p>我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/103433">第27讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>里面讲过，CPU里有一种叫作SIMD的处理技术。这个技术是说，在做向量计算的时候，我们要执行的指令是一样的，只是同一个指令的数据有所不同而已。在GPU的渲染管线里，这个技术可就大有用处了。</p><p>无论是顶点去进行线性变换，还是屏幕上临近像素点的光照和上色，都是在用相同的指令流程进行计算。所以，GPU就借鉴了CPU里面的SIMD，用了一种叫作<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads">SIMT<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>（Single Instruction，Multiple Threads）的技术。SIMT呢，比SIMD更加灵活。在SIMD里面，CPU一次性取出了固定长度的多个数据，放到寄存器里面，用一个指令去执行。而SIMT，可以把多条数据，交给不同的线程去处理。</p><p>各个线程里面执行的指令流程是一样的，但是可能根据数据的不同，走到不同的条件分支。这样，相同的代码和相同的流程，可能执行不同的具体的指令。这个线程走到的是if的条件分支，另外一个线程走到的就是else的条件分支了。</p><p>于是，我们的GPU设计就可以进一步进化，也就是在取指令和指令译码的阶段，取出的指令可以给到后面多个不同的ALU并行进行运算。这样，我们的一个GPU的核里，就可以放下更多的ALU，同时进行更多的并行运算了。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimage3d283d7ce9c053815f6a32a6fbf6f7fb9628.213cbaf4.jpeg" alt=""/></p><h3 id="gpu里的超线程"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#gpu里的超线程"><span class="icon icon-link"></span></a>GPU里的“超线程”</h3><p>虽然GPU里面的主要以数值计算为主。不过既然已经是一个“通用计算”的架构了，GPU里面也避免不了会有if…else这样的条件分支。但是，在GPU里我们可没有CPU这样的分支预测的电路。这些电路在上面“芯片瘦身”的时候，就已经被我们砍掉了。</p><p>所以，GPU里的指令，可能会遇到和CPU类似的“流水线停顿”问题。想到流水线停顿，你应该就能记起，我们之前在CPU里面讲过超线程技术。在GPU上，我们一样可以做类似的事情，也就是遇到停顿的时候，调度一些别的计算任务给当前的ALU。</p><p>和超线程一样，既然要调度一个不同的任务过来，我们就需要针对这个任务，提供更多的<strong>执行上下文</strong>。所以，一个Core里面的<strong>执行上下文</strong>的数量，需要比ALU多。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimagec9b8c971c34e0456dea9e4a87857880bb5b8.9da67276.jpeg" alt=""/></p><h2 id="gpu在深度学习上的性能差异"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#gpu在深度学习上的性能差异"><span class="icon icon-link"></span></a>GPU在深度学习上的性能差异</h2><p>在通过芯片瘦身、SIMT以及更多的执行上下文，我们就有了一个更擅长并行进行暴力运算的GPU。这样的芯片，也正适合我们今天的深度学习的使用场景。</p><p>一方面，GPU是一个可以进行“通用计算”的框架，我们可以通过编程，在GPU上实现不同的算法。另一方面，现在的深度学习计算，都是超大的向量和矩阵，海量的训练样本的计算。整个计算过程中，没有复杂的逻辑和分支，非常适合GPU这样并行、计算能力强的架构。</p><p>我们去看NVidia 2080显卡的<a target="_blank" rel="noopener noreferrer" href="https://www.techpowerup.com/gpu-specs/geforce-rtx-2080.c3224">技术规格<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，就可以算出，它到底有多大的计算能力。</p><p>2080一共有46个SM（Streaming Multiprocessor，流式处理器），这个SM相当于GPU里面的GPU Core，所以你可以认为这是一个46核的GPU，有46个取指令指令译码的渲染管线。每个SM里面有64个Cuda Core。你可以认为，这里的Cuda Core就是我们上面说的ALU的数量或者Pixel Shader的数量，46x64呢一共就有2944个Shader。然后，还有184个TMU，TMU就是Texture Mapping Unit，也就是用来做纹理映射的计算单元，它也可以认为是另一种类型的Shader。</p><p><img src="/blog-base/static/httpsstatic001geekbangorgresourceimage14e214d05a43f559cecff2b0813e8d5bdde2.da84ae33.png" alt=""/></p><p><a target="_blank" rel="noopener noreferrer" href="https://www.anandtech.com/show/13282/nvidia-turing-architecture-deep-dive/7">图片来源<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p>2080 Super显卡有48个SM，比普通版的2080多2个。每个SM（SM也就是GPU Core）里有64个Cuda Core，也就是Shader</p><p>2080的主频是1515MHz，如果自动超频（Boost）的话，可以到1700MHz。而NVidia的显卡，根据硬件架构的设计，每个时钟周期可以执行两条指令。所以，能做的浮点数运算的能力，就是：</p><p>（2944 + 184）× 1700 MHz × 2 = 10.06 TFLOPS</p><p>对照一下官方的技术规格，正好就是10.07TFLOPS。</p><p>那么，最新的Intel i9 9900K的性能是多少呢？不到1TFLOPS。而2080显卡和9900K的价格却是差不多的。所以，在实际进行深度学习的过程中，用GPU所花费的时间，往往能减少一到两个数量级。而大型的深度学习模型计算，往往又是多卡并行，要花上几天乃至几个月。这个时候，用CPU显然就不合适了。</p><p>今天，随着GPGPU的推出，GPU已经不只是一个图形计算设备，更是一个用来做数值计算的好工具了。同样，也是因为GPU的快速发展，带来了过去10年深度学习的繁荣。</p><h2 id="总结延伸"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#总结延伸"><span class="icon icon-link"></span></a>总结延伸</h2><p>这一讲里面，我们讲了，GPU一开始是没有“可编程”能力的，程序员们只能够通过配置来设计需要用到的图形渲染效果。随着“可编程管线”的出现，程序员们可以在顶点处理和片段处理去实现自己的算法。为了进一步去提升GPU硬件里面的芯片利用率，微软在XBox 360里面，第一次引入了“统一着色器架构”，使得GPU变成了一个有“通用计算”能力的架构。</p><p>接着，我们从一个CPU的硬件电路出发，去掉了对GPU没有什么用的分支预测和乱序执行电路，来进行瘦身。之后，基于渲染管线里面顶点处理和片段处理就是天然可以并行的了。我们在GPU里面可以加上很多个核。</p><p>又因为我们的渲染管线里面，整个指令流程是相同的，我们又引入了和CPU里的SIMD类似的SIMT架构。这个改动，进一步增加了GPU里面的ALU的数量。最后，为了能够让GPU不要遭遇流水线停顿，我们又在同一个GPU的计算核里面，加上了更多的执行上下文，让GPU始终保持繁忙。</p><p>GPU里面的多核、多ALU，加上多Context，使得它的并行能力极强。同样架构的GPU，如果光是做数值计算的话，算力在同样价格的CPU的十倍以上。而这个强大计算能力，以及“统一着色器架构”，使得GPU非常适合进行深度学习的计算模式，也就是海量计算，容易并行，并且没有太多的控制分支逻辑。</p><p>使用GPU进行深度学习，往往能够把深度学习算法的训练时间，缩短一个，乃至两个数量级。而GPU现在也越来越多地用在各种科学计算和机器学习上，而不仅仅是用在图形渲染上了。</p><h2 id="推荐阅读"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#推荐阅读"><span class="icon icon-link"></span></a>推荐阅读</h2><p>关于现代GPU的工作原理，你可以仔细阅读一下 haifux.org 上的这个<a target="_blank" rel="noopener noreferrer" href="http://haifux.org/lectures/267/Introduction-to-GPUs.pdf">PPT<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>，里面图文并茂地解释了现代GPU的架构设计的思路。</p><h2 id="课后思考"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15#课后思考"><span class="icon icon-link"></span></a>课后思考</h2><p>上面我给你算了NVidia 2080显卡的FLOPS，你可以尝试算一下9900K CPU的FLOPS。</p><p>欢迎在留言区写下你的答案，你也可以把今天的内容分享给你的朋友，和他一起学习和进步。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/深入浅出计算机组成原理/03.原理篇处理器/15.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 19:21:47</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-base/umi.js"></script>
  </body>
</html>
