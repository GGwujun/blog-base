<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-base/umi.css" />
    <script>
      window.routerBase = "/blog-base";
    </script>
    <script>
      window.publicPath = window.resourceBaseUrl || "/blog-base/";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>33 | 解读TPU：设计和拆解一块ASIC芯片 - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/深入浅出计算机组成原理/03.原理篇处理器/17" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-base/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>计算机基础<ul><li><a href="/blog-base/编译原理之美">编译原理之美</a></li><li><a href="/blog-base/编译原理实战">编译原理实战</a></li><li><a aria-current="page" class="active" href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/详解http">详解http</a></li><li><a href="/blog-base/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog-base/网络排查案例课">网络排查案例课</a></li><li><a href="/blog-base/linux操作系统">linux操作系统</a></li><li><a href="/blog-base/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog-base/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog-base/程序员数学基础">程序员数学基础</a></li><li><a href="/blog-base/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog-base/操作系统实战">操作系统实战</a></li><li><a href="/blog-base/软件工程之美">软件工程之美</a></li><li><a href="/blog-base/sql必知必会">sql必知必会</a></li><li><a href="/blog-base/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog-base/网络编程实战">网络编程实战</a></li><li><a href="/blog-base/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></span><span>算法<ul><li><a href="/blog-base/常用算法25讲">常用算法25讲</a></li><li><a href="/blog-base/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog-base/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog-base/动态规划面试宝典">动态规划面试宝典</a></li></ul></span><span>前端开发<ul><li><a href="/blog-base/正则表达式入门">正则表达式入门</a></li></ul></span><span>前端工程化</span><span>前端性能优化</span><span>移动端开发</span><span>软件测试</span><span>产品与用户体验</span><span>面试</span><span>杂谈<ul><li><a href="/blog-base/代码之丑">代码之丑</a></li><li><a href="/blog-base/代码精进之路">代码精进之路</a></li><li><a href="/blog-base/数据分析思维课">数据分析思维课</a></li><li><a href="/blog-base/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog-base/重学线性代数">重学线性代数</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-base/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>计算机基础<ul><li><a href="/blog-base/编译原理之美">编译原理之美</a></li><li><a href="/blog-base/编译原理实战">编译原理实战</a></li><li><a aria-current="page" class="active" href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/详解http">详解http</a></li><li><a href="/blog-base/计算机网络通关29讲">计算机网络通关29讲</a></li><li><a href="/blog-base/网络排查案例课">网络排查案例课</a></li><li><a href="/blog-base/linux操作系统">linux操作系统</a></li><li><a href="/blog-base/linux内核技术实战课">linux内核技术实战课</a></li><li><a href="/blog-base/linux性能优化实战">linux性能优化实战</a></li><li><a href="/blog-base/程序员数学基础">程序员数学基础</a></li><li><a href="/blog-base/趣谈网络协议">趣谈网络协议</a></li><li><a href="/blog-base/操作系统实战">操作系统实战</a></li><li><a href="/blog-base/软件工程之美">软件工程之美</a></li><li><a href="/blog-base/sql必知必会">sql必知必会</a></li><li><a href="/blog-base/操作系统实战45讲">操作系统实战45讲</a></li><li><a href="/blog-base/网络编程实战">网络编程实战</a></li><li><a href="/blog-base/趣谈linux操作系统">趣谈linux操作系统</a></li></ul></li><li>算法<ul><li><a href="/blog-base/常用算法25讲">常用算法25讲</a></li><li><a href="/blog-base/数据结构与算法之美">数据结构与算法之美</a></li><li><a href="/blog-base/业务开发算法50讲">业务开发算法50讲</a></li><li><a href="/blog-base/动态规划面试宝典">动态规划面试宝典</a></li></ul></li><li>前端开发<ul><li><a href="/blog-base/正则表达式入门">正则表达式入门</a></li></ul></li><li>前端工程化</li><li>前端性能优化</li><li>移动端开发</li><li>软件测试</li><li>产品与用户体验</li><li>面试</li><li>杂谈<ul><li><a href="/blog-base/代码之丑">代码之丑</a></li><li><a href="/blog-base/代码精进之路">代码精进之路</a></li><li><a href="/blog-base/数据分析思维课">数据分析思维课</a></li><li><a href="/blog-base/朱涛kotlin编程第一课">朱涛kotlin编程第一课</a></li><li><a href="/blog-base/重学线性代数">重学线性代数</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-base/深入浅出计算机组成原理">深入浅出计算机组成原理</a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇">01.入门篇</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/01"><span>开篇词 | 为什么你需要学习计算机组成原理？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/02"><span>01 | 冯·诺依曼体系结构：计算机组成的金字塔</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/03"><span>02 | 给你一张知识地图，计算机组成原理应该这么学</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/04"><span>03 | 通过你的CPU主频，我们来谈谈“性能”究竟是什么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/01.入门篇/05"><span>04 | 穿越功耗墙，我们该从哪些方面提升“性能”？</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算">02.原理篇指令和运算</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/01"><span>05 | 计算机指令：让我们试试用纸带编程</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/02"><span>06 | 指令跳转：原来if...else就是goto</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/03"><span>07 | 函数调用：为什么会发生stack overflow？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/04"><span>08 | ELF和静态链接：为什么程序无法同时在Linux和Windows下运行？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/05"><span>09 | 程序装载：“640K内存”真的不够用么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/06"><span>10 | 动态链接：程序内部的“共享单车”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/07"><span>11 | 二进制编码：“手持两把锟斤拷，口中疾呼烫烫烫”？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/08"><span>12 | 理解电路：从电报机到门电路，我们如何做到“千里传信”？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/09"><span>13 | 加法器：如何像搭乐高一样搭电路（上）？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/10"><span>14 | 乘法器：如何像搭乐高一样搭电路（下）？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/11"><span>15 | 浮点数和定点数（上）：怎么用有限的Bit表示尽可能多的信息？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/02.原理篇指令和运算/12"><span>16 | 浮点数和定点数（下）：深入理解浮点数到底有什么用？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器">03.原理篇处理器</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/01"><span>17 | 建立数据通路（上）：指令+运算=CPU</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/02"><span>18 | 建立数据通路（中）：指令+运算=CPU</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/03"><span>19 | 建立数据通路（下）：指令+运算=CPU</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/04"><span>20 | 面向流水线的指令设计（上）：一心多用的现代CPU</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/05"><span>21 | 面向流水线的指令设计（下）：奔腾4是怎么失败的？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/06"><span>22 | 冒险和预测（一）：hazard是“危”也是“机”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/07"><span>23 | 冒险和预测（二）：流水线里的接力赛</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/08"><span>24 | 冒险和预测（三）：CPU里的“线程池”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/09"><span>25 | 冒险和预测（四）：今天下雨了，明天还会下雨么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/10"><span>26 | Superscalar和VLIW：如何让CPU的吞吐率超过1？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/11"><span>27 | SIMD：如何加速矩阵乘法？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/12"><span>28 | 异常和中断：程序出错了怎么办？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/13"><span>29 | CISC和RISC：为什么手机芯片都是ARM？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/14"><span>30 | GPU（上）：为什么玩游戏需要使用GPU？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/15"><span>31 | GPU（下）：为什么深度学习需要使用GPU？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/16"><span>32 | FPGA和ASIC：计算机体系结构的黄金时代</span></a></li><li><a aria-current="page" class="active" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17"><span>33 | 解读TPU：设计和拆解一块ASIC芯片</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/18"><span>34 | 理解虚拟机：你在云上拿到的计算机是什么样的？</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统">04.原理篇存储与IO系统</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/01"><span>35 | 存储器层次结构全景：数据存储的大金字塔长什么样？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/02"><span>36 | 局部性原理：数据库性能跟不上，加个缓存就好了？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/03"><span>37 | 高速缓存（上）：“4毫秒”究竟值多少钱？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/04"><span>38 | 高速缓存（下）：你确定你的数据更新了么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/05"><span>39 | MESI协议：如何让多核CPU的高速缓存保持一致？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/06"><span>40 | 理解内存（上）：虚拟内存和内存保护是什么？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/07"><span>41 | 理解内存（下）：解析TLB和内存保护</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/08"><span>42 | 总线：计算机内部的高速公路</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/09"><span>43 | 输入输出设备：我们并不是只能用灯泡显示“0”和“1”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/10"><span>44 | 理解IO_WAIT：I/O性能到底是怎么回事儿？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/11"><span>45 | 机械硬盘：Google早期用过的“黑科技”</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/12"><span>46 | SSD硬盘（上）：如何完成性能优化的KPI？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/13"><span>47 | SSD硬盘（下）：如何完成性能优化的KPI？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/14"><span>48 | DMA：为什么Kafka这么快？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/15"><span>49 | 数据完整性（上）：硬件坏了怎么办？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/16"><span>50 | 数据完整性（下）：如何还原犯罪现场？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/04.原理篇存储与io系统/17"><span>51 | 分布式计算：如果所有人的大脑都联网会怎样？</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇">05.应用篇</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/01"><span>52 | 设计大型DMP系统（上）：MongoDB并不是什么灵丹妙药</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/02"><span>53 | 设计大型DMP系统（下）：SSD拯救了所有的DBA</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/03"><span>54 | 理解Disruptor（上）：带你体会CPU高速缓存的风驰电掣</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/04"><span>55 | 理解Disruptor（下）：不需要换挡和踩刹车的CPU，有多快？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/05.应用篇/05"><span>结束语 | 知也无涯，愿你也享受发现的乐趣</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐">06.答疑与加餐</a><ul><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/01"><span>特别加餐 | 我在2019年F8大会的两日见闻录</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/02"><span>FAQ第一期 | 学与不学，知识就在那里，不如就先学好了</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/03"><span>用户故事 | 赵文海：怕什么真理无穷，进一寸有一寸的欢喜</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/04"><span>FAQ第二期 | 世界上第一个编程语言是怎么来的？</span></a></li><li><a href="/blog-base/深入浅出计算机组成原理/06.答疑与加餐/05"><span>特别加餐 | 我的一天怎么过？</span></a></li></ul></li><li><a href="/blog-base/深入浅出计算机组成原理/summary">深入浅出计算机组成原理</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="TPU V1想要解决什么问题？" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#tpu-v1想要解决什么问题"><span>TPU V1想要解决什么问题？</span></a></li><li title="深入理解TPU V1" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#深入理解tpu-v1"><span>深入理解TPU V1</span></a></li><li title="快速上线和向前兼容，一个FPU的设计" data-depth="3"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#快速上线和向前兼容一个fpu的设计"><span>快速上线和向前兼容，一个FPU的设计</span></a></li><li title="专用电路和大量缓存，适应推断的工作流程" data-depth="3"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#专用电路和大量缓存适应推断的工作流程"><span>专用电路和大量缓存，适应推断的工作流程</span></a></li><li title="细节优化，使用8 Bits数据" data-depth="3"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#细节优化使用8-bits数据"><span>细节优化，使用8 Bits数据</span></a></li><li title="用数字说话，TPU的应用效果" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#用数字说话tpu的应用效果"><span>用数字说话，TPU的应用效果</span></a></li><li title="总结延伸" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#总结延伸"><span>总结延伸</span></a></li><li title="推荐阅读" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#推荐阅读"><span>推荐阅读</span></a></li><li title="课后思考" data-depth="2"><a href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#课后思考"><span>课后思考</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="33--解读tpu设计和拆解一块asic芯片"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#33--解读tpu设计和拆解一块asic芯片"><span class="icon icon-link"></span></a>33 | 解读TPU：设计和拆解一块ASIC芯片</h1><p>过去几年，最知名、最具有实用价值的ASIC就是TPU了。各种解读TPU论文内容的文章网上也很多。不过，这些文章更多地是从机器学习或者AI的角度，来讲解TPU。</p><p>上一讲，我为你讲解了FPGA和ASIC，讲解了FPGA如何实现通过“软件”来控制“硬件”，以及我们可以进一步把FPGA设计出来的电路变成一块ASIC芯片。</p><p>不过呢，这些似乎距离我们真实的应用场景有点儿远。我们怎么能够设计出来一块有真实应用场景的ASIC呢？如果要去设计一块ASIC，我们应该如何思考和拆解问题呢？今天，我就带着你一起学习一下，如何设计一块专用芯片。</p><h2 id="tpu-v1想要解决什么问题"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#tpu-v1想要解决什么问题"><span class="icon icon-link"></span></a>TPU V1想要解决什么问题？</h2><p>黑格尔说，“世上没有无缘无故的爱，也没有无缘无故的恨”。第一代TPU的设计并不是异想天开的创新，而是来自于真实的需求。</p><p>从2012年解决计算机视觉问题开始，深度学习一下子进入了大爆发阶段，也一下子带火了GPU，NVidia的股价一飞冲天。我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/105401">第31讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>讲过，GPU天生适合进行海量、并行的矩阵数值计算，于是它被大量用在深度学习的模型训练上。</p><p>不过你有没有想过，在深度学习热起来之后，计算量最大的是什么呢？并不是进行深度学习的训练，而是深度学习的推断部分。</p><p>所谓<strong>推断部分</strong>，是指我们在完成深度学习训练之后，把训练完成的模型存储下来。这个存储下来的模型，是许许多多个向量组成的参数。然后，我们根据这些参数，去计算输入的数据，最终得到一个计算结果。这个推断过程，可能是在互联网广告领域，去推测某一个用户是否会点击特定的广告；也可能是我们在经过高铁站的时候，扫一下身份证进行一次人脸识别，判断一下是不是你本人。</p><p>虽然训练一个深度学习的模型需要花的时间不少，但是实际在推断上花的时间要更多。比如，我们上面说的高铁，去年（2018年）一年就有20亿人次坐了高铁，这也就意味着至少进行了20亿次的人脸识别“推断“工作。</p><p>所以，第一代的TPU，首先优化的并不是深度学习的模型训练，而是深度学习的模型推断。这个时候你可能要问了，那模型的训练和推断有什么不同呢？主要有三个点。</p><p>**第一点，深度学习的推断工作更简单，对灵活性的要求也就更低。**模型推断的过程，我们只需要去计算一些矩阵的乘法、加法，调用一些Sigmoid或者RELU这样的激活函数。这样的过程可能需要反复进行很多层，但是也只是这些计算过程的简单组合。</p><p>**第二点，深度学习的推断的性能，首先要保障响应时间的指标。**我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/93246">第4讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>讲过，计算机关注的性能指标，有响应时间（Response Time）和吞吐率（Throughput）。我们在模型训练的时候，只需要考虑吞吐率问题就行了。因为一个模型训练少则好几分钟，多的话要几个月。而推断过程，像互联网广告的点击预测，我们往往希望能在几十毫秒乃至几毫秒之内就完成，而人脸识别也不希望会超过几秒钟。很显然，模型训练和推断对于性能的要求是截然不同的。</p><p><strong>第三点，深度学习的推断工作，希望在功耗上尽可能少一些</strong>。深度学习的训练，对功耗没有那么敏感，只是希望训练速度能够尽可能快，多费点电就多费点儿了。这是因为，深度学习的推断，要7×24h地跑在数据中心里面。而且，对应的芯片，要大规模地部署在数据中心。一块芯片减少5%的功耗，就能节省大量的电费。而深度学习的训练工作，大部分情况下只是少部分算法工程师用少量的机器进行。很多时候，只是做小规模的实验，尽快得到结果，节约人力成本。少数几台机器多花的电费，比起算法工程师的工资来说，只能算九牛一毛了。</p><p>这三点的差别，也就带出了第一代TPU的设计目标。那就是，在保障响应时间的情况下，能够尽可能地提高<strong>能效比</strong>这个指标，也就是进行同样多数量的推断工作，花费的整体能源要显著低于CPU和GPU。</p><h2 id="深入理解tpu-v1"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#深入理解tpu-v1"><span class="icon icon-link"></span></a>深入理解TPU V1</h2><h3 id="快速上线和向前兼容一个fpu的设计"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#快速上线和向前兼容一个fpu的设计"><span class="icon icon-link"></span></a>快速上线和向前兼容，一个FPU的设计</h3><p>如果你来设计TPU，除了满足上面的深度学习的推断特性之外，还有什么是你要重点考虑的呢？你可以停下来思考一下，然后再继续往下看。</p><p>不知道你的答案是什么，我的第一反应是，有两件事情必须要考虑，第一个是TPU要有向前兼容性，第二个是希望TPU能够尽早上线。我下面说说我考虑这两点的原因。</p><p><img src="/images/httpsstatic001geekbangorgresourceimagef65ef6637990792e8de1ef84891fadd11e5e.png" alt=""/></p><p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/ftp/arxiv/papers/1704/1704.04760.pdf">图片来源<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p>第一代的TPU就像一块显卡一样，可以直接插在主板的PCI-E口上</p><p>第一点，向前兼容。在计算机产业界里，因为没有考虑向前兼容，惨遭失败的产品数不胜数。典型的有我在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/102888">第26讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>提过的安腾处理器。所以，TPU并没有设计成一个独立的“CPU“，而是设计成一块像显卡一样，插在主板PCI-E接口上的板卡。更进一步地，TPU甚至没有像我们之前说的现代GPU一样，设计成自己有对应的取指令的电路，而是通过CPU，向TPU发送需要执行的指令。</p><p>这两个设计，使得我们的TPU的硬件设计变得简单了，我们只需要专心完成一个专用的“计算芯片”就好了。所以，TPU整个芯片的设计上线时间也就缩短到了15个月。不过，这样一个TPU，其实是第26讲里我们提过的387浮点数计算芯片，是一个像FPU（浮点数处理器）的协处理器（Coprocessor），而不是像CPU和GPU这样可以独立工作的Processor Unit。</p><h3 id="专用电路和大量缓存适应推断的工作流程"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#专用电路和大量缓存适应推断的工作流程"><span class="icon icon-link"></span></a>专用电路和大量缓存，适应推断的工作流程</h3><p>明确了TPU整体的设计思路之后，我们可以来看一看，TPU内部有哪些芯片和数据处理流程。我在文稿里面，放了TPU的模块图和对应的芯片布局图，你可以对照着看一下。</p><p><img src="/images/httpsstatic001geekbangorgresourceimage6aae6a14254b2bda4dd42adac6a2129e8bae.jpeg" alt=""/></p><p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/ftp/arxiv/papers/1704/1704.04760.pdf">图片来源<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p>模块图：整个TPU的硬件，完全是按照深度学习一个层（Layer）的计算流程来设计的</p><p>你可以看到，在芯片模块图里面，有单独的矩阵乘法单元（Matrix Multiply Unit）、累加器（Accumulators）模块、激活函数（Activation）模块和归一化/池化（Normalization/Pool）模块。而且，这些模块是顺序串联在一起的。</p><p>这是因为，一个深度学习的推断过程，是由很多层的计算组成的。而每一个层（Layer）的计算过程，就是先进行矩阵乘法，再进行累加，接着调用激活函数，最后进行归一化和池化。这里的硬件设计呢，就是把整个流程变成一套固定的硬件电路。这也是一个ASIC的典型设计思路，其实就是把确定的程序指令流程，变成固定的硬件电路。</p><p>接着，我们再来看下面的芯片布局图，其中控制电路（Control）只占了2%。这是因为，TPU的计算过程基本上是一个固定的流程。不像我们之前讲的CPU那样，有各种复杂的控制功能，比如冒险、分支预测等等。</p><p>你可以看到，超过一半的TPU的面积，都被用来作为Local Unified Buffer（本地统一缓冲区）（29%）和矩阵乘法单元（Matrix Mutliply Unit）了。</p><p>相比于矩阵乘法单元，累加器、实现激活函数和后续的归一/池化功能的激活管线（Activation Pipeline）也用得不多。这是因为，在深度学习推断的过程中，矩阵乘法的计算量是最大的，计算也更复杂，所以比简单的累加器和激活函数要占用更多的晶体管。</p><p>而统一缓冲区（Unified Buffer），则由SRAM这样高速的存储设备组成。SRAM一般被直接拿来作为CPU的寄存器或者高速缓存。我们在后面的存储器部分会具体讲。SRAM比起内存使用的DRAM速度要快上很多，但是因为电路密度小，所以占用的空间要大很多。统一缓冲区之所以使用SRAM，是因为在整个的推断过程中，它会高频反复地被矩阵乘法单元读写，来完成计算。</p><p><img src="/images/httpsstatic001geekbangorgresourceimage082a08e29a700898e5dabf60fbf0f026082a.jpeg" alt=""/></p><p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/ftp/arxiv/papers/1704/1704.04760.pdf">图片来源<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p><p>芯片布局图：从尺寸可以看出，统一缓冲区和矩阵乘法单元是TPU的核心功能组件</p><p>可以看到，整个TPU里面，每一个组件的设计，完全是为了深度学习的推断过程设计出来的。这也是我们设计开发ASIC的核心原因：用特制的硬件，最大化特定任务的运行效率。</p><h3 id="细节优化使用8-bits数据"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#细节优化使用8-bits数据"><span class="icon icon-link"></span></a>细节优化，使用8 Bits数据</h3><p>除了整个TPU的模块设计和芯片布局之外，TPU在各个细节上也充分考虑了自己的应用场景，我们可以拿里面的矩阵乘法单元（Matrix Multiply Unit）来作为一个例子。</p><p>如果你仔细一点看的话，会发现这个矩阵乘法单元，没有用32 Bits来存放一个浮点数，而是只用了一个8 Bits来存放浮点数。这是因为，在实践的机器学习应用中，会对数据做<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Normalization">归一化<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>（Normalization）和<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">正则化<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>（Regularization）的处理。咱们毕竟不是一个机器学习课，所以我就不深入去讲什么是归一化和正则化了，你只需要知道，这两个操作呢，会使得我们在深度学习里面操作的数据都不会变得太大。通常来说呢，都能控制在-3到3这样一定的范围之内。</p><p>因为这个数值上的特征，我们需要的浮点数的精度也不需要太高了。我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/98312">第16讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>讲解浮点数的时候说过，32位浮点数的精度，差不多可以到1/1600万。如果我们用8位或者16位表示浮点数，也能把精度放到2^6或者2^12，也就是1/64或者1/4096。在深度学习里，常常够用了。特别是在模型推断的时候，要求的计算精度，往往可以比模型训练低。所以，8 Bits的矩阵乘法器，就可以放下更多的计算量，使得TPU的推断速度更快。</p><h2 id="用数字说话tpu的应用效果"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#用数字说话tpu的应用效果"><span class="icon icon-link"></span></a>用数字说话，TPU的应用效果</h2><p>那么，综合了这么多优秀设计点的TPU，实际的使用效果怎么样呢？不管设计得有多好，最后还是要拿效果和数据说话。俗话说，是骡子是马，总要拿出来溜溜啊。</p><p>Google在TPU的论文里面给出了答案。一方面，在性能上，TPU比现在的CPU、GPU在深度学习的推断任务上，要快15～30倍。而在能耗比上，更是好出30～80倍。另一方面，Google已经用TPU替换了自家数据中心里95%的推断任务，可谓是拿自己的实际业务做了一个明证。</p><h2 id="总结延伸"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#总结延伸"><span class="icon icon-link"></span></a>总结延伸</h2><p>这一讲，我从第一代TPU的设计目标讲起，为你解读了TPU的设计。你可以通过这篇文章，回顾我们过去32讲提到的各种知识点。</p><p>第一代TPU，是为了做各种深度学习的推断而设计出来的，并且希望能够尽早上线。这样，Google才能节约现有数据中心里面的大量计算资源。</p><p>从深度学习的推断角度来考虑，TPU并不需要太灵活的可编程能力，只要能够迭代完成常见的深度学习推断过程中一层的计算过程就好了。所以，TPU的硬件构造里面，把矩阵乘法、累加器和激活函数都做成了对应的专门的电路。</p><p>为了满足深度学习推断功能的响应时间短的需求，TPU设置了很大的使用SRAM的Unified Buffer（UB），就好像一个CPU里面的寄存器一样，能够快速响应对于这些数据的反复读取。</p><p>为了让TPU尽可能快地部署在数据中心里面，TPU采用了现有的PCI-E接口，可以和GPU一样直接插在主板上，并且采用了作为一个没有取指令功能的协处理器，就像387之于386一样，仅仅用来进行需要的各种运算。</p><p>在整个电路设计的细节层面，TPU也尽可能做到了优化。因为机器学习的推断功能，通常做了数值的归一化，所以对于矩阵乘法的计算精度要求有限，整个矩阵乘法的计算模块采用了8 Bits来表示浮点数，而不是像Intel CPU里那样用上了32 Bits。</p><p>最终，综合了种种硬件设计点之后的TPU，做到了在深度学习的推断层面更高的能效比。按照Google论文里面给出的官方数据，它可以比CPU、GPU快上15～30倍，能耗比更是可以高出30～80倍。而TPU，也最终替代了Google自己的数据中心里，95%的深度学习推断任务。</p><h2 id="推荐阅读"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#推荐阅读"><span class="icon icon-link"></span></a>推荐阅读</h2><p>既然要深入了解TPU，自然要读一读关于TPU的论文<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/ftp/arxiv/papers/1704/1704.04760.pdf">In-Datacenter Performance Analysis of a Tensor Processing Unit<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p><p>除了这篇论文之外，你也可以读一读Google官方专门讲解TPU构造的博客文章 <a target="_blank" rel="noopener noreferrer" href="https://cloud.google.com/blog/products/gcp/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu">An in-depth look at Google’s first Tensor Processing Unit(TPU)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p><h2 id="课后思考"><a aria-hidden="true" tabindex="-1" href="/blog-base/深入浅出计算机组成原理/03.原理篇处理器/17#课后思考"><span class="icon icon-link"></span></a>课后思考</h2><p>你能想一想，如果我们想要做一个能够进行深度学习模型训练的TPU，我们应该在第一代的TPU的设计之上做怎么样的修改呢？</p><p>欢迎留言和我分享你的想法。如果这篇文章对你有收获，你也可以把他分享给你的朋友。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/深入浅出计算机组成原理/03.原理篇处理器/17.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/23 18:45:53</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-base/umi.js"></script>
  </body>
</html>
