exports.category = 'algorithm'
exports.title = '常用算法25讲'
exports.data = [
  {
    chapterTitle: "开篇词 (1讲)",
    children: [
      {
        title: "开篇词 | 解决这三个误区，才能真正学好算法！",
        herf: "https://time.geekbang.org/column/article/274522",
        id: "274522",
        content:
          '<p>你好，我是胡光。欢迎来到我的算法课！</p>\n<p>我曾经是百度高级算法研发工程师。在百度期间，我开发了部门内部的第一版推理引擎，并顺利在人物关系推理等应用场景中落地实施。</p>\n<p>说起来，我的算法之路很早就开始了。高中上大学，我靠的是算法竞赛的保送名额。大学期间，我还参加了ACM国际大学生程序设计大赛，拿到了亚洲区金牌，进过两次 ACM 全球总决赛。可以这么说，我的算法知识，是在激烈的竞赛环境中积累起来的。</p>\n<p>现在，我是一名教育行业的创业者，我非常希望能向和我一样热爱算法、热爱编程的你，分享我的经验。所以，在2019年开设了<a href="https://time.geekbang.org/column/intro/100043901">《人人都能学会的编程入门课》</a>之后，时隔一年，我又带来了《常用算法25讲》。</p>\n<p>算法到底有多重要，这已经是一个老生常谈的话题了。我相信，你在看这个课程之前，肯定也看过非常多的文章，这些文章都从不同的角度告诉你，为什么要学算法，以及怎么学。但你真的学会了吗？</p>\n<p>就像有很多的学生，在和我学习算法之前，会问我这几个问题：</p>\n<ul>\n<li>我知道算法很重要，但是工作中好像总也用不到。</li>\n<li>我为了面试学算法，刷了那么多题，遇到新题还是不会怎么办？</li>\n<li>这么多算法知识，总是学了又忘，忘了又学，怎么才算学会呢？</li>\n</ul>\n<p>如果你也有同样的疑问，那说明你真没学好算法。想要学好算法，我们必须要纠正几个误区。</p>\n<h2>误区一：学算法就是为了面试，工作中根本没用</h2>\n<p>很多大厂的面试都要考算法，所以很多人学算法，就只是为了面试，他们把算法当成了一种应用技术。这会导致我们在学算法的时候，只关注能不能用某个算法解决某个问题。当解决不了这个问题的时候，算法自然就显得“没用”了。</p>\n<p>可我想说，有些知识的学习是面向当下的。例如，我想用命令操作一个服务器，那我学习相关命令的使用就行了，不用去了解操作系统底层。而有些知识的学习，是面向未来的，就像算法学习。</p>\n<p>为了更形象地说明这一点，我想给你讲一个建筑工人村头老王的故事。首先，我想问你一个问题，如果我让你盖一个“茅草屋”，你会做些什么准备？你会去学习建筑艺术，还是去学习相关的计算机设计软件，又或者是去了解相关知识？</p>\n<p>如果你真的去盖了房子，就会发现这些准备都是无用的。因为即便是村头的“王大爷”，在不了解这些专业知识的情况下，也能用现有的材料，给你盖一个像样的茅草屋。那么问题来了，会盖茅草屋就等于懂建筑吗？当然不是。因为我们重复盖20次茅草屋，也盖不出 20 层楼。所以，<strong>知识有没有用，主要是看你要实现的目标是什么</strong>。</p>\n<p>如果你要实现的目标，就是盖一个茅草屋，那么建筑学相关的知识很多都是用不上的，凭感觉盖就行了。而如果你的目标是盖20层的高楼，那你真的需要花很多时间来学习大量的理论知识。理论与实践永远都是相辅相成的，没有理论的实践会丧失高度，没有实践的理论也会变得空洞无用。</p>\n<p>编程或者说我们的程序设计之路，就像是去盖这20层高楼，我们必须要学习大量的基础理论知识才能走得更稳，算法就是其中非常重要的基石。</p>\n<h2>误区二：学数据结构和算法 = 走“弯路”</h2>\n<p>抛开面试，我们再来谈谈工作。</p>\n<p>在 IT 企业中流传着一句老话：大公司造轮子，小公司用轮子。越是大型的互联网公司，自己造的轮子越多。因此，<strong>快速掌握行业知识的能力，也是我们必须要具备的核心竞争力。这都是建立在拥有大量专业基础知识之上的。</strong></p>\n<p>如果说应用知识标记了你在行业跑道中的距离，基础知识就是你在行业跑道中的加速度。一个加速度大的人，即便他在一开始是落后的，通过几年的发展，最终也会赶上那些起点很高，但速度很慢的人。</p>\n<p>可是很多人并不注重基础知识。举个简单的例子，我教过一些学生，他们在最开始学习写代码的时候，就是把代码写出来而已。一旦他们的代码运行出错，就会跑过来问我到底是怎么回事儿。因为他们认为，写代码就是写代码，找代码的错误就是在“<strong>走弯路</strong>”。可实际上，<strong>写代码的目标并不是把代码写出来，而是用代码将逻辑正确地表达出来</strong>。只有找到自己代码中的错误，才能使自己的代码能力真正得到增长。</p>\n<p>这其实也是我们学习数据结构和算法的意义。换句话说，我们要根据数据的性质，用一套合适的计算流程把它们写到计算机中，然后表达出我们想要的逻辑。</p>\n<p>总的来说，我认为，<strong>在学习中犯错不是在走弯路，学习基础知识也不是在走弯路，而正是这些所谓的“弯路”才是通往行业核心的真正捷径</strong>。所以我说的捷径，其实就是在学习过程中，多给自己一些耐心、努力，找对真正有用的学习方法。这也是我做这门课的初衷。想想我们将来要面对的几十年行业生涯，除了学习应用技术外，多花几个月时间在基础知识的学习上，我觉得一点儿都不多，甚至很划算。</p>\n<h2>误区三：算法我自己能学，没必要跟老师学</h2>\n<p>有些同学可能会问，那算法一定要跟着老师学吗？在回答这个问题之前，我想先问你一个事儿：去肯德基点东西的时候，如果多点一个蛋挞会让你这顿饭吃得更满足，你会不会点？我想咱们的答案应该是一样的，肯定会点。</p>\n<p>其实肯德基这个例子，就已经回答了最开始的问题，需要跟老师学么？答案就是，不冲突。咱们假设，你现在可选的学习方式有：看技术博客 + 看书学习。那么所谓的跟老师学习，不是剥夺了你看技术博客和看书学习的权利，而是作为你现有学习方法的一种补充。老师的作用，也不是单纯的知识灌输。一个好的老师，最主要的作用，是帮助你抓住学习重点，帮助你规范你的训练方法，帮助你提高学习效率。</p>\n<p>所以，跟着老师学习，是对你现有学习方法的补充。如果你自己就能学好，那么跟着一个老师学，肯定会学得更好。只是，你需要选择一个好的老师。尤其是计算机领域的好老师，需要理论和实战两手抓两手硬，这就非常难找。如果你真的碰到了好老师，跟他学，准没错的。</p>\n<h2>这门课是怎么设计的？</h2>\n<p>那说了这么多，我们其实还是要落回到怎么学算法这个话题上。我认为，学算法最重要的不是学习这个算法是什么或者刷题目，而是要学习这类算法，具体的设计过程。就像你到了健身房里面，你要做的第一件事情不是马上去举铁，而是要找个健身教练问问每一块肌肉的训练方法，这是我们肌肉训练的框架。</p>\n<p>算法训练也是有这种框架的。举个例子，很多同学认为动态规划算法很难学，那是因为他们训练动态规划算法的方式错了。如果他们幻想通过多刷几道题目，就能掌握动态规划算法，就会像进入健身房试图直接举铁的健身小白一样，十有八九都会失败。</p>\n<p>设计动态规划算法，一般可以分成三步走：状态定义、推导动归方程和程序编写。其中最难的，就是准确地理解状态定义。可以说，搞定了状态定义，也就搞定了动态规划算法。所以，我们没必要盲目刷题，只需要在解决一道题目的同时，从中不断加强我们对于动态规划三个部分的理解深度就行了。</p>\n<p>最后，你一定要记住，<strong>学习算法最重要的，是学习算法的设计过程，而不是算法本身</strong>。</p>\n<p>以上这些，其实就是我们课程的核心设计思想。接下来，我就和你说说这门课程是如何设计的。</p>\n<p>我希望这门算法课，能带你学习最常用、最实用的算法知识，教给你相关算法的高效学习方法，让你从不懂算法或者不了解算法，到掌握算法，并且拥有自学算法的能力。因此，我特意选择了在实际工作中经常会被用到的三类算法，分别是排序算法、查找算法与搜索算法。我们的课程也因此分为三个部分：<strong>排序篇</strong>、<strong>查找搜索篇和进阶篇</strong>。</p>\n<h3>排序篇</h3>\n<p>我会从快速排序算法、快排优化、快速选择算法，讲到堆排序、归并排序，以及由这些排序延伸出来的一些趣味算法。我希望你从中学会的不是单一的算法，而是这些排序算法中所映射出来的思维方式。毕竟，<strong>掌握算法思维，才是算法学习的重中之重</strong>。</p>\n<p>基于此，针对每个算法，我会搭配一些经典的面试题，给你详细讲解它能解决的问题、算法流程、优化拓展，以及它所需要的数据结构基础。时间复杂度我也会讲，但因为它涉及非常多的公式推导，所以我不会详细去讲。我的建议是，等你的算法能力掌握到一定程度之后，再学不迟。</p>\n<p>除此之外，我还会带你从0到1一起封装一个线程池，让你体会程序设计的全过程。</p>\n<h3>查找搜索篇</h3>\n<p>查找部分，我主要会给你讲两种非常重要，也是工作中最常用的数据结构：<strong>红黑树与哈希表</strong>。学好这两种数据结构，能更好地理解和使用语言中给我们准备好的相关功能模块。</p>\n<p>为了让你更好地理解红黑树，我会从最基础的排序二叉树入手，由浅入深带你学习。并且我对于网上现有的红黑树代码做了优化，帮助你大幅度降低了红黑树的编码学习难度，只要你跟着学，我保证这是全网最简单、易学的红黑树教程。</p>\n<p>关于哈希表，我会重点带你学习哈希表的映射思想，也就是其中的哈希操作。对于如何设计哈希函数这个哲学问题，我也会跟你深入讨论一下。</p>\n<p>搜索算法部分，我也会结合迷宫问题，来讲两种经典，并且非常基础的搜索算法，<strong>深度优先搜索</strong>和<strong>广度优先搜索</strong>。保证你学起来不枯燥。</p>\n<h3>进阶篇</h3>\n<p>我会带你综合运用我们所学的内容，一起来求解数独游戏、2-Sum 问题、计算sqrt。而且，我还会给你分享一种比系统自带的 sqrt 更快的函数。除此之外，我还给你准备了一个有挑战的毕业设计，就是设计一个用 O(1) 时间复杂度计算数字末尾 0 的个数的程序。你可不要小看这个问题，这个问题会用到你在算法课程中学到的全部知识，包括所有的算法及程序设计方面的技巧。做好准备，和我一起做点儿有挑战的事情吧！</p>\n<p><img src="https://static001.geekbang.org/resource/image/40/fd/40585f63142e002f4e09d531db032afd.jpg" alt="" /></p>\n<p>最后，我想说，算法学习，就跟你进健身房一样，要学会正确的锻炼方法，还需要不断地训练巩固。这是一个不断挑战你“智力+毅力”的过程，也是算法的价值所在。你需要明白一个道理，算法没有会或者不会一说，只有程度深、浅一说。坚持锻炼算法思维的你，总会比那个曾经的你要更强，那你究竟选择拥抱哪个自己呢？这不是算法难或者简单的问题，而是你自己如何选择的问题。</p>\n<p>还等什么？快加入和我一起学算法吧！</p>\n',
        article_title: "开篇词 | 解决这三个误区，才能真正学好算法！",
      },
    ],
  },
  {
    chapterTitle: "排序篇 (12讲)",
    children: [
      {
        title: "01 | 理解快排：打通算法学习的任督二脉",
        herf: "https://time.geekbang.org/column/article/270342",
        id: "270342",
        content:
          '<p>你好，我是胡光。今天是第一节课，我们来聊聊快速排序。</p>\n<p>排序算法在工作中最常用，也是学习很多其他算法的前置知识，例如在运用二分查找算法之前，我们通常需要保证数据是有序的，如果数据无序，我们还要对数据进行排序。在程序员的面试中，排序算法也经常会配合其他算法进行综合考察，比如经典的 2-sum 问题，就需要在一组无序数字中，找到两个数字相加之和等于目标值，其中一种做法就是先对数据进行排序，然后采用头尾指针扫描法来解决。所以，想要学好数据结构与算法，掌握排序算法是第一步。</p>\n<p><span class="orange">今天，我就给你出一道和排序算法有关的题目：假设给你一组无序的数字，让你找到其中排名第 k 位的数字。你会怎么做？</span></p>\n<p>这道题最简单的解决办法，就是利用选择排序算法，对这组数字进行排序。选择排序的过程如下图所示：</p>\n<p><img src="https://static001.geekbang.org/resource/image/54/51/548a151516dac98bd1fdb1d0c8723f51.jpg" alt="" /></p>\n<p>具体来说就是，用选择排序算法将数组中的元素，分成已排序区与待排序区。然后，每一轮从待排序区中选择一个最小值元素，放到已排序区的末尾，也就是待排序区的头部。这样，每一次的选择操作，都会使已排序区的长度增加一位，那经过 n-1 轮选择操作以后，整个数组就是一个有序数组了。</p>\n<p>因此，如果我们想找到排名第 k 位的元素，只需要做 $k$ 次选择操作就可以了。这种做法的时间复杂度是 $O(k*n) $，当 k 值接近 $n / 2$ 的时候，时间复杂度就是 $O(n^2/2) $。</p>\n<p>为了更快地解决今天的这个问题，今天我会给你讲一种经典的排序算法，<strong>快速排序</strong>（Quicksort）算法。</p>\n<p>快速排序是一种优秀的排序算法。这一点毫无疑问，可并不代表这种排序算法就是无敌的，它也有自己的问题。所以在工程实现中，我们往往使用的都是混合排序算法，例如 C++ STL 的 sort，使用的就是“<strong>快速排序+插入排序+堆排序</strong>”的方式。因此，面对算法学习，永远不要功利心太重，因为你永远不会知道，你抛弃掉的是什么样的伟大思想。</p>\n<p>除了快速排序算法以外，下节课我还会给你讲一种由快速排序算法所延伸出来的，叫做<strong>快速选择</strong>（Quick Selection）的算法。快速选择算法将是解决我们今天这个问题的终极利器。</p>\n<p>在这里，我希望你能记住一点，从今天开始，我们所讲的所有问题，都不止一种解决方案。就像今天这个问题，虽说快速选择算法是我们最后要讲的方法，可实际上，学习了快速排序以后，你也可以既快又好地解决这个问题，只不过使用快速选择会比快速排序更好而已。</p>\n<h2>理解快速排序算法的核心思想</h2>\n<p>基础的快速排序算法思想很简单，核心就是一句话：<strong>找到基准值的位置</strong>。</p>\n<p>具体的过程其实和把大象装进冰箱这个问题一样，都可以分成三步：第一步，选择一个值作为基准值；第二步，找到基准值的位置，并将小于基准值的元素放在基准值的前面，大于基准值的元素放在基准值的后面；第三步，对基准值的左右两侧递归地进行这个过程。这么说还是很抽象，下面我一步一步来给你讲解。</p>\n<p>第一步，<strong>选择一个值作为基准值</strong>。最简单的选择方法，一定是选择待排序区间的头部元素作为基准值。如下图所示，我们选择 8 作为本轮排序的基准值。</p>\n<p><img src="https://static001.geekbang.org/resource/image/c5/c2/c5aeb573fd47e58e1a8b74e79f503ec2.jpg" alt="" /></p>\n<p>确定了本轮操作的基准值以后，快速排序的第二步，就是<strong>将小于基准值的元素放在基准值的前面，将大于基准值的元素放在基准值的后面</strong>。这一步通常被叫做 <strong>partition</strong> 操作，中文直译过来就是分割操作，也就是用基准值将原数组分割成前后两部分。</p>\n<p>理解了 partition 操作的目的以后，我们再来讨论它具体是怎么做的。partition 操作简单来说，<strong>就是空出一个位置，反复地前后调换元素</strong>。这该怎么理解呢？首先，你要理解一点，当我们选择了基准值以后，原先基准值的位置就相当于被空出来了，也就是说数组的第一位是空着的。</p>\n<p><img src="https://static001.geekbang.org/resource/image/2e/11/2e43506d0d8516bce42393c0612cf911.jpg" alt="" /></p>\n<p>如果第一位是空的，那剩下的事儿就好办了。我们借助这个空位，将后面小于基准值的元素放到前面的空位上，这样后面就空出一位了。然后，我们再将前面大于基准值的元素放到后面这个空位上。就这样交替进行，直到空位前面的值都小于基准值，空位后面的值都大于基准值为止。过程如下图所示：</p>\n<p><img src="https://static001.geekbang.org/resource/image/ce/56/ce5d08f986007bf3b0e178d8d0445856.jpg" alt="" /></p>\n<p><strong>快速排序的第三步，是对基准值的左右两侧，递归地进行第一步和第二步</strong>。也就是说，我们要分别对 6、3、7、2 和 10、9、12 这两部分，再做选择基准值、找基准值位置和递归这三步。由于每次 partition 操作中，我们都会确定一个值，也就是基准值的正确位置，所以，经过有限次递归操作以后，整个数组也就变成了一个有序数组。</p>\n<p>当然，像上面这样的描述是不严谨的，但它确实是正确的。而且严谨的证明过程太过复杂，我就不详细来说了，如果你还记得数学归纳法和递归程序之间的关系，可以试着用它来证明快速排序算法的正确性。</p>\n<h2>分析快速排序的时间复杂度</h2>\n<p>看完了快速排序的算法过程，我们再来分析一下快速排序的时间复杂度。我会借助二叉树的结构，来帮助你理解和分析快速排序算法的时间复杂度。</p>\n<p>在讲快速排序算法过程的时候，我们说其中最关键的步骤是理解  parition 操作。因此，分析快速排序的时间复杂度，我们也要先来分析  partition 操作这一步的时间复杂度。</p>\n<p>在partition 操作的过程中，头指针会循环扫描到基准值最后放置的位置，尾指针也会扫描到最后基准值放置的位置。这样，头尾指针扫描加在一起，其实相当于扫描了整个待排序数组的区域。因此，我们就能得出单次 partition 操作的时间复杂度为 O(n)。也就是说，当前数组区间中有 10 个元素时，我们大概操作10 次就能找到<strong>基准值的位置</strong>了。清楚了单次操作的时间复杂度以后，我们就能知道总体的时间复杂度了。</p>\n<p>首先，我们要确定总体时间复杂度的公式。我们用 <code>T(n)</code>表示对 <code>n</code>个元素的数组进行快速排序所用的时间，那么 T(n)中应该包括了单次的 partition 操作用时，以及 parition 操作以后，我们对左右两个子数组分别做快速排序所用的时间，也就是 <code>T(n) = n + T(L) + T(R)</code>。其中 <code>n</code>是单次 partition 操作的用时，<code>T(L)</code>和 <code>T(R)</code>分别是对左右区间进行快速排序的用时，<code>L</code> 和 <code>R</code>分别代表左区间和右区间中元素的数量。</p>\n<p><img src="https://static001.geekbang.org/resource/image/03/e0/0396fd48cee04847bd335b9b6ecddee0.jpg" alt="" /></p>\n<p>接着，我们借助二叉树的结构来求一下T(n) 。首先，我们可以将基准值看成是由 n 个元素组成的二叉树的根节点，那么partition 操作就是找到这个根节点的正确位置，总用时就是 n。如果我们将这个用时 n  当做二叉树根节点的独立用时，那么左子树根节点的独立用时就是 L，右子树根节点的独立用时就是 R。这样，我们就得到了这个二叉树第二层上所有节点的独立用时：L + R = n - 1。我们可以将这个值大致看成是 n。依照此方法，你会得到接下来各层二叉树节点的独立用时，关系如图所示：</p>\n<p><img src="https://static001.geekbang.org/resource/image/0b/88/0b7b917d6e9a691305c272cd23442f88.jpg" alt="" /></p>\n<p>其中，每个节点上的数值代表了这个节点的独立用时。 n = L + R + 1，L = LL + LR + 1， R = RL + RR + 1。这也就意味着，第一层上节点的独立用时总和是 n，第二层上节点的独立用时总和是 L + R = n - 1，第三层上节点的独立用时总和是 LL + LR + RL + RR = n - 3。</p>\n<p>其实，如果n足够大，那每一层上的所有节点的独立用时总和，我们都可以让其约等于 n。那快速排序的总用时，就可以约等于 n 乘上树的层数，也就是树的高度。因此，这棵树的高度越低，快速排序的效率越好，而树的高度越高，快速排序的效率也就越差。这样一来，我们就让树高这个直观的量和快速排序的效率有了概念上的关联。因此，我们只需要分析树高，就能分析清楚快速排序的执行效率了。</p>\n<p>那针对有n个节点的二叉树（每个节点代表一个基准值，n 个节点就代表确定了 n 个基准值的位置），我们该怎么确定树高的范围呢？稍微一分析，你会发现，树高最低是 $\\log_{2}{(n+1)}$ ，也就是每个节点的左右两棵子树，所包含节点数量都差不多。这就意味着，我们每次选择基准值的时候，都要尽可能选择处在待排序数组中间的数字。也只有这样，快速排序算法才会达到最好的时间复杂度，也就是 $O(nlog_{2}{n})$。</p>\n<p>结合二叉树的结构，我们分析了快速排序的最好时间复杂度。而快速排序的最坏时间复杂度是O(n^2) ，这又是怎么得到呢？ 你可以参考我的这种方法自己做下分析。从中你就能体会到：<strong>数据结构的价值，在于其思维逻辑结构层面的价值。</strong></p>\n<p>总的来说，上面关于时间复杂度的分析，虽然不是一个严谨的时间复杂度分析过程，可却是一个有效且正确的分析方法。所以，如果你之后有遇到相关算法，完全可以直接应用这样的方法去加深理解。</p>\n<p>那现在，你再想想课程一开始给你出的那道题，是不是很容易就能解出来了？过程很简单，我就不细说了，不过，你可以想想使用快速排序解决这个问题的时间复杂度是什么样的。</p>\n<h2>课程小结</h2>\n<p>今天，我们讲了快速排序的核心的思想，也结合二叉树的结构一起分析了快排的时间复杂度。在这里，我希望你记住两件事情。</p>\n<p>第一，<strong>理解partition 操作，是理解快速排序算法的关键</strong>。如果你还没搞懂partition 操作的话，我建议你多花些时间把它搞清楚，这绝对是值得的。</p>\n<p>第二，<strong>想要理解快排的时间复杂度，最有效的途径就是掌握二叉树分析法</strong>。其实这种分析方法，不仅可以用于分析我们今天所讲的快速排序算法，后面，当我们讲到归并排序算法的时候也能用得上。甚至可以说，掌握这种思维方式，是打通你算法与数据结构任督二脉的必经之路。</p>\n<h2>课后练习</h2>\n<p>最后，我教你一招儿快速检验学习成果的方法，你可以试着把快速排序算法是什么，它的核心思想等等，用最简洁的语言讲给你身边不会快速排序的人听，只要他能听懂，遇到简述快速排序算法的面试题，你就不会有任何问题了。</p>\n<p>好了，今天就到这里了，你理解快排了吗？那你的朋友们理解快排吗？如果它对你有帮助，欢迎你把今天的内容，分享给你的朋友们。我是胡光，我们下节课见！</p>\n<hr />\n<p><a href="https://github.com/alicia-ying/wang.git">课后参考代码</a></p>\n',
        article_title: "01 | 理解快排：打通算法学习的任督二脉",
      },
      {
        title: "02 | 快排优化：举一反三，轻松面对快排面试题",
        herf: "https://time.geekbang.org/column/article/274591",
        id: "274591",
        content:
          '<p>你好，我是胡光，欢迎回来。今天我们来聊聊快排算法的升级。</p>\n<p>我们知道，用快速排序算法在一堆无序的数字中查找第k位元素，需要先对原数字序列快速排序以后，才能输出第k位元素。这样整体的时间复杂度，如果控制得好的话，可以达到 $O(nlogn)$，但是这个方法存在2个问题。</p>\n<p>首先，我们是想求排名第 k 位的元素，又不是真的想对整体序列进行排序。如果对全部数学序列进行快排，我们实际上<strong>做了大量的无用操作，这会导致算法效率很低</strong>。其次，快速排序算法的时间复杂度不稳定，很有可能退化到最坏的时间复杂度$O(n^2)$。</p>\n<p><span class="orange">那有没有不需要排序，且效率更高的做法呢？或者，就算依然要使用快速排序算法，我们要如何才能让它的时间复杂度大概率稳定在$O(nlogn)$呢？</span></p>\n<p>今天，我们就带着这两个问题，来继续查找第k位的元素。</p>\n<p>针对第一个问题，我们可以使用快速选择算法解决。快速选择算法是基于快速排序算法的一种拓展算法，它可以在不对数据整体进行排序的前提下，快速找到排名第 k 位的元素，而且时间复杂度还能优化到 $O(n)$。而对于第二个问题，我会给你讲几种快速排序中的优化方法。这些优化方法，会使你应对快速排序相关的面试题的时候，更加游刃有余。</p>\n<h2>理解快速选择算法的核心原理</h2>\n<p>首先，我们来看快速选择算法。快速选择算法的基本思想是，当我们需要快速找到一个元素 X，并且使得小于 X 的元素数量是 k-1 个时，那 X 就是我们要查找的排名第 k 位的元素了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/b6/82/b60bfb2e6121cb7c52982fyy00f97782.jpg" alt="" /></p>\n<p>这也就意味着，我们没必要对原数组进行整体排序，只需要找到满足上面我们所说条件的元素 $X$ 即可。这一点你有没有觉得很熟悉？没错，这和 partition 过程很像。partition 过程就是在每一轮排序中找到一个基准值元素的正确位置 ind ，并且它最厉害的地方在于，它会用基准值将数组分成前后两部分，小于等于基准值的元素在前面，大于等于基准值的元素在后面。</p>\n<p>那我们是不是可以用 partition 过程实现快速选择呢？接下来，让我们先来分析一轮 partition 过后，基准值元素的排名 ind 与 k 之间的关系。我把可能出现的三种情况都列了出来：</p>\n<ul>\n<li>如果 ind 正好等于 k，那说明<strong>当前的基准值，就是我们要找的排名第 k 位的元素</strong>；</li>\n<li>如果 ind 大于 k，说明排名第 k 位的元素在基准值的前面。接下来，我们要解决的问题就是，<strong>在基准值的前面查找排名第 k 位的元素</strong>；</li>\n<li>如果 ind 小于 k ，就说明排名第 k 位的元素在基准值的后面，并且，当前包括基准值在内的 ind 个元素，都是小于基准值的元素。那么，问题就转化成了，<strong>在基准值的后面查找排名第 k - ind 位的元素</strong>。</li>\n</ul>\n<p>这么说你可能还不是特别理解，下面，我们再结合下面的示意图理解一下。假设本轮基准值为 X，绿色区域中的值均小于 X，蓝色区域中的值都大于 X，基准值的位置是 ind。当 k &lt; ind 时，下一轮我们就在绿色区域中继续查找，当 k &gt; ind 时，下一轮我们就在蓝色区域中继续查找。这个过程，其实有点儿类似于二分查找的思想。</p>\n<p><img src="https://static001.geekbang.org/resource/image/a8/2c/a84ae8e49de8c73fyye2d3753e71852c.jpg" alt="" /></p>\n<p>也就是说，经过一轮 partition 操作以后，我们总能将<strong>在当前数组中查找排名第 k 位元素</strong>的问题，转化成递归子问题。也就是<strong>在基准值的前面查找排名第 k 位的元素，<strong>或者</strong>在基准值的后面查找排名第 k - ind 位的元素</strong>。</p>\n<p>那快速选择算法的时间复杂度究竟是多少呢？分析起来很简单，你可以自己试试。为了便于你验证自己的分析结果，先给你个结论：<strong>快速选择算法的时间复杂度，最好情况是 $O(n)$ ，最坏情况是 $O(n^2) $，平均情况是 $O(n)$</strong> 。并且，为了让快速选择算法能够发挥得更稳定，我们需要在选择基准值的时候做一些优化。具体优化方法，你可以参考快排优化中的基准值选择优化，我们马上就会讲到了。</p>\n<h2>三种快排优化</h2>\n<p>以前我在做面试官的时候，当问到面试者会不会快速排序，他们都会回答：会。但如果我让他们说一下快速排序的内容，80% 的面试者都只能说出快速排序的基础知识，也就是我们上节课讲过的内容，只有 20% 的人能说出快排的优化内容。当然了，能说出这20%内容的人面试分数就会相对更高。</p>\n<p>那么为了让你对快排的理解更加深刻，也在面试的时候能多一些“谈资”，我会给你讲三个比较常见的快排优化，分别是<strong>单边递归优化、基准值选取优化</strong>和<strong>partition 操作优化</strong>。</p>\n<h3>优化一：单边递归优化</h3>\n<p>第一个优化被形象地称为：单边递归优化。这是什么意思呢？</p>\n<p>我们知道，在快排函数的实现过程中，当本层完成了 partition 操作以后，剩余的工作就是等待着左边和右边的排序完成。代码如下所示：</p>\n<pre><code>quick_sort(arr, l, x - 1); // 对左半边排序\nquick_sort(arr, x + 1 , r); // 对右半边排序\n</code></pre>\n<p>这段代码就分别对基准值的左右两边进行了排序的递归调用。从程序的运行时间来考虑的话，我们每次函数调用，都会消耗掉一部分运行时间。那只要我们可以<strong>减少函数调用的次数</strong>，其实就可以加快一点程序运行的速度。</p>\n<p>因此，单边递归优化的方式，就是当本层完成了 partition 操作以后，让本层继续完成基准值左边的 partition 操作，而基准值右边的排序工作交给下一层递归函数去处理。</p>\n<p><img src="https://static001.geekbang.org/resource/image/f5/5e/f5f8c3de54e917a5f11d706b95e4f35e.jpg" alt="" /></p>\n<p>经过单边递归优化后生成的递归树如上图所示，为了方便你理解，我把在同一个函数调用内的操作用同样的颜色表示。一共用了黄色、红色、蓝色、绿色这4种颜色，也就是说我们实际调用了4次函数。而如果不采用单边递归法，实际发生的函数调用次数就是图中二叉树的节点个数，也就是7次。可见，我们采用了单边递归法以后，函数实际调用次数减少了一半。</p>\n<p>下面是一段单边递归法的代码：</p>\n<pre><code>void quick_sort(int *arr, int l, int r) {\n    while (l &lt; r) {\n        // 进行一轮 partition 操作\n        // 获得基准值的位置\n        int ind = partition(arr, l, r);\n        // 右侧正常调用递归函数 \n        quick_sort(arr, ind + 1, r);\n        // 用本层处理左侧的排序\n        r = ind - 1;\n    }\n    return ;\n}\n</code></pre>\n<p>从代码中可知，l 和 r 是数组中待排序的区间范围，ind 是本轮 partition 操作后基准值的位置。当找到基准值的位置以后，对于右侧从 ind + 1 到 r 位置，我们就正常调用递归函数。然后，我们通过将 r 设置为 ind - 1，直接利用本层 while 循环逻辑，继续对左侧进行 partition 等相关排序操作。</p>\n<h3>优化二：基准值选取优化</h3>\n<p>说完了单边递归，我们接着来说<strong>快排中对于基准值选取的优化</strong>。我们知道，如果基准值选取不合理的话，快速排序的时间复杂度有可能达到 $O(n^2)$ 这个量级，也就是退化成和选择排序、插入排序等算法一样的时间复杂度。只有当基准值每次都能将排序区间中的数据平分时，时间复杂度才是最好情况下的 $O(nlogn)$。</p>\n<p>当然，我们没有办法在一个无序数组中，用 $O(1)$的时间复杂度找到一个可以将数组平分的基准值。退而求其次，我们能不能尽可能地找到一个可以大概率将数组平分的数字呢？这就是接下来我要给你讲的，关于基准值选取的一个优化策略，三点取中法。</p>\n<p><img src="https://static001.geekbang.org/resource/image/c4/d8/c4a0920318d94089bd516cf2925bfdd8.jpg" alt="" /></p>\n<p>所谓<strong>三点取中法</strong>，就是每一轮取排序区间的头、尾和中间元素这三个值，然后把它们排序以后的中间值作为本轮的基准值。当然，你也可以根据自己的理解，调整要选取的这三个值的位置。我们就以上图为例，假设本轮的三个值分别为2、9、7，中间值是7，所以，本轮的基准值就是 7。</p>\n<p>在实际应用中，由于基准值选择不合理而陷入最差情况的概率，我们利用三点取中法就已经可以大幅度降低了。而且，这种方法实现起来也比较简单，所以 C++ STL 中的 sort 实现，其实就是采用的这种基准值选择优化策略。</p>\n<h3>优化三：partition 操作优化</h3>\n<p>前面我们讲的两种优化方法，分别是从<strong>递归代码结构</strong>和<strong>基准值选取</strong>这两方面对快速排序做了优化。下面，我再给你讲一种对 partition 代码实现过程进行优化的方法。这种优化方法很容易被我们忽略。那它到底是怎么优化的呢？</p>\n<p>在说它之前，我们先来回顾一下 partition 的实现过程：先从后向前找个小于基准值的数字放到前面，再从前向后找个大于基准值的数字放到后面，直到首尾指针相遇为止。其实，想要比较容易地理解这个过程，我们可以假设基准值的位置是数组中间的一条分割线，小于基准值的都是绿色元素，大于基准值的都是红色元素。如下图所示：</p>\n<p><img src="https://static001.geekbang.org/resource/image/21/63/21e86e947647e20ffe293f6ca07ca063.jpg" alt="" /></p>\n<p>这个时候，你可以想一想，在什么情况下，我们才需要将基准值后面的元素调换到前面？一定是因为这个分割线后面有绿色的元素。而且，基准值的客观位置不变，红色与绿色元素数量是确定的，所以存在多少个绿色元素在基准值位置的后面，就一定存在多少个红色元素在基准值位置的前面。</p>\n<p><img src="https://static001.geekbang.org/resource/image/a4/71/a4yy570ae32ca1d612d34cc7bbaaa071.jpg" alt="" /></p>\n<p>那 partition 操作的目的，就是要把基准值位置后面的绿色元素调整到前面，将基准值位置前面的红色元素调整到后面。也就是交换上图中 1、2 号元素的位置。既然需要调换的红色与绿色元素的数量相同，我们就可以让头指针向后查找红色元素，尾指针向前查找绿色元素，然后交换头尾指针所指向的元素，重复这个过程，直到头尾指针交错后停止。这就是对partition 操作进行的优化。</p>\n<h2>课程小结</h2>\n<p>这节课，我们讲了快速选择算法，和针对快速排序算法的三种优化。这里，我希望你能记住4件事情：</p>\n<ol>\n<li>快速选择算法可以用来快速查找一个序列中排名第 k 位的元素；</li>\n<li>单边递归法可以使快排过程中的递归调用次数减少一半，并且，这种优化方法也可以使用在所有和快速排序类似的程序结构中；</li>\n<li>三点取中法能帮助我们选出更加合理的基准值，保证快速排序的运行效率；</li>\n<li>优化 partition 的操作，通过减少程序实现中的比较操作，来提高程序的运行效率。</li>\n</ol>\n<p>其中，关于快速排序的三种优化方法中，第二种优化，是为了使快速排序的时间复杂度尽量稳定在 $O(nlogn)$ 而提出来的，而第一种和第三种优化，没有对时间复杂度做优化，而是对程序的实际运行时间做了优化。对于实际工作而言，往往第一种和第三种优化，对我们的启发会更大一些。毕竟，公司内部的一个成型的技术或者产品中，能让你优化时间复杂度的部分可太少了。大多数时候我们能做的，就是切实可行地让系统运行得更快一些。</p>\n<p>另外，我还要补充一点。在使用快速选择算法求解排名第 k 位的元素的过程中，其实当我们通过快速选择算法求得了第 k 位的元素值之后，再加上第 k 位元素值之前的元素，其实就找到了前 k 位的元素值。换句话说，快速选择算法不仅可以用于求解第 k 位的元素，也可以用于求解前 k 小或者前 k 大元素等问题，也就是所谓的 Top-K 问题。</p>\n<p>如果你要参加面试，Top-K 问题也是经常被问到的一类问题。之后遇到具体问题的时候，我会详细来讲。</p>\n<h2>课后练习</h2>\n<ol>\n<li>\n<p>请你参考partition 方法的优化代码，想想为什么这样的 partition 实现方法会比我们上节课实现的 parition 方法更优化。这里我给你个提示，这个新的 partition 实现方法，比旧的 partition 方法做了更少的比较操作，那具体少了多少呢？请你分析以后，把思考结果留在评论区中吧！</p>\n</li>\n<li>\n<p>你知道快速选择算法的时间复杂度是怎么得到的吗？你可以借助上节课我们讲的二叉树的方法来试着分析一下。</p>\n</li>\n</ol>\n<p>好了，今天就到这里了。如果你的朋友也正在为快排优化的问题而头疼，那就快把这篇文章分享给他吧！我是胡光，我们下节课见！</p>\n<hr />\n<p><a href="https://github.com/alicia-ying/wang.git">课后参考代码</a></p>\n',
        article_title: "02 | 快排优化：举一反三，轻松面对快排面试题",
      },
      {
        title: "03 | 二叉堆：动态维护集合最值的利器",
        herf: "https://time.geekbang.org/column/article/275747",
        id: "275747",
        content:
          '<p>你好，我是胡光，欢迎回来。今天，我们开始学习<strong>堆排序</strong>（Heapsort）。</p>\n<p>堆排序是利用堆这种数据结构完成的排序。所以，在了解堆排序之前，我们需要先了解“堆（Heap）”这种数据结构。可以说，在维护集合最值的操作上，堆是一种简单、易懂、且非常高效的数据结构。</p>\n<p>那我们先来看一个比较经典的堆问题：蚂蚁问题。</p>\n<p><span class="orange">假设现在有一个水平面，上面有8只蚂蚁排成一排。方便起见，我们给所有的蚂蚁从左到右依次编号，编号为 1 到 8。从0秒开始，红色蚂蚁向左爬，蓝色蚂蚁向右爬，爬行的速度都是1m/s。如果有 2 只蚂蚁迎面碰到以后，这 2 只蚂蚁不会做任何的感情交流，而会立刻掉头向相反方向继续爬行。而爬行到桌子边沿的蚂蚁，会从桌子上掉下去。问：有哪些蚂蚁会从左边掉下去，又有哪些蚂蚁会从右边掉下去？</span></p>\n<p><img src="https://static001.geekbang.org/resource/image/63/56/63881947b2354832c4260463c022e456.jpg" alt="" /></p>\n<p>如果你是第一次看到这个问题，肯定会有点儿懵，不知道从何下手解决。不过没关系，我会先一点一点地帮你补足堆相关的基础知识，然后咱们再一起解决这个问题。那我们就先从最基础的二叉堆开始讲起吧！</p>\n<h2>理解完全二叉树基础</h2>\n<p>既然要讲堆这种结构，就离不开一种特殊的二叉树，也就是完全二叉树（Complete Binary Tree）。因为堆就是一种具有特殊性质的完全二叉树。什么是完全二叉树呢？完全二叉树是由满二叉树去掉最后一层右侧的若干节点而形成的二叉树结构。这么说你可能没概念，你可以直接看我在下面中给出的示例，它就是一个包含 6 个节点的完全二叉树。</p>\n<p><img src="https://static001.geekbang.org/resource/image/be/f2/be70f37ca4ab58fbdcf3d01dd1b5c3f2.jpg" alt="" /></p>\n<p>完全二叉树有一个很优秀的性质，<strong>就是可以被存储在一片连续的数组空间中</strong>。这怎么理解呢？还是看上面这个示意图，如果我们对它的每个节点进行编号，采用从上到下、从左到右的顺序依次标上 1 到 6。那么你仔细观察其中父节点编号与子节点编号之间的关系就会发现，如果父节点编号是 i，其左孩子的编号就是2 * i，右孩子的编号就是2 * i + 1。例如，我们以3号节点作为父节点，其左孩子的编号就是 2 * 3 = 6 号，如果有右孩子，那它右孩子的编号就一定是 2 * 3 + 1 = 7。</p>\n<p>我们再继续深入思考，在一棵有 n 个节点的完全二叉树中，节点编号应该为 1 到 n。这样，我们就可以使用数组的 1 到 n 位对应于这 n 个节点。由于完全二叉树父节点与子节点编号之间的特殊计算关系，因此只要我们知道父节点编号，就可以通过计算得到子节点编号。</p>\n<p>这就意味着，即使我们将完全二叉树的所有数据，存储在一个连续的数组空间中，也不会破坏其特殊的树形结构信息。也就是说，一棵完全二叉树可以对应到一段连续的数组空间，而根据数组空间的内容，我们也可以唯一地还原成一棵完全二叉树。</p>\n<p>如图所示，这就是完全二叉树与数组的对应关系。</p>\n<p><img src="https://static001.geekbang.org/resource/image/97/00/9754d1c6579002df4ba6ca5894509300.jpg" alt="" /></p>\n<p>实际上，在计算机中，我们会把数组作为完全二叉树的实际存储结构，而完全二叉树，则是我们重新看待这段数组信息的思维逻辑结构。因此，数据结构最大的价值，就是对我们思维逻辑结构的改造。</p>\n<h2>堆结构的定义</h2>\n<p>有了完全二叉树这种思维逻辑结构的加持以后，接下来你就可以很轻松地掌握堆这种结构了。堆可以分为两类，小顶堆和大顶堆。</p>\n<p>如果在一棵完全二叉树中，每个父节点的值都要小于其两个子节点的值，我们就管这种结构叫做小顶堆。相对应地，大顶堆就是每个父节点的值要大于其两个子节点的值。今天呢，咱们主要拿小顶堆做说明，因为小顶堆学会了，大顶堆自然不在话下。下图就是一个小顶堆的示意图。</p>\n<p><img src="https://static001.geekbang.org/resource/image/be/37/be5a6957yyc34996239ef34745489537.jpg" alt="" /></p>\n<p>根据小顶堆的性质定义，我们可以轻松得知，小顶堆中的最小值一定放在了根节点，也就是存储在数组中的第一个位置。如果我们将数组中的所有元素看成一个集合的话，那小顶堆的作用就非常明显了，就是维护这个集合中的最小值。</p>\n<p>为了让你更好地学习堆这种数据结构，我要和你分享一个学习数据结构的公式：数据结构=结构定义+结构操作。结构定义和结构操作是组成数据结构最重要的两个部分，也是你之后在学任何一种数据结构时的重点内容。结构定义就是定义一种性质，结构操作就是维护这种性质。</p>\n<p>那现在我们已经知道了堆这种结构的结构定义，下面，我们再来看看堆这种结构支持的两种最基本的结构操作：<strong>插入新元素</strong>和<strong>删除最值元素</strong>。那在详细讲解堆的两种基本结构操作之前，我希望你先牢牢记住一点：<strong>堆的实际存储结构是数组，<strong>这个数组</strong>是一段从下标 1 开始的连续存储空间</strong>。记住这一点之后，我们再接着往下看。</p>\n<h2>堆的插入操作</h2>\n<p>首先，我们来讲堆的插入操作。如图所示，假设我们想要在堆中放入一个新的元素 1，那么我们可以将这个新的元素，放置到整个数组的最后一位。对应到完全二叉树的思维逻辑结构中，就是向树中的最后一层添加了一个新的叶节点。</p>\n<p><img src="https://static001.geekbang.org/resource/image/0d/ee/0de0a63918eabaea63846eab343b62ee.jpg" alt="" /></p>\n<p>这一步的操作叫做<strong>元素放置</strong>。你会看到这么做之后，数组的结构就不满足小顶堆的性质了。所以下一步，我们要调整数组的结构，让它依然满足堆的性质。</p>\n<p>由于堆的性质定义中，只规定了父节点与子节点之间的大小关系，所以，我们的调整操作只需要维护父子节点之间的大小关系即可。也就是说，新插入的元素 1，只需要和其父节点进行比较。</p>\n<p>结合上面的示意图，我来说一下具体的操作。由于 1 比 4 小，所以我们把1 交换到 4 的位置，然后让1再继续向上跟当前的父节点比较。因为1比 2 小，所以再让它们交换。这一步叫做<strong>向上调整</strong>，它的原理就是在当前元素值小于其父节点值的时候，交换子节点与父节点值的位置，就这样一直向上调整，直到当前节点大于父节点的值或者调整到了堆顶。</p>\n<p>这样一来，经过<strong>元素放置</strong>  以及 2 次 <strong>向上调整</strong> 以后，堆中就增加了一个新元素，还依然满足堆的性质定义。这样，我们就完成了向堆中插入元素的操作。具体过程如图所示：</p>\n<p><img src="https://static001.geekbang.org/resource/image/56/44/56ca8f6bf9c294d085bbba9a0be0d544.jpg" alt="" /></p>\n<h2>堆的删除最值操作</h2>\n<p>看完了堆的插入操作以后，下面我们再来看看堆的删除操作。</p>\n<p>首先，我们要知道，堆的删除操作是有局限性的，这怎么理解呢？我们可以从删除操作的定义入手。堆的删除操作也叫做<strong>删除最值元素</strong>，对小顶堆进行删除操作就是删除最小的元素，其实就是删除数组中第一位的元素。</p>\n<p>那为了保证删除最值元素以后，整个堆结构的存储还是从数组的第 1 位开始的，所以我们第一步要做的就是<strong>元素覆盖</strong>，也就是用堆的最后一位元素，覆盖掉堆顶元素。</p>\n<p><img src="https://static001.geekbang.org/resource/image/1b/b5/1bc73192812611ceefd3bf2f2c1709b5.jpg" alt="" /></p>\n<p>这里呢，我们就接着前面插入元素后的结果，来继续删除元素。从上图中你可以看到，我们使用数组中的最后一个元素 4，覆盖了堆顶元素 1。接下来，我们就需要通过适当调整，让它重新满足堆的性质。调整的方法其实也很简单，就是从堆顶位置开始，每次从当前元素所在三元组中找到一个最小值，与当前元素交换。交换后，让当前位置的元素继续和下面两个元素比较，如果这个三元组中依然有最小值，那我们就继续<strong>向下调整</strong>，直到当前元素是三元组中的最小值为止。操作过程非常简单，你看下面的示意图就可以理解了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/2e/ab/2e41d9d82610ecba8e3df50fb3531dab.jpg" alt="" /></p>\n<p>于是，针对这个小顶堆，我们通过 1 次 <strong>元素覆盖</strong> 和 1次 <strong>向下调整</strong>，就完成了删除最值元素的操作。到这里，我们就学完了二叉堆最基础，也是最重要的两个操作：插入和删除。是不是很简单？</p>\n<h2>拓展内容：优先队列</h2>\n<p>讲完了堆这种数据结构以后，我还想给你讲讲<strong>优先队列</strong>（Priority Queue)。</p>\n<p>首先，我们先来回想一下堆实际的存储结构和结构操作。之前我们说过，它其实就是一个数组，在插入元素时，从数组的末尾放入元素，而删除元素时，是从数组的头部移出元素。</p>\n<p><img src="https://static001.geekbang.org/resource/image/ec/d2/ecb6760c6f8yy2cb1def10ff63972bd2.jpg" alt="" /></p>\n<p>如果你学习过队列这种结构，肯定能想到，堆的特点其实和队列类似。队列结构就是从尾部入元素，从头部出元素。而且堆这种结构，每次从头部移出的都是当前堆中的最值元素。所以，如果我们把堆的存储结构看成是一个队列的话，那堆就是一种可以灵活控制元素出队优先级的数据结构，我们管这种结构就叫做优先队列。</p>\n<p>可能你会好奇，优先队列好像就是堆的别名啊？其实不然。你可以把优先队列当成是一种概念，那它的定义就是一种可以实现根据优先级出队的结构。而堆只是实现优先队列的其中一种方式，当然也是最普遍的方式。所以，在之后的课程中，我们所说的优先队列将特指用堆实现的优先队列。</p>\n<p>关于优先队列的实现，我在这节课的最后用 C 语言实现了一下，你可以参考一下我的代码。</p>\n<p>到这里，我们就讲完了和堆有关的基础知识。那现在，你能解出课程一开始的蚂蚁问题了吗？我给你一个提示，想要解决这个问题，一种最容易想到的方法就是模拟蚂蚁们的行进过程。你可以想想怎么利用堆来模拟这个过程。至于具体怎么解决，我会在下节课告诉你。</p>\n<h2>课程小结</h2>\n<p>今天，我们学习了堆这种数据结构的性质及相关操作。</p>\n<p>首先，堆是一种特殊的完全二叉树，它可以分为两类，分别是大顶堆和小顶堆。在小顶堆中，每个父节点的值都要小于其两个子节点的值，大顶堆则相反。</p>\n<p>其次，堆有两种基本的结构操作，插入操作和删除最值操作。在插入操作中，我们是将新元素放到整个堆结构的末尾，然后对新插入的元素执行向上调整的操作，一直调整到满足堆的结构性质为止。而在删除操作中，我们是将堆顶元素弹出以后，再将堆的尾部元素移动到堆顶，对其执行向下调整的操作，一直调整到满足堆的结构性质为止。</p>\n<p>此外，我们还知道了，堆是实现优先队列的其中一种方式，优先队列每次出队的元素，都是队列中优先级最大的值。</p>\n<p>最后，我希望你要牢牢记住一句话：堆是用来维护集合最值的高效数据结构。在后续的文章中，我还会帮你深入理解这一句话，让你能够活学活用堆这种数据结构。</p>\n<h2>课后练习</h2>\n<p>在你的生活中，有哪些场景下的问题可以抽象成维护集合最值的问题？欢迎把你的答案写在留言区。</p>\n<p>好了，今天就到这里。我是胡光，我们下节课见。</p>\n<hr />\n<p><a href="https://github.com/alicia-ying/jikeshijian.git">课后参考代码</a></p>\n',
        article_title: "03 | 二叉堆：动态维护集合最值的利器",
      },
      {
        title: "04 | 堆排序：体会线性建堆法的威力",
        herf: "https://time.geekbang.org/column/article/277193",
        id: "277193",
        content:
          '<p>你好，我是胡光，欢迎回来。</p>\n<p>上节课，我们讲了堆这种维护集合中最值的高效数据结构，也留下了一道经典的算法题，蚂蚁问题。这节课，我们一起来看看怎么利用堆来解决它。</p>\n<p>我们先回顾一下上节课的问题。</p>\n<p><span class="orange">假设现在有一个水平面，上面有8只蚂蚁排成一排，我把这张示意图放在了文稿中。方便起见，我们给所有的蚂蚁从左到右依次编号，编号为 1 到 8。从0秒开始，红色蚂蚁向左爬，蓝色蚂蚁向右爬，爬行的速度都是1m/s。如果有 2 只蚂蚁迎面碰到以后，这 2 只蚂蚁不会做任何的感情交流，而是会立刻掉头向相反方向继续爬行。而爬行到桌子边沿的蚂蚁，会从桌子上掉下去。问：有哪些蚂蚁会从左边掉下去，又有哪些蚂蚁会从右边掉下去？</span></p>\n<p><img src="https://static001.geekbang.org/resource/image/63/56/63881947b2354832c4260463c022e456.jpg" alt="" /></p>\n<h2>怎么解决蚂蚁问题？</h2>\n<p>要搞定蚂蚁问题，首先你需要把自己带入到问题场景中，只有充分理解了问题场景，才能更好地解决这个问题。下图是一个蚂蚁问题的具体场景：</p>\n<p><img src="https://static001.geekbang.org/resource/image/63/56/63881947b2354832c4260463c022e456.jpg" alt="" /></p>\n<p>从图中我们可以看出，2、3 号蚂蚁会相撞，5、6 号蚂蚁会相撞，7、8号蚂蚁也会相撞。因为相撞以后的两只蚂蚁的方向会改变，所以 2、3 号蚂蚁相撞以后，2 号蚂蚁会向着 1 号蚂蚁所在的方向行进，3号蚂蚁会向着4号蚂蚁所在的方向行进。这样，在之后的某个时刻，1、2 号蚂蚁，3、4 号蚂蚁就会相撞。</p>\n<p>那要想知道最终有哪些蚂蚁会分别从左、右两边掉下去，一种最基本的解法，就是根据时间顺序来模拟蚂蚁们的相撞过程。具体怎么做呢？下面，我们先模拟分析一下这4只蚂蚁的相撞过程。</p>\n<p><img src="https://static001.geekbang.org/resource/image/9b/fc/9b7bb6c1d67e8fb263c90f46ceac97fc.jpg" alt="" /></p>\n<p>如图所示，一共有4只蚂蚁，我们从1到4给它们编号。最开始，它们之间的距离分别是3米、1米 和 6米。其中，2号和3号离得最近，并且方向相对。因为蚂蚁的移动速度是1m/s，所以2号和3号会在 0.5s 的时刻相撞，然后它们会向相反方向爬去。</p>\n<p>这个时候，1号和2号方向相对、3号和4号方向相对，并且1号和2号距离最近。所以下一次最先相撞的，应该是在1、2号蚂蚁.通过计算我们能知道，它们会在 2s 的时刻相撞。相撞之后，2、3号蚂蚁同向而行，3、4号蚂蚁相向而行。</p>\n<p>由此我们能得出一个结论，想要模拟蚂蚁相撞的过程，我们就要找到当前时刻距离最近的两只相向而行的蚂蚁。请你注意这句话：<strong>我们要找到当前时刻距离最近的两只相向而行的蚂蚁</strong>。那在一堆距离数据中，每次找到一个最小的距离，这不就是小顶堆的经典应用场景吗？因此，解决这个问题的关键，就是使用小顶堆来存储当前桌面上所有相向而行的蚂蚁之间的距离。</p>\n<h3>1. 用小顶堆解决蚂蚁问题</h3>\n<p>确定了使用小顶堆以后，我们又要面临一个新问题，那就是相向而行的蚂蚁之间的距离会随着时间而变化。就像两只蚂蚁一开始的相对距离是6米，下一秒就可能会变成5米。而我们现阶段所掌握的堆结构，并不支持存储动态更新的数据。这该怎么办呢？</p>\n<p>其实解决起来也很简单，只要我们存储在堆中的是两只蚂蚁在固定时刻的相对距离，比如 0 时刻，我们就可以不用更新堆中的数据。</p>\n<p>需要注意的是，两只蚂蚁在时刻  0  时的相对距离，不是指时刻  0  时这两只蚂蚁的真实距离，而是逻辑距离。这两个距离有什么不同呢？我们还是通过一个具体的例子来理解。</p>\n<p><img src="https://static001.geekbang.org/resource/image/2f/c9/2f3c6da4e9e1202403b37bfbedf8a6c9.jpeg" alt="" /></p>\n<p>如上图所示，在 0s 的时候，3、4号蚂蚁是同向而行的，距离是6米。在 0.5s 的时候3号蚂蚁发生了转向，这个时候3、4号蚂蚁开始了相向而行。此时，3、4号蚂蚁之间的实际距离是6米，也就意味着，它俩会在 3.5s 的时候相遇。</p>\n<p>这个时候，我们从逻辑上面让两只蚂蚁退回去，它们会以每秒钟 2 米的速度远离对方。也就是说，在 0s 的时候，逻辑上这两只蚂蚁的距离应该是 7m，所以我们存储到堆中的数据应该是逻辑上的 7m，而不是 3、4 号蚂蚁在 0s 时候的实际距离 6 米。</p>\n<p>理解这一步的重点，在于理解堆中的数据是不可以动态更新的，所以我们要将两只蚂蚁在0时刻的逻辑距离存储到堆中。当然你也可以直接将两只蚂蚁相遇的绝对时间存储在堆中，作为堆中元素排序的依据，然后按照蚂蚁相遇的绝对时间，来模拟蚂蚁们的相撞顺序。这样，我们就能得到蚂蚁们全部相撞后的爬行顺序了。</p>\n<p>到这里，我们就讲完了如何用模拟的方法来解决蚂蚁问题。其实解决的核心就在于用堆来维护蚂蚁之间相撞的顺序。</p>\n<h3>2. 蚂蚁问题最快的解法</h3>\n<p>实际上，除了使用小顶堆，蚂蚁问题还有一种更简单的解决方式，那思路是什么呢？其实一句话就能说明白：<strong>一只向右走的蚂蚁和一只向左走的蚂蚁碰撞之后，会变成一只向左走、一只向右走。也就是说，碰撞并不会改变桌面上向左和向右的蚂蚁总数</strong>。</p>\n<p>而且通过前面的分析，你也会发现，无论怎么碰撞，蚂蚁之间的相对顺序是不会改变的（不管怎么碰撞，蚂蚁的顺序不会改变）。最后，只有向左走的蚂蚁，才有可能从左边的桌子边掉下去，向右走的蚂蚁会从右边的桌子边掉下去。所以在图1中，一开始有4只蚂蚁是向左走的，也就意味着，最后1、2、3、4这四只蚂蚁会从左侧桌子掉下去，剩余的蚂蚁会从右侧桌子掉下去。</p>\n<p>怎么样，上面这种方法，是不是比用小顶堆模拟的方式更容易理解和实现呢？你可能要问了，那我们为什么还要学习小顶堆这种更麻烦的解决方案呢？这就好比，你现在的目标是要画一个圆，我可以选择给你一个印章，你只需要用印章往纸上盖一下，就会得到一个圆。可如果将来，你面对的任务是画一个正方形，又该怎么办呢？因此，你真正需要的是一支笔，而不是一个固定形状的印章，而小顶堆就是这支笔。今天呢，我们就是在锻炼这支笔的使用方式。我也希望，今后如果碰到画正方形或者三角形之类的问题，你能想起来使用这支笔。</p>\n<h2>堆排序</h2>\n<p>搞定了蚂蚁问题以后，我想再和你说说，由堆衍生出来的一种排序算法，堆排序。</p>\n<p><img src="https://static001.geekbang.org/resource/image/5a/06/5a36da1091252111c51yy86948208006.jpg" alt="" /></p>\n<p>那堆排序怎么理解呢？我们还是先看一个例子。假设我们要对一个数组从小到大进行排序，首先我们可以将原数组中的数据建立成一个大顶堆。这样，最大的元素就会在数组的首位，大顶堆的存储结构如上图。正常情况下，从堆中删除一个元素，是直接将堆顶元素弹出，然后将堆中最后一位的元素放到堆顶，再做向下调整的。这样的话，原来堆中的末尾元素位置就空了出来。</p>\n<p>现在，由于要对原数组进行排序，因此我们可以把弹出的堆顶元素与堆中的末尾元素进行位置交换，再向下做调整。也就是将图中的元素9和4做调换，再对4做向下调整。经过一轮这样的操作，我们就可以将一个堆顶的最大值放到正确的排序位置上。我在下图中给出了三轮操作以后，数组中元素的排序情况：</p>\n<p><img src="https://static001.geekbang.org/resource/image/11/1e/11e68f1aa9f83a403b279f8a805fbb1e.jpg" alt="" /></p>\n<p>如图所示，经过三轮弹出大顶堆顶元素的操作以后，原数组中最大的三个值就被放置到了最后三位。当大顶堆中元素弹空时，也就完成了对原数组排序的过程。</p>\n<p>好了，那我们来总结一下堆排序的流程：</p>\n<ol>\n<li>在原数组上建立堆结构</li>\n<li>将堆顶元素与堆末元素进行调换，再对堆顶元素进行向下调整</li>\n<li>经过 n 轮操作以后，数组中的元素就有序了</li>\n</ol>\n<p>通过我前面的解释，相信你应该已经理解第2、3步了，它们操作起来非常简单，我就不再细说了。而对于第 1 步，如果想在一个数组上建立一个堆结构，我们要怎么做呢？</p>\n<p>一种最直接的方式，就是我们先将原数组分成两部分，前半部分是堆，后半部分是数组中的元素。然后通过堆的向上调整策略，我们依次将后面的元素插入到前面的堆结构中。下图展示的就是用这种尾插法建堆的前三轮数组中的元素情况：</p>\n<p><img src="https://static001.geekbang.org/resource/image/88/ec/88182559c591392400e37e40e0d80bec.jpg" alt="" /></p>\n<p>这种建堆的方法比较直观，所以建堆的时间复杂度我们很容易就可以计算出来，就是 O(nlogn)。到这里，我们就算是掌握堆排序的整个流程了。</p>\n<h2>堆排序优化：线性建堆法</h2>\n<p>其实，对于堆排序中建堆的这个流程，我们还可以再优化，优化的方法叫做线性建堆法。线性建堆法就是将原数组分成两半部分，前半部分是数组部分，后半部分是已经建好的堆，然后采用向下调整的方式，从后向前依次将数组中的元素调整到堆中。如下图所示：</p>\n<p><img src="https://static001.geekbang.org/resource/image/12/89/12f2e521ff8d260ffbf0f8b4b70f4e89.jpg" alt="" /></p>\n<p>因为在上图这个数组中，处在堆中最下一层的 8、9、7这 三个节点，已经无法向下调整了，所以我们在初始化的时候，就直接把它们三个当成是已经调整好的堆结构就好了。之后，我们从元素4开始，向前依次将4、6、2三个元素进行向下调整，插入到他们下面的堆结构中。具体的过程，你直接参考正常的堆结构向下调整过程就可以理解了，我就不细说了。</p>\n<p>事实上，这种所谓的线性建堆法，用的就是向下调整策略。而之前我们学习的尾插法，用的是向上调整。两者好像没有太大的区别。那怎么能说线性建堆法比尾插法要优化呢？下面，我们来简单分析一下它们的时间复杂度，你就能明白了。</p>\n<p>首先，假设堆中的节点数量是 n，那么树高就是 $log_{2}{n}$。其中，根节点可能需要向下调整 $log_{2}{n}$次。根节点下面的2个子节点，可能需要向下调整 $log_{2}{n} - 1 $次，第三层的4 个子节点，可能需要调整$ log_{2}{n} - 2 $次。也就是说，有 $2^i $个节点，可能需要向下调整 $log_{2}{n} - i $次。最后，我们算出所有节点需要调整的总次数，就能得到如下式子：</p>\n<p>$$<br />\n\\begin{array}{c}<br />\n\\operatorname{sum}=1 \\times \\log _{2} n+2 \\times\\left(\\log _{2} n-1\\right)+4 \\times\\left(\\log _{2} n-2\\right) \\ldots \\\\\\<br />\n2 \\operatorname{sum}=2 \\times \\log _{2} n+4 \\times\\left(\\log _{2} n-1\\right)+8 \\times\\left(\\log _{2} n-2\\right) \\ldots \\\\\\<br />\n2 \\operatorname{sum}-\\text {sum}=2+4+8+\\ldots+\\left(2^{\\log _{2} n}=n\\right)-\\log _{2} n \\\\\\<br />\n\\approx 2 n<br />\n\\end{array}<br />\n$$</p>\n<p>因此，线性建堆法之所以称为线性，是因为时间复杂度真的为 O(n)。总之，线性建堆法的思想很好理解，因为在二叉树中，每向下一层节点数量就会翻一倍。所以在线性建堆法中，如果某一层包含的节点数量越多，那这一层中每个节点的调整次数就越少。这样，我们就能尽可能保证整体效率的最优。用一句话总结就是“让少数人多动，多数人少动”。</p>\n<h2>课程小结</h2>\n<p>今天，我们用两种方法解决了蚂蚁问题。</p>\n<p>第一种是利用小顶堆结构，来维护最近相撞的两只蚂蚁的距离，模拟出蚂蚁的相撞过程，确定最终的蚂蚁排序。第二种方法类似脑筋急转弯比较取巧，你只需了解就可以了。</p>\n<p>除此以外，我们还学习了堆排序算法以及一种更高效的建堆方式线性建堆法。线性建堆法思想简单来说，就是利用向下调整策略，当节点越多的时候，我们的调整次数就越少。因此，它的时间复杂度是 O(n)。</p>\n<p>最后，我希望你通过今天的学习，能够记住用堆解决蚂蚁问题的过程，以及推导线性建堆法的时间复杂度的过程。这会对你之后的学习和工作，非常有帮助。</p>\n<h2>课后练习</h2>\n<p>因为蚂蚁问题是一个锻炼思维方式的好题目。所以，我希望你能深入去想一想，如果蚂蚁问题不是发生在桌面上，而是在一个圆环上的话。那经过 n 秒以后，你能输出每个蚂蚁的位置吗？欢迎在留言区把你的思考和具体做法写下来，我们一起讨论。</p>\n<p>如果你身边的朋友也被类似的问题“难住”过，那就快把这节课分享给他吧！今天就到这里，我是胡光，我们下节课见！</p>\n<hr />\n<p><a href="https://github.com/alicia-ying/jikeshijian.git">课后参考代码</a></p>\n',
        article_title: "04 | 堆排序：体会线性建堆法的威力",
      },
      {
        title: "05 | 堆排序面试题：如何维护Top-K元素和中位数？",
        herf: "https://time.geekbang.org/column/article/277706",
        id: "277706",
        content:
          '<p>你好，我是胡光，欢迎回来。</p>\n<p>前两节课呢，我们认识了堆这种数据结构，并且学习了堆排序这种基于堆的排序算法。而实际上，用堆来做排序只是堆众多应用方式的其中一种。</p>\n<p>对于堆这种数据结构而言，还有哪些其他的应用方式呢？以及，想要对堆结构的使用达到融会贯通的程度，我们需要掌握哪些关键点呢？今天，我将通过2道与堆相关的经典的面试题，来帮助你加强对堆结构应用场景的理解。</p>\n<h2>使用 STL-set 模拟堆</h2>\n<p>在讲和堆有关的面试题之前呢，我想先用 C++ 作为目标语言，跟你讲讲我最喜欢使用的堆技巧。如果你对 C++ 不了解也不用担心，我接下来要讲的编程技巧属于思想层面的技巧，听懂了思想，再在你所使用的语言中，找到对应性质的工具就可以了。</p>\n<p>在C++ 的标准库中，其实已经给我们提供了一套面向过程的堆的相关操作。其中包括了：创建一个堆、向堆中插入或者删除最值元素等堆结构的基本操作。不过，在一门面向对象的语言中，使用一套面向过程的标准库方法，着实有点儿奇怪。另外，就我个人的使用习惯来说，真的有点儿用不惯标准库提供的这套现成方法。</p>\n<p>正所谓：虽然开局不容易，生活还是得继续。现有的标准库用不习惯的话，我们可以找一些替代工具，用来替代堆结构所带来的效果。找替代工具的思路很简单，能够实现如下2种操作的工具，就可以被当成堆的替代品：</p>\n<ol>\n<li>可以动态地添加元素</li>\n<li>能够查看及删除极值元素</li>\n</ol>\n<p>如果你熟悉C++，你可能会想到priority_queue这种容器，它本质上就是一个大顶堆，也就是一个现成的优先队列。可是，这工具的名字太长了，对于新手来说，使用起来不太友好。所以今天，我给你推荐另外一个结构，就是 C++ STL 中的 set ：<strong>有序集合模板类</strong>。我在下图中列了一些 set 的方法，你可以看看。</p>\n<p><img src="https://static001.geekbang.org/resource/image/3d/18/3dcc8e289e8092bcbfbc42a8e81c0d18.jpg" alt="" /></p>\n<p>如图所示，std::set<T> s; 就能定义一个存储T 类型元素的有序集合对象。set 一共有四个方法，包括查看元素数量、插入元素、删除元素以及查看最小值元素。利用这四个方法，我们就可以模拟小顶堆的行为模式。我在下面给出了一段使用 set 的参考代码，你可以先看一看。</p>\n<pre><code>/**************************************************************\n\t&gt; File Name: set.cpp\n\t&gt; Author: huguang\n\t&gt; Mail: hug@haizeix.com\n\t&gt; Created Time: 日  5/ 3 19:40:32 2020\n **************************************************************/\n\n#include &lt;iostream&gt;\n#include &lt;set&gt;\nusing namespace std;\n\nint main() {\n    // 定义存储整型元素的有序集合\n    // 依次插入 5、9、3、3 四个元素\n    // 输出集合元素数量，输出 3\n    set&lt;int&gt; s;\n    s.insert(5);\n    s.insert(9);\n    s.insert(3);\n    s.insert(3);\n    cout &lt;&lt; s.size() &lt;&lt; endl;    \n\n    // 打印最小值元素，输出 3\n    // 然后删除最小值元素\n    // 再打印最小值元素，输出 5\n    cout &lt;&lt; *(s.begin()) &lt;&lt; endl;\n    s.erase(s.begin());\n    cout &lt;&lt; *(s.begin()) &lt;&lt; endl;\n    return 0;\n}\n</code></pre>\n<p>我在这段代码中，演示了 set 的基本操作，模拟了一个堆结构插入和删除的基本过程。其中，有一点需要你特别注意：当我们向集合中插入了 5、9、3、3 这4个元素的时候，输出集合中只会显示 3 个而不是4个元素。之所以不是 4 个，就是因为C++ 中的 set 对值相同的元素只会保留一个。也就是说，<strong>集合中的元素具有唯一性</strong>。当然了，想要记录相同值的元素，也有相应的编码小技巧，这个我们后面遇到的时候再具体说。</p>\n<p>实际上，C++ set 的底层数据结构是红黑树，本质上也是一种基于二叉树的有序数据结构。等学完了红黑树的知识，你再回来看  set 的内容一定会有新的理解和体会。</p>\n<p>至此，我们就掌握了使用 STL 中的 set 模拟小顶堆的基本技巧。在遇到实际问题时，如果我们需要的是大顶堆，可以通过<strong>重载比较运算符</strong>或者<strong>编写用于比较大小的仿函数</strong>来实现。</p>\n<p>不过，这两种技巧都是与 C++ 语言特性相关的方法，那在这节课里，我会尽量绕过这两种技巧，脱离对某种特定语言特性的依赖，来给你讲一种更偏向于思维的堆处理技巧。</p>\n<h2>小顶堆：维护 Top-K 元素</h2>\n<p>知道了怎么用 set 模拟小顶堆之后，我们来看第一道与堆有关的面试题：维护 Top-K 元素。</p>\n<p>题目是这样的：假设，我们想在大量的数据，如100 亿个整型数据中，找到值最大的 K 个元素，K 小于 10000。你会怎么做呢？</p>\n<p>一种最直接的方法，就是对 100 亿个元素从大到小排序，然后输出前 K 个元素值。可是，无论我们掌握的是快速排序算法还是堆排序算法，在排序的时候，都需要将全部的元素读入到内存中。也就是说，100亿个整型元素大约需要占用 40GB 的内存空间，这听起来就不像是普通民用电脑能干的事情，（一般的民用电脑内存比这个小，比如我写文章用的电脑内存是 32GB）。其实，想对这么大的数据进行排序，不是没有可能，我们可以使用<strong>归并排序</strong>算法。很可惜，此时的我们还没有掌握这种技术。</p>\n<p>那另外一种朴素的想法，就是进行 <strong>K 轮查找</strong>。具体来说就是，我们每次找到一个最大值，然后将其从所有数字中删除。这种做法的时间复杂度是 O(KN)，K 是要查找的次数，N 是所有数字的总数量。这种做法好像也不太优美，那具体怎么做呢？别着急，我们先来看个例子。</p>\n<p>假设，学校现在要选出 3 个围棋水平最高的人代表学校去比赛，已知校队中已经有了 3 个围棋选手，但你也想要代表学校去比赛的话，应该怎么做？很简单，你和校队中的任何一个人比一场，只要赢了他，你就能进入校队了。为了能顺利进入校队，你一定会优先选择现有校队中能力最弱的人，如果比赛赢了他，你进入校队，他则被踢出校队。如果全校的人都像你一样，挑战一遍现有校队中的人，那校队中最终剩下的 3 个人，一定是全校最强的 3 个人。</p>\n<p>事实上，在全校同学中找出3个最强的人，和我们今天要解决的在100亿个元素中找出K 个最大值，本质上它们都是一个问题。解决过程可以总结为3步：首先，我们需要维护一个<strong>候选集合</strong>，就类似于上面例子中的校队。然后，我们每次读入一个新数字，如果这个新数字大于候选集合中 K 个元素的最小值，我们就把这个新数字加入到候选集合中，把候选集合中的最小值删除。最后，候选集合中的 K 个数字就是我们要求的 K 个最大值了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/0e/66/0ef5166250a9334b46c8837f85bffa66.jpg" alt="" /></p>\n<p>那在这个过程中，我们该如何维护候选集合中的最小值呢？这时候，小顶堆就要起作用了，也就是将候选集合维护成一个小顶堆。</p>\n<p>通过这道题目我想让你清楚一点：<strong>在用堆解决一个实际问题的时候，我们的思考方式不是拼命地去想用堆如何解决这个问题，而是当我们发现在设计算法的过程中，需要动态地查询和删除集合中最大值或最小值时，再用堆来维护</strong>。</p>\n<p>那延伸来说，在解决实际问题时，我们一定是通过某些性质来反推我们需要的数据结构。因此<strong>准确理解各种数据结构的性质，才是将理论应用到实践的要点</strong>。</p>\n<h2>对顶堆：维护中位数</h2>\n<p>通过 Top-K 的题目我们明确了一点：当算法过程中需要维护集合最值的时候，我们就可以拿出堆这种数据结构了。因此，设计一套合理的算法过程，是我们应用数据结构的前提条件。</p>\n<p>接下来，我们再来看另一道经典的与堆相关的面试题：维护中位数。题目也很简单，就是让我们实现一种新的数据结构，来支持插入元素以及查询当前所有元素的中位数。</p>\n<p>所谓中位数，就是在集合中所有元素排序以后，处于中间位置的元素。如果元素数量是偶数个，中位数则是中间两个数字的平均值。</p>\n<p>在没有任何思路的情况下，我们先假设一个具体的小例子，来理解一下这种数据结构的性质。</p>\n<pre><code>插入：7 1 6\n查询中位数\n插入：9 8 7 8 12\n查询中位数\n</code></pre>\n<p>那在第一次查询的时候，集合中有 3 个元素：1、6、7，所以中位数是 6。之后，由于集合中又插入了 5 个元素，此时集合中的元素是：1、6、7、7、8、8、9、12，又由于元素总数是偶数，因此中位数等于中间两个数字的平均值，也就是 (7+8)/2 = 7.5。</p>\n<p>从这个小例子中你会发现，这种数据结构的难点就在于其中位数所在的中间位置，是会随着插入元素而变化的。所以，如果我们能够维护这个中间位置，就能完成新数据结构的设计了。但具体该怎么做呢？</p>\n<p>我们以一组元素，2、6、7、9、12、14为例。把它们从中间位置切开，我们就将所有元素分成了左右两部分，而且左边集合的元素值小于右边集合的元素值。</p>\n<p><img src="https://static001.geekbang.org/resource/image/24/38/24236d22a039d5fc4aa9e9f58ae12538.jpg" alt="" /></p>\n<p>图中，有两个元素 7 和 9 被标成蓝色，它们被称为关键元素。那什么是关键元素呢？就是如果我们能够定位这两个元素，就能定位中间位置求出中位数。并且，这两个关键元素有个非常重要的性质，7 是左半边所有元素中的最大值，9 是右半边所有元素中的最小值。也就是说，如果将左右两边看成是两个集合，那我们既需要维护左边集合的最大值，也需要维护右边集合的最小值。</p>\n<p>当插入新元素的时候，通过与中间的两个关键元素比较，我们就可以知道应该向左边集合插入，还是右边集合插入。当左右两边集合元素数量相差 2 时，说明中间位置发生了移动，如果是左边集合比右边集合元素多2个，说明中间位置向左发生了移动，我们维护的位置向右移动了，所以我们将左边集合的最大值插入到右边集合中即可，反之亦然。如图所示，我们管这种结构叫做对顶堆，是不是很形象？</p>\n<p><img src="https://static001.geekbang.org/resource/image/88/1d/88be266e88a123c7d6yy4e6927d5de1d.jpg" alt="" /></p>\n<h2>课程小结</h2>\n<p>通过今天这节课，我希望你牢牢记住一件事：在解决实际问题的时候，不是我们先知道了要使用堆，而是在我们设计算法流程时，需要动态查询、插入和删除集合的最值元素，而这种功能需求恰好符合堆的性质，从而确定了要使用堆结构。</p>\n<p>因此，只有从问题性质出发选择合适的算法数据结构，才能彻底增强你解决实际问题的能力。届时，你所思考的将不再是使用某一个数据结构解决问题，而是真正学会使用某一类数据结构解决问题。</p>\n<p>好了，今天就到这里了，道阻且长，行则将至，我是胡光，我们下期见。</p>\n<hr />\n<p><a href="https://github.com/alicia-ying/jikeshijian.git">课后参考代码</a></p>\n',
        article_title: "05 | 堆排序面试题：如何维护Top-K元素和中位数？",
      },
      {
        title: "06 | 线程池基础：如何用线程池设计出更“优美”的代码？",
        herf: "https://time.geekbang.org/column/article/279082",
        id: "279082",
        content:
          '<p>你好，我是胡光，欢迎回来。</p>\n<p>在之前的课程中，我们学习了二叉堆这种数据结构。基于完全二叉树的二叉堆从逻辑上我们可以看成是一个优先队列。之所以叫优先队列，是因为其对外的行为表现像极了一个队列：头部出队、尾部入队，而且，每次出队的时候，都是将优先级最高的任务弹出队列。</p>\n<p>完成了基础学习以后，这节课开始，我们来聊聊线程池。线程池的内容比较多，我会分成三节课来讲，今天我们先来说说线程池的基础，后两节课再动手来封装一个<strong>线程池</strong>（Thread Pool）。</p>\n<p>考虑到学习这门课的同学所用的编程语言不太一样，众口真的难调，所以我会选择用 C/C++ 语言作为讲解的示例语言，争取做到只要你有一定面向对象基础就能看懂。不过在讲解过程中，我也会尽量避免讲解与语言特性相关的知识点，更多地，我会跟你讨论线程池中所反映出来的，与编程范式相关的思维模式，还有优先队列在线程池中的应用。</p>\n<h2>理解线程和进程的基础概念</h2>\n<p>要想封装一个<strong>线程池</strong>，首先你得了解什么是<strong>线程</strong>（Thread），以及与线程相关的另一个概念<strong>进程</strong>（Process）。如果你之前对进程和线程有一点了解，也可以借着这个机会进行复习巩固。</p>\n<p>学术一点儿来说，<strong>线程是操作系统进行运算调度的基本单元，进程是操作系统进行资源分配的最基本单元</strong>。这怎么理解呢？下面，我就模拟程序的运行过程，来带你理解这两个概念。</p>\n<h3>如何理解进程？</h3>\n<p>当你写完了一段程序以后，通过编译链接你会得到一个可执行文件，通过运行这个可执行文件会出现一个运行效果。其实，这个可执行程序每次运行的时候，操作系统都会创建一个新的进程，这个新创建的进程就是这个可执行文件在内存中的副本。说白了，如果你“手抖”运行了 6 次可执行程序，操作系统就会创建 6 个进程。虽然这6个进程都由一个可执行文件运行得到，但它们本质上是独立的，各自都有独立的数据存储空间。</p>\n<p>具体我们来看一个例子。假设，进程 1、2、3 对应了同一个可执行文件的运行结果，并且均包含一个变量 a。但是， 3 个进程中的 a 变量并不相同，它们都存储在内存不同的地方，所以这 3 个进程之间的运行，并不会受到对方的影响，每个进程都有一片自己独立存储数据的空间，因此，进程是操作系统分配资源的最基本单元。</p>\n<p><img src="https://static001.geekbang.org/resource/image/cd/eb/cdece5bc89085768f1c37a999a63a9eb.jpg" alt="" /></p>\n<p>在这个例子中，资源就是数据存储所用的内存空间。其实操作系统中的资源形式还有很多，比如，一个内存空间是资源，一个文件描述符是资源，一个网络端口是资源，一个 CPU 也是资源。操作系统会按照需要，把相应的资源分配给每一个进程。</p>\n<h3>如何理解线程？</h3>\n<p>理解了进程的概念以后，接下来让我们再来看线程。刚才说了，线程就是操作系统进行计算调度的基本单元。说到计算调度，我们就必须要说说 <strong>CPU 时间片</strong>。什么是CPU 时间片呢？我想先问你一个问题：当只有1个 CPU 可以提供计算能力的时候，你该如何同时运行100个程序呢？先别急着回答，我们先来看一个相似的生活场景。</p>\n<p>你知道，在生意火爆的饭店后厨中，厨师是按照什么顺序做菜的吗？假设现在饭店大堂来了三桌客人，如果要按顺序给每一桌提供饭菜，第三桌的客人肯定早就走了。因为在第三桌客人看来，我们三桌同时来的，怎么第一桌的客人吃完饭了，我们的菜还没上来？</p>\n<p>为了让三桌的客人都满意，一般厨师会先给第一桌做一道菜，再给第二桌上一道菜，然后再给第三桌上一道菜。在这种上菜策略下，这三桌客人的感受就是，仿佛厨房有三位厨师在同时为三桌客人做菜，实际上做菜的师傅只有一位。这就是我们接下来要讲的<strong>分时系统</strong>。</p>\n<p>CPU 在给程序提供计算能力的时候，不是等到第一个程序执行完了，才执行第二个程序，而是先给第一个程序提供一小段时间的计算能力，再给第二个程序提供一小段时间的计算能力。如果我们站在 100 个程序一端，就会感觉 CPU 同时在运行着 100 个程序，而实际上 CPU 在同一时间只为 1 个程序服务。因此，分时系统就是指多个程序依据时间来共享硬件或者软件资源。</p>\n<p>那么 CPU 为程序提供服务的一小段时间，其实就是一个<strong>时间片</strong>。更准确点来说，CPU 在一个时间片里运行的不是程序而是线程。这该怎么理解呢？我们接着来看一个例子。比如说，下图就是 3 个线程占用 CPU 时间片的情况。</p>\n<p><img src="https://static001.geekbang.org/resource/image/e7/15/e7d67391d1c1bed12af9021b8a46ae15.jpg" alt="" /></p>\n<p>你会看到，图中有T1、T2、T3 这 3 个线程，它们依次占用 CPU 的每一个时间片。这样，一个时间片就唯一对应到了一个线程，CPU 到了新的时间片就会切换去执行新的线程。这样，你应该就能理解，线程是操作系统进行计算调度的基本单元。</p>\n<p>同样地，你也可以认为一个线程只对应一组CPU 的时间片，也就相当于只对应一部分计算资源。又因为，进程是操作系统进行资源分配的基本单元，所以，线程资源会被分配到各个进程中。</p>\n<p>结合上图，我们可以看到 T1、T2 线程在进程1中，T3 线程在进程 2 中。也就是说，单纯从时间片的占用角度来说，进程 1 比进程 2 的运行速度快了 1 倍。如果CPU 在 1 个时间片内可以进行 10000 次运算，那么在经过6次时间片之后，进程 1 运算了 40000 次，而进程 2 才运算 20000 次。所以，掌握设计多线程程序的技巧，可以让你在不改变程序算法的情况下，让程序的运行速度更快，是不是想想都刺激！</p>\n<h3>工作中常见的爆栈和线程有什么关系？</h3>\n<p>理解了线程和进程的基本概念以后，你可能还有一个疑问：我在编程工作中，好像并没用过线程啊？其实你很可能用过，只是你不知道。</p>\n<p>如果你学过 C 语言，一定记得在 C 语言中，变量有局部变量和全局变量之分吧。其实一般的局部变量，是存储在当前线程所对应的存储区中的，我们称这个存储区为栈区。在我的 Mac 系统中，操作系统给进程分配一个线程时，这个线程所对应的默认栈区大小是8M。也就是说，这个栈区可以存储 200 万个整型数据。</p>\n<p>那当递归深度过深发生爆栈情况时，爆的就是这个线程栈。这也就是为什么，我们不建议在函数内部申请过大的数组空间。因为过大的数组空间，很有可能把这个只有8M大小的栈区挤爆。</p>\n<p>总的来说，一个线程其实不仅仅代表了一份计算资源，还绑定了一个存储局部变量的存储区。所以，之前我们所写的 C/C++ 程序，实际上是单线程的程序。当我们的程序想要申请更多的线程资源的时候，可以像申请更多的内存空间一样，使用系统中提供的方法进行申请，例如， Unix 系统中的 pthread_create 方法就是用来申请一个新的线程。</p>\n<h2>如何利用线程池优化代码设计？</h2>\n<p>明白了多线程的好处以后，你是不是已经开始摩拳擦掌，想要直接利用相关函数方法开发多线程程序了。先别急，我们先来看看下面这个多线程的程序，你能看出它有什么问题吗？</p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;pthread.h&gt;\n\nvoid *func1(void *data) {\n    printf(&quot;hello geek\\n&quot;);\n    return NULL;\n}\n\nvoid *func2(void *data) {\n    printf(&quot;hello world\\n&quot;);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&amp;t1, NULL, func1, NULL);\n    pthread_create(&amp;t2, NULL, func2, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    return 0;\n}\n</code></pre>\n<p>代码中，第 17、18 行创建了两个线程，这两个线程分别以 func1 和 func2 函数作为线程的入口函数。代码的第 19、20 行，是在等待两个线程执行结束。如果运行这个程序，你会在屏幕上看到两段信息，分别是“hello geek”和“hello world”。这段多线程的程序在功能上没什么问题，但在代码设计上却不够优美。</p>\n<p>在代码设计中，像这样零散地去申请线程，根本无法精确地控制我们申请到的线程的数量。要知道，线程也是会占用存储空间的。而无法控制线程数量，就意味着无法控制进程所占用的存储空间。</p>\n<p>要想解决这个问题，我们就需要用到线程池。一开始，如果我们把进程所需要的线程资源申请好，全部存储在一个空间中，我们就会得到一个装着很多线程的池子，它就叫做线程池。当有计算任务的时候，我们只需要将计算任务投入到池子中，这个池子中就会有一个线程执行这个计算任务。</p>\n<p>接下来，我就以装有3个线程的线程池为例，来和你讲讲线程池的基本结构。</p>\n<p><img src="https://static001.geekbang.org/resource/image/f5/fc/f5b2a44d69bd20d9d0bcc14cd0ddb4fc.jpg" alt="" /></p>\n<p>上图的线程池中装着3个线程，Func1 和 Func2 代表了两个待处理的计算任务。我们把它们投入到线程池中以后，会由线程池安排相关的线程进行具体的执行。但是就这个结构图而言，如果同时来了100个任务，而线程池中只有3个线程，我们又该怎么办呢？</p>\n<p>其实，要解决这个问题很简单，只需要我们给线程池里增加一个内部的队列结构就行了。这样一来，等到任务来了以后，它会先进入任务队列，然后线程池中的工作线程，会从这个任务队列中依次获取需要计算的任务进行执行操作。这样，原本的线程池结构就需要修改成如下的样子。有了这个任务队列，整个线程池的工作逻辑就能变得更加灵活。</p>\n<p><img src="https://static001.geekbang.org/resource/image/8b/d0/8bce9fdc0a472d43b095ef276373c3d0.jpg" alt="" /></p>\n<p>但是有了这个任务队列之后，又会产生一个新的问题：工作线程到这个任务队列中取任务的顺序，是应该按照任务在队列中的先后顺序依次取出，还是应该按照任务的优先级从高到低依次执行呢？答案是都可以。我们还是应该看应用场景的具体需求再决定，所以，线程池中的任务队列应该是可配置的。如果应用场景中，要求我们按照任务在队列中的顺序依次取出，我们配置成普通队列即可；如果要求任务是按照优先级从高到低依次进行执行的，那我们就需要将任务队列配置成优先队列。</p>\n<p>以上，就是线程池的基本结构和作用。</p>\n<h2>课程小结</h2>\n<p>通过今天的课程，我希望你能够深刻地理解一件事儿：<strong>线程是操作系统进行计算调度的最基本单元，进程是操作系统进行资源分配的最基本单元。</strong></p>\n<p>由此，我们引出了线程池的概念，它的作用，其实是为了更精准地控制程序中的线程数量，而且为了能让有限的线程处理更多的任务，我们可以在线程池中增加一个任务队列。这个任务队列是一个灵活的结构，它能根据问题场景不同，配置成普通队列或者是优先队列。当然，你也可以根据实际开发过程中的需求，将任务队列设计成其他的线性结构。</p>\n<h2>课后练习</h2>\n<p>最后，我想给你留一道思考题，你能利用线程池设计一个可以计算 1 亿以内素数个数的程序吗？</p>\n<p>欢迎在留言区分享你的答案，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "06 | 线程池基础：如何用线程池设计出更“优美”的代码？",
      },
      {
        title: "07 | 封装线程池（上）：初探泛型编程",
        herf: "https://time.geekbang.org/column/article/280279",
        id: "280279",
        content:
          '<p>你好，我是胡光，欢迎回来。</p>\n<p>上节课，我们学习了线程池的基本作用和结构。线程池就是管理着线程资源的池子，内部除了管理着若干线程以外，还需要用一个任务队列来缓存要执行的计算任务。而这个任务队列，根据线程池的应用场景不同，可以配置成不同特性的队列。</p>\n<p>今天，我们就动手来封装一个线程池类。在封装的过程中，我会用 C++ 语言作为基础。如果你对C++不是很熟也没关系，你可以重点学习我今天讲的封装思想，然后，在你会的语言中根据其语言特性找到相应的实现方式，尝试自己封装一个线程池。</p>\n<p>下面，让我们开始今天的课程吧。</p>\n<h2>初探泛型编程</h2>\n<p>在正式封装一个线程池类之前，我们先来学习一个基础的编程概念<strong>泛型编程</strong>，它是一种编程范式。那说到编程范式，你可能有点儿懵，其实，编程范式就是设计程序的方法和模式。下面我就说几个你比较熟悉的编程范式，通过它们来帮助你认识泛型编程。</p>\n<p>第一种是面向过程。这种编程范式想必你不会陌生，一般来说，我们在刚开始学习程序时接触的第一个编程范式，就是面向过程。<strong>所谓面向过程，就是在进行程序设计的时候，我们要重点思考怎么将处理步骤封装成函数过程，以此来达到代码复用的目的，从而降低程序设计过程中可能存在的 Bug。</strong> 这该怎么理解呢？</p>\n<p>举个例子，在没有过程性封装的情况下，如果我们写了10 处逻辑过程相同的代码，我们必须要保证这 10 个地方的实现都没有问题，否则，只要我们有 1 处写错了，整个程序就会存在 Bug。那如果我们能将逻辑过程相同的代码封装成函数过程，只需要保证这个函数过程实现的没问题，就能保证程序中同样逻辑的10 个调用处都没问题了。</p>\n<p>第二，是面向对象。如果你学过 C++、C# 或者 Java 肯定也很熟悉它，面向对象正是这些语言所提倡的编程范式。但你是否注意到了，面向对象的程序设计方法，首先是将一组数据的描述封装成类，然后再由类实例化出具体程序中所使用的对象。这样，类的概念就像是类型，对象的概念就像是变量。</p>\n<p>也就是说，在这个过程中，我们实际封装的是一个类。那为什么它不叫做面向类的程序设计方法，而叫做面向对象的程序设计方法呢？</p>\n<p>我们从问题抽象的过程来看，要想将一个具体的问题场景转换成计算机程序，我们第一步要做的就是抽象，所以面向对象第一步上来，就要分析问题场景中都有哪些对象，然后再将这些对象归类设计出上层的类，继而设计出类之间的父子关系，以及相关的接口形式。这就是面向对象的含义：<strong>一切从分析对象开始</strong>。</p>\n<p>其实，面向过程和面向对象这两种程序设计方法是有共通之处的，我们来总结一下：<strong>面向过程是将重复的代码逻辑抽象成函数过程，面向对象是将问题场景中具有相同性质的对象抽象成类</strong>。抽象的好处是，它可以应用到很多具体的场景中。比如，我们用面向过程的思想抽象出一个加法过程函数，就可以算任意两个数字之间的加法。再比如，抽象出来的狗类，通过实例化可以代表任意样子的狗。</p>\n<p>得出这样的共性之后，我们接着来看泛型编程。所谓泛型编程，就是从具体的实现过程中抽象出类型。为了帮助你理解泛型编程的思维，我们可以先讨论一个小问题：如何实现一个加法函数？</p>\n<p>第一直觉，你可能会像下面这个代码一样，实现一个传入两个整型的加法函数。</p>\n<pre><code>int add(int a, int b) {\n    return a + b;\n}\n\n</code></pre>\n<p>但是，这个函数还不是纯粹的加法函数。真正的加法过程，应该是只要两个数据支持相加操作，就可以传入 add 函数进行计算，并得到结果。</p>\n<p>由此可见，在函数实现的过程中，只要固定了类型，功能就会变得局限。因此，泛型编程要抽象化出来的就是代码逻辑中的类型。这该怎么理解呢？我们来看一下泛型编程中加法函数长什么样。下面，我给出了一段用 C++ 的模板实现的加法函数。</p>\n<pre><code>template&lt;typename T, typename U&gt;\nauto add(const T &amp;a, const U &amp;b) -&gt; decltype(a + b) {\n    return a + b;\n}\n</code></pre>\n<p>这个函数考虑到了所有加法情况。如果你也学过一点儿 C++，你可能会问了，加法函数一定要这样实现么？这好像有点儿麻烦啊。我可以告诉，在C++中加法函数一定要这样实现，否则在一些情况下，这个加法函数很有可能不好使了。例如，如果 a、b 的类型都是 T，那在a、b 类型不同的时候我们就无法调用这个模板方法。再比如，如果我们不使用 decltype和返回值后置的语法结构，就无法准确描述 a + b 表达式的返回值类型。</p>\n<p>其实说了这么多，我就是想跟你说明一点，泛型编程是一种比较难掌握的编程范式，需要你对语言本身很了解，并且熟练掌握面向过程和面向对象。</p>\n<p>那你可能会问了，花这么大力气，掌握这么麻烦的编程范式有什么好处？其实，<strong>所有编程范式的好处都在于提高开发效率</strong>。利用泛型编程实现 1 种函数，就相当于实现了 10种甚至是20几种函数。这种开发方式形象一点儿说，就是利用编译器帮你写代码，是不是很酷？而且这也是我们今天封装线程池需要用到的。接下来，我们正式开始封装一个线程池。</p>\n<h2>封装：计算任务类</h2>\n<p>在封装之前，我们先来回顾一下上节课讲的线程池结构。</p>\n<p><img src="https://static001.geekbang.org/resource/image/04/ea/0405a73311ec8173130af6ed7b249dea.jpg" alt="" /></p>\n<p>在线程池的结构中，<strong>最基本也是最重要的不是线程，也不是任务队列，而是任务队列中的任务</strong>。因此，我们重点要考虑怎么封装计算任务的基本组成部分。一个计算任务可以看成是，由某个函数入口加上具体的传入参数组成的一个可以延时执行的方法。</p>\n<p>这个概念有点难理解，我们先来解释什么是延时执行。通常情况下，当我们调用 add(3, 4) 函数方法的时候，这个函数会立刻执行。这很好理解。可是在线程池中，我们需要将 add 函数和3、4两个参数打包成一个计算任务放到任务队列中，等线程池中的线程从任务队列中取出这个计算任务以后再执行。那从打包放入函数任务，再到执行函数任务，这中间存在的时间间隔就是我们说的延时执行。</p>\n<p>下面是我用 C++ 实现的一个 Task 类，这个类的作用，就是将函数和函数调用时所需的参数打包成一个任务对象，后续我们会将这个任务对象放到任务队列中。</p>\n<pre><code>#include &lt;iostream&gt;\n#include &lt;cstdio&gt;\n#include &lt;cstdlib&gt;\n#include &lt;queue&gt;\n#include &lt;stack&gt;\n#include &lt;algorithm&gt;\n#include &lt;string&gt;\n#include &lt;map&gt;\n#include &lt;set&gt;\n#include &lt;vector&gt;\nusing namespace std;\n\nclass Task {\npublic :\n    template&lt;typename Func_T, typename ...ARGS&gt;\n    Task(Func_T f, ARGS ...args) {\n        this-&gt;func = bind(f, forward&lt;ARGS&gt;(args)...);\n    }\n    void run() {\n        this-&gt;func();\n        return ;\n    }\n    function&lt;void()&gt; func;\n};\n\nvoid func(int a, int b) {\n    cout &lt;&lt; a &lt;&lt; &quot;+&quot; &lt;&lt; b &lt;&lt; &quot;=&quot; &lt;&lt; a + b &lt;&lt; endl;\n    return ;\n}\n\nint main() {\n    Task t1(func, 3, 4), t2(func, 5, 6);\n    t2.run();\n    t1.run();\n    return 0;\n}\n\n</code></pre>\n<p>代码中的 Task 类，就是我封装的计算任务类。将这个类实例化成对象的时候，我们需要传入函数，以及函数调用时的参数，Task 类会将函数与参数打包成一个函数对象，存储在 func 成员属性中。同时 Task 类提供了一个 run 方法，这个方法就是延时执行计算任务的方法。</p>\n<p>Task 类的代码看不懂没关系，你重点关注主函数中的逻辑就行了。在主函数中，我们封装了两个计算任务，t1 和 t2，然后我们先调用了 t2 的 run 方法，再调用 t1 的 run 方法。这样结果就是先输出 “5+6=11”，后输出“3+4=7”。至此，我们就完成了计算任务类的封装。</p>\n<h2>线程池的初始化方法</h2>\n<p>封装好了计算任务类以后，接下来，我们就开始设计和封装线程池类。我们知道线程池的核心作用，就是准确地控制线程的数量，所以，线程池类的构造函数的作用就是新建相应数量的线程。代码如下所示：</p>\n<pre><code>#include &lt;iostream&gt;\n#include &lt;cstdio&gt;\n#include &lt;cstdlib&gt;\n#include &lt;queue&gt;\n#include &lt;stack&gt;\n#include &lt;algorithm&gt;\n#include &lt;string&gt;\n#include &lt;map&gt;\n#include &lt;set&gt;\n#include &lt;vector&gt;\n#include &lt;thread&gt;\nusing namespace std;\n\nclass ThreadPool {\npublic :\n    ThreadPool(size_t n) {\n        for (int i = 0; i &lt; n; i++) {\n            threads.push_back(\n                new thread(\n                    &amp;ThreadPool::thread_worker, \n                    this\n                )\n            );\n        }\n        return ;\n    }\n    void thread_worker() {\n        cout &lt;&lt; &quot;waiting for task&quot; &lt;&lt; endl;\n        return ;\n    }\n    ~ThreadPool() {\n        for (int i = 0; i &lt; threads.size(); i++) {\n            threads[i]-&gt;join();\n            delete threads[i];\n        }\n        return ;\n    }\nprivate:\n    vector&lt;thread *&gt; threads;\n};\n\nint main() {\n    ThreadPool tp(5);\n    return 0;\n}\n</code></pre>\n<p>如代码所示，我们完成了一个线程池类 ThreadPool 的大框架。在主函数中，我们定义了一个包含5个工作线程的线程池。其中， thread_worker 成员方法，就是工作线程的入口函数方法，也是我们后续要去实现的重点方法。</p>\n<p>然后，我们又定义了线程池类的构造函数与析构函数，它们一个负责在线程池中新建 n 个线程，一个负责销毁 n 个线程。因为代码逻辑非常清晰，所以这里我带你简单梳理一下。在构造函数中，我们通过 new 新建了 n 个线程，并且保存到 threads 动态数组中。在析构函数中，我们通过调用 join 方法等待线程执行结束，然后调用 delete 方法释放线程所占用空间。</p>\n<p>到这里，我们就已经准备好了线程池的周边工具 Task 类，与线程池主体部分的设计与封装。下堂课我们会围绕着线程的入口函数 thread_worker 进行线程池功能的进一步完善。</p>\n<h2>课程小结</h2>\n<p>最后呢，我带你做一下课程小结。</p>\n<p>今天，我们重点讨论了泛型编程，以及怎么利用泛型编程封装线程池。</p>\n<p>泛型编程的思想，就是将类型从具体的实现过程中抽象出来。相比于面向对象和面向过程，泛型编程是最难掌握，也是威力最强大的一种编程范式。比如，C++中 STL 的实现其实就是泛型编程的典范之作。</p>\n<p>因为泛型编程能够很好提高开发效率，所以在封装线程池的过程中，我们会用泛型编程的思想来封装计算任务 Task 类，以及线程池类的大体框架等等。</p>\n<p>总之，通过今天课程，我希望你能明白一件事儿：工欲善其事，必先利其器。我们在封装线程池之前，首先将计算任务抽象出来，封装成相关的 Task 类，这其实是在为我们封装线程池做准备工作。</p>\n<h2>课后练习</h2>\n<p>最后，你能参考我们封装计算任务类的思路，使用你最熟悉的编程语言，来实现一个基础的线程池吗？请把你的实现代码写在留言区，我们一起讨论。</p>\n<p>好了，今天就到这里了。我是胡光，下节课我会和你继续完成线程池的封装，你可要准备好啦！下节课见！</p>\n',
        article_title: "07 | 封装线程池（上）：初探泛型编程",
      },
      {
        title: "08 | 封装线程池（下）：从0到1，体验程序设计全过程",
        herf: "https://time.geekbang.org/column/article/280810",
        id: "280810",
        content:
          '<p>你好，我是胡光，欢迎回来。</p>\n<p>上节课，我们完成了线程池封装的基础准备工作，包括封装计算任务 Task 类，封装线程池的整体结构，准备好工作线程的入口函数 thread_worker 成员方法。今天，我们继续来完成线程池的封装，包括封装工作线程的逻辑过程，封装工作线程的取任务过程，封装向线程池中添加任务的过程，以及任务队列的设计与实现。</p>\n<h2>实现工作线程</h2>\n<p>要实现工作线程，首先我们要知道它的工作逻辑。下面，我用一张图把这个逻辑表示了出来。</p>\n<p><img src="https://static001.geekbang.org/resource/image/4e/e7/4e1a547dfa86dc450ed552bcdc776be7.jpeg" alt="" /></p>\n<p>从图中你可以看到，工作线程入口函数 thread_worker 函数的工作逻辑非常简单，就是在取任务和执行任务之间做循环，直到整个线程池停止工作、被销毁为止。如果要实现成代码，就是下面这个样子：</p>\n<pre><code>class ThreadPool {\npublic :\n    ThreadPool(size_t n) {\n        is_running = true;\n        for (int i = 0; i &lt; n; i++) {\n            threads.push_back(\n                new thread(\n                    &amp;ThreadPool::thread_worker, \n                    this\n                )\n            );\n        }\n    }\n    void thread_worker() {\n        while (is_running) {\n            Task *t = this-&gt;getOneTask();\n            if (t == nullptr) break;\n            t-&gt;run();\n        }\n        return ;\n    }\n    Task *getOneTask() {\n        // to do something\n        return nullptr;\n    }\n    ~ThreadPool() {\n        is_running = false;\n        for (int i = 0; i &lt; threads.size(); i++) {\n            threads[i]-&gt;join();\n            delete threads[i];\n        }\n        return ;\n    }\nprivate:\n    vector&lt;thread *&gt; threads;\n    bool is_running;\n};\n\n</code></pre>\n<p>这段代码比较长，你重点关注 thread_worker 成员方法的实现过程就可以了。</p>\n<p>其中， is_running 代表线程池是否还在继续运行。在 thread_pool 的构造函数中，is_running 被设置为 true，表示线程池处于工作状态。在 thread_pool 的析构函数中，is_running 被设置为 false，表示线程池即将被销毁要停止工作了。</p>\n<p>thread_worker 的代码逻辑主要就是一个循环，循环体干的事情就是获取任务、执行任务。不过，在执行任务之前还要有一个判断，来判断获取到的任务是否为空。为什么要进行这个判断呢？我会在讲getOneTask 函数的时候来解释。</p>\n<h2>实现获取任务的逻辑</h2>\n<p>接着，我们要实现获取任务的逻辑，具体来说就是实现 getOneTask 函数的逻辑。其实这个逻辑比较清楚，就是每次从任务队列中取一个任务返回给调用者。所以，在完善 getOneTask 逻辑之前，我们要先给线程池类添加一个任务队列。为了方便，我们暂时选择 C++ 中的队列 queue 作为任务队列的基础结构。接下来，我们先看看 getOneTask 方法的流程。</p>\n<p><img src="https://static001.geekbang.org/resource/image/ce/90/ce4aa4a013cb893d563859fa46dd7190.jpg" alt="" /></p>\n<p>从图中，我们可以看到，在取任务的逻辑中，我们需要先判断任务队列是否为空。如果是空的，取任务的方法会等待在原地，直到任务队列中有任务，再取出任务向下执行。那该如何等到任务队列中有任务呢？这一步非常复杂，而且也不是我们课程的讲解重点，所以，我们不做重点讲解，如果你有兴趣深入了解，可以去检索这些关键词：多线程同步方法、条件变量、互斥锁、信号量和无锁化编程。</p>\n<p>下面，我们就来实现一个简单的 getOneTask 方法：</p>\n<pre><code>Task *getOneTask() {\n//进入临界区时加锁\n    unique_lock&lt;mutex&gt; lock(m_mutex);\n//等待任务\n    while (is_running &amp;&amp; tasks.empty()) m_cond.wait(lock);\n//取任务\n    Task *t = nullptr;\n    if (is_running) {\n        t = tasks.front();\n        tasks.pop();\n    }\n    return t;\n}\n</code></pre>\n<p>首先，我们要设置进入临界区时的加锁动作，这是保证多线程环境下资源访问安全性的最基本做法。接下来，我们就要访问这个临界资源。</p>\n<p>我们在函数的第3行实现了等待的逻辑。这里我们用到了条件量，用以等待队列中被放入任务，或者线程池停止工作。所以，我们需要在代码的另外两个地方加上条件量的通知动作，一个是在放入任务以后，发送一个条件量的通知，代表队列中被放入了任务。另一个，就是在线程池的析构函数中，我们需要加上条件量的通知操作，代表线程池要停止工作被销毁了。</p>\n<p>然后，函数的第 4 行到第 8 行就是取任务的逻辑：如果线程池要停止工作了，代表取到任务的 t 变量会指向空地址，否则就指向其取出来的任务。</p>\n<p>接下来，我们在析构函数中加上条件量的通知操作。代码如下：</p>\n<pre><code>~ThreadPool() {\n    do {\n//条件量的通知\n        is_running = false;\n        unique_lock&lt;mutex&gt; lock(m_mutex);\n        m_cond.notify_all();\n    } while (0);\n    for (int i = 0; i &lt; threads.size(); i++) {\n        threads[i]-&gt;join();\n        delete threads[i];\n    }\n    return ;\n}\n\n</code></pre>\n<p>代码中的第 2 行到第 6 行，就是条件量的通知操作。在通知之前，我们需要先将 is_running 设置为false，然后再发送条件量的通知，这样才能使各个工作线程，在等待状态中退出。</p>\n<p>不过，代码中为什么要用 do while 循环将这一段代码逻辑包含起来呢？这主要是为了将 lock 做成局部变量，出了作用域以后，互斥锁就会被自动释放，而不释放互斥锁的话，其他工作线程就没有办法正常停止工作。至此，我们就算是完成了线程池中工作线程获取任务的逻辑。</p>\n<h2>添加任务的逻辑</h2>\n<p>有获取，就需要有添加。添加任务的逻辑也比较简单和直白，用到的就是 addOneTask 函数方法。对于addOneTask 函数来说，传入参数应该是一个计算任务对象的地址，然后我们需要将这个对象存储到任务队列中，由于任务队列属于多线程均可访问的临界资源，因此在访问之前我们必须做同步加锁。具体的代码如下所示：</p>\n<pre><code>void addOneTask(Task *t) {\n    unique_lock&lt;mutex&gt; lock(m_mutex);\n    tasks.push(t);\n    m_cond.notify_one();\n    return ;\n}\n</code></pre>\n<p>代码的逻辑其实很简单，就是三步，首先是给临界区加锁，然后将计算任务放到计算队列中，最后是通知正在等待的工作线程，告诉它们来活儿了。</p>\n<p>那到这里，我们就算是完成了整个线程池基本的框架以及基本功能。当然，如果你对于线程池有其他的功能想法，可以在此基础上继续设计实现。</p>\n<h2>可配置任务队列的设计与实现</h2>\n<p>最后，我们要把任务队列设计成可以配置的。这里，我们需要用到上节课提到的泛型编程思想，也就是将队列的类型从具体实现中抽象出来。</p>\n<p>在实现获取任务逻辑的时候，队列的类型都是固定的 C++ STL 中的 queue 队列类型，抽象出来以后就变成 QueueType 类型。而这个QueueType 类型只需要支持四个方法，分别是push（入队）、pop（出队）、empty（判空）以及front（查看队首元素）。</p>\n<p>按照这个设计，我们第一步要将线程池类先改成模板类，模板中的参数就是任务队列的类型，如下所示：</p>\n<pre><code>template&lt;typename QueueType = queue&lt;Task *&gt;&gt;\nclass ThreadPool {\nprivate:\n    QueueType tasks;\n};\n</code></pre>\n<p>这里，我给出了简化过后的代码，它只列出了和队列相关的声明部分。我们可以看到，任务队列 tasks 的类型从之前的 queue&lt;Task *&gt; ，抽象成了 QueueType 模板参数类型。并且 QueueType 模板参数的默认值就是 queue&lt;Task *&gt; 类型。当我们想要将任务队列换成其他种类的队列时，只需要修改这个 QueueType 模板参数的值即可。</p>\n<p>为了让你更直观地看到效果，我将前面学习的优先队列实现出来，代码如下：</p>\n<pre><code>template&lt;\n    typename T, \n    typename Array=vector&lt;T&gt;, \n    typename compare_T=less&lt;T&gt;\n&gt;\nclass HeapQueue {\npublic :\n    HeapQueue() { elements.clear(); }\n    bool empty() { return elements.size() == 0; }\n    T front() { return elements[0]; }\n    // 入队，并向上调整\n    void push(const T &amp;val) {\n        elements.push_back(val);\n        up_update();\n        return ;\n    }\n    // 出队，弹出堆顶元素\n    void pop() {\n        if (empty()) return ;\n        int ind = 0, n = elements.size();\n        swap(elements[n - 1], elements[0]);\n        elements.pop_back();\n        down_update();\n        return ;\n    }\n\nprivate:\n    Array elements;\n    compare_T compare;\n    // 向上调整\n    void up_update() {\n        int ind = elements.size();\n        while (ind &gt; 1 &amp;&amp; \n               compare(elements[ind / 2 - 1], elements[ind - 1])) {\n            swap(elements[ind / 2 - 1], elements[ind - 1]);\n            ind /= 2;\n        }\n        return ;\n    }\n    // 向下调整\n    void down_update() {\n        int ind = 0, n = elements.size();\n        while (ind * 2 + 1 &lt; n) {\n            int tind = ind;\n            if (compare(elements[tind], elements[ind * 2 + 1])) {\n                tind = ind * 2 + 1;\n            }\n            if (ind * 2 + 2 &lt; n &amp;&amp;\n                compare(elements[tind], elements[ind * 2 + 2])) {\n                tind = ind * 2 + 2;\n            }\n            if (ind == tind) break;\n            swap(elements[ind], elements[tind]);\n            ind = tind;\n        }\n        return ;\n    }\n};\n</code></pre>\n<p>你可以看到，在优先队列的实现中，我们抽象出了三种类型。第一种是优先队列中存储的元素类型 T， 第二种是用于存储堆结构的底层数据结构，默认是动态数组 vector。最后一种是用于 T 类型数据之间优先级的比较方法，默认情况是 less 方法，也就是小于号比较。</p>\n<p>由于我们需要把这个队列结构嵌入到线程池中使用，因此，我们必须要实现上面提到的四个方法：push（入队）、pop（出队）、empty（判空）以及 front（查看队首元素）。在 push 和 pop 过程中，我们分别使用了堆结构的向上调整和向下调整操作，这两个过程也是我们之前所掌握的基础操作，具体实现在代码中的 up_update 与 down_update 函数中。因为其他的逻辑都比较简单，你直接参考我给出的具体代码就能理解了。</p>\n<p>这样，我们就给线程池开发出了另外一种性质的任务队列，就是支持按照优先级弹出的任务队列。</p>\n<h2>课程小结</h2>\n<p>今天，我带你完成了线程池的初步封装。这一份线程池代码中还有很多不够优美的地方，如果你精力比较充沛，可以试着改进一下这个线程池的功能设计与封装形式。如果你之前没有接触过这类项目，那现有的代码以及封装逻辑也足够你学习了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/38/62/385a812ebdf8fd39e4735baec131yy62.jpg" alt="" /></p>\n<p>通过从0到1封装一个线程池，我希望带你体会一个完整的程序设计过程。从中你会发现，一开始设计框架结构的时候，我们根本用不到什么算法以及数据结构的知识，只有当我们逐渐完善框架的过程中，才能显现出算法及数据结构的作用。这也就是当你单纯地学习算法数据结构时感到困惑的本质原因，因为算法数据结构的确是程序设计的灵魂，而当你想把这份灵魂思想用在项目开发过程中的时候，还需要外在骨架与血肉的支撑。</p>\n<p>总之，算法是工程开发的核心，虽然算法不是万能的，但没有算法是万万不能的。并且随着工程开发的深入，我们对算法的依赖程度只会越来越强。这也就是为什么计算机科学中，将算法称为<strong>程序的灵魂</strong>。因此，对于想成为卓越工程师的你来说，算法思维是必须要具备的。</p>\n<h2>课后练习</h2>\n<p>最后，你可以尝试着把今天学到的线程池的封装思想，使用你最熟悉的语言实现出来写在留言区。</p>\n<p>好了，今天就到这里了。怎么封装线程池你学会了吗？那不妨也把这节课分享给你的朋友吧。我是胡光，我们下节课见！</p>\n<hr />\n<p><a href="https://github.com/alicia-ying/jikeshijian.git">课程参考代码</a></p>\n',
        article_title: "08 | 封装线程池（下）：从0到1，体验程序设计全过程",
      },
      {
        title: "09 | 归并排序：如何解决逆序数问题？",
        herf: "https://time.geekbang.org/column/article/281803",
        id: "281803",
        content:
          '<p>你好，我是胡光，欢迎回来。</p>\n<p>通过前面几节课，我们完成了线程池的封装，经历了从算法到工程开发的全过程。今天，我们继续学习排序类算法，开始学习归并排序。说到归并排序，我们就会想到一类非常经典的算法面试题，求逆序数的问题。</p>\n<p>接下来，我们就一起来看看今天要解决的问题：给你一个任意的序列，你怎么求出序列的逆序数？</p>\n<p>首先，我们要知道什么是逆序数。在一个排列中，如果一对数的前后位置与大小顺序相反，即前面的数大于后面的数，那么它们就是一个逆序。一个排列中逆序的总数就是这个排列的逆序数。</p>\n<p>我们看下面这个序列，根据逆序数的定义，序列中逆序的个数有 5 个，分别是（7，2）、（9，2）、（7，6）、（9，6）和（14，12）。</p>\n<p><img src="https://static001.geekbang.org/resource/image/13/60/138bb197eb689848b84367d32bcbab60.jpg" alt="" /></p>\n<p>那要求序列的逆序数，一种最简单的做法就是，我们从前向后遍历序列的每个位置，每到一个位置，我们就记录一下有多少个元素大于当前位置值。这样，遍历完这个序列之后，我们就得到了它的逆序数。这种做法的时间复杂度是 $O(n^2)$，也是逆序数问题的一个时间上限。接下来，我们就一起来讨论一下，怎么利用归并排序算法来优化这个时间复杂度。</p>\n<h2>简述归并排序</h2>\n<p>归并排序的算法过程，我们可以基于递归的思想来学习和理解。递归是什么呢？递归是一种编程技巧，“递归”中的每一步过程都类似，可是问题规模不同。</p>\n<p><img src="https://static001.geekbang.org/resource/image/a5/ee/a5d4fe3657a6fa2e9e30d3034d08efee.jpg" alt="" title="递归示意图" /></p>\n<p>假设，我们要用归并排序对一组无序数组排序。根据递归的思想，我们可以将当前序列的左半部分和右半部分，分别排成两个有序数组，然后我们再将左右两个有序数组，合并成一个有序序列，这样就完成了当前序列的整体排序。整个过程如图所示：</p>\n<p><img src="https://static001.geekbang.org/resource/image/d8/aa/d81377b3cc9296c232c73db4171781aa.jpg" alt="" /></p>\n<p>因此，对于一个无序序列，归并排序算法会先把序列的左右两半部分看成是两个待排序的子问题，先解决这两子问题，再把得到的两个有序子序列合并成一个完整的有序序列。</p>\n<p>这当中涉及一个非常重要的算法思想，分治算法。分治算法的过程，就是将当前问题先分成若干个规模更小的子问题，通过先解决小规模的子问题，最终得到原问题的解。正如这个算法名字一样，就是分而治之的意思。</p>\n<p>使用递归实现归并排序的算法写成代码的话，大致如下：</p>\n<pre><code>void merge_sort(int *arr, int l, int r) {\n    if (l == r) return ;\n    int mid = (l + r) &gt;&gt; 1;\n    merge_sort(arr, l, mid);\n    merge_sort(arr, mid + 1, r);\n    merge(arr, l, mid, r);\n    return ;\n}\n</code></pre>\n<p>如代码所示，我们先给merge_sort 函数传入三个参数，分别是数据数组 arr，待排序区间的起始位置 l 以及 待排序区间的终止位置 r。程序的第 2 行，是递归的终止条件，也就是当待排序区间中只剩下 1 个元素的时候，就可以直接返回结果。代码的第 3 行定义了一个整型变量 mid，代表待排序区间 l 到 r 的中间位置。之后我们对左区间 l 到 mid，以及右区间 mid + 1 到 r 分别排序。最后，我们通过调用 merge 方法，将左右两个有序区间合并成一个有序区间。</p>\n<p>从代码中，我们可以看到，实现归并排序的重点就是 merge 方法，也就是将两个有序数组合并成一个有序数组的过程。下面，我们就来重点讲解一下这个合并过程。</p>\n<h2>归并排序中的 merge 过程</h2>\n<p>将两个有序数组合并成一个有序数组的过程中，我们可以每次选出两个有序数组中最小的元素，把它放到结果数组中，当两个有序数组中的元素都被取干净以后，merge 过程就结束了。</p>\n<p>举个例子，我们模拟2个有序数组的合并过程，这2个数组一共有6个元素。从下图中可知，在合并的过程中，我们需要一个额外的存储空间，用来存放合并以后的结果。当然，在归并排序的过程中，当我们完成了合并以后，还需要把合并以后的结果，拷贝回原数组所对应的空间中。</p>\n<p><img src="https://static001.geekbang.org/resource/image/5e/a2/5e9885e7293ff606a1475b63b00faea2.jpg" alt="" /></p>\n<p>上述过程所对应的代码如下：</p>\n<pre><code>void merge(int *arr, int l, int mid, int r) {\n    int n = r - l + 1;\n    int *temp = (int *)malloc(sizeof(int) * n);\n    int p1 = l, p2 = mid + 1, k = 0;\n    while (p1 &lt;= mid || p2 &lt;= r) {\n        if (p2 &gt; r || (p1 &lt;= mid &amp;&amp; arr[p1] &lt;= arr[p2])) {\n            temp[k++] = arr[p1++];\n        } else {\n            temp[k++] = arr[p2++];\n        }\n    }\n    for (int i = 0, j = l; i &lt; n; i++, j++) {\n        arr[j] = temp[i];\n    }\n    free(temp);\n    return ;\n}\n</code></pre>\n<p>我来说说其中的重点代码。</p>\n<p>首先是代码中的第 3 行。我们申请了一个额外的存储空间 temp，用来存放合并的结果。下一行的 p1、p2分别指向两个有序数组的第一个元素。</p>\n<p>然后在第 5 行，我们设置了 while 循环条件，当两个数组中某一个还有元素的时候，合并过程继续。</p>\n<p>为什么要这么设置呢？因为在合并过程中，我们首先要考虑，什么情况下会将第一个数组中的元素放入结果数组 temp 中。其实很简单，只有在两种情况下，我们会把第一个数组中的元素放入到结果数组中。</p>\n<p>第一种情况，就是当第二个数组为空时。第二种情况，就是两个数组不为空，并且第一个数组中的元素小于等于第二个数组中的元素。这分别对应了代码中你所看到或语句中的两个条件。否则，我们就将第二个数组中的元素放入结果数组中。</p>\n<p>最后是代码的第 12 行到第 15 行，我们将最后合并的结果放置回原数组对应的位置中。至此，归并排序中最重要的 merge 过程，我们就学习完了。</p>\n<h2>解决逆序数问题</h2>\n<p>理解了归并排序之后，我们再来优化逆序数问题的解决方案。这里，我们可以参考分治的思想。具体的优化方案是，如果我们能先求左半边的逆序数 a，再求右半边的逆序数 b，最后求出跨越左右两边的逆序数 c，三个逆序数相加的和，不就是全体数组的逆序数了吗？</p>\n<p>这个方法可行吗？我们通过课程开始的数组来验证一下。</p>\n<p><img src="https://static001.geekbang.org/resource/image/ef/3f/ef01cb577e6085a42731aa39de5fec3f.jpg" alt="" /></p>\n<p>现在，这个序列有 7、9、2、6、14、12这6个数字，我们把它们按顺序平均分成两部分。这样，左半部分逆序数是2个，右半部分逆序数是 1个，跨越中间的逆序数是 2 个，所以整个序列的逆序数就是 5 个。</p>\n<p>如果把求逆序数的这个过程写成代码，如下所示：</p>\n<pre><code>int inversion_number(int *arr, int l, int r) {\n    if (l == r) return 0;\n    int mid = (l + r) &gt;&gt; 1;\n    int a = inversion_number(arr, l, mid);\n    int b = inversion_number(arr, mid + 1, r);\n    int c = across_number(arr, l, mid, r);\n    return a + b + c;\n}\n</code></pre>\n<p>代码中的 inversion_number 函数就是求解序列逆序数的方法，传入数组 arr，以及求解区间 l 到 r，返回值是一个整型，代表在数组 arr 的 l 到 r 区间内的逆序数个数。函数中，mid 代表 l 到 r 的中间位置，我们从中间位置将数组分成左右两部分，分别调用 inversion_number 函数进行递归求解，并分别得到左右两部分的逆序数 a 和 b，然后通过 across_number 方法求解跨越中间的逆序数 c，最后返回 a + b + c，就是数组 arr 从 l 到 r 位置的逆序数了。</p>\n<p>观察上面的代码过程，你发现了什么？如果不看返回值的话，是不是就是改了名字的归并排序代码过程？在归并排序的代码实现中，关键部分是 merge 合并左右两部分的过程，而在求解逆序数的这个代码中，最关键的也是 across_number 求跨越左右两部分逆序数个数的这个过程。</p>\n<p>实际上，我们可以参考归并排序中 merge 合并的过程，来实现 across_number 过程。你可以先想一想逆序是怎样产生的：我们把一个较小的值放到一个较大值的后面，就产生了一个逆序。而在 merge 合并过程中，我们将左右两部分合并成一个有序数组，当右半部分数组中的元素被放置到合并数组中，我们就可以知道，当前的这个数字与左半部分数组中剩余的数字分别产生了一个逆序。</p>\n<p><img src="https://static001.geekbang.org/resource/image/7e/7c/7e918dc83605b532e0960d5822674a7c.jpg" alt="" /></p>\n<p>结合上图你会看到，当右侧有序数组中的 5 被放入到合并数组中，左侧还剩下 6 和 14 两个元素，此时，我们所统计的逆序数量就增加了 2 个。通过这个过程，当完成 merge 合并操作以后，跨越中间的逆序数量我们也就统计完了。这个过程的实现，只需要我们在 merge 函数中增加两、三行代码就可以了。是不是很简单呢？</p>\n<h2>课程小结</h2>\n<p>今天，我们学习了一种算法思想叫做分治，就是把大问题分成很多个小问题，依次解决之后得到大问题的解。基于分治思想，我们学习了最基本的归并排序的算法过程。最后，我们利用归并排序的代码框架解决了逆序数的问题。</p>\n<p>今天的重点内容用一句话总结，就是分而治之，你一定要记住。</p>\n<h2>课后练习</h2>\n<p>最后，你能试着修改一下 merge 函数，求出序列7、9、2、6、14、12的逆序数吗？欢迎你把答案写在留言区，我们一起讨论。</p>\n<p>你会用归并排序解决逆序数问题了吗？快把这节课也转发给你的朋友吧！今天就讲到这里了，我是胡光，我们下节课见。</p>\n',
        article_title: "09 | 归并排序：如何解决逆序数问题？",
      },
      {
        title: "10 | 多路归并排序：如何解决搜索引擎中的大数据排序问题？",
        herf: "https://time.geekbang.org/column/article/282904",
        id: "282904",
        content:
          '<p>你好，我是胡光，欢迎回来。</p>\n<p>上节课，我们学习了归并排序算法的基本思路，由归并排序算法我们了解了分治算法的基本思想，并且配合归并排序的代码框架解决了求解逆序数的问题。</p>\n<p>其实，归并排序能够解决的问题非常多，今天，我们把目光放到工业界的搜索引擎上，来说说怎么利用归并排序解决大数据排序问题。</p>\n<p><span class="orange">老规矩，我先给你出一道题：假设给你一组数据让你排序，你会怎么做？我们可以轻松回答出来，使用快速排序、堆排序或者归并排序都可以完成这个任务。那如果我告诉你这组数据有4TB，也就是说，现在有 4096GB 大小的数据正在等你排序，你又该怎么做呢？</span></p>\n<p>这时候你会发现，之前我们学习的排序算法都不灵了。因为我们之前所掌握的算法，好像都需要先将数据存放在内存中才能进行操作，而现在要处理的数据量太大，无法全部载入内存中。内存都存不下的数据，我们肯定操作不了。</p>\n<p>那你可能有疑问了，什么情况下，我们才会遇到数据量这么大的排序问题呢？其实很容易就能想到，像是搜索引擎、推荐系统、广告引擎等等都需要处理这么大的排序问题。那它们是怎么做的呢？下面，我们就以搜索引擎为例，一起来看看。</p>\n<h2>搜索引擎中的倒排索引</h2>\n<p>搜索引擎想必你不陌生，会使用搜索已经是现代人必不可少的生存技能之一了。我们在使用百度或者谷歌这类搜索引擎的时候，可以利用网页内容搜索相关网页，也是利用内容进行索引。能够完成这种搜索方式的最大功臣，就是搜索引擎底层的倒排索引结构。近几年来，搜索引擎其实也开始引入很多前沿的技术，比如<strong>知识图谱</strong>这种图存储结构，用来补充倒排索引在功能上的缺陷。</p>\n<p>倒排索引结构对于搜索引擎来说是非常重要的，可以说是搜索引擎的底层核心。那在建立倒排索引的过程中，非常重要的一步就是对大量的数据进行排序，而且它要处理数据量远大于内存的大小。</p>\n<p>接下来，我们来详细说说倒排索引的结构。</p>\n<p><img src="https://static001.geekbang.org/resource/image/b5/7e/b5510b68e02d260d17d5cd6beeb3487e.jpg" alt="" /></p>\n<p>假设，现在有三个网页，编号依次是1、2、3。通过分析网页内容，我们在每个网页里面都能提取出若干可以代表该网页的关键词，以及每个关键词和该网页的一个相关程度。网页1中包含关键词1和2，相关程度分别是 0.4 与 0.3；网页2中包含关键词1、3和4，相关程度分别是0.9、0.4 和 0.5；网页3中包含关键词2和3，相关度分别是0.7和0.2。</p>\n<p>倒排索引就是以关键词作为索引项，再把与关键词相关的网页按照其与关键词的相关程度，从高到低排序所形成的索引结构。这句话比较绕，具体的你可以参考上图进行理解。</p>\n<p>这里，我再举个例子，让你理解倒排索引的作用。当我们搜索关键词3的时候，在倒排索引中，相关网页是网页2和3，搜索引擎会按照相关程度将网页从前到后展现在我们的页面上。那关键词与网页的相关程度到底是怎么算出来的？可用的算法可以说是五花八门了，其中最简单的就是 TF-IDF。你可以自己搜索一下，来了解相关的内容。</p>\n<p>通过这个案例我们知道，建立倒排索引的过程中，我们要根据网页与关键词的相关程度进行排序，而这个排序量就属于大数据排序场景，一般内存是装不下的。拿教育这个关键词举例，在百度上搜索到的网页数量就有1亿个，如果每个文档的数据量是1kb，光这一个关键词涉及的排序数据量就是 100GB，当然这还是保守估计。</p>\n<p>那么，这种大数据排序的问题应该怎么解决呢？接下来，我们就来解决这个问题。</p>\n<h2>多路归并排序</h2>\n<p>首先，我们来理解两个概念：<strong>内部排序</strong> 与 <strong>外部排序</strong>。</p>\n<p>所谓内部排序，就是在内存中进行的排序，比如，我们之前学过的快速排序和堆排序。快速排序中每一轮的 partition 操作和递归操作，其实都是在内存中完成的。那堆排序中，建堆以及最后弹出元素调整的过程，也都需要元素在内存中。</p>\n<p>但是，在对大数据进行排序的时候，数据是无法一次性装进内存的，需要分成若干次。因此，外部排序就是将待排序数据先分割成若干个可以存进内存的小文件，再对这若干个小文件分别排序，最后合并成若干个有序小文件的过程。</p>\n<p>外部排序的过程，是不是听着有点儿像我们学过的归并排序的升级版？没错，归并排序在合并数据的时候，合并的是两个有序数组，所以准确来说它应该叫<strong>二路归并排序算法。</strong>而外部排序合并的是多个有序文件，其实我们也可以把它们看成是多个有序数组。那将多个有序数组合并成一个有序数组的算法，就叫做多路归并排序，也就是所谓的归并排序的升级版。</p>\n<p>基于此，我们其实可以把二路归并排序当作是多路归并排序的一个特例。</p>\n<p>我们上节课学习的归并排序，准确来说叫做二路归并排序，而这种所谓归并排序的升级版，名字就叫做多路归并排序，而二路归并排序就是多路归并排序的一个特例。</p>\n<p>那我们就可以通过二路归并排序，推导出多路归并排序的过程。因此，我们就可以通过二路归并排序，推导出多路归并排序的过程。</p>\n<p>我们先回忆一下，二路归并排序算法的合并过程。在将两个有序数组合并成一个的时候，每次我们都是在两个数组头部选取一个最小值放入到合并数组中。因此，多路归并排序算法就是将多个有序数组合并成一个，在合并的过程中，每次从多个数组的头部选择一个最小值加入到合并数组中。这里的数组，你可以理解成是文件或者集合。</p>\n<p><img src="https://static001.geekbang.org/resource/image/0e/d3/0e1fd1a10858b46013262e5943d96fd3.jpg" alt="" /></p>\n<p>结合上图，红色虚线框内部是所有待合并数组的头部元素，每一次我们都从这个红色的集合中选择一个最小值放入到合并数组中，之后还会有一个新的元素进入到红色虚线框内。</p>\n<p>这一步就是考查你算法思维的时候了，你觉得对于红色虚线框内部的元素，我们应该用什么数据结构进行维护？答案是一个支持添加元素和弹出最值元素的数据结构，这是不是和我们之前讲到的堆的性质是一致的？</p>\n<p>好，其实到这里，今天的问题我们就解决了，多路归并是不是很好理解？在这里，我还想再强调一下，我们在学习数据结构的时候，学习的是每种数据结构适用的问题性质，只有扎实地掌握了每种数据结构所适用的问题性质，你才能真正具备运用数据结构解决实际问题的能力。</p>\n<h2>课程小结</h2>\n<p>在今天的课程中，我们在原本数据排序问题的基础上，增加了数据量，提出了大数据场景下的数据排序问题。面对这种无法一次性读入内存的数据排序问题，我们通常是将数据，分割成若干个可以载入内存的部分分别排序，并且将排序结果写入到相关文件中，最后我们再对这些有序文件执行合并操作，合并操作这一步可能需要借助我们之前学过的堆结构。</p>\n<p>多路归并排序最重要的应用场景之一，就是搜索引擎中的倒排索引结构，相信通过今天的内容也能够帮助你理解倒排索引。</p>\n<p>如果说，通过今天课程我只想让你记住一句话，我想那应该是：学习每种数据结构能够解决问题的性质，才是掌握数据结构的核心法门。</p>\n<h2>课后练习</h2>\n<p>最后，你能参考前几堂课的代码，用你熟悉的语言来完成本堂课多路归并排序的算法代码吗？</p>\n<p>欢迎把你的实现代码和疑问写在留言区，我们一起讨论，也欢迎你把这节课分享给你的朋友。好了，今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title:
          "10 | 多路归并排序：如何解决搜索引擎中的大数据排序问题？",
      },
      {
        title: "11 | 算法思维：融汇贯通，教你3个有趣的排序算法",
        herf: "https://time.geekbang.org/column/article/283642",
        id: "283642",
        content:
          '<p>你好，我是胡光，欢迎回来。</p>\n<p>我们前面学了这么多的排序算法，你都掌握了吗？这里，我带你总结一下。这一模块我们主要学习了三大种排序算法：</p>\n<p><strong>1.  快速排序及快速排序的优化思想；<br />\n2.  堆结构及堆排序算法，此外，我们还使用优先队列封装了一个线程池工具；<br />\n3.  归并排序算法，以及用多路归并排序解决大数据排序问题。</strong></p>\n<p>总的来说，它们的目的都是对数据排序。乍一看这是一个具体的问题，那我们一般认为只要是具体问题，就应该有一个具体的解决方案，可我们为什么花了好几节课去解决这个问题呢？或者说，我们为什么要学习这些不同种类的排序算法呢？</p>\n<p>其实，这就问到了算法学习的核心。我们学习排序算法，一是为解决不同场景下的排序问题做知识储备，二是为了学习不同算法的不同思维方式以及相关的延伸应用。从中我们可以体会到不同算法思维的闪光点，这也是我认为的算法学习的捷径。</p>\n<p>所以今天，我还想给你再讲几种有趣的排序算法，让你从不同的角度认识排序问题，深入体会算法思维。</p>\n<h2>理解多线程等待排序算法</h2>\n<p>还记得吗？在堆排序那节课中，我们封装了一个线程池工具。虽然说它是工具，可我们一直没有使用过这个工具。今天我们就用它来实现一个叫做多线程等待排序的算法。</p>\n<p>所谓多线程等待排序算法，是个有点搞笑的排序算法。在实际工作中，我们并不会用到它，可它的算法思想非常值得我们仔细品味。</p>\n<p>它的算法思想很简单，就是当我们要对 n 个整数排序的时候，就启动 n 个线程，让每个线程拿到一个数字，然后按照数字大小，让相应的线程依照数字大小决定睡眠时间，最后再输出这个线程负责的数字。</p>\n<p><img src="https://static001.geekbang.org/resource/image/28/25/28bc91b3408b222981a0d09d95047b25.jpg" alt="" /></p>\n<p>比如说，如果我们要对 4 个数字 12、2、6 和 20 排序的话，就启动 4 个线程。这4个线程分别是在2秒的时候输出2，在6 秒的时候输出 6，在12 秒的时候输出 12 以及在20 秒的时候输出 20。数据输出的时间顺序，就是我们要的数字排序顺序。</p>\n<p>听完这个算法的过程以后，想必不用我强调，你也知道这个排序算法很难应用到实际场景中。其实，我讲它的目的，就是单纯希望能够帮助你体会不同算法思维的闪光点。毕竟，<strong>接口的调用千篇一律，有趣的算法万里挑一</strong>。</p>\n<h2>理解计数排序算法</h2>\n<p>多线程等待排序算法是利用<strong>程序系统的特性</strong>完成排序任务的一种算法，那接下来，我还想给你讲一种根据数据特性排序的计数排序算法。</p>\n<p>首先，我们来解决一个问题：如果要对全国 14 亿人按照年龄排序的话，你会怎么做？根据之前所学的知识，你可能会采用快速排序或者归并排序，又或是堆排序来完成任务。这些排序的时间复杂度的最好情况都是 O(nlogn)，在 n 等于 14 的时候，logn 大约等于 30 多。这种效率等价于对全体数据扫描30多遍。</p>\n<p>其实，从工程实现的角度来说，这种效率是完全可以接受的，毕竟对全国人民进行排序，等待个 30 秒左右也不算长。可对于我们学习算法来说，即使应用不到真正的工程中，我们也要知道这个算法的优化方向。</p>\n<p>再仔细看一遍问题我们会发现，年龄数据有一个很强的特点：一般都在3位数以内。由于规定“建国以后不许成精”，因此我们也收集不到4 位数的年龄情况，并且我们假设年龄数据都是整数。根据年龄数据的这种特点，我们就可以采用计数排序算法来排序。</p>\n<p>最简单的计数排序思想是，我们利用数组这种存储结构，记录每种数字出现的次数，最后根据统计得到的信息进行相应的输出。大体流程如下图：</p>\n<p><img src="https://static001.geekbang.org/resource/image/54/aa/549aef6c18ff8992d6cc6dac3d675eaa.jpg" alt="" /></p>\n<p>比如说，在面对一组无序的整数的时候，假设数据的范围在 0-5 之内，对于计数排序来说，只需要开一个大小为5的数组空间，数组的第 i 位统计的就是数字 i 出现的次数。结合上图的例子，我们可以统计得到 0 出现了 3 次，1 出现了 2 次，依次类推。这样，在输出的时候，我们只需要先输出 3 个 0，再输出 2 个 1，按照这个过程依次处理每一个数字的输出即可。</p>\n<p>其中，统计每种数字出现的次数，需要 O(n) 的时间复杂度。也就是说，我们对原序列扫描一遍就能完成统计过程。输出的时间复杂度也是 O(n + m) 的，m 是数据范围，n 是元素数量，在 m 远远小于 n 的排序问题场景中，我们把这个输出的时间复杂当成 O(n)，所以计数排序算法的整体时间复杂度是 O(n) 的。这简直快到飞起。</p>\n<p>理解了计数排序算法，我们再回到对 14 亿人按照年龄排序的场景中。这个时候，我们只需要按照计数排序算法的思想，开一个 200 位的数组，然后将每个人根据其年龄放入数组对应的位置中。所谓“放入数组对应的位置中”，就不像是上面统计每种数字个数的操作那么简单了。想要完成这个操作，你可以去学习一些链表相关的操作，例如：链表节点的头插法、开辟一个链表数组等知识。这里我就不细讲了。</p>\n<p>总的来说，如果数据具备这种数据范围小，可以有序地映射成数组整型下标的排序问题，采用计数排序算法，是一种既简单又高效的做法。</p>\n<h2>理解基数排序算法</h2>\n<p>不同的算法思维就像通往殿堂的一级级台阶，大部分人都想要一步踩在最后一级台阶上，不想为前面的台阶浪费时间和体力，可哪有什么捷径可走呢，我们只能慢慢来。就像我最后想给你讲的基数排序算法，如果你单纯来学这个算法思想可能会比较难，可基于计数排序的算法思想来理解就会简单很多。</p>\n<p>刚刚计数排序的思想中，待排序的数值，由于范围比较小，所以可以和数组下标一一对应起来。那如果数据范围很大，根本没有办法和数组下标一一对应的时候，我们还能利用计数排序的思想来做吗？</p>\n<p>首先，我们假设所有数字的位数都是一样的，如果出现位数比较少的数字，我们就在这个数字前面补 0。例如，我们假设所有数字都是 3 位数字，当有一个数字是 53 的时候，我们可以认为这个数字可以表示成 053。</p>\n<p>当我们对这样一组数字完成排序以后，数字开头是 0 的数字肯定会排在开头是 1 的数字前面，开头是 1 的数字肯定排在开头是 2 的数字前面，依次类推。也就是说，对于相同位数的数字，我们是可以逐位进行比较的。</p>\n<p>因此，基数排序的核心思想就是进行多轮操作，每轮以数字的其中一位作为排序的依据，当处理完数字的全部位置以后，整个序列就变得有序了。这么说还是太抽象了，下面我就通过具体的例子，给你讲一讲基数排序的整体过程。</p>\n<p>首先，假设有8个两位数待排序，分别是：56、28、36、26、54、35、19、37。如下图所示，我们先按照最低位将每个数字排序放好。</p>\n<p><img src="https://static001.geekbang.org/resource/image/8c/c3/8c32c13cb081e9f9885ec22ae56d36c3.jpg" alt="" /></p>\n<p>我们按照计数排序的思想，统计每一个位上每种数字出现的个数，然后做前缀和累加。所谓前缀和累加，就是求当前位置之前的所有元素的和值。为什么要预处理前缀和呢？我们先往下看。</p>\n<p>根据前面的数据，我们可以统计得到，末尾为数字4的有 1 个数字，数字 5 的有 1 个数字，数字6是3个数字，依次类推。这样，在我们最后求得的前缀和数组中，位置 5 的记录值就是 2，这意味着末尾小于等于 5 的数一共有 2 个，分别是 54 和 35；位置 6 的记录值是 5，这意味着末尾小于等于 6 的数一共有 5 个，分别是 54、35、56、36、26。</p>\n<p>现在你明白前缀和的作用了吧？前缀和就代表，每一种数字最后放置的位置。</p>\n<p>这样一来，所有个位上为 6 的数字，会被放到第 3 位到第 5 位。而且，所有个位上为 6 的数字，要保持其原来的相对顺序进行放置，也就是要按照 56、36、26 的顺序依次放置。</p>\n<p>经过第一轮按照个位数排序的处理，我们得到了一个新序列：54、35、56、36、26、37、28、19。接下来，我们再使用相同的原理，对这些数字按照十位进行排序。</p>\n<p><img src="https://static001.geekbang.org/resource/image/4d/a1/4db11183b8046d3cb74f636926e024a1.jpg" alt="" /></p>\n<p>如图所示，我们还是分成两步来做，第一步是统计每一种数字出现的个数，以及求个数的前缀和。第二步，就是对每个数的十位数字，将原序列中的每个数字，放置到结果数组中，并且保持相同数字的相对位置不变。例如，其中十位数字是 3 的 3 个数字分别是35、36、37，只要我们保持三者在原序列中的相对位置不变，就能保证三者之间的顺序。因为，在第一轮按照个位数字排序的过程中，35一定排在 36 前面，36也一定排在 37 前面，所以第二轮只需要保持十位上相同数字相对位置不变，即可将十位相同的数字，按照个位数字的大小顺序放置。</p>\n<p>如果数字的位数更多，比如还有三位数字的话，我们只要再按照相同的步骤，进行第三轮处理就行了。</p>\n<p>最后，我们来总结一下基数排序。<strong>基数排序是从数据的低位到高位进行多轮处理，每一轮以其中一位做为排序的基准，在排序过程中，保证对应位置相同值元素的相对位置保持不变。我们管这种能够保证相同值元素相对位置的排序算法，叫做稳定排序。基数排序和归并排序就属于稳定排序，而之前我们学习的快速排序、堆排序都属于非稳定排序。</strong></p>\n<h2>课程小结</h2>\n<p>今天，我们学习了三种有趣的排序算法，分别是多线程等待排序、计数排序与基数排序。学习这些排序算法的目的不是为了解决排序问题，而是学习这些排序算法中所映射出来的思维方式。</p>\n<p>比如，多线程排序算法的设计，就是一种用来搞笑的算法。从某种程度上来说，如果你能理解这种幽默，那么程序设计对于你来说才是有意思的！</p>\n<p>再比如，利用数据特点设计的基数排序算法也给了我们启发，在不同问题场景中，数据特点可能不同，那么适用的算法可能也会不同，这也是为什么我们要学习大量算法思维的原因，因为工作中，你会遇到的问题场景中的数据特点是不确定的。</p>\n<p>最后就是基数排序，它是计数排序的基础思想再次升华以后得到的算法思想。所以，很多你看似无用的算法思维，很有可能是高阶算法的基础算法思维，因此在锻炼算法思维的时候，一定不要“挑食”。</p>\n<p>掌握算法思维，是一个循序渐进的过程，我们只有掌握了大量的简单的、基础的算法思维，才能更轻松地掌握那些复杂的算法思维。</p>\n<h2>课后练习</h2>\n<p>对于多线程等待排序与计数排序的算法过程，你能试着自己来实现吗？</p>\n<p>如果你也觉得我今天讲的这几种算法很有趣，那就快把这节课分享出去吧。好了，今天就到这里了，我是胡光，我们下节课见。</p>\n<hr />\n<p><a href="https://github.com/alicia-ying/jikeshijian.git">课程参考代码</a></p>\n',
        article_title: "11 | 算法思维：融汇贯通，教你3个有趣的排序算法",
      },
      {
        title: "12 | 面试实战：经典排序算法面试题详解",
        herf: "https://time.geekbang.org/column/article/284707",
        id: "284707",
        content:
          '<p>你好，我是胡光，欢迎回来。</p>\n<p>这个模块，我们主要讲了快速排序、堆排序、归并排序，以及几个有趣排序算法的原理。我相信，你也已经理解排序算法在整个计算机算法大厦中基础且重要的地位了。在我们实际编写程序的过程中，排序算法的应用无处不在。比如说，排序计数可以利用有限的空间消耗，来统计序列中每个词出现的次数。再比如说，处理大数据时的 map-reduce也频繁用到了排序算法。这都说明充分利用数据的有序性质，能让我们要做的事儿变得更简单。</p>\n<p>不仅如此，排序算法的原理和应用也经常作为考点，出现在基础算法面试中。所以今天，我们就来看几道经典排序面试题，让你从真正的算法面试题中积累经验。</p>\n<h2>磨刀不误砍柴工：C++中sort的用法</h2>\n<p>我们现在使用的主流编程语言中，大部分都已经把时间复杂度稳定在$O(n \\times log_2n)$的排序算法实现好了，所以我们在实际编程中不必自己去实现各类排序算法。C++ STL中的sort就是这样一个成熟的模块。因此，在讲具体的面试题之前，我想先给你讲讲它的用法。</p>\n<p>sort 函数是 C++ STL 的 algorithm 库中对线性序列的排序方法，sort 函数的作用是对一个序列进行本地升序排序。也就是说，我们只需要调用一下 sort 函数就可以完成升序排序。代码例子如下：</p>\n<pre><code>// example 1\n#include &lt;algorithm&gt;\n\nint main() {\n  \tint a[100] = {11, 77, 45, 62, 35, 37, 11, 11, 52, 13};\n\t\tstd::sort(a, a + 10);\n\t\t// a = {11, 11, 11, 13, 35, 37, 45, 52, 62, 77}\n  \treturn 0;\n}\n</code></pre>\n<p>但是你看到这段代码以后，可能就会有疑问了，调用sort 函数的时候，我们为什么要用sort(a, a + 10) 呢？它到底是什么意思呢？</p>\n<p>要弄明白这个问题，我们首先要理解a的概念。数组a变量实际上就是这个数组在内存空间中的首地址，因此，例子中的整数型数组 a+10  指的就是，从a 地址出发向后跨了十个整数型变量的地址。那sort 函数的参数就非常好理解了，其中，第一个参数是序列中我们想要排序的首位置，第二个参数就是末位置。这里你要注意，末位置是不参与排序的。</p>\n<p>明白了这一点之后，如果我想让你对数组中第2个数到第7个数进行排序，是不是就很简单了呢？没错，我们只需要把sort 函数后面的参数设置成a+1和a+8就行了。</p>\n<pre><code>// example 2\n#include &lt;algorithm&gt;\n\nint main() {\n  \tint a[100] = {11, 77, 45, 62, 35, 37, 11, 11, 52, 13};\n\t\tstd::sort(a + 1, a + 8);\n\t\t// a == {11, 11, 11, 35, 37, 45, 62, 77, 52, 13}\n  \treturn 0;\n}\n</code></pre>\n<h3>动态数组 vector 的排序</h3>\n<p>除了数组以外，sort同样可以对序列容器进行排序，比如说 C++ STL 的 vector。不过，我们使用 sort 对 vector 排序的时候，需要借助到容器的迭代器。迭代器是 C++ 中模拟指针的方式，它的使用方式和指针类似，就是在C++ 中通过重载运算符封装的指针对象，它本质上还是一个对象，只是表现得像个指针，所以同样也支持指针的间接引用运算符和取值运算符。因此，vector 迭代器的使用方式和数组类似，我们可以直接把前面两个例子中的a换成vector。</p>\n<p>我们再将 example-1 中的代码更改为 vector 的写法：</p>\n<pre><code>// example 3\n#include &lt;algorithm&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    int a[100] = {11, 77, 45, 62, 35, 37, 11, 11, 52, 13};\n    std::vector&lt;int&gt; b(a, a + 10);\n    for (int i = 0; i &lt; 10; i += 1) {\n        std::cout &lt;&lt; b[i] &lt;&lt; &quot; &quot;;\n    }\n    std::cout &lt;&lt; std::endl;\n    \n    // b.begin()指向的是b的首位置，b.end()指向的是b的末位置\n    std::sort(b.begin(), b.end()); \n    for (int i = 0; i &lt; 10; i += 1) {\n        std::cout &lt;&lt; b[i] &lt;&lt; &quot; &quot;;\n    }\n  \t// 11 11 11 13 35 37 45 52 62 77\n    std::cout &lt;&lt; std::endl;\n}\n</code></pre>\n<p>我们再将 example-2 中的代码更改为 vector 的写法：</p>\n<pre><code>// example 4\n#include &lt;algorithm&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nint main() {\n    int a[100] = {11, 77, 45, 62, 35, 37, 11, 11, 52, 13};\n    std::vector&lt;int&gt; b(a, a + 10);\n    \n    //定义int容器的迭代器，并初始化到b的首位置\n    std::vector&lt;int&gt;::iterator iter = b.begin(); \n    for (int i = 0; i &lt; 10; i += 1) {\n        std::cout &lt;&lt; b[i] &lt;&lt; &quot; &quot;;\n    }\n    std::cout &lt;&lt; std::endl;\n    std::sort(iter + 1, iter + 8);\n  \t\n    // 使用迭代器遍历容器的方法\n    for (iter = b.begin(); iter != b.end(); iter++) {\n        std::cout &lt;&lt; *iter &lt;&lt; &quot; &quot;;\n    }\n  \t\n    // 11 11 11 35 37 45 62 77 52 13\n    std::cout &lt;&lt; std::endl;\n}\n</code></pre>\n<p>我刚才说的呀，就是 sort 的基本用法了。但细心的你肯定也发现了，我前面讲的所有排序方法都是对序列升序排序，那如果我们想对序列降序排序，甚至是想要实现更加复杂的排序又该怎么办呢？</p>\n<h3>排序规则的指定：sort 隐藏的第三个参数</h3>\n<p>接下来，为了解决这个问题，我会给你讲sort 隐藏的第三个参数，比较规则函数。我们还是先看一个例子，代码如下：</p>\n<pre><code>// example 5\n#include &lt;algorithm&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nbool comp(int a, int b) {\n    return a &gt; b;\n}\n\nint main() {\n    int a[100] = {11, 77, 45, 62, 35, 37, 11, 11, 52, 13};\n    std::vector&lt;int&gt; b(a, a + 10);\n    std::vector&lt;int&gt;::iterator iter = b.begin();\n    for (int i = 0; i &lt; 10; i += 1) {\n        std::cout &lt;&lt; b[i] &lt;&lt; &quot; &quot;;\n    }\n    std::cout &lt;&lt; std::endl;\n    std::sort(b.begin(), b.end(), comp);\n    for (iter = b.begin(); iter != b.end(); iter++) {\n        std::cout &lt;&lt; *iter &lt;&lt; &quot; &quot;;\n    }\n    \n  \t// 77 62 52 45 37 35 13 11 11 11\n    std::cout &lt;&lt; std::endl;\n}\n</code></pre>\n<p>可以看到，通过给 sort 函数传入一个比较大小的函数comp，我们就把前后两项的大小关系颠倒了，从而实现了降序排序。</p>\n<p>所以，comp函数其实就是定义一种排序的规则，来比较它所接受的两个参数 a 和 b。最开始的时候， a 在原序列中排在 b 的前面，如果 a 与 b 的顺序不需要交换，函数就返回 true，如果需要交换就返回 false。</p>\n<p>利用 <strong>comp</strong> 函数的这个性质， 我们就可以实现对复杂结构的排序，比如结构体、pair等等，我就不再多说了，你可以自己试试。</p>\n<h2>经典面试题详解</h2>\n<p>我相信，你现在已经知道怎样在C++中使用排序，来方便地实现一个有序的序列了。那接下来，我们就说说怎么利用排序以及有序序列的性质，来解决相关的面试题了。</p>\n<p>不过啊，我想先和你聊聊我对面试的看法。我一直强调，在算法面试中题目的答案不是最重要的，理解面试官真正想要考察什么才重要。我认为面试题其实仅仅只是一种手段，面试官想要通过它来考察你内在的思维方式，看你是不是能把学过的算法灵活地提取成一种思维，应用在编程还有其他问题里。也就是说，<strong>面试考察的是思维能力，而不是记忆力</strong>。</p>\n<p>所以在接下来讲解面试题的过程中，我会重点来讲怎么利用有序序列的特性来解决每一个相关的问题。</p>\n<h3>1.  2-sum问题</h3>\n<p>首先，我们来看2-sum问题。这道题是LeetCode题库中的第一题，如果你刷过题就肯定见过它。我们先来看一下这道题目：</p>\n<blockquote>\n<p>给定一个整数数组nums和一个目标值target，请你在该数组中找出和为目标值的那两个整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。<br />\n <br />\n示例：<br />\n给定 nums = [2, 7, 11, 15], target = 9<br />\n因为 nums[0] + nums[1] = 2 + 7 = 9<br />\n所以返回 [0, 1]</p>\n</blockquote>\n<p>在解决这道题之前，我们还得先来讲一个新的概念——杨氏矩阵。杨氏矩阵的性质是，它的每一行都是从左到右递增的，而每一列都是从上到下递增的。</p>\n<p><img src="https://static001.geekbang.org/resource/image/43/52/43a0d0fb820175ae299f8d7852fdd252.jpeg" alt="" title="杨氏矩阵示意图\n" /></p>\n<p>那知道杨氏矩阵有什么用呢？我们来看一道经典的习题：给定一个杨氏矩阵和一个整数 x，问整数 x 是否在杨氏矩阵中。</p>\n<p>它的解法是，我们从右上角开始查找，对于矩阵中的当前元素 a。如果 x&lt;a，那 x 不可能在 a 所在的那一列。如果 x&gt;a，那 x 不可能在 a 所在的那一行。当然相对称地，从左下角开始查找原则也是一样的。</p>\n<p><img src="https://static001.geekbang.org/resource/image/f6/d3/f6a9c1547a91cd86aff9a377eaa256d3.jpeg" alt="" /></p>\n<p>你可以看到，在最差情况下，我们也只需要从一个角落走到另一个角落。假设矩阵的长度为 N，宽度为 M，那我们只需要进行 N+M 次比较，就可以找到目标值。可是杨氏矩阵问题跟 2-sum 问题又有什么关联呢？我们先接着往下看。</p>\n<p>2-sum问题有一个非常经典的解法，就是给数组 a 排序，然后在数组的头部设置一个指针  p_head ，在数组的尾部设置一个指针p_tail  。如果两个指针所指位置的元素和大于目标值target   ，那 p_tail向前挪动一步。如果二者相加的和小于目标值target，那p_head向后挪一步，直到找到等于目标值为止。这个做法我们叫它双指针法。</p>\n<p>那我们为什么要这么做呢？其实对于2-sum问题来说，我们最直观的做法，就是先把这个数组中的所有元素两两加和，然后从这些结果中寻找目标值。因此，我们所需要的是一种高效的查找方式，而有序序列的查找方式就比直接枚举高效多了。</p>\n<p>我们可以想象一个表格，将排好序的序列分别放在表格的首行和首列，表格中其他位置是对应首行、首列相加的和。这里，我们以2-sum问题中的数字为例。</p>\n<p><img src="https://static001.geekbang.org/resource/image/55/12/55e3e66167c741a9a461f7c6c0f04312.jpeg" alt="" /></p>\n<p>你发现了吗？我们刚好构造了一个杨氏矩阵出来，这个矩阵中除红线所画过的对角线之外都是我们的搜索空间。而右上角或左下角的位置，也刚好就是 p_head和 p_tail 位置相加的和，所以两个指针的每一次移动，我们都可以看作是杨氏矩阵中的一个比较和移动的操作。那么实际上这道题的双指针做法，就可以看作是在生成的杨氏矩阵中查找目标值的位置并返回。</p>\n<p>因为杨氏矩阵是数组元素两两之间计算得到的二维表格。所以，虽然双指针解法是在一维数组上操作的，但实际上它是一种二维思维。这类面试题实际上是在考察我们，优化这类求和查找的思路，让它变得更方便。因此，一个优秀的面试过程，往往考查的不是题目的答案，而是本质的思维方式。这也是为什么，有的时候我们虽然回答出了某些题目的正确答案，但面试官依然不满意。</p>\n<h3>2.  存在重复元素</h3>\n<p>2sum问题就讲完了，我们接着来看第二道题。</p>\n<blockquote>\n<p>给定一个整数数组和一个整数 k，判断数组中是否存在两个不同的索引 i 和 j，使得 nums [i] = nums [j]，并且 i - j 的 绝对值 至多为 k。<br />\n <br />\n示例 1:<br />\n输入: nums = [1,2,3,1], k = 3<br />\n输出: true<br />\n <br />\n示例 2:<br />\n输入: nums = [1,0,1,1], k = 1<br />\n输出: true<br />\n <br />\n示例 3:<br />\n输入: nums = [1,2,3,1,2,3], k = 2<br />\n输出: false</p>\n</blockquote>\n<p>这道题中，首先让我们寻找的是数组中是否存在重复元素。很显然，我们通过排序或哈希计数的方式，都可以直接判断出数组中是否存在重复元素。由于，题目中同时要求重复元素索引之差的绝对值至多为k，因此，我们只需要判断数组中，两个距离最近的重复元素，是不是小于或者等于 k 就可以了。</p>\n<p>知道了这些，我们再分别说说通过排序或哈希计数怎么解决这个问题</p>\n<p>首先是<strong>排序法</strong>。我们知道，有序数组中重复元素的位置都是相邻的，所以我们只需要修改排序条件，让重复元素的索引是升序排列的即可。也就是说，我们只需要判断相邻的重复元素的索引之差是否小于等于 k 。</p>\n<p>其次是哈希计数法。我们需要记录<strong>每一个元素最后出现的位置</strong>。哈希表中记录的索引值，就是在这个元素之前，离它最近的重复元素的索引值。这样一来，我们把它们之间的差和k比较就行了。</p>\n<p>我们来做个总结，这类查找重复元素的题目，通常考查的是我们算法思维的广度，一道题目也会有很多种解法，解决方法的不同也反映了每个人思维方式的不同。因此，能够清楚每种解法的优劣性才是我们学习的重点。</p>\n<h3>3. 两个数组的交集</h3>\n<p>现在，找出存在重复元素的问题就解决了。我们再来看第三道题，求两个数组的交集 。题目是这样的：</p>\n<blockquote>\n<p>给定两个数组，请你编写一个函数来计算它们的交集。<br />\n <br />\n示例 1：<br />\n输入：nums1 = [1,2,2,1], nums2 = [2,2]<br />\n输出：[2,2]<br />\n <br />\n示例 2：<br />\n输入：nums1 = [4,9,5], nums2 = [9,4,9,8,4]<br />\n输出：[4,9]</p>\n</blockquote>\n<p>这个问题，我们同样可以利用有序序列的特性来尝试解决。具体怎么做呢？</p>\n<p>假设，我们要在一个升序的序列中查找一个元素。对于某一个位置 x 来说，如果我们要查找的目标元素比它大，那目标元素必然不会存在于 x 的左边，这是二分法能够成立的条件。</p>\n<p>求交集的问题，我们可以以在一个升序数组a 中查找另外一个数组 b 中包含的所有元素为例，如果我们按照升序顺序依次查找 b 中的每一个元素，每进行到下一次枚举的时候，新枚举到的元素也不可能存在于之前已经枚举过的地方。因此每一步都在缩小我们需要查找的边界。</p>\n<p><img src="https://static001.geekbang.org/resource/image/f6/38/f6a86bbeb464c0a0546c149e3451d338.jpeg" alt="" /></p>\n<p>这样一来，这个问题其实也可以用双指针法来解决，具体解法是，我们先对数组 nums1 和 nums2 排序，然后分别在 nums1 和 nums2 的首部设置两个指针 p_nums1 和 p_nums2 。</p>\n<ul>\n<li>如果 nums1[p_nums1]&gt;nums2[p_nums2] ，就说明 nums1[p_nums1] 一定不在 p_nums2 及之前，那 p_nums2 就后移一步</li>\n<li>如果 nums1[p_nums1]&lt;nums2[p_nums2] ，就说明 nums1[p_nums1] 一定不在 nums2 中，所以 p_nums1 后移一步</li>\n<li>如 nums1[p_nums1]=nums2[p_nums2] ，就说明我们找到交集了，两个指针都后移一步就行了</li>\n</ul>\n<p>在整个查找过程中，由于两个数组都只遍历了一次，因此我们查找所用的时间复杂度是线性变化的。如果 nums1 的长度是N， nums2 的长度是M，那这个方法的时间消耗为$O(M\\times log_2M+N \\times log_2N+N+M)$。</p>\n<h3>4.  合并两个有序的数组</h3>\n<p>好了，第三道题也解决了，我们来看最后一道题，怎么合并两个有序数组。</p>\n<blockquote>\n<p>给你两个有序整数数组 nums1 和 nums2，请你将 nums2 合并到 nums1 中，使 nums1 成为一个有序数组。这里我要说明一点：初始化 nums1 和 nums2 的元素数量分别为 m 和 n 。你可以假设 nums1 有足够的空间（空间大小大于或等于 m + n）来保存 nums2 中的元素。<br />\n <br />\n示例：<br />\n输入：<br />\nnums1 = [1,2,3,0,0,0], m = 3<br />\nnums2 = [2,5,6], n = 3<br />\n输出：[1, 2, 2, 3, 5, 6]</p>\n</blockquote>\n<p>显而易见，这道题就是拆分了归并排序中的一个过程。我相信，在掌握了归并排序算法之后，你肯定能很快知道这道题的解法。</p>\n<p>不过我们还看到，题面中还有一个条件，就是要在 nums1 中做原地合并，并且 nums1 中也预留了用来合并的足够空间。有了这个条件，这道题就和常规的归并排序有些不一样了。在原地合并的过程中，我们需要注意，不要覆盖掉 nums1 中已有的元素，破坏原数组。</p>\n<p>具体怎么做呢？我们注意到， nums1 中预留的空间都集中在它的尾部，所以我们可以考虑优先把尾部的空位填满。这样一来，剩余头部位置就相当于是给剩余元素留出来的空位。因此，在这种情况下，我们就不需要担心原来 nums 中的元素会被覆盖掉。</p>\n<h2>课程小结</h2>\n<p>这节课，我们在实战中综合运用了学过的排序算法。通过这四道经典的排序面试题，我希望你能够充分意识到，利用有序序列可以简化我们所遇到的问题，比如，在求2-sum问题以及求两个数组的交集问题中，我们就是利用有序序列中最大值、最小值的边界，简化了问题的求解步骤，省去了很多不必要的工作。而在存在重复元素问题中，我们又利用了排序计数的方法，快速找出了问题的答案。</p>\n<p>想要从本质上理解排序算法，我们还可以从另一个角度来看。我们都知道一个基础概念熵，它能表示一个体系的混乱程度。那排序算法从本质上来说，可以有效降低问题系统的熵，问题系统的熵越小也就越容易被解决。</p>\n<p>总的来说，排序算法是性价比最高的一类算法，它不仅容易掌握，而且能解决的实际编程问题，远比我们目前看到的多。所以，学好排序真的“太划算”啦。</p>\n<h2>课后练习</h2>\n<ol>\n<li>对于两个数组的交集和杨氏矩阵这两个问题，你有更快的解法吗？</li>\n<li>在求两个数组的交集问题中，如果我们加上一些额外条件：</li>\n</ol>\n<ul>\n<li>给定的数组已经排好序了，你又会怎么优化呢？</li>\n<li>在nums1 比 nums2 小很多的时候，你觉得还有哪种方法是更优的解？</li>\n<li>如果数组太大，内存也有限，你不能一次加载所有元素到内存里，这个时候又该怎么办呢？</li>\n</ul>\n<p>好了，我今天讲的这几道题，你都理解了吗？如果你的朋友也遇到了类似问题，那就快把这节课转发给他吧！今天就讲到这里了，我是胡光，我们下节课见。</p>\n',
        article_title: "12 | 面试实战：经典排序算法面试题详解",
      },
    ],
  },
  {
    chapterTitle: "查找搜索篇 (8讲)",
    children: [
      {
        title: "13 | 树结构基础：二叉树结构及其基础操作",
        herf: "https://time.geekbang.org/column/article/285568",
        id: "285568",
        content:
          '<p>你好，我是胡光。</p>\n<p>在刚刚结束的排序篇，我们讲了各种排序算法以及它们的应用。很重要的一点是，当得到一个有序序列的时候，我们可以轻松利用序列中的元素值作为边界，有效减少查找的次数，方便、高效地实现查找过程。那从这节课开始，我们正式进入查找搜索篇的学习。这一篇，我们会基于排序篇的知识，进一步学习一些和查找、搜索有关的算法与数据结构。</p>\n<p><span class="orange">我们先来看今天要解决的问题：现在有一个无序序列，它里面的元素是动态变化的。也就是说我们随时可能会更改序列中的元素，包括增加元素，修改某一个元素的值，或者从中删除一些元素。如果我们想随时查询这个序列中的第k大值，具体该怎么做呢？</span></p>\n<p>这就属于动态查找第k大元素问题，如果我们还用之前学过的排序算法来解决，你会发现虽然只增加了一个更新操作，但原本的排序算法就会变得非常吃力。因为，我们需要不断地让出空位，或者缩减空位，或者交换元素，以保持这个序列的有序性，那每一次更新，我们都可能要付出 $O(n)$ 的时间代价。</p>\n<p>好了，想要解决这个问题，我们的目标已经很明确了，我们要<strong>维护一个有序，并且可以进行高效地更新、查找操作的数据结构</strong>。</p>\n<h2>重识快排：将过程记录下来</h2>\n<p>如果你现在还没有思路，那我们可以先试着用快速排序来解决这个问题。假设，我们要对一组无序序列，36、74、16、73、67、61、21、80、38、7进行快速排序。第一步，我们会选择一个值作为基准值，第二步，我们再找到基准值的位置，把小于基准值的元素放在基准值的前面，大于基准值的元素放在基准值的后面，第三步，我们会对基准值的左右两侧递归地进行这个过程。</p>\n<p><img src="https://static001.geekbang.org/resource/image/f5/a9/f55264b8c1dc843b87dba2ca219684a9.jpg" alt="" /></p>\n<p>在排序结束之后形成的结构中，每个方框仅代表了一个基准值。最终得到的结果的组织形式其实很像一棵树，具体来说其实是二叉树。</p>\n<p><img src="https://static001.geekbang.org/resource/image/ef/d3/efc475646671acebb7b76d4a054b39d3.png" alt="" /></p>\n<p>二叉树的结构又是怎么保证高效更新和查找的呢？要想理解二叉树结构是怎样运作的，我们得先知道树结构的基础，以及二叉树的基本操作。接下来，我们就详细来说说。</p>\n<h2>如何理解树以及二叉树？</h2>\n<p>首先，什么是树结构呢？直观来看，我们前面组织出来的结构，看上去就像是把自然界的一棵树倒了过来，所以树这种数据结构也因此而得名。下面，我们再看树的正式定义：</p>\n<ul>\n<li>一棵树$T$有一个特定的节点，被称为<strong>根节点</strong>  <em>root(T)</em></li>\n<li>除根节点之外，其余的节点没切分成 m（$m\\ge 0$）个不相交的子集$T_1, T_2, \\cdots, T_m$，每一个子集也都是一棵树，这些子集被称作根节点的<strong>子树</strong></li>\n</ul>\n<p>我们该怎么去理解这种定义呢？其实，这个定义里面提到了树的一个关键概念就是<strong>划分子集</strong>。</p>\n<p>我们再回顾一下快速排序的例子，在快速排序的每一次迭代过程中，我们都会把小于基准值的元素放在基准值的左边，把大于基准值的元素放在基准值的右边。那以基准值为界，我们就划分出来了两个不相交的子集。以基准值为根节点，左边的子树则是整个集合中小于该基准值的子集，右边的子树就是大于该集合的子集。</p>\n<p>所以，构造树结构的过程，可以分成2步。第1步，在集合中找到一个代表性元素，以它为界，使用特定规则把集合划分成若干个不相交的子集。第2步，在每一个子集中，我们使用相同的方式找到一个代表性元素，重复第1步的规则，再把它划分成若干个不相交的子集，直到这个子集不能被划分为止。</p>\n<p>因此，树是一种针对集合建模的数据结构。并且，因为树表示了集合的性质，所以树结构有非常好的递推能力，例如，要赋予一棵子树一种性质，我们无需对子树上的每一个节点都操作一遍，而只需对这棵子树的根节点做这种操作就行了。</p>\n<p>这就像商场在卖东西的时候，如果推出了活动折扣，那么商场的售货员只需要在活动商品所在的货架上贴上折扣标签就可以了，不需要去修改货架上的每一个商品的价格签，或者仓库中每一个符合条件的商品的价格。而顾客在挑选商品时，售货员也只需要检查这个商品是不是符合活动条件的商品，即可给予对应的折扣价格。</p>\n<p>树结构的这种递推性质可以提升很多的效率，所以它能够被广泛应用于计算机科学中，有着举足轻重的地位。比如说，表达式树可以用于求解复杂表达式，也可以用于对复杂表达式求导，而哈夫曼树可以有效利用字符串中字符出现的频次信息完成信息压缩，以及字典树以节点为字符串前缀，以边为字符，可以将多个字符串空间压缩，同时也可以利用前缀索引字符串，甚至计算机中的文件系统也是一种树结构。</p>\n<p><img src="https://static001.geekbang.org/resource/image/90/a9/90138ccb2f465ae6e571f83515c2f5a9.jpg" alt="" /></p>\n<p>搞清楚树的定义之后，二叉树的定义就变得简单了，我们只需要给树增加两个限定条件，它就能变成二叉树。条件一，是二叉树的每一个节点至多有两个子树。条件二，是我们管二叉树的两个子树分别叫做 <strong>左子树</strong> 和 <strong>右子树</strong>。</p>\n<p>二叉树是一种优美的树结构，它简化了树的结构，使得很多操作变得非常简单，同时也保持了相对高效率，从而让我们能够很高效地解决很多问题。</p>\n<p>在<a href="https://time.geekbang.org/column/article/275747">二叉堆</a>那节课中，我们学习过满二叉树和完全二叉树两个概念，并且我还提到过，完全二叉树如果用一个一维数组来存储，可以方便地通过数组下标访问每个节点的子节点，还能不耗费多余的存储空间。</p>\n<p>同样地，我们也完全可以利用一个空间为$2^h$（h为树高）的一维数组存储一棵二叉树，通常一棵随机二叉树的树高和同样节点数的完全二叉树相差不大，所以它也可以用少量的空间浪费换取方便的存储和高效的访问。</p>\n<p>好了，二叉树的基础概念我们已经知道了，接下来，我们就重点讲讲二叉树的基本操作。</p>\n<h2>二叉树的遍历</h2>\n<p>我们知道，有很多算法是依托于树结构实现的，而这些算法的执行过程中，往往都会出现一个非常基础的遍历操作。树结构的遍历，其实就是把树结构上的节点当作一个站点，再把树结构上的边当作一条路，沿着路线依次访问各个站点，且每个站点只访问一次。</p>\n<p>既然每一个站点只访问一次，那从起点（根节点）出发向下行进的过程中，我们就需要尽可能走没有走过的路，最优的方法是先走到最深处的节点，再返回走另一条没有走过的路。实际上，这就是一个递归回溯的过程。在树上，我们从根节点出发，直观来看，我们是尽可能越走越深的，所以这种遍历也被称作<strong>深度优先遍历</strong>。</p>\n<p>而一次完整的遍历会根据每个节点的访问顺序，将一棵树表示成为一个序列，这种访问序列中，利用好每一个节点的前一个节点（前驱）或者后一个节点（后继），可以提升很多算法的效率。</p>\n<p>二叉树作为一种简单的树结构，它的遍历按照顺序可以划分为三种：</p>\n<ul>\n<li>前序遍历：对于每一棵子树，依次访问其根节点→左子节点→右子节点</li>\n<li>中序遍历：对于每一棵子树，依次访问其左子节点→根节点→右子节点</li>\n<li>后序遍历：对于每一棵子树，依次访问其左子节点→右子节点→根节点</li>\n</ul>\n<p><img src="https://static001.geekbang.org/resource/image/89/6f/89ced8ba464e56b1260e574630de586f.jpg" alt="" /></p>\n<p>在遍历的过程中，当一个节点以及它所有的孩子都被访问过的时候，我们就需要回溯到之前的状态继续进行。这个过程可以通过递归实现，也可以通过栈来实现。具体过程的话，你可以看看下面的前序遍历代码。</p>\n<pre><code>struct tree_node {\n    int value;\n    tree_node *left_son;\n    tree_node *right_son;\n};\n\nvoid pre_order(TreeNode *cur_node) {\n    visit(cur_node);\n    pre_order(cur_node-&gt;left_son);\n    pre_order(cur_node-&gt;right_son);\n}\n</code></pre>\n<p>现在，对于我们用快速排序生成的二叉树，如果我让你对它进行三种遍历，你觉得会发生什么样的事情？</p>\n<p>如果你真的动手试过了，就会发现，当我们对那棵树执行了一次中序遍历之后，我们最终得到的元素值的序列，就是一个升序的序列了。这就是二叉树的遍历在特定算法或数据结构中所能发挥的作用。</p>\n<h2>树、森林和二叉树相互转换</h2>\n<p>既然二叉树如此地简单、便捷，那么就有人提出了，二叉树的这些性质能不能复用到一般树上，甚至是复用到森林中，让一般树和森林的操作也像二叉树一样简洁呢？当然可以。接下来，我们就说说<strong>怎么用二叉树表示树和森林</strong>。</p>\n<p>在把一棵树转换成二叉树的过程中，我们需要保证，转换之后再使用二叉树的遍历，不会破坏原来树的层次结构。比如说，我们考虑顺序遍历一棵子树，也就是说，在访问根节点之后，从它的第一个孩子开始，我们依次向下遍历得到遍历序，我们把它转换成二叉树之后再遍历，它的序列也不会改变。</p>\n<p>我把一棵树的顺序访问过程，也就是每一个节点的访问顺序画成一个路线图，如下图所示。当我们从B访问到E之后，就没办法继续访问了，只能重新从B出发去访问C。同样地，我们从C访问到F之后，也无路可走，只能从C重新出发去访问D。我们发现，每一个节点除去回溯之外，会进入序列一次，再至多离开两次，这不刚好和二叉树的节点一样吗？我们将这个路线图重新组织起来，就理所当然得到了一棵二叉树。</p>\n<p>具体来说，对于每一个节点，<strong>我们将它的第一个子节点当作它的左子节点，将它的所有兄弟节点当作它的右子节点</strong>，就能将一棵树转换成为二叉树了。这种方法被称作<strong>左孩子右兄弟</strong>表示法。</p>\n<p><img src="https://static001.geekbang.org/resource/image/f0/e7/f0fcc1ba628ea8a0d625240f10a62ee7.jpg" alt="" /></p>\n<p>这就是把树结构转换成二叉树的方法，其实把森林转换成二叉树的方法与刚才的方法是一样的。具体来说，我们可以假设森林有一个总体的根，而森林中的所有树都是那个根节点的子树。这样，转换方法就呼之欲出了，我们只需要把其他树按照右兄弟的方式和第一棵子树的根节点组织起来就好了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/47/a5/47381c5c266cbb14cccbe7f328cf81a5.jpg" alt="" /></p>\n<p>好了，上面就是树、森林转换成为二叉树的过程。接下来，我们就可以将二叉树的遍历方式套到树或者森林上，但由于树或者森林的子节点不一定存在对称关系，并且森林是没有根的，所以树和森林的遍历就不存在中序遍历。因此，树和森林的遍历规则只有先序遍历和后序遍历。</p>\n<p>对于树来说，先序遍历是先访问根，再依次访问所有孩子，后序遍历是先访问所有孩子，再访问根。对于森林来说，先序遍历是先访问第一棵树的根，再访问第一棵树的所有孩子，再访问其他树。后序遍历是先访问第一棵树的所有孩子，再访问第一棵树的根，再访问其他树。</p>\n<p>最后，如果我们想把二叉树转换回树或者森林，也很简单，只需要做逆向操作就行了。如果是按照左孩子右兄弟方法来转换的，最终二叉树的根节点如果存在右孩子，那原本的结构就一定是森林。</p>\n<p>好了，二叉树的基础操作我们就讲完了。接下来，我还想和你聊聊二叉树的线索化。</p>\n<h2>二叉树的线索化</h2>\n<p>我们在存储二叉树的时候，每一个节点都要预先定义出它的左孩子和右孩子，在实际实现中，则是会定义左指针和右指针。这就导致了，我们在定义和实现二叉树的过程中，有一些指针是利用不到的。线索化二叉树，就是把这些指针充分利用起来，让它们在遍历中起到作用的一种方法。那具体怎么实现呢？</p>\n<p>刚才我们说了，在遍历二叉树的过程中，当走到尽头的时候，我们就会经历一个回溯的过程，这个过程可以是递归回溯，也可以利用栈来实现回溯。那当我们发现这些节点中有空指针的时候，我们就把它指向到下一个要经过的节点上。这样一来，我们就可以充分利用每个节点上的指针，同时也不会发生引入错误。而且，在遍历的过程中，由于我们已经记录了回溯的位置，这让遍历过程也会变得更加容易。</p>\n<p>多出来的这些边，就被称作<strong>线索</strong>，而这个过程就是二叉树的线索化。这样每一个节点都会存在两条出边，每一个节点的边都会指向它的<strong>前驱</strong>或者<strong>后继</strong>，根据遍历顺序的不同，线索化过程也可以分为<strong>前序线索化</strong>、<strong>中序线索化</strong>以及<strong>后序线索化</strong>。</p>\n<p><img src="https://static001.geekbang.org/resource/image/73/05/732069c8ff78630331173690da6fae05.jpg" alt="" /></p>\n<p>上图是一个二叉树中序线索化的结果。你可以看到，树中只有两个指针是指向空的，分别是最左节点的左线索和最右节点的右线索，每一个节点的左线索指向中序前驱，右线索指向中序后驱。这样，在线索二叉树上的遍历过程中，我们只需要沿着边一直走下去就可以了。</p>\n<h2>课程小结</h2>\n<p>这节课，我们讲了树这种非常重要的数据结构，也着重讲了一种特殊的树，就是二叉树。树和二叉树的定义很好理解，首先，一棵树有一个特定的根节点，除了根节点以外，树还有很多不相交的子集，它们被叫做根节点的子树。而二叉树的每一个节点至多有两个子树，分别叫做左子树和右子树。</p>\n<p>然后，我们重点讲解树的遍历。二叉树有三种遍历形式，分别是前序遍历、中序遍历和后序遍历。在特定的算法或者数据结构中，二叉树的遍历能够快速对数据进行升序或者降序排序。</p>\n<p>除此之外，二叉树、树以及森林之间是可以相互转换的，这样二叉树的性质就能复制到树和森林上了。不过，在转换过程中我们要保证，转换后再次进行二叉树遍历的时候，不会破坏树原有的序列结构。</p>\n<p>最后，我相信通过这节课的学习，你肯定对树结构有了一个基本的认识。那距离解决我们动态查找第k大数的问题也就更进一步了。在接下来的课程中，我会带着你继续解决这个问题。</p>\n<h2>课后练习</h2>\n<ol>\n<li>\n<p>在这节课的最后，我们学习了二叉树的线索化，如果我们在线索二叉树中插入一个节点，那树上的线索应该怎样更新呢？</p>\n</li>\n<li>\n<p>如果有一棵二叉树$T$，它由另一棵二叉树$T’$使用<em>左孩子右兄弟</em>构造而成。你觉得$T$和$T’$的遍历序有什么联系吗？</p>\n</li>\n</ol>\n<p>好了，关于树和二叉树的基础知识你都理解了吗？不妨也把这节课转发出去吧！那今天就讲到这里了，我是胡光，我们下节课见。</p>\n',
        article_title: "13 | 树结构基础：二叉树结构及其基础操作",
      },
      {
        title: "14 | 二叉排序树：如何动态查找第k大元素？",
        herf: "https://time.geekbang.org/column/article/286399",
        id: "286399",
        content:
          '<p>你好，我是胡光。</p>\n<p>上节课，我们初步认识了树和二叉树的结构。这节课，我们就一起来解决动态查找第k大元素问题。我们想先来回顾一下这个问题：</p>\n<p><span class="orange">在一个随时都可能进行增、删、改、查这些更新操作的序列中，我们该怎样快速地查找任意的第k大的元素（每次查询的时候，k都可能发生变化）？</span></p>\n<p>上节课我们说过，想要解决动态查找第k大元素问题，首先需要维护一个动态的有序结构，它可以进行高效地更新和查找。接着，我们通过回顾快速排序，记录它的每一步过程，得到了一个二叉树，它经过中序遍历序列之后，会得到一个升序的序列。</p>\n<p>那这棵树就是我们这节课要重点讲解的二叉排序树，也叫做二叉搜索树（Binary Search Tree）。</p>\n<p><img src="https://static001.geekbang.org/resource/image/ba/bb/ba7cc79d153d9544dea26480c42aeabb.png" alt="" /></p>\n<h2>如何用二叉排序树查找第k大元素？</h2>\n<p>下面，我们来正式认识一下它的性质。在二叉排序树中，<strong>每一个节点的左子节点都比它小，而右子节点都比它大</strong>。</p>\n<p>广义上来说，我们也可以以不同的排序规则来定义二叉排序树的结构，但不同规则的内核都是不变的。比如说，你也可以定义左子树是大于根节点的值，右子树是小于根节点的值。这里我就不详细展开了。</p>\n<p>那在这样的一个结构上，我们该怎么去寻找任意第k大元素呢？因为只要是基于树的算法，它们的基本思想大部分都是遍历，所以我们就以在这棵树上的中序遍历为出发点考虑这个问题。</p>\n<p>我们从根出发，根节点的左子树就相当于序列中比根小的所有数，右子树就相当于比根大的所有数。接下来，我们重点考虑根节点的排名：如果右子树中的节点数是 r，那么根节点的排名就是 r + 1；如果 r + 1 等于 k，那么根节点就是我们要找的元素；如果 r + 1 大于 k，说明排名第 k 大的元素在右子树中，否则排名第 k 大的元素就在左子树中。当问题转换到左子树中，你需要注意的是，在左子树中不再是查找排名第 k 大的元素，而是在左子树中查找排名第 k - r - 1大的元素。</p>\n<p>比如说，当k=4的时候，右子树的节点数是5，5+1大于4，所以第4大元素一定在右子树中。而当k=6的时候，5+1等于6，所以第5大元素应该就是当前的根节点。怎么样，是不是很好理解？</p>\n<p><img src="https://static001.geekbang.org/resource/image/1d/f5/1da38a7eb952yyb671c2f9ca17621df5.png" alt="" /></p>\n<p>这样做的具体算法如下：</p>\n<pre><code>// cur_node-&gt;value：树节点的值域\n// cur_node-&gt;count：以该节点为根的子树中的节点数\nint kth_largest_element(TreeNode *cur_node, int k) {\n    int right_count = 0;\n    if (nullptr != cur_node-&gt;rightSon)\n        right_count = cur_node-&gt;rightSon-&gt;count;\n    if (right_count + 1 == k) // 需要把子树的根计数进去\n        return cur_node-&gt;value;\n    else if (right_count + 1 &gt; k) {\n        return kth_largest_element(\n            cur_node-&gt;rightSon,\n            k\n        );\n    } else {\n        return kth_largest_element(\n            cur_node-&gt;leftSon,\n            k - right_count - 1\n        );\n    }\n}\n</code></pre>\n<p>简单来说，这个查找方法的基本思想，其实就是在有序序列中利用有序边界进行查找，同时我们又把它与二叉树的遍历结合了起来。而且，有序边界这个性质能够有效地帮助我们一次性排除掉很多个元素，所以我们只需要少量查找操作就可以得到目标值了。</p>\n<p>就算是最坏的情况，也只不过是从树根到叶子最长的一条路（即树高）。而一棵随机序列的二叉搜索树，树高一般都在$log_2n$这个量级，代价也不会很大。</p>\n<p>好，现在我们已经解决了动态查找第k大元素的查找问题，但我们的旅途还没有结束，因为有序序列的更新问题还亟待解决。序列的更新有增、删、改、查这四个操作，接下来，我们先来看元素的插入操作。</p>\n<h2>二叉排序树的插入</h2>\n<p>想要在插入元素之后，仍旧维持序列的有序性，我们就需要<strong>把要插入的元素放到正确的位置上</strong>。也就是说，如果要在序列a中插入x，那我们就需要在序列中找到一个位置i，让$a_{i-1}\\le x\\le a_i$，然后把x插入到位置i上。如果你基础比较好，我相信你一秒就可以回答上来，这个查找过程其实就是二分查找法。</p>\n<p>二分查找法简单来说，就是对确定的查找区间n不断二分，每次二分都与要查找的元素x进行比较，每次比较后，我们都能减少一半的查找区间，时间复杂度是 ${log_2}{n}$  。</p>\n<p>那为什么要使用二分查找法呢？我们说过，如果是在一个一维序列中直接进行这种插入元素的操作，那每一次更新的耗时其实是很大的。但树结构就不一样了，<strong>树是一种非常方便更新的数据结构</strong>。你可以回忆一下我们讲过的二叉堆，它就是在二叉树结构上维护有序序列的结构。我们只要利用少数的元素放置或者元素覆盖，再加上向上或者是向下的调整操作，就能快速地删除或者插入元素了。</p>\n<p>这节课，我们就把刚才说的更新过程也移植到二叉排序树上，来看看二叉排序树是怎样更新的。</p>\n<p><strong>第一步，找到正确的插入位置。</strong> 其实就相当于我们要在二叉搜索树中寻找一个特定值，如果寻找不到，则插入这个特定值。现在，相信我不用往下说，你也知道该怎么做了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/69/86/6983584bfb4932a029c3ab9147b5c886.png" alt="" /></p>\n<p>示例代码如下：</p>\n<pre><code>void insert(TreeNode *cur_node, int value) {\n    if (cur_node-&gt;value == value) {\n        return;\n    }\n    if (value &lt; cur_node-&gt;value) {\n        if (nullptr != cur_node-&gt;rightSon) {\n            insert(cur_node-&gt;rightSon, value);\n        } else {\n            TreeNode *new_node = new(TreeNode);\n            new_node-&gt;value = value;\n            new_node-&gt;leftSon = nullptr;\n            new_node-&gt;rightSon = nullptr;\n            cur_node-&gt;rightSon = new_node;\n        }\n    } else {\n        if (nullptr != cur_node-&gt;leftSon) {\n            insert(cur_node-&gt;leftSon, value);\n        } else {\n            TreeNode *new_node = new(TreeNode);\n            new_node-&gt;value = value;\n            new_node-&gt;leftSon = nullptr;\n            new_node-&gt;rightSon = nullptr;\n            cur_node-&gt;leftSon = new_node;\n        }\n    }\n}\n</code></pre>\n<p>不过，在上面的插入算法中，我们讨论的是序列中不存在重复元素的情况，那如果序列中存在了重复元素，我们又应该怎么办呢？其中一种方法是把相等看作大于或看作小于，然后按照规则建立二叉排序树，</p>\n<h2>二叉排序树的删除</h2>\n<p>接下来，我们再说说二叉排序树中的删除操作。与插入一样，我们还是从有序的一维序列中删除一个元素出发，来推出在删除掉二叉排序树的一个节点的时候，我们应该做什么。</p>\n<p>首先，我们需要在一维序列中找到那个要删除的目标元素，如果是按值删除其实还是直接用二分查找法最直接省事，如果是按位置删除，那我们直接下标索引就可以。在删掉了目标元素之后，原有序列中就会出现一个空位，这个时候我们要做的就是将前面的元素集体后移，或者将后面的元素集体前移，以此来维护这个序列。</p>\n<p>在二叉排序树中也一样，我们的重点不是找到那个节点的位置，而是删除了那个节点之后，怎么样补上那个节点的空位，让它还是一棵二叉排序树，而不会变成一个森林（即保持树的连通性）。</p>\n<p>因此，我们在删除掉一个节点N之后，需要做的是<strong>填补空位</strong>。假设在有序序列中，我们是把空位后面的元素整体前移。那将这个想法复用到树上的时候，我们要寻找、移动的子树是哪一棵呢？</p>\n<p>其实就是被删除节点的<strong>中序遍历的后继。</strong>这是为什么呢？首先，被删除节点N的中序后继，一定是在有序序列中比它大的第一个节点，想要顶替被删除节点的位置，它是最合适的。在二叉排序树结构上，被删除节点N的左子树中所有节点，一定小于后继节点succ(N)。而在右子树中，除去后继节点本身外，剩余节点一定大于后继节点succ(N)，所以将后继节点顶替到这个位置一定是正确的。</p>\n<p>那在我们删掉一个节点N的时候，会有3种情况发生。</p>\n<ol>\n<li>如果N既没有右子节点，也没有左子节点，那我们直接删除N，释放空间即可。</li>\n<li>如果N没有右子节点，但是有左子节点，那么我们将左子节点leftSon(N)放到N的位置上，然后删除N，释放空间即可。</li>\n<li>如果N有右子节点，那么从它的右子节点rightSon(N)出发，一直向左走，直到走不了为止，然后将最终到达的那个节点succ(N)放到N的位置，删除掉N，释放空间即可。</li>\n</ol>\n<p>你看我这么说，肯定觉得比较麻烦，但它的核心思想其实非常明确，就是<strong>找到当前节点中序遍历的后继，使用后继代替被删除节点的位置</strong>。而且在树上进行这种操作，实际上我们只需要改变指针的指向，所以，二叉排序树的删除操作也非常便捷。</p>\n<p><img src="https://static001.geekbang.org/resource/image/cd/3c/cd83f3fff013c52de7c09e326dd3d83c.png" alt="" /></p>\n<h2>二叉排序树优化</h2>\n<p>二叉排序树是一种非常优秀的索引、排序算法。在一棵给定的二叉排序树上，它的最坏索引次数就是树高。而一个长度为N的序列，在理想情况下，它的二叉排序树树高应当是$log_2n$，可是现实情况下，对于一个随机序列，我们很难构造出来这样一棵最优的二叉树来，一般构造出来的二叉树都是有些退化的，就像我们前面讲的一样。</p>\n<p>实际情况下，在一棵随机二叉树上进行索引，平均的时间复杂度是$\\sqrt n$，看起来好像也不错。但这就有一种听天由命的感觉了，一旦遇到了极端情况，我们仍然束手无策。</p>\n<p>举个例子，如果将元素以升序顺序或者降序顺序插入到二叉排序树中，那我们就会得到一条链。</p>\n<p><img src="https://static001.geekbang.org/resource/image/07/14/0712f1600c3088f38f27e2880531a714.jpg" alt="" /></p>\n<p>这样的话，我们每次插入元素的时候，都要索引整棵树，这个退化就让人非常难受了。像完全升序或完全降序这样的极端情况还有很多种，如大小交替插入等。所以我们要控制二叉排序树，使得它能够有一个更加优化的结构。具体怎么做呢？</p>\n<p>首先，我们来思考一个问题，一个长度为N的序列会对应多少种二叉排序树？当N=3的时候，如下图，会有5棵二叉树（其中<code>[2, 1, 3]</code>和<code>[3, 1, 2]</code>的树结构一样，没有列出）。</p>\n<p><img src="https://static001.geekbang.org/resource/image/a5/0a/a585ebf4f42518489c8452373b456c0a.jpg" alt="" /></p>\n<p>那么当N足够大的时候，其对应二叉排序树的数量将是爆炸式增长（直观来看，这个数量和排列数相关，即N的阶乘），这个数量级我们完全不能接受。所以我们就要<strong>快速找到长度为N的序列对应的最优二叉排序树</strong>。</p>\n<p>知道了目的，那我们就可以形式化地定义这个问题了。假设，有一个长度为N的升序序列，其中的元素为$[a_1, a_2, \\cdots, a_i, \\cdots, a_n]$。我们定义：</p>\n<ul>\n<li>$p_i$是搜索的目标值就是$a_i$的概率；</li>\n<li>$q_i$是搜索的目标值在$a_i$和$a_{i+1}$之间的概率；</li>\n<li>$q_0$是搜索目标值小于$a_1$的概率；</li>\n<li>$q_n$是搜索的目标值大于$a_n$的概率。</li>\n</ul>\n<p>这样一来，$p_1+p_2+\\cdots+p_n+q_0+q_1+\\cdots+q_n=1$，搜索过程的<strong>比较次数</strong>的期望值为：</p>\n<p>$$\\sum_{j=1}^n(level(j)+1)+\\sum_{k=1}^nlevel(k)$$</p>\n<p>我们管这个期望值叫作二叉排序树的<strong>搜索成本</strong>，其中$level(j)$是节点所在的树层。那我们要解决的问题就是，怎样才能让搜索成本最小。</p>\n<p>我们可以先思考一个问题，既然树的子树是可以完美继承树本身的一些性质，这是树的递推性质。那么，一棵最优二叉排序树的子树，是不是也是一棵最优的二叉排序树呢？</p>\n<p>一定是的，这个非常容易证明，我们用反证法来证明：假设一棵最优二叉排序树中存在一棵非最优的子树，那当一次查找索引到这棵子树的时候，在这棵子树中的查找过程就不是一个最优过程，也就说说这棵子树的查找期望值就不是最小的，也就不符合最优二叉排序树的性质。所以最优二叉排序树的子树一定也是最优二叉排序树。</p>\n<p>这样一来，如果我们把一棵二叉排序树的某一个子树优化成了二叉排序树，就离整棵二叉排序树更近了一步。说到底，这就是在递推地查找存在一个最优子结构的问题，那在递推算法中求解最优化问题的方法，就是动态规划。</p>\n<p>我先来简单说说动态规划的解题过程。其实就是4步，分别是：状态定义、状态转移方程、正确性证明，以及程序设计与实现。状态定义就是给问题定义一个带有明确语义信息的数学符号，状态转移方程就是我们从递推过程中，总结出来的公式，而正确性证明，就是利用数学归纳法来证明状态转移方程的重要性，那最后就是程序的设计与实现了。</p>\n<p>下面，我就教你怎么用动态规划来设计这个算法。</p>\n<p>首先是状态定义。我们单刀直入，直接切入到这个问题的最终目标：定义$c(i, j)$是子序列$[a_i, a_{i+1}, \\cdots a_j]$对应的最优二叉排序树的搜索成本。</p>\n<p>然后，我们把状态转移方程设置成如下的方程：<br />\n$$c(i, j)=w(i, j)+min_{i&lt;k\\le j}(c(i, k-1)+c(k, j)), \\text{for i&lt;j}$$</p>\n<p>这个方程的意义是，对于子区间 [i, j] 中的数​，我们一定要把它划分成一棵子二叉排序树。假设其中的根节点是$a_k$，而整个序列都是升序的，那子区间 [i, k - 1] 就是左子树，子区间 [k+1, j] 就是右子树。</p>\n<p>刚才我们已经证明过这个问题的最优子结构的正确性，这里我就不再啰嗦了。那显然，解决这个问题的算法，它的时间复杂度为$O(n^3)$，空间复杂度为$O(n^2)$，这和前面提到的阶乘的数量级相比，已经减少很多了。</p>\n<p>其实我们还可以利用<strong>二叉排序树</strong>中的单调性质，进一步减少这个算法的时间复杂度，你可以自己想想，我就不展开来说了。</p>\n<h2>课程小结</h2>\n<p>这节课，我们带你认识了二叉排序树，然后学习了二叉排序树的基本操作，还利用二叉排序树的性质解决了动态查找第k大元素的问题，同时，我们还讲了如何找到最优二叉排序树的方法。</p>\n<p>二叉排序的性质是每一个节点的左子节点都比它小，而右子节点都比它大。当要查找第k位元素的时候，我们只要把k与右子数节点和左子树节点先后进行比较就可以了。这样，我们就先解决了查找第k位元素的问题。</p>\n<p>而对于有序序列的更新问题，我们从有序的一维序列的插入、删除操作出发，推出了二叉排序树的插入和删除操作。在二叉树中插入元素的时候，我们是利用二分查找法，把要插入的元素放到正确的位置上。而进行删除操作的时候，我们要找出被删除节点的中序遍历的后继，使用后继代替被删除节点的位置。</p>\n<p>除此之外，我们还讲了二叉排序树的优化。我们可以利用动态规划的方法，快速找到长度为N的序列对应的最优二叉排序树。其实最优二叉排序树问题与信息熵结合，还能推导出另外一种算法， Garsia-Wachs算法，这个算法可以将时间复杂度进一步优化到$O(nlogn)$。</p>\n<p>可是，我们的旅程依旧没有结束，如果我们要保持二叉排序树在更新后依旧保持最优状态，哪怕是依靠$O(nlogn)$的Garsia-Wachs算法，代价也是非常大的。这该怎么办呢？下节课我会再给你讲一种具有自适应能力的二叉排序树，期待一下吧。</p>\n<h2>课后练习</h2>\n<ol>\n<li>\n<p>在二叉排序树中插入元素的时候，如果序列中存在重复的元素，二叉排序树又应该怎么定义呢？那动态查找第k大元素的算法需要有什么改动？</p>\n</li>\n<li>\n<p>在二叉树中删除元素的时候，我们除了前移后面的元素之外，还可以把前面的元素后移。那你将后继节点替换更改为前驱节点替换，并且实现出这个方法吗？</p>\n</li>\n</ol>\n<p>欢迎在留言区分享你的答案，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "14 | 二叉排序树：如何动态查找第k大元素？",
      },
      {
        title: "15 |  AVL树：如何让二叉排序树永远保持最优？",
        herf: "https://time.geekbang.org/column/article/287289",
        id: "287289",
        content:
          '<p>你好，我是胡光。</p>\n<p>上节课，我们学习了二叉排序树，并且利用它解决了动态查找第k大元素的问题。但是这还不够，因为二叉排序树中存在退化现象，极端情况下，二叉排序树的操作效率并不会比线性表高。虽然我们也学习了最优二叉排序树的求解算法，但是它的代价依旧不低。</p>\n<p>为了解决这个问题啊，曾经也有人提出来过，在维护一个动态更新的有序序列的时候，我们先不管二叉排序树是否是最优的，只要是在维护过程中树高超出了一定的限制（如$5\\times log_2N$)，我们就重新求解二叉排序树。</p>\n<p>这是一种比较折中的办法，但仍然要我们间歇性花费不低的代价去保持树的效率。那么有没有什么办法，能够让二叉排序树拥有自适应的能力，在每一次插入、删除之后可以随时调整自己，让自己保持最优状态呢？</p>\n<p>当然是有办法的，早在1962年，就有两位数学家提出来了一种方法，这种方法可以做到在二叉排序树上进行增、删、查，以及查找动态第k大元素等操作，时间复杂度都是$O(log_2N)$，这个方法就叫做<strong>平衡树</strong>，也叫做<strong>AVL树</strong>。</p>\n<p><img src="https://static001.geekbang.org/resource/image/2e/ea/2e007fbf1f63d991fc2e2e8956f0e0ea.jpg" alt="" title="图1：AVL树" /></p>\n<p>在平衡树中，“平衡”的意思，就是将二叉树左右两棵子树的高度看作是这两棵树的重量，把这两个重量放在一个天平上，尽可能保持这个天平是平衡的。也就是说，一棵平衡树的<strong>左右两棵子树的树高之差不会超过1</strong>。由此我们知道，平衡树就是一个最优的二叉排序树，平衡树的树高也就一直保持在$log_2N$左右（实际上是在$log_2(N+1)$和$1.4405\\times log_2(N+2)-0.3277$之间）。正因为维持了树高，所以一棵有N个节点的平衡树，每一个操作的时间复杂度都可保持在$O(log_2N)$。</p>\n<p>在正式讲平衡树之前，我们还要引入二叉树上的一个关键的操作，旋转（Rotate）操作，这个操作也是平衡树能够改变形态、保持平衡的关键。</p>\n<h2>二叉树的旋转：二叉树自适应能力的关键</h2>\n<p>旋转操作的字面意思，就是将二叉树转了一下。旋转后的二叉排序树也依然会保持二叉排序树的性质。也就是说，我们在进行了一次旋转操作之后，最终的产物仍然是一棵二叉排序树，这棵二叉树排序上的每一个节点，总是<strong>大于它的左孩子，小于右孩子，而且中序遍历后的结果也保持不变</strong>。</p>\n<p>树的旋转究竟是怎么操作的呢？打个比方，我们可以把树上的每一个节点看作是弹珠，每一条边看作是绳子。平常这棵树，我们都是用手拎着它的根节点那颗弹珠，让其他的弹珠自然垂下。然后我们有一天突发奇想，想要换一颗弹珠来拎着，比如我们想要拎根的左子节点那颗弹珠，然后让其他的弹珠继续自然垂下。这样，左子节点成为了新的树根，而根节点成为了新树根的右子节点。</p>\n<p>但是，只是这么简单的操作是不够的。如果我们把图1中左子节点，也就是4当作根节点，最终的结果就是节点4除了原有的两个子节点之外，根节点也成为了它的子节点，那它就有3个孩子节点，这显然就不符合二叉树的定义了。所以我们还要进一步明确旋转的细节。</p>\n<p>我们把这个问题放到一个比较简单，但却足以代表所有情况的例子中。如下图中左边这棵树，我们将它按照上面描述的方式进行了一次操作之后，2变成了根节点，1、3、4都变成了它的孩子节点。</p>\n<p><img src="https://static001.geekbang.org/resource/image/3a/9e/3a5ab73ea19e09fefdfd8fbc9094639e.jpg" alt="" title="图2：二叉排序树的右旋操作" /></p>\n<p>为了保持二叉树的性质，我们就需要选出一个孩子节点移动到另一个空位上。这个时候，1、3、5有两个空位，4有一个空位。我们可以把其中一个孩子节点移到5上吗？你千万不要被这个简单的例子迷惑了，5 号节点完全可以代表一棵左右孩子双全的子树。</p>\n<p>因此，我们需要找到唯一一个一定会出现一个空位的节点。没有错，就是原来的根节点，所以我们应该把2 号节点多出来的一个孩子节点放到原根节点，也就是4的下面。</p>\n<p>相信你也看到了，根节点空出来的位置刚好是左孩子的位置，而新的根节点 2 号节点，由于它原本就是 4 号节点的左孩子，因此它的所有子树节点的值都小于 4 号节点。也就是说，2 号节点的任意一个孩子都可以放到 4 号节点的左孩子位置。</p>\n<p>但是别忘了，我们还有一个目标，那就是保持原二叉树的中序遍历序列不变。如果我们把2号节点的左孩子变成了4号节点的左孩子，那在中序遍历之后，我们就无法先遍历到这些节点了，所以，我们只能把2号节点的右孩子，变成4号节点的左孩子。这也就保持了4号节点的中序前驱在新的树中，依旧是中序前驱。</p>\n<p><img src="https://static001.geekbang.org/resource/image/ca/2b/caf3b1ccca93605fb6184ece3f82a22b.jpg" alt="" title="图3：右旋操作" /></p>\n<pre><code>Node *right_rotate(Node *root) {\n    Node *temp = root-&gt;lchild;\n    root-&gt;lchild = temp-&gt;rchild;\n    temp-&gt;rchild = root;\n    update_height(root);\n    update_height(temp);\n    return temp;\n}\n</code></pre>\n<p>这种把二叉树的左孩子作为根进行的旋转操作，也被称作是<strong>右旋操作</strong>（Right Rotate），那与之对称的就是左旋操作（Left Rotate）。</p>\n<p><img src="https://static001.geekbang.org/resource/image/65/87/6575a19f43139d7862f02c95d0449887.jpg" alt="" title="图4：左旋操作" /></p>\n<pre><code>Node *left_rotate(Node *root) {\n    Node *temp = root-&gt;rchild;\n    root-&gt;rchild = temp-&gt;lchild;\n    temp-&gt;lchild = root;\n    update_height(root);\n    update_height(temp);\n    return temp;\n}\n</code></pre>\n<p>看到这里，相信你也发现了，<strong>二叉树的旋转操作可以有效地改变左右两棵子树的树高差</strong>，所以，旋转操作是平衡树保持平衡的关键操作。接下来，我们就来聊一聊，平衡树是怎样利用旋转操作保持平衡的。</p>\n<h2>AVL树的基本操作</h2>\n<p>为了保持树的平衡，我们首先需要知道现在这棵树是不是平衡的。这里，我们可以直接计算平衡树的树高差，我们用<strong>右子树的树高减去左子树的树高</strong>，把得到的差叫做<strong>平衡因子</strong>。在平衡树中，平衡因子只可能有3个值：+1，-1和0，一旦某一个节点的平衡因子出现了这3个值之外的数值，就说明这棵子树需要调整。</p>\n<p><img src="https://static001.geekbang.org/resource/image/74/6c/747e6f17a383e0cebbc21f191404426c.jpg" alt="" title="图5：计算每个节点的平衡因子" /></p>\n<p>我们知道，旋转操作可以有效地改变左右两棵子树的高差，所以，我们也主要依赖旋转操作来调整平衡因子。那具体怎么做呢？我们可以结合平衡树的更新操作一起来学习。</p>\n<pre><code>//AVL树节点定义，需要增加数据域h记录当前节点树高\n#define H(root) (root)-&gt;h\n#define K(root) (root)-&gt;key\n#define L(root) (root)-&gt;lchild\n#define R(root) (root)-&gt;rchild\n\ntypedef struct Node {\n    int key, h;\n    struct Node *lchild, *rchild;\n} Node;\n</code></pre>\n<h3>AVL树的插入</h3>\n<p>首先，是插入操作。我们先想两个问题，在向平衡树中插入节点的时候，树上会发生什么样的变化？我们怎么利用旋转操作让二叉排序树回归到平衡中呢？</p>\n<p>因为影响平衡的主要因素是树高，所以我们主要考虑插入节点后对树高的影响就好啦。</p>\n<p>最简单的情况，就是我们插入一个节点之后，并没有影响到子树的树高，这个时候，我们不需要进行调整。</p>\n<p>第二种情况，我们插入一个节点之后，虽然影响到了子树的树高，但没有影响到子树平衡。这种情况其实还能细分成三种情况。第一种，我们把节点插入到根节点平衡因子为0的子树中的任意一处，第二种，我们把节点插入到根节点的平衡因子为+1的子树的左子树中，第三种，我们把节点插入到根节点的平衡因子为+1的子树的右子树中。这三种情况听起来可能有点绕，你可以结合任意一张示意图来理解。</p>\n<p>所以，我们需要考虑的情况，只有<strong>插入了节点之后，确实影响到了树的平衡</strong>。其实，这种情况还能进行细分。下面，我就详细来说说。</p>\n<p>首先，我们向一棵平衡因子为+1的子树的右子树中插入一个节点，这样右子树的会树高增加，这个节点的平衡因子就变成了+2。</p>\n<p><img src="https://static001.geekbang.org/resource/image/f4/79/f4fa30a30fd800081a7dd47df0148079.jpg" alt="" title="图6：插入节点，平衡因子变成+2" /></p>\n<p>我们看到，节点A的平衡因子超出了限制，所以我们需要降低A节点的平衡因子。那么这棵树只要经历一次<strong>左旋操作</strong>就能恢复平衡了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/ee/c1/ee24b57d155d4ab5526c346cf239e1c1.jpg" alt="" title="图7：经历一次左旋操作，恢复平衡" /></p>\n<p>这种情况其实还有一种对称的情况：我们向平衡因子为-1的子树的左子树中插入节点，因为影响了左子树的树高，所以平衡因子就变成-2，怎么恢复平衡，相信我不说，你也知道了。</p>\n<p>其实前面这些情况，都是<strong>向一个方向插入的节点</strong>。比如说，刚才我们插入的位置是子树A的最右子节点下面，这样A的右子树C的平衡因子就变成了+1。但是，还有一种情况是，我们插入了节点之后，C的平衡因子就变成了-1。</p>\n<p><img src="https://static001.geekbang.org/resource/image/9a/bc/9aa53f5db53b38d7c96b7eyy08ba1bbc.jpg" alt="" title="图8：插入节点，平衡因子变成-1" /></p>\n<p>如果我们把这种情况直接做左旋处理的话，很显然，右子树C的左子树D就会直接成为A的右子树，那么左子树的树高则变成了3，右子树由于只有一个E节点，树高变成了1，根节点C的平衡因子变成了-2，树仍旧是不平衡的。这个时候，我们该怎么办呢？</p>\n<p>我们最终还是要经过左旋让这棵树变平衡，所以我们只能想办法让树在左旋之后，左子树的树高不会增加那么多。因此，我们需要做的是，减少掉右子树C的左子树的树高。那由于C的平衡因子是-1，我们对C子树进行右旋，也不会影响该子树的平衡性，还可以让左子树的树高变成-1。</p>\n<p><img src="https://static001.geekbang.org/resource/image/d0/c6/d0e9e53be2642c0d2c71f1bf6376e4c6.jpg" alt="" title="图9：经历一次旋转操作，依然没有恢复平衡" /></p>\n<p>发现了吗，这种情况刚好又和第一种情况是一样的了，我们再进行一次左旋，就可以将这棵树重新调整到平衡状态了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/53/46/5310390ed1e2cf39774bf7035b85e446.jpg" alt="" title="图10：经历多次旋转操作，恢复平衡" /></p>\n<p>当然，这种情况也是有对称情况的，对称情况是什么，怎么解决，你可以自己操作试试。</p>\n<p>说了这么多，这里我再带你做个总结。我们通过旋转操作来调整二叉树的平衡性的原则是，如果插入节点破坏了树的平衡，我们就需要找到这一次的插入操作，到底影响了哪一棵子树的树高，无非是左、右两种。</p>\n<p>当我们向右子树中插入节点，导致树不平衡时，我们最终一定是通过左旋操作让树重归平衡。但如果我们插入节点的位置是右子树的左子树，那在左旋的时候，这棵左子树会被新的左子树继承，它不平衡的树高也会被继承，所以我们仍然是要通过一次额外的旋转，将不平衡的左子树解决掉。对称情况同理。</p>\n<pre><code>//AVL树调整平衡\nNode *maintain(Node *root) {\n    if (abs(H(L(root)) - H(R(root))) &lt;= 1) return root;\n    if (H(L(root)) &gt; H(R(root))) {\n        if (H(R(L(root))) &gt; H(L(L(root)))) {\n            root-&gt;lchild = left_rotate(root-&gt;lchild);\n        }\n        root = right_rotate(root);\n    } else {\n        if (H(L(R(root))) &gt; H(R(R(root)))) {\n            root-&gt;rchild = right_rotate(root-&gt;rchild);\n        }\n        root = left_rotate(root);\n    }\n    return root;\n}\n</code></pre>\n<p>实际上，插入节点导致平衡树不平衡的情况，归根到底就是这两种，或它们的对称情况。所以在插入节点的过程中，我们只需要利用这两种处理方式，就可以一直让树保持平衡状态，这也就保证了这棵树的树高最小，每次插入索引的时间复杂度都是$O(log_2N)$。</p>\n<p>除了插入节点会导致树不平衡，平衡树的插入操作的其他部分就和一般二叉排序树是一样的了，相信你也能理解，我就不多说了。</p>\n<p>当然，平衡树的删除操作也是类似的，在删除了一个节点之后，我们也要解决树不平衡的问题。那除此之外，它的删除操作也和二叉排序树的删除操作一样。</p>\n<h3>AVL 树的级联合并</h3>\n<p>在解决了平衡树的基本操作之后，我们来讨论一个更加有挑战性的问题。怎么把两棵平衡树合并成一棵平衡树，并且我们假设，一棵树中的所有值都比另一棵树大。</p>\n<p>首先，最直观合并方法，就是把其中一棵平衡树的N个节点逐一插入到另一棵带有M个节点的平衡树中，那么合并的时间复杂度就是$O(Nlog_2M)$。这种合并的代价看上去也可以接受。</p>\n<p>但是，我们还有一种更加巧妙的方法，就是利用有序序列的边界信息。</p>\n<p>假设，我们要合并的两棵树分别是$T_1$和$T_2$，并且，这两棵树的值之间的关系是$max(T_1)&lt;min(T_2)$，这两棵树之间高度的关系是$height(T_1)\\ge height(T_2)$。</p>\n<p>第一步，我们要找到$T_2$中最小的节点J，把它删除，得到树$T_2’$，那$T_2$中剩余的节点就全都在J的右子树之中了。</p>\n<p>第二步，我们在$T_1$中，不断向右下走，找到一棵子树P，让$height§-height(T_2’)=0或1$。</p>\n<p>由于$T_1$中的值都比$T_2$中的值小，我们就可以推出，J的值一定比P的值大，因此我们就把P当作J的左子树，$T_2$剩余的节点当作J的右子树，再把P的父亲当作J的父亲。</p>\n<p>因为P是向右下寻找得到的，所以$T_1$中剩余的值依旧符合二叉排序树的性质。而由于我们控制了节点P所在的高度，因此，这个问题我们可以看作是把J节点插入到了$T_1$中。对称情况的解决方法也是类似的。</p>\n<h2>课程小结</h2>\n<p>平衡树的内容讲完了，我们一起来做个总结。</p>\n<p>这节课，我们先学习了二叉排序树上，一种非常基础也非常重要的操作，二叉树的旋转操作。旋转操作，分成左旋操作和右旋操作，它们都能有效改变树高，所以利用旋转操作，我们可以时刻保持平衡树是平衡状态的。这也让我们在平衡树上的查找，变得非常地容易。</p>\n<p>接着，我们又一起讨论了平衡树的合并和分解操作。其实核心原则就是在插入和删除节点之后，如果树不平衡了，我就进行左旋或者右旋操作，让它恢复平衡。这让我们可以更加灵活地操纵有序序列。</p>\n<p>不过，即使平衡树在索引上保持了如此优秀的效率，但为了能让树在频繁更新的时候依然保持平衡，我们仍旧要付出相当大的代价。</p>\n<p>因此，在实际的应用中，我们很可能不需要让树时刻保持严格的平衡，而只需要让树保持一个相对平衡的状态就行了，当树的不平衡程度打破了我们的忍耐限度时，再让树通过少量的调整恢复到相对平衡的状态中。这种二叉排序树也被称作近似平衡二叉排序树，它可以应用于需要频繁更新的结构上。</p>\n<p>那在接下来的课程中，我会带你学习一种应用非常广泛的近似平衡二叉树，也就是红黑树。</p>\n<h2>课后练习</h2>\n<p>今天，我们在讨论平衡树中插入或者删除元素的时候，还有一些对称情况没有细说。你能结合你的理解，把这些对称情况的算法实现出来吗？</p>\n<p>欢迎在留言区分享你的答案，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "15 |  AVL树：如何让二叉排序树永远保持最优？",
      },
      {
        title: "16 | 红黑树（上）：红黑树基础与插入调整操作",
        herf: "https://time.geekbang.org/column/article/288739",
        id: "288739",
        content:
          '<p>你好，我是胡光。</p>\n<p>上节课我们讲了，AVL树能时刻保持平衡，所以它拥有非常优秀的检索性能，但它每一次更新之后都需要调整自己，强调自己的平衡性。因此，我们在维护频繁更新的有序序列的时候，就要付出相应的代价。</p>\n<p>在实际的应用中，为了保持排序二叉树的检索性能，我们经常不需要它有那么严格的平衡性，只要保持一种近似的平衡就可以了。这该怎么做呢？我今天就给你讲一种非常常用的近似平衡二叉排序树，红黑树。因为红黑树的内容比较多，我会花两节课的时间去讲。这节课我们先讨论，红黑树的基础和插入调整操作，下节课再讨论删除调整操作。</p>\n<h2>什么是红黑树？</h2>\n<p>红黑树在计算机科学中有非常广泛的应用，例如C++ STL中的 <code>set</code> 、 <code>map</code> ，JAVA中的 <code>TreeMap</code> 都是用红黑树来实现的。顾名思义，红黑树就是一种每一个节点都被染上黑色或者红色的二叉排序树。我们会利用每个节点的颜色，来决定红黑树上的一些简单或者复杂的操作。</p>\n<p><img src="https://static001.geekbang.org/resource/image/1f/d1/1fbebeb3e65f1bf238013f484d31c7d1.jpg" alt="" title="图1：红黑树示意图" /></p>\n<p>上图就是一棵红黑树，通常我们在画图的时候会省去空指针叶子，为了方便讲解，我在这里都标出来了。那么，红黑树究竟是怎样保证自己性能的呢？</p>\n<p>首先，我们对照着示意图，来记一下红黑树的5个重要性质：</p>\n<ul>\n<li>\n<p>每一个节点的颜色不是红色就是黑色的；</p>\n</li>\n<li>\n<p>根节点是黑色的；</p>\n</li>\n<li>\n<p>每一个叶子节点（Nil，最下层节点的空指针孩子）都是黑色的；</p>\n</li>\n<li>\n<p>如果一个节点是红色的，那它的两个孩子都是黑色的；</p>\n</li>\n<li>\n<p>对于每一个节点，从它出发到它的后代叶子节点的所有简单路径上，黑色节点的数量都是相同的。</p>\n</li>\n</ul>\n<p>你会发现，在红黑树的五条性质中，我们对<strong>黑色节点的规定</strong>比较多，尤其是第5条，从某一个节点出发到后代的黑色节点数量是相同的。那我们就假设，从某一个节点T出发，到叶子节点的一条简单路径上，黑色非叶子节点的数量是black_height(T)，我们管它叫<strong>子树的阶</strong>。如果T的两个孩子都非空，那T节点两个孩子的黑树高就有可能是black_height(T)或者black_height(T)-1，这主要取决于那两个子节点的颜色。</p>\n<p>所以，对于有N个节点的两个孩子，以它们为根的子树分别会有至少$2^{black_height(T)-1}$个节点，而以N为根的子树至少会有$2^{black_height(T)-1}\\times 2+1=2^{black_height(T)}-1$个节点。</p>\n<p>然后根据性质4，每个红色节点的两个孩子一定是黑色的，我们就能得出，从节点N出发到叶子节点的一条简单路径上，一定有至少一半的节点都是黑色的（因为没有限制黑色节点的孩子的数量）。由此，我们就能得到，以N节点为根节点的子树的树高h满足$height(T)\\le 2\\times black_height(T)$，那以N为根的子树，它的节点数满足：</p>\n<p>$$count(T)\\ge 2^{black_height(T)}-1=2^{\\frac{height(T)}{2}}-1$$</p>\n<p>则有：</p>\n<p>$$count(N)+1\\ge 2^{\\frac{height(N)}{2}}$$</p>\n<p>两边同时取对数，则有：</p>\n<p>$$log_2(count(T)+1)\\ge \\frac{height(T)}{2}$$</p>\n<p>也就是说，一棵有N个节点的红黑树的树高不会超过$2\\times log_2(N+1)$，这就保证了红黑树的检索效率仍然是对数级别的。</p>\n<p>从前面的推导过程中我们不难看出，红黑树通过性质5保证了红黑树树高的相对平衡性，通过性质4又保证了红黑树的树高不会相差太大。这其中，红色节点起到了调节的作用，能够让红黑树在不那么平衡的情况下，仍保证黑色节点的数量，同时又保证了红色节点不会泛滥，树上的性能不会被破坏。毕竟如果红黑树上没有红色节点，那它就是一棵严格的平衡树了。</p>\n<p>可以说正是红黑树这五条性质，保证了红黑树的优秀性能。但也正因为要维持红黑树的这5条性质，红黑树的基础操作就和我们之前讲过的二叉排序树有一定的区别了。那区别都有哪些呢？接下来，我们就来说说红黑树的插入操作。</p>\n<h2>理解红黑树的插入操作</h2>\n<p>我们知道，红黑树也是一种二叉排序树，所以向一棵红黑树中插入节点的步骤和二叉排序树是相同的，都是<strong>找到正确的位置，并新建节点插入</strong>。而我们要重点注意的是，在插入一个节点的时候，在什么情况下，有哪些红黑树的性质会被打破，我们又该怎样把红黑树调整回来。</p>\n<p>我们以插入节点z为例。对于这个新的z节点，我们首先要将它初始的颜色设置为<strong>红色</strong>。因为如果我们将插入节点的初始颜色定义为黑色，就会直接打破性质5（从根节点到叶子节点的每条路径上黑色节点数量是一样的），调整起来也比较麻烦。同时红色节点受到周围节点的限制也比黑色节点要少一些，就算出现了打破的情况，也比较好调整。</p>\n<p>在插入了红色节点z之后，我们重新来看红黑树的5条性质，首先，性质1和3是完全不会被打破的。由于z节点的初始颜色是红色，而我们插入的位置一定是一个空指针（黑色），同时z自己也会有两个空指针，它们都是黑色的。所以，在插入z节点之后，z所在的路径上减少了一个黑色的空指针，增加了一个红色的z节点，同时z节点下又会增加一个黑色的空指针，性质5同样会保持下来。</p>\n<p>接下来，我们再来看看性质2和性质4。我可以提前告诉你，<strong>只有性质2（根节点是黑色的）和性质4（红色节点的儿子都是黑色的）在插入的过程中有可能被打破</strong>。</p>\n<p>首先我们来看性质2，性质2被打破的唯一一种可能：我们插入的位置就是根节点（实际上就是将z插入到了一棵空树中）。在这种情况下，其实我们直接把z变成黑色节点就可以了。由于z的位置是根节点，那从根出发的每条路径上的黑色节点都会多一个，这也保持了性质5的稳定。</p>\n<p>而性质4被打破的情况，就是我们插入的节点z在一个红色节点的下面，而当这种情况发生，z节点的叔叔，也就是其祖父的另一个子节点的颜色就至关重要了。我们可以分三种情况讨论：</p>\n<ol>\n<li>\n<p>z节点的叔叔是红色节点</p>\n</li>\n<li>\n<p>z节点是其父亲的左子节点，z节点的叔叔是黑色节点</p>\n</li>\n<li>\n<p>z节点是其父亲的右子节点，z节点的叔叔是黑色节点</p>\n</li>\n</ol>\n<p>当然，这三种情况只考虑了z节点的父亲是其祖父左子节点的情况，因为其他情况都是对称情况，只要你掌握了这三种情况，对称情况自然就可以掌握了。</p>\n<p>那为什么要分三种情况讨论呢？在二叉排序树的旋转操作中，我们讲过，当二叉排序树旋转的时候，被转到根的那个节点的某一棵子树会被原来的根节点重新继承。在红黑树中也是一样，如果发生了右旋，则原左子节点的右子树就会被原根节点继承，右子树中的黑色节点会被根节点继承。如果原根节点也是一个黑色的节点，那么旋转后的子树，右边的黑色节点数就会发生变化，这种变化和性质5息息相关，所以在旋转的时候，我们要小心考虑这种情况。因此，z节点的叔叔是黑色节点的时候，我们要分为两种情况讨论。</p>\n<p><img src="https://static001.geekbang.org/resource/image/9c/5d/9c1a68ecd15be17e74b00295f0f9745d.jpg" alt="" title="图2：三种元素插入情况" /></p>\n<p>明白了这一点，接下来，我再来详细说说，当面对这三种情况的时候，我们具体该怎么操作。</p>\n<h3>Case 1：z节点的叔叔是红色节点</h3>\n<p><img src="https://static001.geekbang.org/resource/image/1d/fc/1d8e9bb6504ca7a08cf478a8f3f641fc.jpeg" alt="" title="图3：Case1示意图" /></p>\n<p>如果我们是把节点z插入到一棵符合性质的红黑树中，那z的祖父C节点就一定是黑色的节点，否则原来的树就不符合性质4了。同时，图上的这几棵子树$\\alpha、\\beta、\\gamma、\\zeta、\\epsilon$的阶（black_height）也都是相等的。</p>\n<p>注意，这棵子树和其他子树还要共同在整棵树上保持性质5，所以每条路径上黑节点的数量不能发生变化，那我们为了保持性质5，也为了修复性质4，就需要在每一条路径上去掉一个红色节点，增加一个黑色节点。因此，处理方法就很简单了，把z节点的父亲和叔叔，也就是A节点和D节点变成黑色，这样z的祖父C节点就变成红色了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/5e/a1/5e4f7c6cb94ab110d5c363a163cfbda1.jpg" alt="" title="图4：更改根节点颜色" /></p>\n<p>但要注意的是，我们调整了这个子树之后，因为更改了C节点的颜色，很有可能会影响上面子树的性质（例如原本C节点的父亲是红节点），所以这棵子树调整过之后，事情还没有结束，我们应该再从C节点出发，向上调整。而由于树结构的递推性质，子树符合红黑树的性质，那它的祖先也一定会符合红黑树的性质，因此我们也只需逐级向上调整，将整条路径调整到完全符合性质即可，无需担心会牵一发而动全身。</p>\n<h3>Case 2：z节点是其父亲的左子节点，z节点的叔叔是黑色节点</h3>\n<p><img src="https://static001.geekbang.org/resource/image/1c/3f/1c25c2740123b6c4c32f9f8273573e3f.jpeg" alt="" title="图5：Case 2示意图" /></p>\n<p>当z节点的叔叔D是黑色节点的时候，显然Case1中以一换一，只通过染色来解决问题就行不通了。如果我们还是将A节点染黑，则这条路径上多了一个黑色节点，打破性质5。如果同时将C节点染红，虽然可以保持左路径上黑色节点数量不变，但右路径又少了一个黑色节点，这仍旧会打破性质5。那我们该怎么办呢？</p>\n<p>别着急，我们还有一个法宝没有用，那就是树的旋转。</p>\n<p>我们注意到，在这棵树中，$\\alpha$、$\\beta$、$\\gamma$和$\\zeta$四棵子树的阶是相等的，并且它们都利用了黑色的根节点C，但$\\beta$和$\\gamma$上面有两个红色的节点。这就意味着，无论我们怎么染色，左右两边路径的黑色节点数都没办法相等。但是，我们可以通过旋转操作，将黑色的节点集中到一边，在一条路径里进行以一换一的操作。</p>\n<p>没错，就是直接针对C节点进行一次右旋，这样A节点（红）就成了子树的根节点，C节点成为了右子节点。这个时候，右边路径的黑色节点数刚好多出来了一个黑色节点（C）。你会发现，如果我们将C节点换成红色节点的话，那C也是红的、B也是红的，这会打破性质4，同时，整棵子树所有路径上都会少一个黑色节点，这又打破了整棵树的性质5。</p>\n<p>因为它们共同的父亲是根节点A（红），所以我们把A节点换成黑色节点，就能满足性质4，同时由于根节点是黑色的，所有的路径上又加回来了一个黑色节点，这又重新满足了性质5。</p>\n<p><img src="https://static001.geekbang.org/resource/image/f8/85/f8b7e4cd83086a1791b7cf6b3b0d1585.jpg" alt="" title="图6：一次右旋+更改根节点颜色" /></p>\n<h3>Case 3：z节点是其父亲的右子节点，z节点的叔叔是黑色节点</h3>\n<p><img src="https://static001.geekbang.org/resource/image/99/e8/99b5ef5c1fca0903b11462dc7fbd13e8.jpeg" alt="" title="图7：Case 3示意图" /></p>\n<p>这种情况就更复杂一些了。解决它最直观想法，就是直接对树进行右旋。</p>\n<p>右旋之后，z节点就直接成为C节点的左子节点，$\\beta$子树和$\\gamma$子树的上面将会有B、C两个节点，而根节点A的左边只剩下了$\\alpha$子树。也就是说，无论我们怎么调整A、B、C这三个节点的颜色，最终子树都会打破性质5。</p>\n<p><img src="https://static001.geekbang.org/resource/image/eb/34/ebfa04f7837e80ea0de977aa842b2534.jpg" alt="" title="图8：右旋示意图" /></p>\n<p>还记得上一节课我们讲AVL树插入的时候提到的情况2吗？其实Case 3和那种情况是类似的，为了防止右旋的时候将左子树的右子树的树高整块继承下来，我们必须要先缩减左子树和右子树的树高。具体来说，我们要先在A节点上进行左旋，把B旋转成C的左儿子，然后，你发现了吗，现在的情况和Case 2就一样了，我们再进行一次右旋，将B的颜色染成黑色，C的颜色染成红色，问题就解决了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/2a/c9/2ab887a06cb9236806436aba0db56dc9.jpg" alt="" title="图9：一次左旋+一次右旋" /></p>\n<p>以上就是红黑树的插入操作，你理解了吗？理解起来确实不容易，记得结合示意图多看几遍。</p>\n<p>总的来说，红黑树在插入元素调整的时候，至多会向上调整一条路径，也就是整体的树高，所以红黑树的插入操作，索引及调整都是$O(log_2N)$的。而且多数情况下，我们可能不需要调整那么多步，就可以保持红黑树的性质了。从这点上来看，红黑树的调整频率是低于AVL树的，所以红黑树也常常用来维护动态序列。</p>\n<h2>课程小结</h2>\n<p>这节课，我带你认识了红黑树。</p>\n<p>我们先学习了红黑树的基础知识，红黑树具有5个非常重要的性质。分别是，红黑树中每一个节点的颜色不是红色就是黑色；红黑树的根节点都是黑色的；而且它的每一个叶子节点都是黑色的；如果一个节点是红色的，那它的两个孩子都是黑色的；对于每一个节点，从它出发到它的后代叶子节点的所有简单路径上，黑色节点的数量都是相同的。这5个性质保证了红黑树的优秀性能。</p>\n<p>然后，我们一起讨论了红黑树插入元素之后的调整操作。因为向红黑树插入元素，只有性质2和性质4有可能被打破。所以我们要分三种情况分别讨论。既然有插入操作，肯定也有删除操作。相对于插入，删除操作就更复杂了，需要讨论的情况也更多，我会在下节课和你详细讨论。</p>\n<h2>课后练习</h2>\n<p>如果在插入节点的时候，我们将节点初始化成为黑色节点，会发生什么？</p>\n<p>欢迎在留言区分享你的答案，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "16 | 红黑树（上）：红黑树基础与插入调整操作",
      },
      {
        title: "17 | 红黑树（下）：红黑树的双黑节点与删除调整",
        herf: "https://time.geekbang.org/column/article/289585",
        id: "289585",
        content:
          '<p>你好，我是胡光。</p>\n<p>上节课，我们讲了红黑树的5条基础性质，以及红黑树的插入操作。这节课我们依然围绕红黑树的5条性质，来讲讲红黑树的删除操作。</p>\n<p>我们先来回顾一下红黑树的5条性质：</p>\n<ul>\n<li>红黑树中每一个节点的颜色不是红色就是黑色；</li>\n<li>红黑树的根节点都是黑色的；</li>\n<li>每一个叶子节点都是黑色的；</li>\n<li>如果一个节点是红色的，那它的两个孩子都是黑色的；</li>\n<li>对于每一个节点，从它出发到它的后代叶子节点的所有简单路径上，黑色节点的数量都是相同的。</li>\n</ul>\n<p>我们知道，向红黑树中插入一个新节点的时候，无论这个节点是红色还是黑色，都会破坏掉红黑树中的某几个性质，这就需要我们重新调整节点的颜色或者通过旋转操作来调整树的结构。那如果我们删除掉红黑树中的一个节点会造成什么样的影响呢？</p>\n<h2>红黑树中的双黑节点是什么？</h2>\n<p>首先，红黑树也是一棵二叉排序树，所以红黑树上的删除过程也和二叉排序树的删除过程类似。我们先来回顾一下二叉排序树的删除过程，假设我们要删除的节点是z，如果z没有孩子，直接删除就行，否则我们就得找到z的中序遍历前驱或后继顶替它的位置。</p>\n<p>不过，因为红黑树的每一个节点都带有颜色信息，所以我们的每一次删除操作之后，还要保持红黑树的性质。具体怎么做呢？我们还是要分情况来讨论，逐个击破。</p>\n<p>第一种情况，如果被删除的节点z有两个孩子，那我们需要找到的补位节点就是它的前驱节点或者后继节点y，将y补到z的位置之后，我们再把y的唯一一个孩子x补到y的位置。同时，我们还要把y的颜色替换成为z的颜色。这样，至少在z的位置上，颜色是没有改变的。</p>\n<p><img src="https://static001.geekbang.org/resource/image/96/24/965yyb622bdc4db3546ce7622fb0ab24.jpeg" alt="" /></p>\n<p>我们在以上图为例详细解释一下，如果想要删掉有两个孩子的节点17，我们只能向下寻找，把17的中序遍历后继19补到17的位置上，再把19染成黑色。这样节点17所在的局部位置，相当于没有发生任何变化，而实际受影响的，是节点17的后缀19节点的位置。因为19节点只有20这一个孩子节点，所以图中我们的实际操作就是删除掉节点19，将节点20补位到19的位置上。</p>\n<p>总的来说，被删除的节点z有两个孩子这种情况非常简单，调整操作就相当于我们删除了z的后继节点y，然后用y唯一的孩子进行补位。所以我们重点要讨论的情况，其实是被删除的节点z只有一个孩子x。</p>\n<p>我们先来想一个问题，如果被删除的节点是红色的，这对红黑树的性质有什么影响？答案是没有任何影响，因为在红黑树的5条性质中，我们只对黑色节点进行了明确的数量限制。那如果被删除的节点z是黑色的，这对红黑树的性质又有什么影响？这里，我们要结合它的孩子节点x的颜色来一起考虑。</p>\n<p>首先，如果x是红色的，其实也不会对红黑树的性质有什么太大影响，我们只需要把x染成黑色就可以了。这是为什么呢？因为对于以z为根节点的子树来讲，虽然我们删了一个黑色的节点，让它每条路径上的黑色节点数都少了一个，但我们将红色节点染成黑色节点之后，它的黑色节点数量又恢复了。</p>\n<p>可是，如果被删除节点z是黑色的，同时它的孩子节点x也是黑色的，那我们就无法补上这个丢失的黑色节点了。不过这也没关系，我们可以让这个补位的x节点暂时承担两份黑色节点的工作，这种节点我们叫它<strong>双黑节点</strong>（Doubly Black）或者<strong>双重黑节点</strong>，它虽然是黑色的，但我们认为它比单纯的黑色要黑很多，所以这个节点的存在打破了红黑树的性质1。</p>\n<p>那遇到了这种节点之后，我们该怎么解决它呢？其实，<strong>整个红黑树的删除过程，我们都在围绕着如何解决双黑节点进行</strong>。想要消解掉双黑节点上的一个黑色节点，我们就必须要考虑消解掉它兄弟节点的一个黑色节点，这样才能保证以它的父亲为根的子树还是一棵合法的红黑树。因此，我们一共可以分4种情况来讨论。</p>\n<h2>Case 1：x的兄弟节点w是黑色节点，w的两个儿子都是黑色节点</h2>\n<p><img src="https://static001.geekbang.org/resource/image/48/87/4849f98030ba1d4d753f7f4363888d87.jpeg" alt="" /></p>\n<p>这种情况是最简单的。就像我们前面所说，x节点是个双黑节点，我们想要把它消解掉，则一定要从w中消解。而w的两个儿子都是黑的，所以我们把w节点变成红色之后，子树w的平衡就不会受到影响，又同时消解掉x的一个黑色，双黑节点的问题也就解决掉了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/aa/a7/aaf4591b217effb2b885daa25422cfa7.jpeg" alt="" /></p>\n<p>当然，与红黑树的插入操作一样，如果我们更改了D节点的颜色，就很有可能破坏它和B的性质，所以我们还要去检查它和B的关系。这个问题我们之前讨论过了，你可以自己思考一下。</p>\n<h2>Case 2：x节点的兄弟节点w是黑色节点，w的右孩子是红色节点</h2>\n<p><img src="https://static001.geekbang.org/resource/image/da/73/da10061dd4f0c2aeb051c8e669756473.jpeg" alt="" /></p>\n<p>在这种情况中，我们还是想要利用红色节点分担掉x节点上多出来的那一重黑色。但是我们发现，红色节点E所处的位置很深，它是A节点兄弟节点的孩子节点，我们如果直接用E来分担，就必然会破坏掉整棵子树的性质。那怎么才能让E去分担这个黑色呢？</p>\n<p>实际上，我们要先弄明白，E节点改变颜色是参照哪棵子树进行的。没错，就是它的兄弟，也就是以C为根的那棵子树。这个时候，我们发现可以通过旋转操作，让E节点的参照子树中有A节点。</p>\n<p><img src="https://static001.geekbang.org/resource/image/cb/03/cb63e606ff33ab987e971fb33783c503.jpeg" alt="" /></p>\n<p>如上图，我们先进行了一次左旋操作，左旋之后又将D、B颜色互换，保持了C节点所在子树不受影响。这个时候，相比于初始情况，$\\alpha$子树、$\\beta$子树的阶（black height）多了一个，同时$\\epsilon$子树、$\\zeta$子树的阶又分别少了一个，所以E就可以直接分担A多出来的黑色了：我们将E染成黑色，再把A从特别黑变成黑色。最终子树的性质没有被破坏。</p>\n<p><img src="https://static001.geekbang.org/resource/image/1a/04/1a7f4242166552f64762c8535f3a4d04.jpeg" alt="" /></p>\n<h2>Case 3：x的兄弟节点w是黑色节点，w的左孩子是红色节点，右孩子是黑色节点</h2>\n<p><img src="https://static001.geekbang.org/resource/image/f1/99/f1cf43a746580af21ed4e40a8339ec99.jpeg" alt="" /></p>\n<p>这次和第二种情况不同了，如果我们直接进行左旋操作，那么右子树中将没有任何可以找补的黑色节点，整棵树的平衡一定会被破坏掉。不过，在AVL树和红黑树的插入操作中，我们每次遇到这种情况，都可以先尝试把它归到我们熟悉的情况中，这样再去解决它就会容易很多。这次也一样，我们利用双旋操作来试着调整一下。</p>\n<p><img src="https://static001.geekbang.org/resource/image/a1/4f/a19c35b0471e77a1d446340c6a7dd04f.jpeg" alt="" /></p>\n<p>结合上面这张图，我们可以先通过右旋将红色节点变成w的右子节点，把它归化到第二种情况中。然后，我们再对D节点进行一次右旋。同时，为了保证$\\gamma$子树和$\\delta$子树的性质，我们将C节点和D节点的颜色交换一下。这样一来，这种情况就成功归化到了第二种情况中，我们用第二种情况的方法去解决它就好了。</p>\n<p>现在，我们已经解决双黑节点x的兄弟节点是黑色节点的所有情况了，下面，我们再来看最后一种情况。</p>\n<h2>Case 4：x的兄弟节点w是红色节点</h2>\n<p>如果x的兄弟节点w是红色节点，那么根据性质4，它们的父亲节点就一定是黑色节点，且w的孩子节点一定也是黑色节点。</p>\n<p><img src="https://static001.geekbang.org/resource/image/4e/c5/4ea5ba9d343f95f6fdd018da5408c5c5.jpeg" alt="" /></p>\n<p>这种情况下，如果我们直接拿兄弟节点w去分担x节点的黑色，w的节点D和E的平衡会受到影响，整棵子树的性质5会被打破，所以我们就要继续考虑能否通过旋转操作，让这个问题得以解决。而我们看到上图的结构，如果直接进行右旋，A节点成为根节点，则所有子树的性质5都会被打破，这种情况调整起来就更加复杂了，所以我们只能对B进行右旋，尝试后的结果如下：</p>\n<p><img src="https://static001.geekbang.org/resource/image/39/e9/396bbdb2ffc9e0a3f1f90cc83fc573e9.jpeg" alt="" /></p>\n<p>右旋之后，同样是为了保持平衡，我们将D节点染成黑色，将B节点染成红色。</p>\n<p>发现了吗？双黑节点的兄弟节点变成了一个黑色节点，所以这种情况被归化到前三种情况的任意一种了。我们直接利用之前的方法，按图索骥就可以解决这种情况。</p>\n<h2>课程小结</h2>\n<p>到这里，红黑树相关的内容我们就彻底讲完了。这节课，我们一起学习了红黑树的删除操作。</p>\n<p>在删除操作的整个过程中，我们都是在围绕着如何解决双黑节点进行的。双黑节点的产生情况，其实就是被删除的节点z只有一个孩子x，并且x是黑色。</p>\n<p>想要完全消解掉双黑节点，我们要分4种情况讨论：</p>\n<ul>\n<li>x的兄弟节点以及它的两个儿子都是黑色节点；</li>\n<li>x的兄弟节点是黑色节点，而它的右孩子是红色节点；</li>\n<li>x的兄弟节点w是黑色节点，w的左孩子是红色节点，右孩子是黑色节点；</li>\n<li>x的兄弟节点w是红色节点。</li>\n</ul>\n<p>总的来说，调整的原则其实就两个，一个是改变节点的颜色，另一个是进行旋转操作。如果遇到了不熟悉的情况，我们可以先尝试把它归到我们熟悉的情况中，这样再去解决它就会容易很多了。比如，我们会常用到双旋操作。</p>\n<p>不得不说，红黑树的操作相对来讲，不仅情况繁多，而且操作也比较复杂。但我们实际上只需要在局部进行调整操作，很少涉及大规模的调整，所以红黑树依然可以保持着较低的更新成本。</p>\n<p>同时，你可能也发现了，在删除操作中，我们不断用红色节点补充缺失的黑色节点，所以在删除操作中，红色节点会变得越来越少，红黑树也就越来越向AVL树发展。这也是我们在红黑树插入的时候默认被插入节点是红色节点的原因之一。</p>\n<p>实际上，红黑树虽然经常出现在计算机应用的各个角落，看上去我们只需要调包就可以使用它，但由于它较为复杂的情况，我们理解它的同时也在一定程度上锻炼了我们的算法思维，所以红黑树的原理以及相关操作，也是各大公司在面试的时候的热门问题。因此，我们用了2节课去推导红黑树的各项性质，以及各种操作，就是希望你能去理解它，而不是仅仅去记忆它。</p>\n<h2>课后练习</h2>\n<ol>\n<li>如果某一个节点被插入到红黑树之后，立刻被删除了，那么红黑树的形态和插入节点之前一样吗？</li>\n<li>红黑树是存在哪些高效的级联算法吗？如果有，可以在留言区分享出来。</li>\n</ol>\n<p>好啦，关于红黑树的插入和删除操作，你都理解了吗？可以在留言区写下你的疑惑，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "17 | 红黑树（下）：红黑树的双黑节点与删除调整",
      },
      {
        title: "18 | 哈希表：文件的身份认证系统是如何实现的？",
        herf: "https://time.geekbang.org/column/article/290366",
        id: "290366",
        content:
          '<p>你好，我是胡光。</p>\n<p>平常，我们在互联网上下载文件，文件的下载页面有的时候会专门列出来一栏 <code>sha</code> 或 <code>md5</code> ，里面是一长串的数字和字母的混合。其中， <code>md5</code> 或 <code>sha</code> 叫做数据签名，是下载网站为了防止文件被篡改，而提供的一种校验数据一致性的方式。如果下载下来的文件运行相应的算法，计算出来的 <code>sha</code> 或 <code>md5</code> 是一样的，就说明这个文件没有被篡改过，我们仍然可以使用。</p>\n<p>这就让我们联想到了杀毒软件的应用场景，杀毒软件在扫描计算机中文件的时候，仿佛每一个文件也有一个标记，如果检查出了那个标记，我们就可以认为这个文件是病毒。这到底是怎么做到的呢？</p>\n<p>这个技术的实现，依靠的就是我们今天要讲的<strong>哈希表</strong>（Hash Tables），也叫做<strong>散列表</strong>。哈希表在我们的日常生活中应用非常广泛，比如我们的姓名、身份证号、学号、护照编号，地区的邮政编码、电话号码、电话区号。这些编码都是实际事物的重要信息的编码认证方式，例如我们看到了010的电话区号，就知道这是北京的电话号码，公安系统得到了一个人的身份证号，就可以调取这个人的相关信息等等。</p>\n<p>说了这么多，哈希表到底是什么呢？</p>\n<h2>哈希函数：数据的“身份证”</h2>\n<p>哈希表是一种将集合U映射到表$T[0\\cdots m-1]$中的方法，其中，集合U中的元素我们称之为<strong>键值</strong>（key），表T中每一个位置我们称之为<strong>槽位</strong>（slots），将键值映射到槽位上的方法我们称之为<strong>哈希函数</strong>。</p>\n<p>看了这样的定义之后，你可能要问了，我们直接将键值当成下标，数组存储不就可以了吗？为什么还要那么麻烦呢？当然可以，<strong>数组也是一种特殊的哈希结构</strong>，但是想象一下，计算机中的文件浩如烟海，且呈井喷式增长，如果我们直接用数组编号存储，这将会是爆炸式的数据量。</p>\n<p>比如说，中国每天出生的婴儿非常多，我们会利用出生婴儿信息对他们编码，这在信息存储和检索上，比直接使用顺序编号要方便太多了。所以，哈希表利用元素本身的信息，可以将原本取值范围很大的复杂数据映射成原始数据唯一的“身份标识”，方便我们检索、比对和存储等。</p>\n<p>这个操作其实就是哈希函数来完成的，哈希函数是将原始数据转换成为编码的计算方法。</p>\n<p><img src="https://static001.geekbang.org/resource/image/d1/3d/d12fe48d5fac85235cc6b5b27bcc5d3d.jpeg" alt="" /></p>\n<p>以我国的身份证号为例，假设现在有一个刚刚出生的人叫张三，他本身就可以看作是一条数据，而他的身份证号可以看作是一个哈希值，那计算一个人身份证号的哈希函数就可以看作：</p>\n<p>户口所在省/直辖市+户口所在地市行政区域+户口所在县区级行政区域+出生年月日+当天同一区域出生顺序编号（最后一位代表性别）+校验位</p>\n<p>我们可以看到，张三的身份证编号就是把张三的重要信息编码形成的。当然，未来，我们也可能会把基因、指纹等等信息也都编码集成身份认证。</p>\n<p>因此，哈希表中最关键的部分就是哈希函数，而<strong>哈希函数最重要的作用就是利用被映射数据的重要信息来计算最终的映射值</strong>。</p>\n<p>同时，哈希算法还需要满足一个条件，那就是分布均匀，也就是键值映射到槽位的概率是相等的，这可以显著降低相似数据碰撞的概率。同时，在一些应用，如数字签名、数据一致性检验上，也不容易通过相似数据来伪造函数计算的结果。</p>\n<p>哈希算法在实际工作中是怎么应用的呢？一开始我们讲到的 <code>sha</code> 和 <code>md5</code> ，其实就是摘要了文件中的部分重要信息，通过对应的哈希函数所计算出来的哈希值，它们是现在非常常用的两种哈希函数。想要弄明白这些哈希算法的基本框架，我们还得先弄明白另一个算法，MD4。</p>\n<h2>MD4：常用哈希函数族的基础</h2>\n<p>MD4算法在1992年被发现，是现在常用的MD5算法和SHA算法的基础。它将文件分为若干个512比特（bit）的分组，然后对每一个分组执行MD变换函数，共执行三轮，最后将三轮的结果相加，形成一个128bit的编码再输出。</p>\n<p><img src="https://static001.geekbang.org/resource/image/b1/35/b13eda5896a63fff3d5a1a43376b3a35.jpeg" alt="" /></p>\n<p>理解了思路，我们再来看看算法的执行过程，主要可以分4步。</p>\n<ol>\n<li>填充原始数据，让原始数据的最终长度满足$l_f\\ mod\\ 512=448$。</li>\n</ol>\n<p>因为最终要处理的数据必须是512的倍数，所以我们在数据的末尾要使用64比特记录原始数据的长度。因此，我们要将数据填充到448（|512-64|=448）。数据填充的方式为：在原始数据的末尾填充一个1，剩余位数补位为0。</p>\n<p><img src="https://static001.geekbang.org/resource/image/2c/a3/2c7634ccc2f0a2c555d6e0dfc593f7a3.jpeg" alt="" /></p>\n<p>例如，我们将 <code>abc</code> 填充为MD4算法的输入。</p>\n<p>首先，因为 <code>abc</code> 共占据了24比特，所以我们在abc的末尾填充一个1，再填充$448-24-1=423$个0，接着我们要将它表示成为64个比特，填充到原始数据的末尾，所以最终数据为：</p>\n<pre><code>[0100 0001 0100 0010 0100 0011][1][000000...(423个0)][(0000)*14 0001 1000]\n</code></pre>\n<p>之后，我们将得到的这一串数据分为512比特一组。当，然<code>abc</code>被填充之后总共也就只有512位，也就只有这一组。</p>\n<p>这个填充规则在之后的MD5、以及SHA算法家族中都被沿用了下来。</p>\n<ol start="2">\n<li>初始化4个32比特特征值A、B、C、D，其中：</li>\n</ol>\n<pre><code>  A=0x67452301\n   B=0xefcdab89\n   C=0x98badcfe\n   D=0x10325476\n</code></pre>\n<p>这4个特征值跟随着填充后的每一组数据变换，最终会形成MD4的输出</p>\n<ol start="3">\n<li>我们将每一组数据切分成16块子数据，让每一块的长度都是32比特，再依次将每一块输入到MD变换函数中进行变换，变换过程如下：</li>\n</ol>\n<p><img src="https://static001.geekbang.org/resource/image/f1/67/f186a329e840328b56648c9bbeacc067.jpeg" alt="" /></p>\n<p>这个变换过程一共要执行3轮，每一轮函数$f_j$都是不一样的。每一次左移的位数S也是周期变化的，每一轮的变换周期也是不一样的。有啥规律呢？</p>\n<p>我们来看个例子。当我们处理第一块子数据的时候，变换函数为：</p>\n<p>$$A=(A+f_j(B, C, D)+X_0)\\times 2^S$$</p>\n<p>而当我们处理第二块子数据的时候，变换函数为：</p>\n<p>$$D=(D+f_j(A, B, C)+X_1)\\times 2^S$$</p>\n<p>处理第三块子数据的时候，变换函数为</p>\n<p>$$C=(C+f_j(D, A, B)+X_2)\\times 2^S$$</p>\n<p>依此类推，一直到计算完16块子数据为止，再开始下一轮。</p>\n<p>3轮终止之后，A、B、C、D都会迭代成为新的值，再将其分别和原来的A、B、C、D值相加，得到新的A、B、C、D特征值，就是MD变换函数最终的输出，也是再进入下一组的数据。</p>\n<ol start="4">\n<li>处理完所有的数据分组后，我们将A作为最低位，D作为最高位拼接输出，最终形成了128比特的MD4编码。其中，变换函数$f_j$是完全基于位运算的。</li>\n</ol>\n<p>我们看到，MD4算法中有大量的数据分组、分块、移位、取模等过程，所以该算法几乎是无法逆向的。也就是说，除了暴力穷举以外，我们无法通过最终的哈希值反推回原来的数据是什么样子的。这就是MD4算法的完整架构了。</p>\n<p>虽然这个算法早已被证实不安全，并且已经过时了，但是其基本的思路被沿袭了下来，科学家们在它的基础上，衍生出了MD5算法、SHA算法家族等。</p>\n<p>其中MD5算法则是在MD4算法的基础上增加了一个“安全带（Safe Belt）”机制，并且将原有的三轮变换变成了四轮变换。不过，最终生成的数据也是128比特。</p>\n<p>而SHA-1算法则是在MD5的基础上又增加了一些变换操作，并且将数据切分成为了5块，最终生成了长度为160比特的编码。它的长度更长，碰撞几率更低，但相应地，算法的效率也比MD5稍慢了些。</p>\n<p>除此之外，SHA-2算法将数据分成了8块，最终产出256比特长的数据，算法更加复杂，但是产出的编码也更加安全。SHA-2算法，也有不同的变种，如SHA-256（生成256比特长度的编码），SHA-224（生成224比特长度的编码）等，我就不再详细说了。</p>\n<h2>哈希的实际应用</h2>\n<p>哈希算法的基础结构讲完了，我们再回过头来，看看开头说的<strong>文件签名和病毒扫描</strong>，这两个哈希算法的经典应用是怎么实现的。</p>\n<h3>文件签名</h3>\n<p>首先，我们来说说文件签名的应用。</p>\n<p>哈希函数的特点就是利用数据中的重要信息计算数据的编码值，并且在最终取值上分布均匀、不易碰撞。但是它有一个缺点，真实的数据哪怕有一些非常微小的修改，也可能导致最终计算出来的哈希值有很大差别，这也被称为雪崩效应。</p>\n<p>例如，现在有一个很长的文本文件，我们只修改它其中的一个字。修改前后，文件的 <code>md5</code> 如下：</p>\n<pre><code>修改前：9dea372891cf7cc669c9a4b96b9b7727\n修改后：e5c8b5e45feb43c4985769f864a299ca\n</code></pre>\n<p>因此，哈希算法被当作非常好的文件一致性校验工具。当我们在网站上下载的时候，下载网站上就会贴出这个文件的哈希值。如果我们下载到这个文件之后，用计算机计算出它的哈希值和原来的不一样了，那这个文件就很有可能已经被篡改过，比如说被嵌入了病毒等等。</p>\n<p>还有一个常见的例子，网站数据库在存储密码的时候，也会用一些哈希函数将明文密码映射之后再存储到网站的后台中。这样在用户登录的时候，只要输入的密码经过同样的哈希算法计算后与网站后台密码比对一致，就可以完成校验，成功登录（当然为了防止抓包，在信息传输的过程中往往还会进行一重加密）。这样一来，哪怕网站的数据库被攻破了，也不至于将明文密码暴露在黑客面前。</p>\n<p>不过我们之前也提到过，哈希算法总归是存在碰撞的，在了解了这些算法原理之后，其实我们已经可以找到碰撞的规律，利用碰撞也能在修改文件的时候，保证文件的哈希值不变，这是所有哈希算法都可能存在的漏洞。同时，一些古老的哈希算法，例如MD4、MD5、SHA-1也已经实质性地被攻破了（例如可以直接生成某种算法的碰撞），甚至还有人通过暴力穷举记录一些数据的哈希值，并提供些非法的查询服务（cmd5）。</p>\n<p>与此同时。我们也看到，哈希算法也在不断地发展，编码越来越长，算法越来越复杂，这样碰撞的概率就越来越低，从而模拟碰撞和暴力穷举的成本越来越大。比如说，有一些签名算法（比如说，举个例子吧）会同时利用不同的哈希算法计算数据的哈希值，将每一个哈希值取一部分拼接起来形成混合编码，或者在原始数据的前后拼接一些额外的数据再进行哈希。</p>\n<p><img src="https://static001.geekbang.org/resource/image/8e/c8/8ee4609195017cf9dbe801fyy28891c8.jpeg" alt="" /></p>\n<h3>病毒扫描</h3>\n<p>哈希算法的另一个常用领域就是病毒扫描中的特征码扫描技术。</p>\n<p>我们知道，每一个杀毒软件都会有一个病毒库，它在每一次扫描的时候实际上都是在扫描文件是否能够命中病毒库。但是我们也知道，杀毒软件的病毒库中不可能存有真正的计算机病毒，而且在文件比对的时候，我们也不可能真实地比对每一个文件中的所有数据，去判定这个数据是不是病毒。</p>\n<p>所以，杀毒软件的病毒库中存储的也是病毒的特征值，本质上就是安全专家们对病毒的行为分析之后，定位到了某种病毒或某一类病毒（包括某一病毒的变种、变形）的关键部分，使用某一种哈希算法$hv$计算出这一部分的特征值再存到病毒库之中。因此，我们如果打开病毒库的文件，就会看到里面有很多看起来长得很像MD5的东西。而扫描的过程，实际上是在做这样3件事儿：</p>\n<ol>\n<li>假设特征码对应的原始数据长度是$w$字节，那我们就对待扫描的文件，每个长度为$w$字节窗口取一段</li>\n<li>利用计算特征码同样的哈希算法$hv$，计算取出的$w$字节长度的特征值</li>\n<li>将计算出来的特征值与病毒库中的特征值比较，如果命中则为感染，未命中则为安全</li>\n</ol>\n<p>这种方法的实现是早期人们对病毒的一种人为的判断：某一种病毒或者某一类病毒，它们都会含有相同的代码。所以从病毒的数据中分析出来这样一个关键部分，把它存储为特征值，再对计算机中的每个文件逐节判断，杀毒软件就可以判断出计算机是否感染了某一种已知的病毒。</p>\n<p>特征码扫描技术虽然很方便，但也具有极大的局限性。首先，它依赖于人类对于病毒的分析与信息摘要。实际上，从一个比较长的病毒中取部分字节计算特征码，本身可能是不精确的，会造成一定的误杀、误报；其次，某些病毒中可能带有反追踪技术，比如作者在病毒中增加了一些干扰性的代码片段，或者一些很容易影响到哈希算法的随机填充、变形方法等。所以在实际上的反病毒技术中，除特征码之外，也有虚拟机技术、规则探测、灾难恢复等一系列的技术。</p>\n<h2>课程小结</h2>\n<p>这节课，我们先学习了哈希算法的基本原理。哈希算法就是利用被映射数据的重要信息来计算最终的映射值。这能让哈希表将原本取值范围很大的复杂数据映射成唯一的“身份标识”，方便我们检索、比对、存储等等。</p>\n<p>接着，我们讲了经典的MD4哈希算法，它开创了现在我们常用的哈希算法的基本框架，所以你一定要好好理解。</p>\n<p>最后，我们讲了哈希算法的两种重要的应用。从中我们也看到，哈希算法由于充分利用了原始数据中的重要信息，又具有易检索、不易碰撞，不易分析，无法逆向等特点，在众多领域中都起着非常重要的作用。</p>\n<p>不过，除了前面提到的两个安全性方面的应用之外，哈希算法还在很多其他领域占据着非常重要的位置。比如，在分布式系统中，我们就利用一致性哈希算法作为服务器运维的基础部分，再比如，Google开发的SimHash算法，就是利用哈希值快速计算了文本的相似程度，甚至GeoHash算法会把某一地理区域映射成为哈希值，让复杂的地图数据便于缓存。</p>\n<p>好啦，关于哈希表的基础知识，你都理解了吗？可以在留言区写下你的疑惑，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "18 | 哈希表：文件的身份认证系统是如何实现的？",
      },
      {
        title: "19 | 深度优先搜索：理解搜索状态树，快速输出序列的排列组合",
        herf: "https://time.geekbang.org/column/article/291803",
        id: "291803",
        content:
          '<p>你好，我是胡光。从这节课开始，我们学习搜索算法。</p>\n<p>在岳云鹏的相声段子中，有这么一个段子，说孙越的爸爸带他参观家里面的聚宝盆，走到了一个密室门前，密室的门上上了一把锁，孙越的爸爸身上带了一万多把钥匙，他还忘了哪一把钥匙能打开个门了，于是就一把把试，试到了最后一把，门开了。</p>\n<p>这个段子中，孙越的爸爸找钥匙开门的过程就是一个搜索过程。简而言之，搜索就是尝试问题中所有的可能性，在所有的可能性中找到正确的结果。那搜索算法就是帮助我们快速找到正确结果的手段。</p>\n<p>今天，我就从求解序列的全排序和组合这两个问题入手，带你学习初步理解搜索算法中的常见概念，再一起去解决一个经典的题目，八皇后问题。</p>\n<h2>序列的全排列</h2>\n<p><span class="orange">我们先来看第一个问题：现在有一个长度为N的序列，序列中不含有重复元素，我们要输出这个序列的所有排列，该怎么做？</span></p>\n<p>假设，这个序列是 <code>[1, 2, 3]</code> ，则它的所有排列就是：</p>\n<pre><code>1, 2, 3\n1, 3, 2\n2, 1, 3\n2, 3, 1\n3, 1, 2\n3, 2, 1\n</code></pre>\n<p>这些排列是怎么得到的呢？以序列 <code>[1, 2, 3]</code> 为例，我们准备3个空位，那排列的过程就是我们将这3个数填到3个空位中的过程。首先，我们在第一个空位填1，在第二个空位填2，在第三个空位填3，序列里面所有的数用完了，所有的空也都填上了，我们就得到了第一种排列123。</p>\n<p><img src="https://static001.geekbang.org/resource/image/9e/21/9ef05dfd569a17f16c10546yyf564d21.jpeg" alt="" /></p>\n<p>接着，我们去寻找下一个排列。我们想到，是不是可以从最后一个数开始替换。首先，当把3从第三个空里面拿出来的时候，我们发现没有其他的数字可以填上，所以我们只能把2再从第二个空里面取出来，重新填充。这个时候，我们在第二个空中填一个3，在第三个空里面填剩下的2，就得到了第二个排列132。</p>\n<p><img src="https://static001.geekbang.org/resource/image/91/c1/9156eb7da3a54f4213fff148df6b33c1.jpeg" alt="" /></p>\n<p>我们接着之前的流程向下走，再将3和2分别从空里面取出，这个时候我们又发现，第二个空和第三个空没有其他的数可以填了，那我们只能把1从第一个空里面取出，将2填到第一个空里面……。</p>\n<p>总之，我们不断地重复这个尝试过程，将每一个数填进每一个空里面尝试，直到所有的数都填过所有的空为止。这样，我们也就找到了序列的所有排列。</p>\n<p><img src="https://static001.geekbang.org/resource/image/77/6d/77220c6bdc6893927f44eb5297b5106d.jpeg" alt="" /></p>\n<p>我把全排列的整个过程画了下来，如上图所示。仔细观察，你会看到一种熟悉的数据结构——树。这是怎么看出来的呢？我们将求解过程中的某一个时刻中，三个空的状态表示成为了树上的节点，由一种状态变成另一种状态的转移表示成树上的边。这样的一棵树就叫做这个问题的<strong>状态树</strong>，树上的节点称作<strong>状态</strong>，树上的边称作<strong>状态转移</strong>，<strong>状态</strong>和<strong>状态转移</strong>是设计搜索算法的关键。</p>\n<p>因此，我们在求解全排列问题的过程中，相当于是从树上的根节点出发，不断地向下走，走到叶节点为止，这样求出来了第一个解。求出解，再取出数重新填的过程相当于是回溯到上位节点重新向下走。也就是说，这个搜索过程会不断地走到树的深处，所以这个方法叫做<strong>深度优先搜索</strong>。</p>\n<p>通过状态树我们也看到，深度优先搜索过程的每一步都在继承上一步的状态，而继续向下搜索，如果走到尽头又会回溯到之前的状态，所以深度优先搜索要用到<strong>栈</strong>或<strong>递归</strong>来实现：</p>\n<pre><code>//全排列递归实现\nvoid dfs(int depth, int n) {\n    if (depth &gt;= n) {\n        for (int i = 0; i &lt; 3; i += 1) {\n            cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;;\n        }\n        cout &lt;&lt; endl;\n      return;\n    }\n    for (int i = 1; i &lt;= n; i += 1) {\n        if (used[i] == false) {\n            used[i] = true;\n            a[depth] = i;\n            dfs(depth + 1, n);\n            used[i] = false;\n        } \n    }\n}\n</code></pre>\n<p>上面的代码就是对N个数进行全排列问题的解决方法，我们只要对这个过程稍作修改，就可以快速求出$A_n^m$。这个问题非常简单留给你解决，这里我就不再多说啦。</p>\n<h2>求解组合问题</h2>\n<p><span class="orange">解决了排列数之后，我们继续来看，如果现在要求的不是输出排列数$A_n^m$，而是要求输出组合数$C_n^m$（从 n 个物品中选出 m 个物品的方案数）呢？</span></p>\n<p>以$C_5^3$为例，我们仍旧把求解的过程看作是将5个数填进3个空里的过程。在第一个空里面填1，在第二个空里面填2，剩下一个空里面则分别可以填3，4，5。在输出过 <code>[1, 2, 5]</code> 这个序列之后，我们也就处理完了 <code>[1, 2, *]</code> 状态下所有的情况，所以我们需要回溯到 <code>[1, *, *]</code> 状态中继续向下搜索。</p>\n<p>这个时候，我们就需要在第二个空里面填上3，当前状态变成了 <code>[1, 3, *]</code>  。但是你要注意，这个时候，2已经不能填到第三个空里面了，因为 <code>[1, 3, 2]</code> 这三个数的组合已经出现过了，所以，第三个空里面只有4和5可以填。</p>\n<p>同样，当我们进行到 <code>[1, 4, *]</code> 状态的时候，2和3已经不能填到第三个空里面了，第三个空只有5可以填。</p>\n<p>当我们回溯到序列全空的时候，在第一个空里面填上一个2，处于 <code>[2, *, *]</code> 的状态中，第二个空如果填1也是不对的，因为 <code>[2, 1, *]</code> 状态下，无论最后一个空填什么，都会和 <code>[1, 2, *]</code> 之后出现的组合重复。</p>\n<p>发现规律了吗？每一个空填上的数必须要比前面的数大，否则就会和前面出现过的组合重复，那么也就是说，我们省去了很多不必要的搜索。</p>\n<p><img src="https://static001.geekbang.org/resource/image/9d/8f/9d7770dc240a8753b4310eb05d38028f.jpeg" alt="" /></p>\n<p>这就好像是我们在状态树上剪掉了很多不必要的树枝，只留下来了有效的部分，这个方法有一个形象的名字，就叫做<strong>剪枝</strong>。</p>\n<pre><code>void dfs(int depth, int n) {\n    if (depth &gt;= n) {\n        for (int i = 0; i &lt; 3; i += 1) {\n            cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;;\n        }\n        cout &lt;&lt; endl;\n        return;\n    }\n    int start = 1;\n    if (depth &gt; 0) start = a[depth - 1] + 1;\n    for (int i = start; i &lt; 6; i += 1) {\n        if (used[i] == false) {\n            used[i] = true;\n            a[depth] = i;\n            dfs(depth + 1, n);\n            used[i] = false;\n        } \n    }\n}\n</code></pre>\n<p>为什么要学习这个方法呢？我们知道，一般来说搜索方法会检查这个问题的所有可能性来确认最终的结果，但在实际应用中，问题的可能性总是非常多的，如果完全不进行剪枝，直接搜索会非常耗费时间。有了剪枝技术，就可以有效帮助我们去掉那些不可能的分支，大幅度地减少运算代价。</p>\n<blockquote>\n<p>例如$A_n^m$排列问题中，我们实际默认了一个数只能被填进一个空中，而不能重复使用，而全排列问题实际的可能性是每个数可以重复填在每个空中，那么这个问题的可能性则是$n^m$种，我们增加了可重复的条件之后，问题的可能性则变成了$\\frac{n!}{(n-m)!}$种。</p>\n</blockquote>\n<p>例如，密文破译就是一个典型的搜索问题。当我们面对一个被打乱字母加密过的英文消息的时候，就是在面对一个可能性极其庞大的搜索问题。如果一个长度为L的英文消息，它的可能性就有$26^L$种，哪怕只是破解出原文和密文之间字母的对应关系，面对的可能性都是$26!=403291461126605635584000000$种，这是非常的庞大。</p>\n<p>但是根据统计我们知道，英文中，字母e出现的最频繁，q和u经常连在一起出现等等。借助这些规律，在破解这段密文的搜索过程中，我们就可以剪掉大量的分支，让这个工作变得相对简单一些。</p>\n<p>同样，自然语言处理中的中文分词问题、词性标注问题、翻译问题等等，都是典型的搜索问题，它们也都是通过统计方法，帮助我们找到某一个状态下最有可能的状态转移，从而大幅节省计算的时间。</p>\n<h2>搜索实战：八皇后问题</h2>\n<p><span class="orange">接下来，我们来看一个经典的问题：八皇后问题。我们要在一个$8\\times 8$的棋盘上放置8个皇后，其中，如果两个皇后处于同一行、同一列、同一对角线，就可以攻击对方。要求：放置8个皇后之后，它们互相不会攻击到对方。</span></p>\n<p>首先，我们来看问题的状态和状态转移分别是什么。这个问题的状态很简单，就是棋盘上当前哪个位置已经被摆了皇后，而状态转移是什么呢？</p>\n<p>我们很容易想到，棋盘上每一个格子都可以当作一个状态转移。以这种视角来看，棋盘上有64个格子，要从里面选出来8个格子放皇后，会有$C_{64}^8=4426165368$种可能性，这是非常大的一个数，不用说，做起来也比较困难。但我们看到题目中还有一个条件，皇后之间互相不能处在同一行、同一列、同一对角线。</p>\n<p>也就是说，我们每一次放新皇后的时候，完全不用考虑转移到当前这个状态时皇后所在的那一行，直接考虑下一个皇后应该放在下一行的哪个位置就可以了。那这个问题的状态可以是，当前 <code>i</code> 行已经合理地摆上了皇后之后，状态转移可以是在第 <code>i+1</code> 行的哪个位置摆上皇后。</p>\n<p><img src="https://static001.geekbang.org/resource/image/16/eb/16eb6052084d08d3fb144577d5bee0eb.jpeg" alt="" /></p>\n<p>接着，不能放在同一列这个条件就非常好满足了，我们只需要记录哪一列已经被放上皇后就可以了。但是，不能放在同一对角线，这个条件满足起来有点复杂，我们来看一看该怎么来解决。首先，我们在这个$8\\times 8$的棋盘中，随意找到两条对角线。</p>\n<p><img src="https://static001.geekbang.org/resource/image/d1/17/d1e7f9d57dd36755cdb3c2d87cf9e317.jpeg" alt="" /></p>\n<p>我们先看红色对角线，它经过的格子分别是 <code>[1, 3]</code> 、 <code>[2, 2]</code> 、 <code>[3, 1]</code>  。我们看到，这个对角线经过的所有格子的横纵坐标相加是相等的，在这个方向上再画一条对角线也会有这样的规律。我们再看图中蓝色的对角线，它依次经过了 <code>[4, 1]</code> 、 <code>[5, 2]</code> 、 <code>[6, 3]</code> 、 <code>[7, 4]</code> 、 <code>[8, 5]</code>  。我们发现，这条线上每个格子的横纵坐标之差是相等的。</p>\n<p>好，这样我们就有了记录某一条对角线是否被放过皇后的方法了，当然，也就利用了题目中给出的所有条件进行剪枝。接下来，我们只需要一行行尝试着放皇后，就可以搜索出所有的放置方法了。</p>\n<pre><code>void dfs(int depth) {\n    if (depth &gt;= 8) {\n        for (int i = 0; i &lt; 8; i++) {\n            for (int j = 0; j &lt; 8; j++) {\n                if (j == row[i]) cout &lt;&lt; &quot;* &quot;;\n                else cout &lt;&lt; &quot;O &quot;;\n            }\n            cout &lt;&lt; endl;\n        }\n        cout &lt;&lt; endl;\n        return;\n    }\n    for (int i = 0; i &lt; 8; i++) {\n        if (!col[i] &amp;&amp; !left_diag[depth + i] &amp;&amp; !right_diag[depth - i + 7]) {\n            col[i] = left_diag[depth + i] = right_diag[depth - i + 7] = true;\n            row[depth] = i;\n            dfs(depth + 1);\n            row[depth] = -1;\n            col[i] = left_diag[depth + i] = right_diag[depth - i + 7] = false;\n        }\n    }\n}\n</code></pre>\n<h2>课堂小结</h2>\n<p>这节课，我们学习了深度优先搜索算法和一些简单的剪枝应用。</p>\n<p>状态和状态转移是设计搜索算法的关键。在求解实际问题的时候，所有的答案会形成一棵树，状态是树上的每个节点，从一种状态变成另一种状态的转移就是树上的边。</p>\n<p>深度优先搜索过程的每一步都在继承上一步的状态，继续向下搜索，如果走到尽头，又会回溯到之前的状态，所以深度优先搜索要用到栈或递归来实现。</p>\n<p>在使用深度优先搜索的时候，为了大幅减少运算代价，我们会借助一些规律和已知条件，剪掉状态树上很多不必要的树枝，只留下来了有效的部分，这就是剪枝。</p>\n<p>深度优先搜索是一种盲目搜索算法，它尝试每一种可能性来解决问题的方法看上去虽然笨拙，却也是搜索算法家族的重要基础算法，有着很广泛的应用，例如在机器学习的图嵌入方法中，有时就是利用深度优先搜索方法建立节点的特征空间。</p>\n<p>同时，深度优先搜索也是一种非常有效的算法思维，往往当我们在解决一些问题的时候，从深度优先搜索入手，再在其基础上增加各种优化手段，如记忆化搜索、贪心等，往往也能利用搜索方法高效地解决问题。</p>\n<h2>课后练习</h2>\n<p>现在，我给你一个有向图$G(V, E)$，你能试着利用深度优先搜索算法求出图中是否存在环路吗？</p>\n<p>这就是深度学优先搜索的基础内容了，你学会了吗？欢迎你把这节课转发出去。下节课，我会带你学习另外一个重要的基础算法，广度优先搜索，并用它来解决迷宫问题。好了，今天就到这里了，我是胡光，我们下节课见。</p>\n',
        article_title:
          "19 | 深度优先搜索：理解搜索状态树，快速输出序列的排列组合",
      },
      {
        title: "20 | 广度优先搜索：如何快速解决迷宫问题？",
        herf: "https://time.geekbang.org/column/article/292638",
        id: "292638",
        content:
          '<p>你好，我是胡光。</p>\n<p>上节课，我们一起学习了深度优先搜索和状态树，以及一些简单的剪枝技巧。这节课，我们继续学习搜索算法，解决另外一种常见的问题：迷宫问题。</p>\n<p><span class="orange">迷宫问题是这样的，现在有一个$N\\times M$大小的迷宫，我们可以从迷宫的某一个格子出发，向上、下、左、右四个方向走。但是，迷宫中存在一些障碍格子，我们不能走上去。比如下图中，白色的格子代表可以走，黑色的格子代表障碍不能走。假设迷宫的起点是左上角，终点是右下角，那我们从起点走到终点，最短的路径是多长，又是哪一条呢？</span></p>\n<p><img src="https://static001.geekbang.org/resource/image/74/9f/747eabfec4eb0d0edee27d3478beee9f.jpeg" alt="" /></p>\n<p>针对这个问题，我们可以使用上节课学过的深度优先搜索去解决吗？</p>\n<p>我们尝试之后发现，使用深度优先搜索的时候，就像我们独自身处在这个迷宫中，从起点出发之后，碰到了岔路就一条一条去尝试。如果走到了死路，就原路返回，接着尝试下一条路，再碰到了岔路还是用同样的方法继续尝试。而当我们终于走到终点的时候，走的却又未必是最短的那一条路。如果想要确认走的是不是最短的那一条，我们只能回到前面，继续尝试，直到走完所有的路才能确认。</p>\n<p>这样做显然非常浪费时间，于是我们就开始设想，我们在迷宫中遇到岔路的时候，能不能像漩涡鸣人一样，用一次分身术生出许多分身，让它们同时走所有的路径。当某一个分身再遇到岔路的时候，就再使用一次分身术，让这些分身继续走新的岔路，并且让走到死路上的分身直接解除掉。最后，所有走到终点的分身来报告走的路径长度，这样我们就能找到最短的那个路径了。</p>\n<p>当然了，这个想法在现实中是没有办法实现的，但在搜索算法中却可以做到，这就是我们今天要讲的搜索方法，广度优先搜索。</p>\n<h2>广度优先搜索：搜索中的“影分身术”</h2>\n<p>还是以刚才的迷宫为例，首先我们从起点 <code>[0, 0]</code> 出发。不巧，起点就是一个岔路，它的右边和下边都可以走，那我们只能派出两个分身分别走到 <code>[0, 1]</code> 和 <code>[1, 0]</code> ，为了方便，我们先分别称它们为分身1号和分身2号。</p>\n<p><img src="https://static001.geekbang.org/resource/image/1d/b8/1daff021e023e83d52404a40bbe5dab8.jpeg" alt="" /></p>\n<p>然后我们先看分身1号，它的前面没有岔路了，所以只能往右边再走一步。同时，分身2号面前也没有岔路，只能向下再走一步。</p>\n<p><img src="https://static001.geekbang.org/resource/image/68/yy/688bca3df82a43acd78973c44caa6fyy.jpeg" alt="" /></p>\n<p>这之后，我们再去看分身1号，发现分身1号面对一个岔路。这个时候，它只能再使用一次分身术，分别代替它往下和往右走……就这样，直到所有的分身都走到终点。</p>\n<p>这里你要注意了，我们刚才描述的过程虽然是同时进行的，但在程序实现中我们做不到同时，它们总会有一个先后关系。比如说，当分身1号向右边走了一步之后，我们就需要知道分身2号走到哪儿了，然后才能让分身2号继续走下一步。同样，在分身2号走完了之后，我们还要回去更新分身1号，知道分身1号走到哪儿了，再去更新分身1号的状态。也就是说，我们每一次的搜索，所有的分身都得向前走一步。</p>\n<p>如果是这样的话，我们就得能够依次取出所有分身的位置才能更新。</p>\n<p>想要实现这个功能，我们就必须使用一个<strong>先进先出</strong>的数据结构来维护每个节点上的状态，所以我们需要借助<strong>队列</strong>来实现这一算法。接下来，我们就来正式描述一下解决迷宫问题的算法是什么样的。</p>\n<p>首先，我们在每个格子上记录的是，<strong>目前从起点到当前格子的最短路径长度</strong>。那我们每次到达这个节点的时候，如果走过的路径比它现在记录的值短就更新它。同时，我们还要记录，从哪个格子到的当前格子，才能得到这个最小值。因为到达每个格子的最短路径一定是由上一个格子的最短路径而来，那依次回溯回去，我们就能找到这条最短路径了。</p>\n<p>那么问题来了，我们该怎么结合队列来实现呢？</p>\n<p>最开始，我们当然是把起点的路径长度置为0，再把起点放到队列中，然后开始搜索过程。</p>\n<p>在每一次搜索更新过程中，我们都会先取出队首，分别检查它的上、下、左、右四个格子。检查分两步，一是查看它们是不是障碍，如果不是障碍，再看它们有没有被走过，如果没被走过，再更新格子上的值和前驱格子，入队列。如果被走过了，我们就看由当前格子出发到这个格子是不是最短的路，如果是最短的路，就跟新格子上的值和前驱格子入队列，反之就不管它。</p>\n<p>我们一直重复这个过程，直到这个队列为空。最后，我们再从终点出发一步步地向回找，就能找出这条最短的路径了。</p>\n<p>在我们刚才进行的搜索过程中，检查从当前格子出发到下一个格子是否构成最短路径，并且更新的操作，叫做<strong>松弛操作</strong>。正因为这个操作的存在，我们搜索的过程中才不会走回头路，也就不会出现在两个格子上反复横跳这种事情了。代码如下：</p>\n<pre><code>void bfs(int n, int m) {\n    int pos_x, pos_y;\n    queue&lt;pair&lt;int, int&gt; &gt; que;\n\n    // 起点入队\n    que.push(pair&lt;int, int&gt;(0, 0));\n    dis[0][0] = 0;\n\n    while (!que.empty()) {\n        pair&lt;int, int&gt; cur_pos = que.front();\n        que.pop();\n        pos_x = cur_pos.first;\n        pos_y = cur_pos.second;\n\n        // 判断向下走一步\n        if (pos_x &lt; n - 1 &amp;&amp; a[pos_x + 1][pos_y] != -1) {\n            if (dis[pos_x + 1][pos_y] == -1 || (dis[pos_x][pos_y] + 1 &lt; dis[pos_x + 1][pos_y])) {\n                dis[pos_x + 1][pos_y] = dis[pos_x][pos_y] + 1;\n                father[pos_x + 1][pos_y] = cur_pos;\n                que.push(pair&lt;int, int&gt;(pos_x + 1, pos_y));\n            }\n        }\n\n        // 判断向上走一步\n        if (pos_x &gt; 0 &amp;&amp; a[pos_x - 1][pos_y] != -1) {\n            if (dis[pos_x - 1][pos_y] == -1 || (dis[pos_x][pos_y] + 1 &lt; dis[pos_x - 1][pos_y])) {\n                dis[pos_x - 1][pos_y] = dis[pos_x][pos_y] + 1;\n                father[pos_x - 1][pos_y] = cur_pos;\n                que.push(pair&lt;int, int&gt;(pos_x - 1, pos_y));\n            }\n        }\n\n        // 判断向右走一步\n        if (pos_y &lt; m - 1 &amp;&amp; a[pos_x][pos_y + 1] != -1) {\n            if (dis[pos_x][pos_y + 1] == -1 || (dis[pos_x][pos_y] + 1 &lt; dis[pos_x][pos_y + 1])) {\n                dis[pos_x][pos_y + 1] = dis[pos_x][pos_y] + 1;\n                father[pos_x][pos_y + 1] = cur_pos;\n                que.push(pair&lt;int, int&gt;(pos_x, pos_y + 1));\n            }\n        }\n\n        // 判断向左走一步\n        if (pos_y &gt; 0 &amp;&amp; a[pos_x][pos_y - 1] != -1) {\n            if (dis[pos_x][pos_y - 1] == -1 || (dis[pos_x][pos_y] + 1 &lt; dis[pos_x][pos_y - 1])) {\n                dis[pos_x][pos_y - 1] = dis[pos_x][pos_y] + 1;\n                father[pos_x][pos_y - 1] = cur_pos;\n                que.push(pair&lt;int, int&gt;(pos_x, pos_y - 1));\n            }\n        }\n    }\n}\n</code></pre>\n<p>如果我们要输出这条最短的路径，一步步找回去就好了。代码如下：</p>\n<pre><code>void dfs_output(int x, int y) {\n    if (x == 0 &amp;&amp; y == 0) {\n        printf(&quot;(%d, %d)\\n&quot;, x, y);\n        return;\n    }\n    dfs_output(father[x][y].first, father[x][y].second);\n    printf(&quot;(%d, %d)\\n&quot;, x, y);\n}\n</code></pre>\n<p>由于在这个过程中，我们每进行一次操作，都会关注当前状态的所有可能的下一个状态，非常注重广度，所以这个算法就叫做广度优先搜索，也叫做宽度优先搜索，简称就是广搜、宽搜。</p>\n<p>总的来说，虽然我们不断地派出分身去走每一条岔路，可实际上整个广搜的过程，我们还是走了迷宫中所有可能的节点，所以广度优先搜索的时间复杂度是$O(N\\times M)$的，也是一种盲目搜索算法。</p>\n<p>广度优先搜索图结构相关算法中占有非常重要的地位，很多相关算法其实都是广度优先搜索思想的延续，例如在图结构上求解单源最短路的Dijkstra算法、SPFA算法，都是利用广度优先思想进行的。那广度优先思想到底是怎么应用在这些算法中的呢？</p>\n<h2>Dijkstra算法：城市路程问题</h2>\n<p>接下来，我就以实际的城市路程问题为例，来和你详细讲讲Dijkstra算法的思路。</p>\n<p>假设，现在有N个城市，各个城市相互之间修了一条路，这些路的长度都不相等。如果张三想要从A城市开车出发到达B城市，请问：他怎么走，距离才最短？</p>\n<p><img src="https://static001.geekbang.org/resource/image/92/99/924byya0198e6bf0c2160616a0576d99.jpeg" alt="" /></p>\n<p>我们依据广度优先搜索的思想，先从A出发，而从A出发能直接到达的节点是C和F，那在当前阶段，从A出发到C和F的最短距离就得到了。提前说下，在这个过程中，我会用绿色表示当前在处理的节点，黄色表示待处理的节点，红色表示已经处理过的节点。</p>\n<p><img src="https://static001.geekbang.org/resource/image/f4/53/f45e79e3ccd58e01ff4071b0ce803b53.jpeg" alt="" /></p>\n<p>然后，按照正常广搜的思路，我们要依次从C城市和F城市出发，再去摸索接下来能到达什么城市，对吧？但到了这里，我们的做法就有变化了，我们会从已经知道的城市中，找到距离A城市最近的那个城市，从它出发去向下找。</p>\n<p>为什么要这么做呢？仔细想想就知道了，因为我们要求的是最短路程，那从目前路程最短的城市出发去摸索新的路径，就是一个非常直观的优化想法了。其实，我们还可以从另一个角度来证明这个做法是正确的。那就是从A城市出发，到达某一个城市的最短路程，例如B城市，<strong>一定是从A城市到其相邻的城市，也就是E城市和I城市的最短路径获得的</strong>。</p>\n<p>我们可以看到，下图中A城市到C城市的路程是最短的，那我们就从C城市出发，更新它相邻的城市的路程。我们发现，D城市我们没有访问过，所以我们可以更新A城市到它的路程，而F节点我们已经访问过了，并且发现如果从C城市到F城市的话，距离反倒是更远了，那我们就不去更新它。</p>\n<p><img src="https://static001.geekbang.org/resource/image/58/d4/58c030134247af6c11fe8c809c731dd4.jpeg" alt="" /></p>\n<p>当C城市处理完了之后，我们再从A城市出发，这个时候路程最短的城市就变成了F城市，那我们继续从F城市出发，看看会发生什么。就这样，我们依次到达H和I城市。</p>\n<p><img src="https://static001.geekbang.org/resource/image/87/b4/8757cc9aaa9931fyyba0b492bc65c9b4.jpeg" alt="" /></p>\n<p>接下来，我们再来看D城市。这个时候，我们发现，从D城市出发，相邻的两个城市都被访问过了。但是呢，从D城市出发，到G城市的路程，比之前计算出来的A城市到G城市的路程要小，那我们就利用松弛操作，更新G城市的路程。而且，我们也发现，从D城市出发到E城市的距离也比之前的路程要短，所以我们同样利用松弛操作，来更新E城市的路程。</p>\n<p><img src="https://static001.geekbang.org/resource/image/0c/2f/0c72eace44609992eb616745cd22752f.jpeg" alt="" /></p>\n<p>我们就继续这样的操作，最终走到B节点。这样，我们就可以求出，从A节点到B节点的最短路程是21。</p>\n<p>好了，我刚才讲的就是Dijkstra算法的基本思想，它利用了广度优先搜索当做基础，但在每次更新的时候，都有一个关键的筛选条件，就是找到当前已经更新的节点中路程最短的那个节点。Dijkstra算法使用了这样的技巧避免了多次搜索，提升了效率。</p>\n<p>关于这个最短路程的节点，你还能想到什么手段来进一步加速这个查找过程呢？没错，就是<strong>堆</strong>。也就是说，Dijkstra算法是有专门的堆优化技巧，从而很快得到所有节点的单源最短路径。这里，你可以尝试结合堆来解决一下，我就不展开说了。</p>\n<h2>课程小结</h2>\n<p>这节课，我们又学习了一种非常重要的基础搜索算法，广度优先搜索算法。并且利用广度优先搜索解决了迷宫问题。广度优先搜索算法利用“分身术”，不断地派出分身走遍迷宫中所有可能的节点，并且，每一次更新都会关注当前状态的所有可能的下一个状态，从中选出最短的路径。因此，广度优先搜索的时间复杂度是$O(N\\times M)$的，是一种盲目搜索算法。</p>\n<p>不过，在使用广搜算法的实际应用中，我们可以通过增加一些筛选条件，来提升它的效率，这让它的应用非常广泛。比如我们最后讲到的Dijkstra算法，就是一种重要的寻路算法，在很多图结构的应用中都会用到它。</p>\n<p>同时广搜算法也广泛应用于游戏之中，比如，基于启发式搜索的寻路算法，它和Dijkstra一样，都是在每次更新的次序上做文章。另外，在人工智能领域相关应用中，搜索也是重要的解码算法。</p>\n<p>因此，在接下来的课程中，我们会继续学习搜索算法的优化技巧，遇到的题目也都非常有趣，你可以期待一下！</p>\n<h2>课后练习</h2>\n<p>解决了初级版的迷宫问题之后，我们再来解决进阶的迷宫问题，现在有一个非常大的迷宫，长宽量级$10^5$那么大，迷宫里面还是有一些不能走的障碍，但是这些障碍的数量要远小于迷宫中的格子数。请问，如果我们从起点出发，能不能走到终点。</p>\n<p>欢迎在留言区分享你的答案，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "20 | 广度优先搜索：如何快速解决迷宫问题？",
      },
    ],
  },
  {
    chapterTitle: "国庆策划 (4讲)",
    children: [
      {
        title: "期中测试 | 一套习题，测出你的掌握程度",
        herf: "https://time.geekbang.org/column/article/293261",
        id: "293261",
        content:
          "<p>你好，我是胡光。今天，我们来进行一场期中考试，共有3道选择题和2道主观题，希望你能好好思考，下节课我来公布答案。</p><h2>选择题</h2><p>1.下面这些对于堆的描述中，错误的选项是（）</p><p>A. 由于堆可以存储在一个数组中，所以堆属于一种线性结构</p><p>B. 堆分为大顶堆与小顶堆，大顶堆的堆顶是最大值</p><p>C. 在一个数组上，建立一个堆的时间复杂度不可能低于 O(nlogn)</p><p>D. 对顶堆主要可以解决动态查找中位数的问题</p><p>2.关于快速排序优化中的“基准值选取优”的说法，错误的是（）</p><p>A. 三点取中法的优化，是概率性优化，程序是否展现出优化效果，要看具体的数据分布</p><p>B. 三点取中法的优化，可以保证在所有数据上，都能展现出优化以后的好效果</p><p>C. 基准值选取优化，根本目的是为了让程序实现更简单</p><p>D. 基准值选取优化，根本目的是为了稳定住快速排序的时间复杂度，使其在最差的情况下，也能表现良好</p><p>3.关于归并排序的说法中，错误的是（）</p><p>A. 归并排序和快速排序一样，最坏时间复杂度是 $O(n^2)$，最好是 $O(nlogn)$</p><p>B. 归并排序最好、最坏、平均时间复杂度都是 $O(nlogn)$</p><!-- [[[read_end]]] --><p>C. 归并排序和快速排序一样，都属于稳定排序，相同值排序以后，相对位置保持不变</p><p>D. 归并排序和快速排序不一样，快速排序属于稳定排序，归并排序属于非稳定排序</p><h2>主观题</h2><ol>\n<li>请阐述 Top-k 的解法。按照你的理解，分情况讨论。</li>\n<li>请说出 4 种生活中需要排序的具体场景。</li>\n</ol>",
        article_title: "期中测试 | 一套习题，测出你的掌握程度",
      },
      {
        title: "期中测试题答案 | 这些问题，你都答对了吗？",
        herf: "https://time.geekbang.org/column/article/293364",
        id: "293364",
        content:
          '<p>你好，我是胡光。今天，我来公布一下选择题和主观题的答案。</p>\n<h2>选择题</h2>\n<p><strong>1.下面这些对于堆的描述中，错误的选项是（）</strong></p>\n<p>A. 由于堆可以存储在一个数组中，所以堆属于一种线性结构</p>\n<p>B. 堆分为大顶堆与小顶堆，大顶堆的堆顶是最大值</p>\n<p>C. 在一个数组上，建立一个堆的时间复杂度不可能低于 O(nlogn)</p>\n<p>D. 对顶堆主要可以解决动态查找中位数的问题</p>\n<p><span class="orange">解析：A/C</span></p>\n<p>A 中，堆属于树形结构，一个数据结构属于什么结构，看的是思维逻辑结构中的样子，而不是代码实现中的样子。</p>\n<p>C 中，线性建堆法的时间复杂度为 O(n)</p>\n<hr />\n<p><strong>2.关于快速排序优化中的“基准值选取优”的说法，错误的是（）</strong></p>\n<p>A. 三点取中法的优化，是概率性优化，程序是否展现出优化效果，要看具体的数据分布</p>\n<p>B. 三点取中法的优化，可以保证在所有数据上，都能展现出优化以后的好效果</p>\n<p>C. 基准值选取优化，根本目的是为了让程序实现更简单</p>\n<p>D. 基准值选取优化，根本目的是为了稳定住快速排序的时间复杂度，使其在最差的情况下，也能表现良好</p>\n<p><span class="orange">解析：B/C</span></p>\n<p>A、B 是一组，A 中的说法是对的，三点取中法是否展现出优化效果，要看具体的数据分布。</p>\n<p>C、D 是一组，D 中的说法是对的，根本目的是为了稳定住快速排序的时间复杂度，可以从快速排序的时间复杂度推导入手理解。</p>\n<hr />\n<p><strong>3.关于归并排序的说法中，错误的是（）</strong></p>\n<p>A. 归并排序和快速排序一样，最坏时间复杂度是 $O(n^2)$，最好是 $O(nlogn)$</p>\n<p>B. 归并排序最好、最坏、平均时间复杂度都是 $O(nlogn)$</p>\n<p>C. 归并排序和快速排序一样，都属于稳定排序，相同值排序以后，相对位置保持不变</p>\n<p>D. 归并排序和快速排序不一样，快速排序属于稳定排序，归并排序属于非稳定排序</p>\n<p><span class="orange">解析：A/C/D</span></p>\n<p>A、B 是一组，B 中说的是对的，归并排序最好、最坏、平均时间复杂度都是 $O(nlogn)$。</p>\n<p>C、D 看似是一组，可 C、D 中说得都是错的。快速排序是非稳定排序，归并排序是稳定排序。所谓稳定或者不稳定，是指排序以后，相同大小的元素的相对位置是否发生改变。</p>\n<hr />\n<h2>主观题</h2>\n<ol>\n<li>请阐述 Top-k 的解法。按照你的理解，分情况讨论。</li>\n</ol>\n<p><span class="orange">解析：以下是我想到的4类情况。</span></p>\n<ol>\n<li>数据是整型，数据范围很小，符合计数排序需要的数据特点时，采用计数排序进行统计。时间复杂度 O(n)。</li>\n<li>数据不符合计数排序特殊时，当数据量 n 很小，内存存得下的时候，可以考虑使用快速选择算法，解决 Top-K 问题。时间复杂度为 O(n)。</li>\n<li>数据不符合计数排序特殊时，当数据量 n 很大，内存存不下时，可 k 很小，内存存的下的时候，维护大小为 k 的小顶堆即可以解决问题。时间复杂度为 O(nlogk)。</li>\n<li>数据不符合计数排序特殊时，当数据量 n 很大，内存存不下，k 也很大的时候，可以考虑直接采用归并排序，从而得到 Top-k 数字。时间复杂度为 O(nlogn)。</li>\n</ol>\n<hr />\n<ol start="2">\n<li>请说出 4 种生活中需要排序的具体场景。</li>\n</ol>\n<p><span class="orange">解析：以下是我给出的4种示例情况</span></p>\n<ol>\n<li>照集体照的时候，老师都会按照身高对所有同学进行排序，最终目的是为了让照片效果更好。</li>\n<li>销售在客户跟进的时候，会根据意向程度对客户列表排序，目的是为了精力价值最大化。</li>\n<li>在工作的时候，我们按照工作的紧急重要程度对工作排序，目的是为了明确做事顺序。</li>\n<li>各省市经济发展状况公布时，会按照 GDP 排序，目的是更清楚地展现本年度全国经济发展状况。</li>\n</ol>\n<p>好了，这节课就到这里，我们下节课见。</p>\n',
        article_title: "期中测试题答案 | 这些问题，你都答对了吗？",
      },
      {
        title: "常见算法面试题，等你来挑战！",
        herf: "https://time.geekbang.org/column/article/293771",
        id: "293771",
        content:
          "<p>你好，我是胡光。</p>\n<p>我们学了那么多的算法知识，那在算法面试中到底是如何考察这些知识的呢？今天，我就给你出几道简单的算法面试题。它们都是简答题，在面试中出现的频率也比较高，我希望你能好好思考，下节课我来公布答案。</p>\n<hr />\n<ol>\n<li>请尽可能多的说出二叉排序树与快速排序算法之间的联系。</li>\n<li>请总结 AVL 树的失衡调整方式。</li>\n<li>简述红黑树的五条性质。</li>\n<li>请对比一下二叉排序树和哈希表。</li>\n<li>请你说出 4 种生活中需要查找的例子，并且分析需要的查找算法和数据结构。</li>\n</ol>\n<p>好了，这节课就到这里。希望你能抓住国庆假期最后几天的时间，查漏补缺，巩固所学。</p>\n",
        article_title: "常见算法面试题，等你来挑战！",
      },
      {
        title: "这些常见算法面试题，你会解了吗？",
        herf: "https://time.geekbang.org/column/article/294317",
        id: "294317",
        content:
          '<p>你好，我是胡光。前几天，我留了几道简单的算法面试题，你解决的怎么样了？今天我来公布一下答案。</p>\n<p><strong>1. 请尽可能多地说出二叉排序树与快速排序算法之间的联系。</strong></p>\n<p><span class="orange">参考答案：</span></p>\n<ol>\n<li>二叉排序树是快速排序算法的思维逻辑结构。</li>\n<li>快速排序每一轮选出的基准值，就是二叉排序树当前子树的根节点。</li>\n<li>快排中的 Partition（分区）操作后的左右两个集合，对应了二叉排序树中的左右两个子树。</li>\n<li>分析快速排序的时间复杂度，其实可以对应到建立一棵二叉排序树的时间复杂度。</li>\n<li>二叉排序树上查找第 k 大元素，与快速排序的拓展算法快速选择算法相对应。</li>\n</ol>\n<hr />\n<p><strong>2. 请总结出 AVL 树的失衡调整方式。</strong></p>\n<p><span class="orange">参考答案：</span></p>\n<ol>\n<li>LL 型失衡，左子树的左子树更高，直接大右旋即可。</li>\n<li>LR 型失衡，左子树的右子树更高，先抓着左子树进行小左旋，再大右旋。</li>\n<li>RL 型失衡，右子树的左子树更高，先抓着右子树进行小右旋，再大左旋。</li>\n<li>RR 型失衡，右子树的右子树更高，直接大左旋即可。</li>\n</ol>\n<hr />\n<p><strong>3. 简述红黑树的五条性质。</strong></p>\n<p><span class="orange">参考答案：</span></p>\n<p>1.节点非黑即红。<br />\n2. 根节点是黑色。<br />\n3. 叶子（NIL）节点是黑色。<br />\n4. 红色节点下面的两个孩子，一定是黑色节点。<br />\n5. 从根节点到所有叶子结点路径上，黑色节点数量相同。</p>\n<hr />\n<p><strong>4. 请对比一下二叉排序树和哈希表。</strong></p>\n<p><span class="orange">参考答案：</span></p>\n<ol>\n<li>本质上二者都是做数据的索引查找。</li>\n<li>二叉排序树维护了数据的有序性，哈希表则会破坏这种有序性。</li>\n<li>单纯的查找操作的话，哈希表要比二叉排序树更优秀一些，哈希表的时间复杂度是 $O(1)$ 的，二叉排序树是 $O(logn)$ 的。</li>\n<li>二叉排序树由于维持了数据的有序性，因此在一些需要数据之间这种有序的拓展查找问题上，二叉排序树比哈希表更具备优势。例如：查找第 $k$ 大元素。</li>\n<li>二叉树中的节点是依次添加进去的，所以在扩容方面显得更简单一些。哈希表的扩容操作，通常都比二叉排序树要麻烦一些。</li>\n</ol>\n<hr />\n<p><strong>5. 请你说出 4 种生活中需要查找的例子，并且分析需要的查找算法和数据结构。</strong></p>\n<p><span class="orange">参考答案：</span></p>\n<ol>\n<li>在图书馆中，我们需要按照图书的编号到对应的书架上查找图书。这更像是块状链表。</li>\n<li>收费站处，经过车牌识别系统以后，我们需要到资料库中找到对应车辆的具体信息。这的过程我们可以采用哈希表。</li>\n<li>快递小哥在送快递的时候，会根据快递地址找到具体的物理位置，再把快递送出去。地址信息更像是一个树形索引结构。</li>\n<li>期末考试成绩公布了以后，爸爸妈妈会在成绩单上快速查找你的名字。这就是普通的顺序查找。</li>\n</ol>\n<p>好了，你可以利用我给出的参考答案和你自己的对照一下，看看有哪方面遗漏了。那这节课就到这里，我是胡光，我们下节课见！</p>\n',
        article_title: "这些常见算法面试题，你会解了吗？",
      },
    ],
  },
  {
    chapterTitle: "进阶篇 (5讲)",
    children: [
      {
        title: "21 | 深度优先搜索进阶：数独游戏如何快速求解?",
        herf: "https://time.geekbang.org/column/article/295150",
        id: "295150",
        content:
          '<p>你好，我是胡光。</p>\n<p>上节课，我们学习了深度优先搜索算法和一些简单的剪枝技巧。不过，我们在深度优先搜索上的探索还没有结束，这节课我们将通过数独和虫食算这两类经典题目，继续学习深度优先搜索的优化技巧，学习怎么让深度优先搜索的效率更高、速度更快。</p>\n<p><span class="orange">首先，我们来看看今天要解决的数独问题。数独游戏是一个经典游戏，其规则就是在9个$3\\times3$方阵的空格里填上1-9这9个数字，最终填满整个$9\\times9$的大方阵，并且要求每一行、每一列、每一个$3\\times3$的小方阵中不能有重复的数。那这个问题该怎么用计算机求解呢？</span></p>\n<p><img src="https://static001.geekbang.org/resource/image/fd/c9/fd79be92cdd113a04d23392baf4fe4c9.jpeg" alt="" /></p>\n<h2>如何利用深度优先搜索解决数独问题？</h2>\n<p>一看到这个题目，想必你就已经有了解决它的办法。没错，我们直接使用深度优先搜索就可以求解，搜索状态就是当前这个方阵的状态，每一步的状态转移就是填上一个格子，其他的什么都不用管，就这样一直搜索下去就行了。</p>\n<p>的确，直接这么搜索下去一定可以求出数独的解。但从实际的运行效率来讲，这种方法其实就是在碰运气。为什么这么说呢？在今天的例子中，第<code>[1, 2]</code>是第一个空格子，它可以填上4、7、8三个数字，我们要分别尝试依次把它们填到这个格子中。如果走到某一步走不下去了，我们还要再向上回溯，一步步走回来，回到数独最原始的状态重新进行尝试。也就是说，这个格子有几种可能性，我们就要重新遍历几次这个状态树。</p>\n<p><img src="https://static001.geekbang.org/resource/image/84/d3/8443c26e6bfb08bac33f60de03a2cfd3.jpeg" alt="" /></p>\n<p>这么做显然非常浪费时间，就算在现实生活的数独游戏中，我们也不会这么去填数字。那我们在现实生活中是怎么玩数独游戏的呢？相信你和我一样，都会选择先填待选数字最少的那个格子。那当把一个格子填上之后，它同行、同列、同块的其他格子的可能行就都被占用了，这就相当于是在消减其他格子的状态数，这可以减少整个数独的不确定性。</p>\n<p>在这个数独中也是一样，我们发现<code>[5, 6]</code>格子似乎只可以填上7这一个数字。给这个格子填上数字之后，整个数独中的不确定性就更少了，并且由于这个格子只有7这一种可能性，因此我们不会再回溯到原始状态重新尝试，搜索次数也会大幅度减少。</p>\n<p><img src="https://static001.geekbang.org/resource/image/8b/39/8bc88b6e538c0fc0b22886bb3aff6339.jpeg" alt="" /></p>\n<p>在搜索中我们当然也可以这么做：每一步状态转移，我们都找到现在这个方阵中可以填的数最少的节点，就可以有效减少状态数了。这种搜索技巧就是通过<strong>修改搜索的次序而完成的剪枝操作</strong>。</p>\n<p>不过，使用这种剪枝技巧，我们需要去判断每一个格子中能填几个数，以及都有哪些数能填。可是如果判断每一个格子的时候，我们都要去枚举它所在的行、列、块，这需要循环$81\\times 27=2187$次，也是非常麻烦的。</p>\n<p>这该怎么优化呢？我们可以利用一个数组去记录某一行都用了哪些数，以及哪些数没用。举个例子，对于今天这个数独例子的第一行，我们可以把这一行里面可以用（也就是没有出现的）的数标成1，不可以用的数标成0，由于数独中只会出现1到9这九个数字，因此我们给这一行开一个长度为10的数组就可以记录了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/a0/4f/a0cfe0fbe82ed62a2e645e0791c0734f.jpeg" alt="" /></p>\n<p>但是这样记录的话，我们还是要询问1到9所有的数字是否在这一行里面出现过，这还有点儿麻烦，那我们能否把这个操作也省掉呢？</p>\n<p>答案已经在这个数组中了，这个数组只记录9个数是否出现，而且分别是用0和1来记录的。这自然而然就对应了位运算，那这个记录就可以转变成我们用一个9比特的数记录这一行中1到9的使用情况。具体来说，我们用右数第一位代表1的使用情况，第二位代表2的使用情况，第三位代表3的使用情况……依此类推。</p>\n<p>如果这一行的值是$(4)_{10}=(000000100)_{2}$，那这一行里面只有3可以使用，如果这一行的值是$(21)_{10}=(000010101)_2$，则代表1、3、5都可以填到这一行中。再回到上面这个例子中，数独的第一行对应的值就是$(100010101)_2=277$，我们很容易就可以记录下来。</p>\n<p>不仅如此，利用位运算我们还能同时实现三个功能。首先，利用位运算，我们可以直接计算某一个数在这一行中能否使用。比如说，要计算5能否填在这行中，我们只需要计算<code>(1 &lt;&lt; (5 - 1)) &amp; row[i]的值</code>，如果是0就不能使用，否则就可以使用。其次，如果某一个格子填上了数或者拿下了数，我们也可以通过异或运算轻松更新这几个值。最后，通过位运算，我们也可以快速计算一个数中有多少个1，计算过程如下：</p>\n<pre><code>while (a &gt; 0) {\n    a = a &amp; (a - 1);\n    count += 1;\n}\n</code></pre>\n<p>利用位运算之后，我们每操作一次都会去掉原来数组中一个低位的1，例如$(1011)_{2}\\&amp;(1010)_{2}=(1010)_{2}$，$(1010)_{2}\\&amp;(1001)_{2}=(1000)_{2}$。</p>\n<p>不过这样做了之后，还是会有极端情况出现，比如当这个数的二进制表示全都是1的时候，还是相当于循环了很多次。但是，根据上面的操作，我们可以总结出来一个递推的规律：一个数<code>x</code>中含有1的个数，一定是<code>x &gt;&gt; 1</code>中含有1的个数加上<code>x</code>的最低位是否有1，公式如下：</p>\n<pre><code>nums_1[x] = nums_1[x &gt;&gt; 1] + (x &amp; 1)\n</code></pre>\n<p>那么，我们就可以先用$2^9$的代价，先枚举出来每个数的二进制表示中有多少个1，把它们记录下来，判断的时候直接利用$O(1)$时间查表就行了。这样一来，我们分别使用三个数组，记录每一行、每一列、每一块的状态就可以大大减少运算量了。</p>\n<p>你看到了吗？位运算也是一种强有力的优化技巧，利用位运算，我们有效地将循环判断变成了一次操作。不过，即便使用位运算能大幅减少我们每一次搜索判断的时间，但每次要找出所有的空格子，还是要枚举到所有的格子，那我们能不能把这一块运算也减少呢？</p>\n<p>你还记得我们之前是怎么优化八皇后问题的吗？我们把一个格子拆成了行和列两个维度去解决这个问题，对于数独问题，我们也可以尝试应用这个思路。我们把每一步从方阵中找到一个可以填的数最少的格子拆分成两步，我们先在方阵中找到可以填的数最少的行<code>x</code>，然后在行<code>x</code>中找到可以填的数最少的格子<code>y</code>，最后以格子<code>[x, y]</code>作为状态转移去搜索下一步。这样一来，每一次搜索查找的运算量就从$9\\times9=81$变成了$9+9=18$，考虑到数独这个问题的搜索深度（空格子数，往往几十个），这已经大幅度减少运算量了。</p>\n<p>以上就是我们解决数独问题所有的剪枝优化思路，我们一起来做个总结。总的来说，搜索的剪枝操作有4个优化思路可以用来参考：</p>\n<ol>\n<li>改变搜索次序：<strong>将分支少的状态尽可能往前放</strong>，让前面的状态限制后面的分支，来大幅减少搜索分支；</li>\n<li>修改状态转移方式，减少无用搜索：如八皇后问题中，我们将格子之间的状态转移转换成为行之间的状态转移，这避免了很多无用的搜索；</li>\n<li>去掉等效的状态。如组合数问题中，我们已经知道了<code>[1, 2, *]</code>状态和<code>[2, 1, *]</code>状态是一样的，自然不会再进行搜索；</li>\n<li>去掉不可行的状态，这种剪枝技巧几乎应用到了我们讲过的所有搜索例题中。比如，八皇后问题中，我们对行、列、对角线的限制；再比如，数独问题中我们对行、列、块的限制等等。</li>\n</ol>\n<h2>搜索优化实战：解决虫食算问题</h2>\n<p>解决了数独问题，学到了剪枝操作的4个优化思路之后。接下来，我们就利用这4个优化思路一起来解决虫食算问题。所谓虫食算，就是原先的算式中有一部分被虫子啃掉了，需要我们根据剩下的数字来判定被啃掉的字母。我们先来看一个简单的例子：</p>\n<pre><code>  43#9865#045\n+   8468#6633\n= 44445506678\n\n</code></pre>\n<p>其中<code>#</code>号代表被虫子啃掉的数字。根据算式，我们很容易判断：第一行的两个数字分别是5和0，第二行的数字是5。</p>\n<p><span class="orange">现在，我给出一个N进制的加法算式，其中N=5，让你用计算机来求出这个算式原本是什么样子的，你会怎么做？算式的形式如下（其中，不同字母的值不相同）：</span></p>\n<p><img src="https://static001.geekbang.org/resource/image/85/75/85fec226969a662f57a10f230353b175.jpeg" alt="" /></p>\n<p>接下来，我们依旧试着用搜索来解决这个问题。</p>\n<p><strong>首先，我们还是要确定这个问题的状态。</strong>这个问题有两种搜索状态可以选择：每一个字母填什么或者每一个位置填什么。显然，第一种状态数量比较少，看上去比较好搜，但是我们无法利用算式上的规则去剪枝，而使用位置当状态，我们可以轻松地利用算式之中的规律当做剪枝条件。</p>\n<p>比如，在上面的算式中，由于两个数的和与两个数的位数相同，就说明最高位的两个数相加之后没有进位，则有<code>A+B&lt;N</code>，同时也有<code>A + B = E</code>或<code>A+B+1=E</code>（考虑到B+D的进位）。</p>\n<p>虽然我们搜索的状态是每一个位置上填什么，但实际上，某一个字母确定了，这个字母所在的其他位置也就都确定了，并且，我们还可以利用加法运算的规则，直接判断出矛盾来减少搜索次数。比如在之前的状态中，我们搜索到A是3，但是向下搜索再碰到A的时候，发现A必须是2才能使这一列的等式成立，这就遇到了矛盾，接下来我们就没必要继续搜索了。</p>\n<p><strong>确定了状态之后，最后我们确定搜索的次序。</strong>我们讲了这么久的加法运算规则，到这里就能利用上了，我们应该从最低位开始，一位一位地去确定这个算式的值。</p>\n<p>针对上面的例子，我们从最上面的D开始搜索，先把0到4依次填到D中尝试。首先，0肯定不能填到D里面，因为如果D是0，那<code>0 + E = E</code>，但算式最下面是A就会出现矛盾，所以D只能填1。</p>\n<p>将最上面的D填上1之后，D下面的那个E同样不能填0，那我们只能从2开始试。根据加法运算规则<code>(D + E) % 5 = A</code>，则A=3。</p>\n<p><img src="https://static001.geekbang.org/resource/image/e8/39/e85cce989716ef0b5c444335534ce639.jpeg" alt="" /></p>\n<p>确定了E、D、A的值之后，我们再搜右数第二列E下面的C。这个时候矛盾又出现了，根据<code>(2 + C) % 5 = 3</code>，当E=2、A=3的时候，C只能是1（否则C就得是$(6)_{10}=(11)_5$，不符合题目要求），可是1已经被D占用了。因此，这个状态不合理，我们就没有必要接着往下搜了。</p>\n<p>那我们只能回溯回来重新搜索E，这次尝试让E=3，又发现3也和C有矛盾，我们就接着尝试4。这时候我们发现，右数第一列的等式是1 + 4 = 5，需要进位，那么A就等于0。当A=0 的时候，右数第二列的等式就变成了<code>(4 + C + 1) % 5 = 0</code>。这个等式要成立的话，C必须是0才可以，这个时候A和C又出现矛盾了，所以我们也没有必要搜索下去了。</p>\n<p>就这样，我们尝试了D=1的所有情况，接下来我们就可以尝试D=2的情况了，尝试的方法还是一样，我就不再详细来说了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/32/0a/32b5c6c831ea69501d93097b9b0de60a.jpeg" alt="" /></p>\n<p>通过这个例子，相信你也看到了，我们将搜索次序由横向搜索变成了从右向左、从上到下、一列一列的搜索。这样一来，我们可以很早就剪掉大量的状态，不用搜索5层才能去判断合理性。这也就是我们刚才说的，改变搜索次序来大幅减少搜索分支的搜索优化方法。</p>\n<h2>课程小结</h2>\n<p>这节课我们通过数独问题和虫食算问题练习了深度优先搜索的剪枝技巧，让深度优先搜索变得不那么盲目，也可以高效起来。从中，我们总结了深度优先搜索的4个优化思路，分别是改变搜索次序。比如在刚才说过的虫食算问题中，我们就把搜索次序由横向搜索改成了纵向搜索，来大幅减少搜索分支。接着是修改状态转移方式，减少无用搜索。然后是去掉等效的状态。最后是去掉不可行的状态。</p>\n<p>我希望在日后搜索算法的应用实践中，你也可以灵活运用这几种思路去提升算法的效率。</p>\n<h2>课后练习</h2>\n<p>假设，有若干根一样长的木棍被切成了n个小木棍，我们已知这n个木棍和它们分别的长度，求木棍原来的长度最短是多长。你会怎么做？</p>\n<p>欢迎在留言区分享你的答案，也希望你能把这节课的内容转发出去。今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "21 | 深度优先搜索进阶：数独游戏如何快速求解?",
      },
      {
        title: "22 | 排序与查找：抓住关键，2-Sum问题的多种解法",
        herf: "https://time.geekbang.org/column/article/296049",
        id: "296049",
        content:
          '<p>你好，我是胡光。</p>\n<p>经常有人问我，老师，你说学算法最重要的是学习它具体的设计过程，可是学完之后，我好像还是用不好？为了帮助你更好地应用我们讲过的各种排序、查找、搜索算法，从这节课开始，我们一起进入实战。</p>\n<p>今天，我会先带你一起来解决2-Sum问题。这里，你可能会疑惑，2-Sum问题我们不是在第<a href="https://time.geekbang.org/column/article/284707">12课</a>里面讲过了吗，怎么这里又要再讲一遍？首先，2-Sum问题本身就非常经典，而且我们已经知道它的经典解法，这样你再理解今天的内容就会更容易。其次，2-Sum问题的解法非常多，这些解法能把我们学过的算法知识都串联起来，是一类非常具有代表性的问题。</p>\n<p>话不多说，我们正式开始今天的课程吧！</p>\n<h2>2-Sum问题的多种解法</h2>\n<p>首先，我们来回顾一下2-Sum问题，以及第12课里讲过的经典解法。</p>\n<blockquote>\n<p>给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那两个整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。<br />\n <br />\n示例：<br />\n给定 nums = [2, 7, 11, 15], target = 9<br />\n因为 nums[0] + nums[1] = 2 + 7 = 9<br />\n所以返回 [0, 1]</p>\n</blockquote>\n<p>经典解法是在有序的nums序列中，使用前后双指针就能在$O(N)$的时间复杂度内得到解。而如果nums是无序的，我们也可以通过排序先将这个问题简化到双指针再来解决。双指针解决这个问题的依据是二维思维的杨氏矩阵。今天，我们还是利用杨氏矩阵来进一步讨论这个问题的解法。</p>\n<h3>利用二分查找解决2-Sum问题</h3>\n<p>首先，我们来看一个杨氏矩阵问题。现在给你一个如下图的杨氏矩阵，让你找出31是否在这个矩阵中，你要怎么做？</p>\n<p><img src="https://static001.geekbang.org/resource/image/a4/a1/a4fdfac1da0ac6136e05215b070eafa1.jpeg" alt="" /></p>\n<p>正常来讲，我们从右上角开始与目标值比较，如果目标值小于元素值，就向左走一步查找；如果目标值大于元素值，就向下走一步查找，依此类推，一直走下去就可以找到它。事实上，这种方法已经非常高效了。不过，我们还可以找到更加高效的解法。</p>\n<p>认真看这个矩阵，我们会发现它的每一行，每一列都是有序的。那我们每一步的查找，实际上都是试图在最上面<code>r0</code>行中找到第k列，让它满足：<code>a[r0][k] &lt; 31 &amp;&amp; a[r0][k + 1] &gt; 31</code>，当k=2的时候是满足这个关系式的。</p>\n<p>接下来，我们就从<code>a[r][k + 1]</code>元素开始查找，我们发现它下面和右面的所有元素都比它大。也就是说，以49为左上角的子矩阵中，49就是这个矩阵中的最小值。因为最小值49还大于31，所以我们就能推出目标值31一定不在这个子矩阵中，那这个子矩阵就可以被去掉。</p>\n<p><img src="https://static001.geekbang.org/resource/image/03/f8/0334bb54e4749be44c4dbd240a60c0f8.jpeg" alt="" /></p>\n<p>那除了顺序查找之外，在杨氏矩阵这个有序序列中找到符合这样条件的位置，我们还有更快的方式吗？相信你心中已经有答案了，没错，就是二分查找法。</p>\n<p>当我们用上面的方法纵向地去掉了矩阵的一部分之后，就要在得到的新矩阵的最右列上重复一次这样的操作。我们得到的新矩阵的最右列就是第k列，那我们就要在第k列上找到一行r，使得：<code>a[r][k] &lt; 31 &amp;&amp; a[r + 1][k] &gt; 31</code>，我们定位到这个第<code>r</code>行之后，矩阵自然也被分成了两个子矩阵，而我们定位到的元素<code>a[r][k]</code>就是以它为右下角的子矩阵的最大值。当k=2、r=2的时候，<code>a[r][k]</code>就是29，我们就能推知目标值31一定不在这个子矩阵中，这个子矩阵自然也可以去掉了。</p>\n<p><img src="https://static001.geekbang.org/resource/image/77/75/777856be976453cf045017f4eb194a75.jpeg" alt="" /></p>\n<p>这次切分之后，我们继续在新暴露出来的最上面一行，也就是<code>r+1</code>行上做二分查找操作，直到找到目标值或者矩阵被删空为止。这样一来，我们把2-Sum转换成杨氏矩阵之后，再利用杨氏矩阵的行、列与序列中元素之间的对应关系，就可以更快地解决2-Sum问题了。并且，由于使用了二分查找，解决2-Sum问题的时间复杂度被我们进一步降到了对数级别。实际上，在有序序列上进行查找操作的时候，我们都可以考虑用这种方式来做。</p>\n<p>到这里，第一种解法就说完了。接下来，我们继续来讨论这个问题的其他解法。</p>\n<h3>2-Sum问题的其他解决办法</h3>\n<p>这次我们再好好思考一下题干，这道题让我们从<code>nums</code>序列中取出两个数<code>a</code>和<code>b</code>，并且让<code>a + b = target</code>。那这是不是可以转换成为：在确定第一个数<code>a</code>的情况下，查找<code>target-a</code>这个数是否在nums序列中呢？的确可以。这样一来，这个问题的另一种解法我们就得到了，就是先确认一个数，再查找另一个数是否在这个数之后的子序列中。既然这个序列是有序的，查找过程自然也可以使用二分法来做，这个解法的时间复杂度是$O(N\\times log_2N)$。</p>\n<p>那么除了<strong>先排序再二分的做法</strong>之外，还有更快的解决办法吗？我们要注意，解决这个问题的关键在于查找一个数在序列中是否存在。这就让我们想到了之前学过的一种高效的查找结构，哈希表。哈希表可以用$O(1)$的时间查找元素是否存在，对吧？</p>\n<p>这样，2-Sum问题的第三个解法也就得到了。我们先将序列<code>nums</code>所有的元素都放到一个哈希表中，然后按照前面的思路，去查找<code>target-a</code>这个数是否在nums序列中就可以了。这种方法使用起来与无序序列一样，时间复杂度都是$O(N)$，它们的快慢主要取决于哈希函数的操作效率。</p>\n<p>讲完了2-Sum问题的3种解法，我还想把这个问题拓展一下，带你看看怎么解决3-Sum问题和4-Sum问题。</p>\n<h2>3-Sum问题和4-Sum问题的解法</h2>\n<p>首先，我们来看3-Sum问题。</p>\n<blockquote>\n<p>给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那三个整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。<br />\n <br />\n示例：<br />\n给定 nums = [2, 7, 11, 15], target = 24<br />\n因为 nums[0] + nums[1] + nums[3] = 2 + 7 + 15 = 24<br />\n所以返回 [0, 1, 3]</p>\n</blockquote>\n<p>其实延续2-Sum问题的解题思路，我们很容易就能想到一个比较高效的解法：首先确认一个数<code>a</code>，然后在序列中找到两个数<code>b</code>和<code>c</code>，使得<code>b + c = target - a</code>。看到了吗，这就又变成了一个2-Sum问题。这样，我们只需要依次确定一个数，将序列中剩下的元素当作2-Sum问题来做就好了。这么做的时间复杂度，相当于在2-Sum问题的时间复杂度上再乘上一个$N$，最好情况下，时间复杂度就是$O(N^2)$或者$O(N^2\\times log_2N)$。</p>\n<p>好，简单地解决了3-Sum问题之后，我们再来看4-Sum问题，也就是说，这次我们要在序列中找出来4个数，使得它们的和等于目标值。</p>\n<p>看到这里，你可能会有一个惯性的思维：继续按照3-Sum问题的解决思路，确定了一个数之后，在序列剩下的元素中去解决3-Sum问题不就可以了吗？的确可以，但这个做法相当于在3-Sum的时间复杂度上又乘上了一个N，时间复杂度就成了N的立方。这该怎么优化呢？</p>\n<p>你还记得之前在第12篇中，我们学习用杨氏矩阵的思想来解决2-Sum问题的时候，提到了一种算法思维，就是<strong>用二维的思维去解决一维的问题</strong>。那我们是否可以尝试使用这个思维去优化4-Sum问题的解决方案呢？</p>\n<p>按照这个思路，我们实际上要在序列中事先确认两个数<code>a</code>和<code>b</code>，然后在序列余下的元素中解决目标值为<code>target - (a + b)</code>的2-Sum问题。那么，事先确定<code>a</code>和<code>b</code>的操作，是否可以直接组合，然后继续计算呢？</p>\n<p>没问题，我们先将序列<code>nums</code>中的元素两两加和，得到一个新的序列<code>sum_nums</code>。这个新序列的长度，用简单的组合数公式就可以算出来：$C_N^2=\\frac{N\\times(N-1)}{2}$，结果大概是N平方的复杂度。由于序列<code>sum_nums</code>之中全都是元素加和，那么我们直接对这个新的序列做2-Sum问题，最终求得的结果就是4-Sum的结果。</p>\n<p>不过，这个解法中有一个细节问题需要你注意，题目中要求选取的元素是不可以重复的。但是，如果我们使用这个方法去求解这个问题，不同的加和之间很可能会存在重复使用的元素。比如说，我们找出来的结果有可能是<code>a + b + b + c = target</code>，我们应该在求解过程中把它规避掉。</p>\n<p>这个解法的时间复杂度也是$O(N^2)$，它和3-Sum的时间复杂度是一样的。总的来说，对于4-Sum问题，我们打破了3-Sum问题带来的思维定式，使用二维的算法思维去解决一维的问题，解题的基本思路与3-Sum问题完全不同，解题效率更高。</p>\n<h2>课程小结</h2>\n<p>这节课，我们重新讨论了2-Sum问题的多种解法。这些解法实际上都是在解决同一个问题，就是找到线性序列中更高效的查找方式。</p>\n<p>针对2-Sum问题，我们讲了三种解法。首先，我们借助杨氏矩阵每一行、每一列都是有序的这一特性，利用了二分查找法来解决问题。后来，我们又将问题转换成在确定第一个数<code>a</code>的情况下，查找<code>target-a</code>这个数是否在nums序列中，也就是<strong>先排序再二分的做法</strong>。这种解法的关键在于查找一个数是否存在于序列中，最后，我们借助哈希表对第二种解法进行了优化。</p>\n<p>此外，我们又拓展学习了3-Sum问题和4-Sum问题的解法。3-Sum问题的解法其实就是延续2-Sum问题第二种解法的思路。而4-Sum问题的解法，应用到了我们学过的利用多维算法思维去解决一维问题。</p>\n<p>通过今天的学习，我希望你能明白一点，那就是我们在解决实际问题的过程中，一定不要被问题本身的形式、结构，或者是相似问题给限制住，要打破思维定势，利用问题本身的特性去寻求更高效的解法。</p>\n<h2>课后练习</h2>\n<p>1.你能试着把杨氏矩阵的二分解法应用到2-Sum问题上吗？</p>\n<p>2.你可以利用我们今天学到的知识，试着讨论一下k-Sum问题的解法吗？</p>\n<p>欢迎在留言区分享你的答案，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "22 | 排序与查找：抓住关键，2-Sum问题的多种解法",
      },
      {
        title: "23 | 位运算：位=数据结构，算=算法",
        herf: "https://time.geekbang.org/column/article/296692",
        id: "296692",
        content:
          '<p>你好，我是胡光。今天，我们学习位运算。</p>\n<p>还记得吗？第21课里，我们在用深度优先搜索和剪枝技巧来解决数独问题的时候，使用位统计了数独中每行、每列、每块的状态，利用了位运算来计算状态转移。这让原本需要在序列上进行的操作，只需要在整数上就可以完成。</p>\n<p>位运算这种强有力的优化技巧，帮助我们减少了统计所需要的空间消耗和时间消耗，加速了搜索过程。在实际应用中，很多对效率有着绝对要求的领域（如游戏领域）也经常会使用位运算技巧来加速。</p>\n<p>不过，同学们对位运算的了解可能并没有那么深，虽然我们在学习C语言的时候都会接触到位运算，但往往浅尝辄止。那今天，我就结合几道实战题目带你深入学习位运算的技巧，让它成为你实战过程中的“最佳”助力！</p>\n<h2>位运算的基础知识</h2>\n<p>在开始实战之前，我们先来回顾一些位运算的基础知识。首先是位，位也是一种数据结构。它有两种状态，分别是0（false）和1（true）。而位运算，就是对这种数据结构进行的基础操作，一共有6种，分别是与（&amp;）、或（|）、取反（~）、异或（^）、左移（&lt;&lt;）和右移（&gt;&gt;）。接下来，我们分别看一下它们的概念。</p>\n<p><img src="https://static001.geekbang.org/resource/image/b8/17/b8c648790a679aced3be977d5b5fce17.jpeg" alt="" /></p>\n<p>好了，现在我们已经重新回顾了位运算的基础知识，接下来，我们正式开始实战。</p>\n<h2>位运算的应用技巧</h2>\n<p>在解决实际问题的时候，我们经常会使用2种位运算技巧，分别是按位统计法和分组统计法。接下来，我就结合几道典型例题，来和你详细讲讲它们的应用。</p>\n<h3>1. 按位统计法</h3>\n<p><span class="orange">如果要在所有的4位素数中，找到数字组成是一样的素数（素数是指在大于1的自然数中，除了1和它本身以外不再有其他因数的自然数）。比如说，9937和9973，它们两个都是由2个9、1个7、1个3组成，所以它们两个的数字组成就是一样的。这个时候，你会怎么做？ </span></p>\n<p>要解决这个问题，我们就要先找到所有的4位素数。这好像有点难办啊，没关系，我们可以利用素数筛这个方法来解决。它的基本思路就是将素数的倍数全都标记成为合数（合数是指在大于1的整数中除了能被1和本身整除外，还能被除0以外的其他数整除的数），剩余的没有被标记的数自然就都是素数了。</p>\n<p>我把具体的方法总结在了下面这张图上。结合它，我们来举个例子。假设，我们先找到了第一个素数2，然后我们把2的倍数都标记成合数。接着我们找到未标记的第一个数，它肯定还是一个素数，我们重复刚才这个过程，直到把4位数中的所有素数都找出来。</p>\n<p><img src="https://static001.geekbang.org/resource/image/ed/7b/ed6912b507bb8f08fe2b6c27a62d1c7b.png" alt="" /></p>\n<p>找到所有的4位素数之后，我们就要去统计计算每个素数的组合。最简单的办法就是，我们给每一个4位数开一个长度为10的数组，记录其中0到9出现的次数。计算完之后，我们再判断一下这些统计数组中是否有完全相同的就可以了。这个方法想想就比较麻烦，那我们有没有更好的解决方法呢？</p>\n<p>首先，我们可以想一想，在4位的素数中，每一个数字至多出现几次呢？你首先想到的可能是4次，但这并不可能。因为如果一个四位数每一位都是一样的，那它一定可以被11整除，也就是说它不会是一个素数。所以，4位素数中，每一个数字出现的次数最多是3次。因此，在一个4位素数中，每个数字只会有4种状态，那就是出现0次、1次、2次和3次，这4种状态我们用两个bit就能够存储起来了。</p>\n<p>所以，我们可以分别用两个bit来存储每个数字的状态。因为一共有10个数字，那我们用20bit就可以将它们都存储下来。这么一看，刚好一个整数（32 bit）就可以把这10个数字的状态存储下来了。统计一个数x的具体操作如下：</p>\n<pre><code>int count = 0;\nwhile (x &gt; 0) {\n    count += 1 &lt;&lt; (x % 10);\n    x /= 10;\n}\n\n</code></pre>\n<p>最后，我们用哈希表存储下每个统计结果对应的数，就可以得到组成一样的4位素数了。这种方法就叫做<strong>按位统计法</strong>。简单来说，就是分别统计所有可能出现的数的状态。还记得吗？在数独问题中，我们也是使用这种技巧去记录数独中的状态的。</p>\n<h3>2. 分组统计法</h3>\n<p>第一种方法讲完了，我们接着来看第二种方法，分组统计法。我们还是先来看一道题。</p>\n<p>已知一个序列中，其他数出现了偶数次，只有一个数出现了奇数次，你能求出出现奇数次的那个数吗？</p>\n<p>这道题可能你之前就见过了，甚至你可能已经知道了它的解法。运行下面这段代码之后，最终的x就是我们要找的那个数。</p>\n<pre><code>int x = 0;\nfor (int i = 0; i &lt; n; i++) {\n    x ^= a[i];\n}\n\n</code></pre>\n<p><span class="orange">不过，我们要解决的是一道和它类似的题目：在一个序列中，其他数出现了3次，只有一个数的出现次数小于3次，请你求出出现次数小于3次的那个数 。</span></p>\n<p>这道题显然就不像上一道题那么简单了，我们使用直接异或没有办法解决。不过，想要解决这个问题，我们可以从第二题出发，借助它的思路。我们先来想想在解决第二题的过程中，我们使用异或运算到底是在算什么。</p>\n<p>题目中给出的信息很明确，每一个bit的状态有两个，分别是奇和偶，奇为1、偶为0。所以，我们可以用一个bit来存储这两个状态，用异或操作来统计bit上的奇偶性。简单来说，我们实际上就是在统计所有数中，在每个bit上出现1的次数的奇偶性。</p>\n<p>那我们回到这个问题中想一想，每个bit上的状态有几种呢？其实是4种，分别是出现0次1、1次1、2次1和3次1，而出现3次的数是需要排除掉的，那出现3次可以被视作出现0次。因此，这4种状态我们就可以用2个bit来存储，分别是出现0次1就是00，1次就是01，2次就是10，3次就是00。</p>\n<p>那当这个bit遇到一个新的数的时候，状态会怎么转换呢？假设a和b是分别存储每个bit状态的高位和低位：</p>\n<p><img src="https://static001.geekbang.org/resource/image/40/3d/4032c488e3995fb76828265fb3ba423d.jpeg" alt="" /></p>\n<p>通过上面的表格，我们看到，要想让<code>a\' = 1</code>，则必有<code>a == 1 &amp;&amp; b == 0 &amp;&amp; num == 0</code>或<code>a == 0 &amp;&amp; b == 1 &amp;&amp; num == 1</code>，因此我们就得到了<code>new_a = (a &amp; ~b &amp; ~num) | (~a &amp; b &amp; num)</code>这个状态转移代码。同理，要想让b’ = 1，就会有<code>new_b = (~a &amp; b &amp; ~num) | (~a &amp; ~b &amp; num)</code>这个状态转移代码。这个式子我们还可以化简一下，首先化简低位<code>b</code>，得到<code>new_b = ~a &amp; ((b &amp; ~num) | (~b &amp; num)) = b ^ num &amp; ~a</code>。然后我们用计算好的<code>b\'</code>去重新求取<code>a\'</code>，就能得到<code>new_a = (a &amp; ~num &amp; ~new_b) | (~a &amp; num &amp; ~new_b) = ~new_b &amp; ((a &amp; ~num) | (~a &amp; num)) = a ^ num &amp; ~new_b</code>。</p>\n<p>由于我们要求的那个数要么出现了2次，要么出现了1次，因此，这个数要么存储在了a中，要么存储在了b中。想要取出它，我们只需要求<code>a | b</code>即可。</p>\n<p>上面的这种技巧，就叫做<strong>分组统计法</strong>。简单来说，分组统计法就是将bit按照一定规则分成若干个不同的组分别统计。</p>\n<p>其实，到这里，两种常见的位运算技巧我们就讲完了。不过我还想给你讲讲基于分组统计法的进阶技巧。</p>\n<h3>3. 分治思想结合分组统计法</h3>\n<p>下面，我们来看一道题：<span class="orange">给定一个整数，请你求出这个整数二进制表示中1的个数。</span></p>\n<p>你可能发现了，这个问题在数独问题中，我们已经讲过了也介绍过了，当时给出的方法是：</p>\n<pre><code>int count = 0;\nwhile (x &gt; 0) {\n    x = (x &amp; (x - 1));\n    count += 1;\n}\n</code></pre>\n<p>最终得到的<code>count</code>就是1的个数，我们通过这个方法得到了打表方法，用来快速查找有限个数的结果。</p>\n<p>这个方法的时间复杂度是有多少个1就计算多少次，最坏情况是$O(log_2N)$的，其实这个方法的效率已经非常高了。但如果是在相当频繁的操作中，这个效率还是有些吃力的，比如在游戏这种追求极致效率的应用场景中。接下来，我们就一起来探索更快的解决思路。</p>\n<p>那么，我们先来看一个数的二进制表示，例如62989781的二进制表示为11110000010010010111010101。我们知道，在计算机中，一个整数通常是32个bit的，所以我们会在11110000010010010111010101的前面补齐0。好，那么我们想求取这个二进制表示里面有多少个1，除了一个一个地把1消掉之外，是不是也可以想办法把所有的1都累加到低位上，使得最终的计算结果就等于1的个数呢？</p>\n<p>这个想法看似天马行空，但我们可以慢慢尝试去实现它。我们从最高位开始，两位两位地计算，将两位中的高位拿出来加到低位上。</p>\n<p>那我们怎么才能分别取出高位数和低位数呢？这就用到了，我们刚才讲的与（&amp;）操作。两个bit取低位就是使用<code>0b01</code>来操作，取高位就是<code>0b10</code>。那么，32bit的数分别来取高位和地位，就是16个<code>0b01</code>和16个<code>0b10</code>。与二进制最方便转换的一种进制就是16进制，16个<code>01</code>就是8个<code>0101</code>，所以取低位的16进制数就是<code>0x55555555</code>，同理，16个<code>10</code>就是8个<code>1010</code>，所以取高位的16进制数就是<code>0xAAAAAAAA</code>。这样，我们让x = x &amp; 0x55555555 + ((x &amp; 0xAAAAAAAA) &gt;&gt; 1)，就可以把相邻位置的高位1累加到低位1上。</p>\n<p>做完了这个操作之后，下一步我们就是要把之前的2bit分组再每两个取一组，将高位累加到低位上。这次我们取低位用的数是8个<code>0011</code>，也就是<code>0x33333333</code>，取高位用的数是8个<code>1100</code>，也就是<code>0xCCCCCCCC</code>。</p>\n<p>接下来，我们再次取相邻分组，这次相邻分组是8位。那我们取低位是4个<code>00001111</code>，即<code>0x0F0F0F0F</code>，取高位是4个<code>11110000</code>，即<code>0xF0F0F0F0</code>，依此类推。</p>\n<p><img src="https://static001.geekbang.org/resource/image/68/52/68f74d6767edaf9a8ee93befc199b952.jpeg" alt="" /></p>\n<p>最终，我们得到的数字就是我们当前这个数中1的个数。我们的最终计算结果是13个1，你可以去验证一下。</p>\n<pre><code>int count_one(int x) {\n    x = x &amp; 0x55555555 + ((x &amp; 0xAAAAAAAA) &gt;&gt; 1);\n    x = x &amp; 0x33333333 + ((x &amp; 0xCCCCCCCC) &gt;&gt; 2);\n    x = x &amp; 0x0F0F0F0F + ((x &amp; 0xF0F0F0F0) &gt;&gt; 4);\n    x = x &amp; 0x00FF00FF + ((x &amp; 0xFF00FF00) &gt;&gt; 8);\n    x = x &amp; 0x0000FFFF + ((x &amp; 0xFFFF0000) &gt;&gt; 16);\n    return x;\n}\n</code></pre>\n<p>整个过程中，我们一共只计算了5次就可以得到一个数的二进制表示中1的个数，是不是很神奇？</p>\n<p>这个解法实际上是利用了分治的基本思想，结合分组统计法得到了最终的结果，由于整数的bit长度是固定的32个，所以在有限次操作（5次）一定能够得到结果它的时间复杂度是$O(log_2log_2N)$。</p>\n<h2>课程小结</h2>\n<p>今天，我们先一起回顾了位运算中的基本操作。位运算有6种基本操作，分别是与、或、取反、异或、左移和右移。我们今天重点提到了其中两种，与操作和异或操作。</p>\n<p>然后，我们通过3道实战题目，一起学习了位运算的常见技巧，按位统计法和分组统计法，以及分组统计发结合分治思想的进阶方法。其中，按位统计法就是分别统计所有可能出现的数的状态。分组统计法就是把bit按照一定规则分成若干个不同的组，再分别统计。</p>\n<p>总的来说，当我们将bit看作是一种数据结构的时候，往往就可以利用其特性完成一些高效的算法设计。对于今天讲解的这几道题目来说，我们的目的不仅仅是学会这些算法，或者学会几种解题技巧，而是要去不断尝试。只有我们正视了这样一种数据结构，才能知道怎么样利用它的特性设计出来高效、巧妙的算法，真正解决问题。</p>\n<p>一句话总结就是，解题不是目的，学会思维方式才是目的。</p>\n<h2>课后练习</h2>\n<ol>\n<li>你能尝试用位运算优化八皇后算法吗？</li>\n<li>你能求出62989781的二进制表示反转之后的整数吗？</li>\n</ol>\n<p>欢迎在留言区分享你的答案，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "23 | 位运算：位=数据结构，算=算法",
      },
      {
        title: "24 | 牛顿迭代：如何用O(1)的时间复杂度求sqrt？",
        herf: "https://time.geekbang.org/column/article/297623",
        id: "297623",
        content:
          '<p>你好，我是胡光。</p>\n<p>我们知道，特定的方程如二次方程有特定的求根公式。但是，多数方程是不存在求根公式的，而我们用数学工具去手动求解也未必能够得到方程的解，那计算机就更难计算了。</p>\n<p>为了能够快速求出方程的解，这节课，我会给你讲一种计算机中快速求解方程根的方法，即牛顿迭代法，并利用它快速求解数的平方根。</p>\n<h2>使用二分法求解方程的根</h2>\n<p>我们知道，计算机相比于人有一个天然的优势，就是它可以快速、准确地执行重复操作。比如说，我们只能去反复猜测、逼近方程的解，要想达到一定的精度很难，但计算机通过不断迭代就可以很容易地完成这个工作。因此，在计算机上，我们可以使用<strong>迭代方法</strong>去求解方程的根。</p>\n<p>以开平方函数<code>sqrt</code>为例，如果在计算机中我们想求某一个正实数<code>a</code>的正平方根，我们其实可以把这个问题转换成为求方程$x^2-a=0$在一定精度下的解（例如小数点后6位）。这个问题怎么解决呢？下面，我们一起来看看。</p>\n<p>首先，我们能想到的最简单的方法就是二分法。具体来说，就是我们每找到一次中间值(l+r)/2之后，就取它的平方和<code>a</code>比较。这样我们一直使用二分来迭代，直到误差符合要求为止。</p>\n<p>这个代码，我们很轻松就可以写出来：</p>\n<pre><code>c++\nfloat bi_sqrt(float x) {\n    float l = 0.0f, r = x;\n    float mid = (l + r) / 2.0f;\n    float last = 0;\n    while (abs(mid - last) &gt; eps) {\n        printf(&quot;%.7f %.7f %.7f\\n&quot;, l, r, mid);\n        last = mid;\n        if (mid * mid &gt; x) {\n            r = mid;\n        } else {\n            l = mid;\n        }\n        mid = (l + r) / 2.0f;\n    }\n    return mid;\n}\n\n</code></pre>\n<p>虽然二分法的确可以完成方程求解的过程，看上去效率也还可以。但我们还要考虑到<code>sqrt</code>是一个非常基础的数学操作，它的调用频率非常频繁。那使用二分法来求解，计算机需要迭代多少次才能达到<code>1e-6</code>的精度呢？我们得到$\\sqrt{2}=1.4142135\\cdots$，利用二分法的确达到了精度，但它的迭代次数看起来实在是有点儿多。而且，<code>sqrt</code>作为一个非常基础且会被频繁调用的数学操作，这样的迭代次数看起来好像不是那么好。甚至，如果我们要求更高的精度，迭代的次数也会变得更多。这该怎么办呢？</p>\n<pre><code>0.0000000 2.0000000 1.0000000\n1.0000000 2.0000000 1.5000000\n1.0000000 1.5000000 1.2500000\n1.2500000 1.5000000 1.3750000\n1.3750000 1.5000000 1.4375000\n1.3750000 1.4375000 1.4062500\n1.4062500 1.4375000 1.4218750\n1.4062500 1.4218750 1.4140625\n1.4140625 1.4218750 1.4179688\n1.4140625 1.4179688 1.4160156\n1.4140625 1.4160156 1.4150391\n1.4140625 1.4150391 1.4145508\n1.4140625 1.4145508 1.4143066\n1.4140625 1.4143066 1.4141846\n1.4141846 1.4143066 1.4142456\n1.4141846 1.4142456 1.4142151\n1.4141846 1.4142151 1.4141998\n1.4141998 1.4142151 1.4142075\n1.4142075 1.4142151 1.4142113\n1.4142113 1.4142151 1.4142132\n</code></pre>\n<h2>利用牛顿迭代法求解方程的根</h2>\n<p>接下来，我就给你讲一种更常用、更快速的迭代求解方法，它就是牛顿迭代法。我们先从几何角度上来直观认识一下牛顿迭代法。</p>\n<h3>认识牛顿迭代法</h3>\n<p>我们还是以方程$x^2-a=0$为例，假设此时$a=2$，那我们要求的就是$\\sqrt{2}$的值。这个时候，$x^2-a=0$方程可以看作是一个函数$f(x)=x^2-2$，而我们想要求的值就是$f(x)=0$时x的值，也就是这个函数图像和x轴的交点。</p>\n<p>在迭代法中，我们可以从任意一个值不断迭代到正确的值。假设，这次我们从$x_0=2$这个点开始迭代。</p>\n<p><img src="https://static001.geekbang.org/resource/image/a8/aa/a8c472b14c417eb7121c5860903999aa.jpeg" alt="" title="图1 函数示意图" /></p>\n<p>如上图，橙色的那个点就是目标值，而上面那个黑色的点就是我们设置的$x_0=2$时的初始值$x_i$。根据上面的图像，我们每一次迭代都要将$x_i$向目标值逼近，那怎么逼近效率最高呢？当然是按照切线去逼近，也就是说，我们要按照函数在$x_i$点上的切线来逼近。</p>\n<p>既然是函数图像的切线，我们就要知道函数的导数。在这个问题中，$f(x)$的导数为：$f\'(x)=2x$。经过推导，这个切线的方程就是$f\'(x)=4x-6$。由此，我们知道这条切线和x轴的交点为<code>(1.5, 0)</code>。</p>\n<p><img src="https://static001.geekbang.org/resource/image/b5/cc/b5324fd220dcd44ed58161483d2082cc.jpeg" alt="" title="图2 牛顿法第一次迭代" /></p>\n<p>看到了吗，一下子$x_i$就离目标值近了这么多。接着，我们就以（1.5, 0）这个点为新的起点，再按照上面的方式用切线逼近一次，就能得到下面的效果。</p>\n<p><img src="https://static001.geekbang.org/resource/image/0f/88/0f5c406b65c694687a813bc9ddb8ff88.jpeg" alt="" title="图3 牛顿法第二次迭代" /></p>\n<p>如果我们不把这个图片放大，你甚至都无法区分这两个点。这个时候，新的点变成了$[1.41\\dot{6},0]$，精度实际上已经达到了小数点后2位。实际上，有人计算过，按照这种方式来迭代，每一步能增加3位的精度，这是非常强大的。</p>\n<p>好了，牛顿迭代法的过程讲完了，我们一起来总结一下，主要有3步：</p>\n<ol>\n<li>\n<p>选取一个初始值$x_0$，以它作为迭代的起始；</p>\n</li>\n<li>\n<p>求出函数在点$(x_i, f(x_i))$处的切线（i从0开始）与x轴的交点，让它作为新的$x_i$；</p>\n</li>\n<li>\n<p>反复执行第2步，直到得到符合精度要求的结果为止。</p>\n</li>\n</ol>\n<p>这个过程用公式表示就是，我们先得到函数$f(x)$在$x_i$处的切线方程为$f(x_i)+f\'(x_i)(x-x_i)$</p>\n<p>然后，我们要让$x=x_{i+1}$的时候，上面这个式子等于0。此时，公式为：$f(x_i)+f\'(x_i)(x_{i+1}-x_i)=0，则x_{i+1}=x_i-\\frac{f(x_i)}{f\'(x_i)}$，这个公式就是牛顿迭代法的核心。</p>\n<h3>牛顿迭代法和二分法对比</h3>\n<p>好了，理解了什么是牛顿迭代法，那它是怎么实现<code>sqrt</code>的呢？事不宜迟，我们把牛顿迭代法先带入到<code>sqrt</code>对应的那个方程中，则有：</p>\n<p>$$<br />\n\\begin{aligned}<br />\nx_{i+1} &amp;=x_{i}-\\frac{x_{i}^{2}-a}{2 x_{i}} \\\\\\<br />\n&amp;=\\frac{2 x_{i}^{2}-x_{i}^{2}+a}{2 x_{i}} \\\\\\<br />\n&amp;=\\frac{x_{i}+a / x_{i}}{2}<br />\n\\end{aligned}<br />\n$$</p>\n<p>对应的实现代码如下：</p>\n<pre><code>C++\nfloat newton_sqrt(float x) {\n    float y = x;\n    float last;\n    while (abs(y - last) &gt; eps) {\n        printf(&quot;%.7f\\n&quot;, y);\n        last = y;\n        y = (y + x / y) / 2.0f;\n    }\n    return y;\n}\n\n</code></pre>\n<p>接下来，我们再来看一下，同样初始值的情况下，利用牛顿迭代法求取$\\sqrt{2}$的迭代次数：</p>\n<pre><code>CQL\n2.0000000\n1.5000000\n1.4166667\n1.4142157\n1.4142135\n</code></pre>\n<p>没错，我们仅仅经过5次迭代，就能计算出高于<code>1e-6</code>精度的结果。这不仅比二分法迭代次数少，计算结果的精度还高。如果我们的精度要求更高的话，二者的差距会更加大。实际上，有人确实做过二分法和牛顿迭代法在求<code>sqrt</code>的迭代次数对比，如下图：</p>\n<p><img src="https://static001.geekbang.org/resource/image/83/17/83188b1b8f6eb7f0a9416ba8cc697a17.jpeg" alt="" title="图4 牛顿法和二分法对比" /></p>\n<p>从上面这张图中我们可以看到，虽然有个别数二分的迭代次数要比牛顿迭代的迭代次数少一些，但整体上，牛顿迭代法的发挥非常稳定，迭代次数是二分迭代法的1/3~1/2。</p>\n<p>这就是牛顿迭代法的全部内容了。牛顿迭代法是最优化理论中一个非常重要的基础算法，它在机器学习领域中也起到了很重要的作用，比如条件随机场的一种优化方法，使用的就是根据牛顿法进一步而提出来的拟牛顿法，这里我就不展开了。</p>\n<h3>牛顿迭代法的应用</h3>\n<p>看到这里，你可能会有一个疑问，最开始我们说的明明是要在$O(1)$的时间复杂度求解<code>sqrt</code>，但是上面的牛顿迭代，一个明晃晃的<code>while</code>循环摆在那里，显然不是$O(1)$的时间复杂度啊，这不是有点儿标题党的嫌疑吗？实际上，如果我们真去测试牛顿迭代法实现的函数，它和系统的<code>sqrt</code>函数相比，在性能上还是有一定差距的。</p>\n<p>别着急，接下来就是见证牛顿迭代法力量的时刻了。这里，我想给你讲一个故事，这个故事是发生在游戏引擎中的。上世纪90年代，计算机的性能远没有当今这么发达，那个年代的计算机，别说是运行一个流畅的3D画面的游戏，想要渲染一个流畅的3D动画，都足以让人惊叹一番。这时，有一款游戏横空出世，它就是雷神之锤3，它的画面在那个年代非常不错，同时又可以在低配置的PC上运行，这都归功于一个名为约翰·卡马克（John Carmack）的人开发的3D引擎。而后来，在这个3D引擎开源之后，有人打开了它的数学库，找到了一段神奇的代码：</p>\n<pre><code class="language-C++">\nfloat Q_rsqrt( float number )\n\n{\n\nlong i;\n\nfloat x2, y;\n\nconst float threehalfs = 1.5F;\n\nx2 = number * 0.5F;\n\ny = number;\n\ni = * ( long * ) &amp;y; // evil floating point bit level hacking\n\ni = 0x5f3759df - ( i &gt;&gt; 1 ); // what the fuck?\n\ny = * ( float * ) &amp;i;\n\ny = y * ( threehalfs - ( x2 * y * y ) ); // 1st iteration\n\n// y = y * ( threehalfs - ( x2 * y * y ) ); // 2nd iteration, this can be removed\n\n#ifndef Q3_VM\n\n#ifdef __linux__\n\nassert( !isnan(y) ); // bk010122 - FPE?\n\n#endif\n\n#endif\n\nreturn y;\n\n}\n\n</code></pre>\n<p>这段代码求的是$\\frac{1}{\\sqrt{n}}$，我们能看到，它使用的显然就是牛顿迭代，但它仅仅进行了一次运算就结束了，它求解$\\sqrt{2}$的结果是1.41456711。</p>\n<p>看到了吗，一次运算就精确到了小数点后3位，这相当于牛顿迭代法的第4步。你可能会觉得，这个可能就是巧合，那我们再找一个数看一下，比如$\\sqrt{15}=3.872983346207417$，牛顿迭代法的结果是3.87971568。我们发现，这次的精度稍微差了一些，只精确到了小数点后2位，但也相当于牛顿迭代法的第4次迭代了。</p>\n<p>经过这两次实验，相信你也看出来了，这个方法里面最大的玄机就是他所选择的这个初始值，即<code>i = 0x5f3759df - ( i &gt;&gt; 1 );</code>。</p>\n<p>那初始值究竟是怎么计算出来的呢？我们看这一行代码上面的其他操作，计算机存储浮点数的规则是用bit来表示浮点数，浮点数是32bit存储的数据。一个浮点数x，它在计算机中的存储方式是，最高位是符号位，紧接着8bit是指数位$E_x$，最后23bit是有效数字位$M_x$。</p>\n<p>因此，一个浮点数在计算机中的存储数据可以看作是，$x=1.M_x\\times2^{E_x-127}$（注意，指数上的那个<code>-127</code>是考虑到指数也可以有正有负做出的权衡）。这样一来，将一个浮点数表示成为一个整数就可以是：$I_x=2^{23}\\times E_x+M_x$。然后，我们才能去筛选初始值。在选择初始值之后，我们再将初始值用浮点数表示的方法转换回来，就可以开始牛顿迭代了。</p>\n<p>但是，这个神秘的初始值常数<code>0x5f3759df</code>究竟是怎么被选出来的，我们还是不知道，这也很可会成为一个永远的谜团了。曾经，有一位数学家试图去研究这个猜测之有什么奥秘，在精细的研究和实验过后，他从理论上推导出来了一个最佳猜测值，<code>0x5f37642f</code>，但是在实际计算中，使用这个数值却没有卡马克的数值快，也没有它精确。</p>\n<p>最后，那位数学家一怒之下，使用暴力枚举的方法，才找到了一个比卡马克的数字稍微一丁点儿的数字<code>0x5f375a86</code>，但是谁也解释不了这个数字的来源，所以也没有人能解释卡马克是怎么样想到的那个猜测值的。因此还是归结到那句话：我们要永远对力量抱有敬畏之心。</p>\n<h2>课程小结</h2>\n<p>这节课，我们学习了快速求解方程的解的牛顿迭代法，它的实现过程可以总结为三步。首先，我们要选取一个初始值$x_0$，以它作为迭代的起始。然后，我们要求函数在点$(x_i, f(x_i))$处的切线（i从0开始）与x轴的交点，让它作为新的$x_i$。最后，我们反复执行第2步，直到得到符合精度要求的结果为止。</p>\n<p>我们要记住$x_i+1$的公式，它是牛顿迭代法的核心。利用它，我们去实现了<code>sqrt</code>函数。在同样初始值的情况下，使用二分迭代法的迭代次数是牛顿迭代的2~3倍。</p>\n<p>不过，牛顿迭代法虽然可以快速求解方程，但是这个方法也有一定的局限性，比如说，方程如果存在多个解，牛顿迭代法可能无法完整求解。</p>\n<p><img src="https://static001.geekbang.org/resource/image/fb/4b/fbcf1ee759f58d389ecd41e89b3e234b.jpeg" alt="" title="图5 多解情况" /></p>\n<p>再比如说，方程的解对应的点如果是不可导的，如绝对值函数、三次开方函数，那么牛顿迭代法是无法收敛的。</p>\n<p><img src="https://static001.geekbang.org/resource/image/b0/eb/b08fee5ac1a8e1e8c98e766021e4d8eb.jpeg" alt="" title="图6 三次开方函数" /></p>\n<p>以及，如果初始值我们恰好选择在了某一个极值点上，它的导数会是0。</p>\n<p><img src="https://static001.geekbang.org/resource/image/12/75/12c77b83f3f1yy9d1d3621a52ee90975.jpeg" alt="" title="图7 驻点" /></p>\n<p>总的来说，虽然牛顿迭代法在求解方程根的时候非常有优势，但我还是希望你能结合它的局限性来灵活应用。</p>\n<h2>课后练习</h2>\n<p>请使用牛顿迭代法试着求解你所熟悉的其他函数，并把程序实现出来。</p>\n<p>欢迎在留言区分享你的答案，也希望你能把这节课的内容转发出去。那今天就到这里了，我是胡光，我们下节课见！</p>\n',
        article_title: "24 | 牛顿迭代：如何用O(1)的时间复杂度求sqrt？",
      },
      {
        title: "25 | 毕业设计：用O(1)的时间复杂度计算整数末尾0的数量",
        herf: "https://time.geekbang.org/column/article/298424",
        id: "298424",
        content:
          '<p>你好，我是胡光。今天是进阶篇的最后一节课了，首先，我们恭喜坚持学到这里的同学，你马上就要从这门课毕业了。在正式毕业之前，为了能让你将前面所学的内容应用起来，学以致用，这节课我们会一起来完成一个实战题目。</p>\n<p><span class="orange">我们先来看今天要解决的问题：在$O(1)$的时间复杂度内，求一个以二进制表示的整数末尾有多少个0。</span></p>\n<p>如果没有时间复杂度的限制，这个问题看上去非常地简单，我们只需要按照下面这么做，最后<code>count</code>就是末尾0的计数。这个方法的时间复杂度是$O(\\log_2N)$，它和我们所要求的时间复杂度相去甚远，而且这个解法也远远达不到我们毕业设计的要求。这该怎么办呢？</p>\n<pre><code>while ((n &amp; (1 &lt;&lt; count)) == 0) {\ncount += 1;\n}\n</code></pre>\n<p>我们继续来看这个题，既然是想要求这个整数二进制表示末尾有多少个0，那我们是不是可以将这个整数二进制表示的最后一个1取出来。比如说，一个数的二进制表示是<code>101001000</code>，我们就取出<code>1000</code>，设最终0的个数是count，那取出最后一个1，我们得到的数一定是$2^{count}$，我们直接对这个数使用<code>math</code>库里面的函数取对数，或者干脆用哈希表来存储，每次查表就可以了。这个方法看起来是可行的，那么我们要解决的问题就是，怎样得到二进制表示的最后一个1。在讲具体的解决方法之前，我们先来复习一下计算机中存储整数的方式，看看能不能从中得到启发。</p>\n<h2>计算机中存储整数的3种方式</h2>\n<p>在之前的课程中我们讲过，有符号的整数在计算机中存储的方式是最高位是符号位，0为正数，1为负数，后面的31bit存储的是这个数的真值。我们前面的例子中，也都是以正整数为例。但实际上，计算机在存储数据的时候还有其他的形式， 也就是我们接下来讲的3种方式。</p>\n<ol>\n<li>原码：数字转换成二进制就是原码，只是正数的符号位是0，负数的符号位是1。</li>\n<li>反码：正数的反码是它本身，负数的反码是除符号位外全部取反。</li>\n<li>补码：正数的补码是它本身，负数的补码是反码加1。</li>\n</ol>\n<p>我们以8bit长度的整数为例，分别来看看<code>18</code>和<code>-18</code>的原码、反码和补码：</p>\n<p><img src="https://static001.geekbang.org/resource/image/80/92/80217ff17874f95603ded7cf459d9392.jpeg" alt="" /></p>\n<p>那你可能要问了，计算机为什么要把事情搞得这么麻烦呢？直接用原码不就可以了吗？这是因为，虽然我们在对整数做运算的时候有基础的四则运算，以及各种各样的数学运算，但计算机远远没有我们这么聪明，它只能做加法运算。计算机的四则运算和取模运算，都是依靠加法运算来实现的，反码和补码就是这种限制之下的产物。</p>\n<p>换句话说，我们在原码整数上，直接进行加法是完全没有问题的，但如果正数和负数的原码直接相加就会出现问题。比如说，在上面的例子中，<code>18</code>和<code>-18</code>相加应该等于0，但如果我们直接使用原码相加就会等于<code>-36</code>，使用反码相加就会变成<code>-127</code>。使用补码相加会稍微复杂一些，因为补码中是以最低位的1为分界线，高位全都互反，而低位全都是0，两个数相加之后，会把前面有效位上的1全都抵消掉，最终结果就是0。我们发现，只有使用补码的方式才能得到正确的计算结果。</p>\n<p>我们再看一个补码的计算例子，这次，我们要计算<code>18-5</code>，在计算机中就是<code>18+(-5)</code>，而18的补码表示是<code>0 0010010</code>，-5的补码表示是<code>1 1111011</code>，最终的结果<code>0 0001101</code>也就是13。</p>\n<p><img src="https://static001.geekbang.org/resource/image/89/a1/8970393b6f508889576c60ef24072ca1.jpeg" alt="" /></p>\n<p>因此，补码的存在使得四则运算变成了可能，所有的数在计算机中的存储方式也都应用了补码。</p>\n<p>利用补码之后，我们要解决的题目就变得简单得多了。对于正整数<code>x</code>，它在计算机中的存储是它本身的二进制表示，而<code>-x</code>在计算机中的存储则是将它取反之后再加上1，即<code>-x+1</code>。一个数取反之后，它的二进制表示中，最低位的那个1会变成0，从它往低全都变成了1，而加1之后，最低位1的那个bit还会变成1，从它往低又全都变成了0。</p>\n<p><img src="https://static001.geekbang.org/resource/image/53/8b/53851b917fae3yyfcb26cdfee4586c8b.jpeg" alt="" /></p>\n<p>也就是说，<code>x</code>和<code>-x</code>在计算机中的表示，以<code>x</code>的二进制表示中最低位的1为界，从它开始，低位全都一样，高位全都互反，所以我们可以通过x &amp; (-x)，就能取出最低位1。这样一来，我们就能得到我们今天题目的最终解决代码log2(n &amp; (-n));。</p>\n<p>这个时候看上去，我们已经实现了题目的要求，但无论是去对数操作还是去查哈希表，实际上它们都不算是快速的原子操作，就算是$O(1)$和$O(1)$之间也是有区别的。那你可能要问了，都是$O(1)$为什么还要在乎那点儿区别呢？当然要在乎，例如在游戏领域中需要高时效、频繁调用的时候，一点细微的差别对用户来讲都是很显著的差异。那么针对这个问题，我们有没有更快的解决方法呢？</p>\n<h2>De Bruijn序列</h2>\n<p>你还记得，上节课我们在求<code>sqrt</code>的时候，最后讲到的那一段代码吗？在那一段代码中，我们用了真$O(1)$的时间复杂度求得了结果，但是也得到了一个永久的谜团：<code>0x5F3759DF</code>到底是啥。今天，我们再来见证来自斯坦福的另一股神秘力量，位扫描解法：</p>\n<pre><code>unsigned int v; // find the number of trailing zeros in 32-bit v\nint r; // result goes here\nstatic const int MultiplyDeBruijnBitPosition[32] =\n{\n0, 1, 28, 2, 29, 14, 24, 3, 30, 22, 20, 15, 25, 17, 4, 8,\n31, 27, 13, 23, 21, 19, 16, 7, 26, 12, 18, 6, 11, 5, 10, 9\n};\nr = MultiplyDeBruijnBitPosition[((uint32_t)((v &amp; -v) * 0x077CB531U)) &gt;&gt; 27];\n</code></pre>\n<p>利用这一段代码，我们就可以在真$O(1)$的时间复杂度下，求出一个整数的二进制表示中末尾有多少个0。不过，这一段代码中又出现了一个神秘的常量：<code>0x077CB531</code>。现在，我们就来研究一下这个常量是怎么来的。</p>\n<p>首先，一个整数是以32bit的长度存储在计算机中的，如果不算符号位，它的最高5位，一共有多少种情况呢？自然是32种情况，从<code>00000</code>到<code>11111</code>。我们将常量<code>0x077CB531</code>展开成二进制表示，就是<code>00000111011111001011010100110001</code>。我们将它看作是一个循环的圆，然后从中依次取出相邻的5个bit，如下图：</p>\n<p><img src="https://static001.geekbang.org/resource/image/08/50/085f5586f57dbef42999531e2db0dd50.jpeg" alt="" title="图1 位循环表示" /></p>\n<p>这个时候，我们就发现了一个问题，我们取出的这些数刚好是从<code>00000</code>到<code>11111</code>的所有数，既没有重复，也没有遗漏。这样的序列被称作<em>De Bruijn</em>序列。它的定义是，<code>B(n, k)</code>为n个元素组成的一个循环序列，在这个循环序列中所有长度为k，且由n个元素构成的序列都在它的子序列中，且仅出现一次，那<code>0x077CB531</code>这个常量的二进制表示就是<code>B(2, 5)</code>的一个序列。</p>\n<p>上面的代码我们就可以这样来解释：我们去看这个常量乘上了一个$2^x$之后，它的前5bit是什么。由于这个常量中，每一个长度为5的窗口互相之间都是不一样的，或者说，每一个长度为5的窗口都只对应了一个<code>x</code>，因此，它们就可以用一个长度为32的数组存储起来了。</p>\n<p>这样一来，当我们将整数<code>n</code>最低位的1取出与常量相乘，再查看它前5位的时候，直接查表就可以找到那个对应的<code>x</code>，即<code>n</code>的二进制表示中末尾0的位置。</p>\n<p>这么说你可能还不理解，我们来看一个具体的例子。比如说整数104，经过计算就是<code>104 &amp; -104 = 8</code>，也就是<code>1000</code>，因为8=2^3，所以需要把它左移3位：</p>\n<p><img src="https://static001.geekbang.org/resource/image/82/a7/82132db1bcf58d3cyyddfc57ea8c38a7.jpeg" alt="" /></p>\n<p>我们看到它的前五位是<code>00111=7</code>，查表可以看到<code>MultiplyDeBruijnBitPosition[7]=3</code>，结果是正确的。那如果左移超过了27位呢？其实也没有关系，这个常量的前5位都是0，左移也是用0来补低位，所以刚好形成了循环。</p>\n<p>上面我们解释了这个常量的意义，那根据这个常量的意义，接下来我们就要来看，这个常量我们可以用什么样的方式来得到呢？</p>\n<p>遇事不决用搜索，至少搜索能够帮助我们尝试出下面这种可能性。</p>\n<p>首先还是要确定<strong>状态</strong>。想要构造出来这样一个常量，最基本的单元就是那个长度为5的窗口，也就是说，这个问题里面有32种状态。接下来<strong>状态转移</strong>：我们从一个窗口转移到相邻的另一个窗口是什么样的操作呢？自然就是左移一位之后在最右边补一个0或者1，或者右移一位之后在最左边补一个0或者1。所以，在这些状态中，如果某一个状态u的前4位和另一个状态v的后4位是一样的就可以转移。比如，<code>10001</code>和<code>00011</code>就是可以转移的，只考虑向右侧补位可以连边的话，我们就能得到一个图，这个图就叫做<em>De Bruijn图</em>，我们用一个简单的版本<code>B(2, 3)</code>为例：</p>\n<p><img src="https://static001.geekbang.org/resource/image/b4/19/b4dc9edaf9e20ec3e17c8f268ec0ca19.jpeg" alt="" title="图2 DeBruijn图" /></p>\n<p>接下来，我们只需要找到一条回路，即这条路的起点到终点都一样，且途经这个图中所有的点一次。也就是说，我们如果在这个图中找到一条<strong>汉密尔顿回路</strong>（上图中红色的箭头），就可以构造出来一个常量。</p>\n<p>很遗憾，汉密尔顿回路问题是一个<strong>NP完全问题</strong>。也就是说，我们没有有效的方法能够快速找出它（该问题不存在多项式时间解法）。这该怎么办呢？我们可以把图中的思路稍微修改一下，如果我们把状态值和状态转移上补位的那一个数，直接变成边的编号呢？比如<code>000</code>和<code>001</code>之间的那条边，我们就编号成为<code>0001 =1</code>，<code>101</code>到<code>011</code>就编号成为如下图：</p>\n<p><img src="https://static001.geekbang.org/resource/image/58/ed/58a30ed02dede8cac9c4b6b46491daed.jpeg" alt="" title="图3 DeBruijn欧拉图" /></p>\n<p>我们发现，图里面刚好有16($2^4$)条边，而且每一个边的编号还都是不一样的，它们刚好对应了窗口为4的所有情况。这是不是就说明，如果我们能够找到一条回路，它途径这个图中所有的边一次，就找到了一个新的序列<code>B(2, 4)</code>呢？没错，这个回路就是<strong>欧拉回路</strong>。而<a href="https://baike.baidu.com/item/%E6%AC%A7%E6%8B%89%E5%9B%9E%E8%B7%AF/10036484?fr=aladdin">欧拉回路</a>就有比较快速的解决方法了。欧拉回路的具体概念你可以课后自己去深入学习，对于今天的问题，我们只需要了解到这里就可以了。</p>\n<p>由此，我们就能看出来一个规律，就是<code>B(n, k)</code>对应的汉密尔顿回路和<code>B(n, k - 1)</code>对应的欧拉回路是等价的。回归到今天的问题中，我们想找到那个神秘的常量，只需要找到<code>B(2, 4)</code>对应的图中的欧拉回路就可以了。</p>\n<h2>小结</h2>\n<p>今天，我们一起解决一个问题，就是在$O(1)$的时间复杂度内，求出一个以二进制表示的整数末尾有多少个0。</p>\n<p>为了解决这个问题，我们先复习了计算机中存储整数的三种方式，分别是原码、反码和补码。利用它们，我们就能快速地找出整数的二进制表示中最低位的1了，然后我们针对$O(1)$的时间复杂度，提出了取对数和哈希表两种常规方案。</p>\n<p>最后，我又通过斯坦福大学的位扫描解法，为你详细讲解了De Bruijn序列和求取De Bruijn序列的De Bruijn图。我们通过De Bruijn序列的特殊性质，完成了效率更高的$O(1)$解法，希望你能够通过这个例子，学会其中所蕴含的算法思维。</p>\n<h2>课后练习</h2>\n<p>最后，我希望你能自己来完成这个问题的求解流程，为我们整个课程的画上一个完美的句号。</p>\n<p>好了，今天的内容就到这里，欢迎你把实现的求解流程写到留言区，我是胡光，我们下节课见！</p>\n',
        article_title: "25 | 毕业设计：用O(1)的时间复杂度计算整数末尾0的数量",
      },
    ],
  },
  {
    chapterTitle: "结束语 (1讲)",
    children: [
      {
        title: "结束语 | 不忘初心，方得始终",
        herf: "https://time.geekbang.org/column/article/299180",
        id: "299180",
        content:
          '<p>你好，我是胡光。</p>\n<p>今天，是我们这个专栏的最后一节课。在这节课中，我们不谈算法，谈谈这个专栏的初心。</p>\n<p>在这门课里，我们讲了很多经典的算法，从排序到数据结构、搜索、位运算，再到最后两段神奇的代码。每一个模块，我们都是从问题出发，再去一步步地解决这个问题。但这短短25节课，不可能覆盖到所有算法，尤其对现如今的计算机领域来说，问题总是比算法要多。所以这25节课的内容，仅仅是沧海一粟，甚至可能也无法覆盖到你当前最迫切的需求。</p>\n<p>那你有没有想过一个问题，我们学习这门课，最终到底是为了什么？</p>\n<p>答案就是之前我一直在提的一个词，算法思维。算法思维是什么意思呢？其实就是指算法在被设计出来之前，设计者究竟在想什么？你可以回想一下我讲解每一个算法的过程，其实我都会试图去拆解这个算法想要解决的问题是什么，有什么样的思路，去剖析算法中每一个核心改动的思考来源是什么，或者说<strong>我们在试图还原算法设计者在解决这个问题的思路</strong>。这才是这个专栏中，我最想要带给你的东西。</p>\n<p>在武侠小说中，顶级的高手往往是在一定程度上洞悉了武功的本质，有着超强武学境界的人。比如萧峰，论内功并非顶尖，但仅仅使用一套太祖长拳，就可以杀遍聚贤庄的高手，可以将降龙廿八掌变成威力加倍的降龙十八掌。哪怕是令狐冲，他所使用的独孤九式，这种完全从技巧、招式出发的武功，到了最终的破气式上，还是要归结到武学境界上。武侠小说中的武学境界，到了计算机中就是算法思维。</p>\n<p><strong>所以，我希望你在学习这门课程，或者在学习算法的过程中，不要去纠结到底学会了多少书本上的算法知识，而是你是不是学会了去分析、去理解算法中所蕴涵的算法思维。</strong></p>\n<p>同时，我也希望你不要去纠结我学了这个东西有什么用，比如有的同学会留言问我，”老师，这个算法我在实际中工作用不上啊“，或者“老师，这个题目我在刷题的时候也没刷到啊”，甚至可能还有同学会想，“老师，这个题目我在面试中也没被问到过啊”。</p>\n<p>我完全理解这些同学的想法和心理，但是算法思维不是为了我们传统意义上的“有用”而服务的，而是为了提升你的境界，提升你解决问题的能力。就拿刷题来说，题目总是刷不完的，每天都会有无数的新题产生，那你能找到合适的老师去学习所有新题的解法和技巧吗？当然是找不到的。这个时候，算法思维就能保证在碰到了新问题时，你可以有办法去解决它。</p>\n<p>我们再拿面试举个例子，面试的时候，面试官从来都不是在考察你的记忆力，他其实就是在考察你的算法思维能力，你的基本功，以及你解决问题的能力。</p>\n<p>当然了，不仅仅是计算机，在很多其他的领域，洞悉了本质的人往往也会走得更远。比如说，克劳德·香农建立了信息量这个概念，让很多事情变成了可能。再比如说学习一门语言的人，如果看到了这个语言本身的语言学特征，学起来就会更加容易。</p>\n<p>如果你迷茫于怎么样去得到这种思维，怎么样去提升境界，不妨从利用我前面讲到的几种思维方式去解决眼前的一个个问题开始，看能否打破已经学过的算法给你带来的思维定势，去设计出解决问题的好方法。</p>\n<p>到现在为止，我们的专栏就告一段落了。今天，我希望你能记住一句话，算法思维，让我们在面对新问题的时候不会手足无措，是我们披荆斩棘最有力的武器。</p>\n<p>最后的最后，我还为你准备了一份<a href="https://jinshuju.net/f/e758l6">毕业调查问卷</a>，题目不多，希望你能花两分钟的时间填一下。一起走过了这些时间，期待听到你对我和这个课程的反馈和建议！</p>\n<p>我是胡光，江湖很大，我们有缘再见！</p>\n',
        article_title: "结束语 | 不忘初心，方得始终",
      },
    ],
  },
];
