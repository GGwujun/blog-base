exports.category = "other";
exports.title = "数据分析思维课";
exports.data = [
    {
        "chapterTitle": "开篇词",
        "children": [
            {
                "title": "开篇词 | 数据给你一双看透本质的眼睛",
                "id": 400737,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>先和你简单介绍一下我自己。我本科和研究生都就读于北大的计算机系，专业是数据仓库和数据挖掘。毕业后，我待过不少的公司，从Teradata到  IBM，从中金到万达到联想研究院再到易观，职位也从数据架构师、数据部总经理到最后的CTO。在数据这个行业里，我一做就做了二十多年，数据已经成为了我生命中不可分割的一部分。</p><p>我经常听到这样一句话：“数据是客观的，但是解读数据的人是主观的”。在我看来，数据这门科学就像中西医混合的一门医学，既要有西医的理论、分析模型以及实验，又需要有中医的望闻问切这些个人经验。</p><p>我们都生活在一个由数据组成的世界里，不管是工作还是过日子，数据其实无处不在。我觉得我还算是一个“中西结合”的人，所以我想把自己的西医部分（数据科学理论）与中医部分（个人数据经验）一并分享给你。</p><h2>数据时代 ，思维为王</h2><p>前段时间，我的一个游戏分析师朋友告诉我，他的公司做了款游戏，这款游戏很受欢迎，他们分别开发了安卓、iOS、Pad等等版本。他分析了已有的付费数据，发现安卓用户的付费率要高于iOS用户，所以他得出结论：在公司开发资源有限的情况下，他们应该投入更多精力（或者提高优先级）优化安卓版本。</p><!-- [[[read_end]]] --><p>我听完之后，倒吸一口凉气。这个决策执行下去，这个公司可能在投入了很多Android开发工作后，却无法有更多的收入回报，最终导致这个很有前途的小公司破产。</p><p>你知道他是在哪里出错了吗？我给你一个提示：这个数据本身没问题，但是分析数据的逻辑出了问题，他犯了数据分析行业都熟知的叫“<strong>辛普森悖论</strong>”的错误。还不知道什么是“辛普森悖论”吗？不要担心，我会在后面的课程详细跟你讲。</p><p>这些年，随着技术的发展以及时代的变换，我也经常感叹，现在的数据真是比以前更容易获得和计算了——我们有最强大的计算工具、分析算法和浩如烟海的大数据。</p><p>但是，当我们沉醉于数据量之大、算法之精美时，却可能忘记了做数据分析的初衷和最基本的逻辑。你可要知道，不管是大数据还是小数据，只有经过客观合理地分析之后，才能真正产生价值。</p><p>所以我认为，<strong>在这个数据为王的时代，我们缺乏的不是工具、算法，而是数据思维</strong>。这就好比过去，我们打猎用的是弓箭，看见了兔子就去射箭，虽然效率低，但是目标很明确。而现在我们拿着最高级的冲锋枪冲进了森林里，一通乱扫，却不知道打什么。</p><p>我希望这门课程，不仅能告诉你打什么，还能教会你弹无虚发、百步穿杨。</p><h2>开这门课的初心</h2><p>在我过去20年的数据相关工作里，我曾经因为追求极致的技术而没有交付最终的业务结果，最后被老板一通批评；我也曾拿着一个片面的数据分析结果就给出了一个全面的分析解读答案；我还曾经在做管理决策的时候，用一个平均值来去看整体的收入状态和开发迭代速度，导致错失一些优秀的人才和客户；更有时候，我在听汇报的时候，没有甄别出来小伙伴写出来的因果倒置或者一些存在“幸存者偏差”的结论数据，导致走了弯路。</p><p>这些我经历过的教训，让我也意识到数据分析的常识非常重要。我开这门《数据分析思维课》的初衷就是希望能够用简单的生活和工作当中的例子，结合数据分析的原理，帮助你培养数据思维。</p><p>就如我们前面所说，有了数据是第一步，你怎么分析数据，那就是另外一门学问了。在分析数据的时候，你有没有掌握基本的数据分析方法，有没有站在前人的经验之上思考问题，也会决定着你做这件事情的段位，我希望我能通过这个专栏把这些逻辑都告诉给你。</p><p>在这门课当中，我不会“罗列”特别多的公式、复杂的推理、大量的程序等。我只是希望用各种各样的例子告诉你怎样用数据分析的角度来看待这个世界，与此同时也教会你一些数据分析最基本的知识。</p><p>当你学完这门课以后，我希望的效果是：<strong>你再看待同一件事情的维度和以前不一样了，你可以用数据的维度来诠释你身边发生的事情，用数据的思维来做出你的判断。</strong></p><p>为什么我把它做成这样一个通识课的类型，而不是一个专业课呢？我是这么考虑的：如果你知道自己需要什么，比如需要某一个深入的专业领域知识，那么你可以直接到网络搜索引擎去找，或者在“极客时间”里搜索相关的专业课。</p><p>而实际情况往往是你可能并不知道自己需要什么，或者怎么用数据分析去诠释一个问题。这时，你就需要有一门课把这些数据分析的相关知识串起来，扩大自己的认知边界，知道原来还可以利用这样的想法来分析这个问题。</p><h2>你可以从这门课里得到什么</h2><p>做这门课的时候，我给自己定的第一个原则就是“场景化”。我讲的这些不应该是一些需要死记硬背的概念，而是你曾经经历、或者触手可及的案例。</p><p>所以在整个这门课的一开始，我会先将数据分析的基础概念和实际生活结合，让你能够轻松识别生活里的那些“伪科学”和“伪数据”。</p><p>然后我会给出基于这些数据分析基本概念的思路，和你分享一些常见的数据分析算法，去帮助你了解人工智能时代下的数据分析是怎样玩的，这其实是数据分析基础的延伸。</p><p>除此之外，我还会告诉你怎样去用数据和算法来分析解决一些具体的问题并做出实战。也会推荐给你一些我自己常用的分析工具以及这些工具的使用技巧。这样你可以快速地把前面的那些理论，直接应用你的实际工作和生活当中，提高你和数据相关的工作效率，让你在分析管理上也更加得心应手。</p><p>数据分析非常复杂，它融汇了数学、统计学、计算机科学、管理学等一系列的学科。</p><p><img src=\"https://static001.geekbang.org/resource/image/8d/de/8d7e78dae9a1130166811550d59c20de.jpg?wh=1928x1305\" alt=\"\"></p><p>这门课只是一个入门，无论你是文科生还是理科生，无论你是程序员还是产品经理，无论你是高管还是普通的初出茅庐的学生，通过这门课，我都希望能让你对数据分析产生兴趣，让你具有数据思维，以后不管是面对生活还是工作，都可以有一双通过数据看透事物本质的眼睛。</p><p>当然，我想强调的是，并不是说只有工作场景才能用到这些数据分析知识，也并非有了大数据才能用到这些知识，数据分析应该是渗入到我们生活的每一个场景里。</p><p>比如去赌场玩俄罗斯轮盘，连续10次开小了，你心里可能会觉得连续10次小了，下一次开大的概率更高一些，然后就去押大，那实际上大的概率真的会高吗？听过后面的课后，你就会明白，这是典型的“<strong>赌徒谬误</strong>”，是错误的。</p><p>再比如，你带了一个十人的团队，每个人都有自己的优缺点和性格，每次一提到团队管理你就头大，因为内心总是混乱的，没有一条主线。但是不知道你想过没有，这十个人也是数据，你可以根据“四象限法”对他们进行分类，能力是纵轴，意愿是横轴……最后看看谁是你最应该提拔的人才。</p><p>所以，其实只要你有心，生活之中，处处都藏着数据的学问。</p><p>最后，我再重复下我的核心观点：<strong>这世界缺的真不是算法和技术，而是能用算法、技术解决实际问题的人。</strong>我希望能把自己学习到的诸多课程、项目的经验和阅读的大量书籍浓缩一下，深入浅出地用比较朴实和简单的语言让你理解什么是数据分析，以及怎么在自己的生活和工作当中更好地利用好数据做出更有效的决策。</p><p>“数据是有灵魂的，我将用我一生去追寻它”，这是我的座右铭，我发在这里，和你共勉。也欢迎你加入《数据分析思维课》，从今天开始，我们一起开启数据分析之旅！</p><p>当然，也欢迎你在留言区分享你对于数据的思考，以及你曾经用过的那些数据分析小知识。英国教育家约翰·纽曼曾经说过，最好的教育应该是让年轻人们生活在一起相互学习，我想，留言区就是我们最好的学习场地。</p>",
                "article_title": "开篇词 | 数据给你一双看透本质的眼睛"
            },
            {
                "title": "导读 | 万物背后的规律都是数据",
                "id": 400744,
                "content": "<p>你好，我是郭炜。我是一个特别热爱数据的人，我自己有一个座右铭：“数据是有灵魂的，我将用我的一生去追寻他。”</p><p>从小学开始你就一直在学习和考试，用分数定排名，这些计算离不开数据；你工作了，开始自己挣工资，KPI的评估、年终奖的计算也离不开数据；你结婚了，要去买房，你开始思考等额本息和等额本金哪种贷款方式更适合你，这也是数据；平时和朋友玩牌，牌面现在有两张红桃、一张黑桃，你手里有一张红桃，你开始判断拿到全部红桃的概率、应不应该加注，这也是数据。</p><p>我们生命的点点滴滴，其实都是用数据在记录的。在当今这个时代，我可以说，<strong>人这一辈子都离不开数据。</strong></p><h2>万物背后的规律都是数据</h2><p>数据无处不在，每个人都会觉得自己多多少少懂一些数据。但细究起来，你能够拍着胸脯说自己真正懂数据吗？</p><p>就拿我自己来讲，小时候我和小伙伴赌抛硬币，我觉得硬币有两面，是抛20次至少应该有8、9次是正面向上的，我就跑去和别人打赌抛20次至少8次向上，最后我输得很惨，请了好几顿冰棍。同样地，现在你去澳门赌场去赌大小，大概率也会输得很惨。这背后其实有深层次的数据逻辑和数学理论，你会在接下来的课程里具体学到这个理论——“大数定律”。</p><p>在管理中，我也曾听到部下和我吹嘘，竞争对手现在的平均客单价只有10万，我们的平均客单价有100万，我们服务的都是高端客户。但是我做了用户访谈后发现，我们三、五万客单价的单子还有很多，原来是背后一个1000万的单子拉高了整体的平均值。</p><!-- [[[read_end]]] --><p>如果我没有做深入的用户调研，可能我就会按照100万客单价级别的战略去做相关的规划，进而对公司造成影响。</p><p>我当时由于对平均值理解得不够，差点出了差错。同样，如果你不了解这些数字背后的逻辑，你也很可能会做出错误的决策。基于这件事，我在下节课讲平均值的时候就会告诉你，你天天“被幸福”、“被加薪”就是这样的错误的理念在作怪。</p><p>另外，现在有很多“数据科学家”会给你各种算法预测，更有甚者，直接给你画出一条“增长曲线”告诉你未来投资回报率会有多高，要求你进行基金投资或者你所在的部门增大投入，并告诉根据“大数据算法”进行这些投入之后，就能带你或者公司来多少回报。</p><p>但等你真的投入之后，你才发现这根本就不是一回事。于是，你会下结论说“数据预测”都不靠谱，其实这也是不正确的。毕竟在人家给你的数据报告中既可能有“幸存者偏差”，还有“因果倒置”。所以在接下来的课程里，我希望用通俗易懂的例子让你充分了解这些基本知识，这样在下次“数据科学家”给你号脉的时候，你就可以知道他是“真科学家”还是“伪科学家”。</p><p>所以你看，数据无处不在，<strong>你需要很好地去认识数据，这样才能让数据更好地指导你的生活。</strong>而数据背后的规律是什么呢？它是算法。</p><h2>数据背后的规律是算法</h2><p>现在的数据算法分析和过去的数据算法分析又有所不同，现在有了大数据和小数据之分。有人说，大数据加上人工智能才是一切，而又有人认为小而传统的逻辑数据才是真理。那谁才是对的呢？</p><p>我既做过小数据也做过大数据，在我看来，这两种趋势的结论其实都是对的，只是它的应用场景不同。</p><p>在大数据里面我们针对的是个人的数据，这些数据量虽然很大，但是每行数据蕴含的信息量（也叫熵）很小，所以我们会用很多人工智能的数据挖掘算法，来帮我们在浩如烟海的数据里找到其中的珍珠。</p><p>而小数据往往是在企业经营范围内产生的，他们的数据量很小，但是他们蕴含的数据价值（熵）会非常大，所以分析的时候要更讲究，因为每一个数据背后都蕴含着大量的知识，我们要了解它背后的规律才能掌握数据的命脉。</p><p><img src=\"https://static001.geekbang.org/resource/image/e7/76/e74b89308cf09e2c4cd74648236afa76.jpg?wh=1748x1313\" alt=\"\"></p><p>我来给你举个大数据和小数据的例子。从大数据的方向来说，抖音的推荐算法就是典型的大数据代表。抖音需要在复杂多变的环境找到你喜爱的视频并推荐给你，不断增强你的体验，从而让你爱不释手。如果抖音没有一个很好的推荐算法，其实是很难达到今天的地位的。</p><p>但是对于抖音背后的母公司字节跳动来讲，它的上市数据、经营收入、人员成本这些小数据同样重要。这些小数据会影响字节跳动的整体估值，以及每个员工所持有股票最后变现的金额。</p><p>所以你看，就算对于字节跳动这样大数据浩如烟海的一线大厂来说，大数据和小数据依旧要两手抓。<strong>大数据是业务支撑，小数据是内核动力，两者缺一不可，只是应用的场景不同。</strong></p><p>在这门课里，我既会教你一些小数据的基本概念，也会教你大数据算法的基本原理，让你不再对那些奇怪的专用名词和算法感到陌生，帮你初步迈进数据分析和算法的门槛。</p><h2>数据重要的是分析和表达</h2><p>但是，光知道算法还远远不够。数据有它的复杂性，同样的数据往往可以从很多不同的角度诠释，诠释得特别好的人，我们就可以叫他数据分析师了。此外，作为管理者，也必须要有数据分析的常识，才能透过现象看本质。</p><p>我跟你讲一个典故：平江人李元度本来是一个书生，根本不知道领兵作战。曾国藩命令他领兵出战，每打一次仗便败一次。曾国藩很生气，准备写奏折弹劾他。在他的奏折上便有“屡战屡败”这样的词语。后来曾国藩的幕僚中有人为李元度求情，把“屡战屡败”改为“屡败屡战”，最后李元度因此被免罪。</p><p>你看，同样都是100%的失败，但是不同的解释会让结果完全不同。<strong>数据也是如此，你如何看待这个数据和它背后的解释，往往会让你得到完全不同的结果。</strong></p><p>所以当我们有了数据和算法后，就好比手里拿了一块“璞玉”，还不能够完全发挥作用。我们要通过有效地分析数据、表达数据，从而让数据最终影响到人。在我们整个课程里，我会带着你学习怎样把数据表达得更为清晰，让你成为别人眼里的“数据分析师”。</p><h2>小结</h2><p>好了，这节课到这里也就接近尾声了。这节课其实相当于我们正式进入正课内容的一个小预习，通过这节课，我想告诉你，我们很多人平时很容易对数据想当然，但究根结底，我们对数据还需要进一步的认识。万物背后都是数据，不是我想出来的噱头，数据就是这么无处不在。</p><p>光认识数据对我们的生活很重要还不够，数据背后的规律是算法。就像客观世界背后蕴含着哲理一样，学了这门课程你能够从数据算法中同样领会到生活的哲理。比如在接下来的课程中你会发现，原来“物以类聚人以群分”这句话里面是有数学算法支持的，而《飘》里面提到的“tomorrow is another day”其实也是有数据算法根据的。我希望你学了这门课程，不要把它仅仅当成一个知识库来对待，而是通过这门课来培养一个时时思考数据规律的习惯。</p><p>最后，当你有了对数据思考的习惯，我希望你能够进一步去表达数据，用数据正确地影响他人，跨入数据分析师的门槛。在这样一个纷繁复杂的世界里，你要是能够有一个清晰、优雅的数据观，那么你能够把一件事情更好地想明白、说清楚。</p><p>数据就是外行看热闹，内行看门道。看清数据真谛的人才能真正把握自己的命运，把握自己企业的命脉，最终获得生活和事业的成功。所以希望你能够通过这门课，能够对自己的生活有一个新的认知，看到数据背后的逻辑和趋势。在接下来的课程学习中，你如果有任何的思考和疑问，一定要在留言区大胆提出来，我们共同成长。</p><h2>课后思考</h2><p>你在生活或工作中有曾经被哪些数据骗了的经历吗？明白之后又有哪些收获呢？可以写在这里，我们一起来讨论一下。</p>",
                "article_title": "导读 | 万物背后的规律都是数据"
            }
        ]
    },
    {
        "chapterTitle": "数据分析基础",
        "children": [
            {
                "title": "01 | 平均值：不要被骗了，它不能代表整体水平",
                "id": 400764,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>我们在日常生活中经常会遇到这种情况，看到某些统计报告里面说，“某市的人均住房面积是120平米”“计算机行业人均年收入超过50万元”。你看完这个数据之后，倒吸一口凉气，然后去微博感叹：“对不起，我又给大家拖后腿了”“对不起，我又被幸福了”。</p><p>你不必为此焦虑，我只能奉劝你，以后看到这么不专业的统计报告就别看了。来，我带你看看准确客观的平均值统计应该是怎样的。首先，你得知道平均值究竟是什么。</p><p>从概念上看，平均值有很多种。单从数学上来说，就有算术平均值、几何平均值、平方平均值、调和平均值、加权平均值等等。所以当有人和你说平均值的时候，你要留个心眼问问他，你这说的是哪个平均值呀？</p><p>当然，我们日常生活中提到的平均值都默认是“<strong>算术平均值</strong>”，也就是“<strong>一组数据中所有数据之和再除以数据的个数</strong>”。这个概念不难理解，你在小学的时候就开始学了。不过看到这里，你可以先结合我们上面的例子想想，算术平均值有什么短板吗？</p><p>我先给一道极其简单的数学题，你可以先想想。我们有3个数，他们分别是0，1，20，这三个数的平均值不难算，是(0+1+20)/3=7，那7这个平均值和之前的三个数是不是差距挺大呢？是不是有些不客观呢？</p><!-- [[[read_end]]] --><p>所以，有的时候，平均值并不能代表整体水平。</p><h2>平均值在什么情况下才有价值？</h2><p>那平均值到底在什么情况下才有价值呢？回答这个问题之前，我再给你讲个故事。</p><p>昨天下楼的时候，我听到小区两个大妈在讨论，“这次期末考试，班里语文的平均分是71分，我孙子考了85分，厉不厉害！”在工作中，我偶尔也会听到同事说，“我们客户的平均客单价是1000元钱，竞争对手的只有500元，我们的客户比对方的高端多了。”这些说法都对吗？还真不一定。</p><p>为了更好地解释这个问题，我先拿孩子的平均分给你举个例子。假设班级里20名学生的考试成绩如下图一样呈现两极分化的情况，一半孩子都在95分以上，还有近一半的孩子只有三四十分，我们很容易计算出这20名学生的成绩平均值是71.05（图中的红色直线）。</p><p>看上去孩子的85分比平均分71.05分高了很多，但你再仔细看，这个分数在好学生里其实是最差的那个，整体上看也只是班级中游水平。</p><p><img src=\"https://static001.geekbang.org/resource/image/7f/ab/7f7c7aef0fd8e22fd002f73a7a46b7ab.jpg?wh=2000x1285\" alt=\"\"></p><p>同理，看上去这个企业的平均客单价很高——平均1000元，但如果你的数据是由1个1万元客户和10个100元的客户构成的（总收入11000元/11人=1000元/人），对方都是11个客单价500元的客户构成的，那么其实竞争对手才是真正的高客单价企业。</p><p>你可能会觉得我在抬杠，这些例子的数据集都太极端了吧？其实我是想说明一个问题：平均值是用所有样本数据计算的，<strong>容易受到极端值的影响</strong>。在不少情况下，平均值是没有价值的，它无法客观准确地反映数据整体情况。</p><p>更进一步来说，<strong>整体平均值是在数据呈均匀分布或者正态分布的情况下才会有意义，如果忽略整个数据的分布情况，只提平均值，其实是没有意义的</strong>。这也就是为什么你会在读一些统计分析报告时觉得自己不是“被加薪了”，就是“被幸福了”。</p><p>现在你明白了吗？在一些复杂情况下，我们是很难确定人群分布情况的，此时若直接使用平均数值，是很难反映整体真实情况的。</p><h2>分组结论和整体平均值不是一回事</h2><p>那怎么才能反映真实情况呢？</p><p>就拿平均薪水这个例子来说，你肯定有疑问：什么人啊？咋拿到那么多钱的？你肯定想看更详细的数据，诸如具体的岗位属性、工作年限、城市等等。有了这些信息，你才能知道你和人家的薪水差距到底差在哪了。</p><p>比如一个在一线城市工作3年的Java程序员的月平均工资是2万元，而我的月工资是1万元，那我确实是低一些，这个判断比起之前那个一刀切就准确太多了。</p><p>不知道你有没有注意到，在思考这个问题的过程中，你已经在不知不觉中引入了<strong>分组</strong>的逻辑。你应该也发现了，分组中的平均数和从整体中得到的平均数，是完全不一样的，分组中得到的平均数更具参考价值。</p><p>上面这个例子很好理解，我现在要顺着它抛出一个结论：<strong>整体平均值不能代表各分组情况，分组结论和整体平均值结论可能会大相径庭。</strong></p><p>明白了吗？别急，我再讲一个例子反面论证一下这句话。话说NBA有两个球员，球员A和球员B，他们的投球的表现如下面这个图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/39/30/39f22a9b0334591cf1836cc344ed4230.jpg?wh=1908x967\" alt=\"\"></p><p>这里我简单描述下，先说2分球的情况：A球员，2分球总共投了250个，投中了200个，命中率80%；B球员，投了100个，投中了90个，命中率90%。也就是说，以2分球的命中率来看，B更牛一些。</p><p>投3分球的时候，A球员一共投了50个，投中5个，命中率10%；B球员，一共投了150个，投中50个，命中率33.33%。看来，无论2分球还是3分球，Ｂ都比Ａ的投中率要高。看上去也是B比A厉害，对吧？</p><p>那问题就来了，可是从整体命中率来看好像不是这样啊。你看，如果我们算下两位球员的整体平均值（也就是整体投中率）。</p><p><img src=\"https://static001.geekbang.org/resource/image/9f/36/9f1726a5a5431b0fab08ed8c51373e36.jpg?wh=1864x888\" alt=\"\"></p><p>A的总投球数是300个（250个2分球，50个3分球），共投中205个（200个2分球，5个3分球），投中率是68.33%；Ｂ呢，投了250个球，投中的两分和三分加到一起140个，那么他的投中率是56%，这么看来B比Ａ的投中率68.33%要低呀。</p><p>看到这个结果，你是不是很诧异，不信你再仔细看看这个图表，我的确没有在数据上做手脚。</p><p><strong>两分球和三分球投中率都比较高的这个球员B，整体的命中率反而下降了</strong>，是不是让人有点大跌眼镜？如果你是篮球爱好者，你应该会发现问题，NBA里没算过整体命中率，一般都是把二分球和三分球的命中率分开说的。</p><h2>辛普森悖论的启示</h2><p>为什么NBA不计算整体命中率呢？就是因为这样算不准确。这里我们可以引入一个著名的悖论——<strong>辛普森悖论</strong>，它讲的就是这个问题。辛普森悖论是1951年由E.H.辛普森提出的，简单来讲就是<strong>在分组比较中都占优势的一方，有的时候在总评中反而是失势的一方。</strong></p><p>我用前面NBA球员命中率的例子跟你分析下产生辛普森悖论的原因。首先，两分球和三分球的投球能力根本不是一回事，这两个投球数本身就不应该相加；另外，B球员虽然厉害，但是他60%的球都是命中率比较低的三分球，而绝对数量上命中率较高的两分球投得就少了，而三分球的投中率是明显低于两分球的，这样就拉低了他的整体的投中率，造成了整体的劣势。</p><p>是不是还是有点绕？用一句话来讲，就是“质”（命中率）与“量”（投球数）是两个维度的数据，如果全部合并成“质”（命中率）这个维度的数据，那就会出错了。</p><p>再举一个例子，某游戏公司做了款游戏，有Android和iOS版本，而每个系统都有手机版本和Pad版本。一个数据分析师看完用户的付费数据后，发现整体上Android付费率比较高。他就直接告诉老板说，“你看我们Android的用户付费率要高于iOS的用户付费率，我们应该大力发展Android客户端！”这个数字是真实的，但是结论很可能是错误的。</p><p>因为我们再细分下去你会发现，这个数据分析师也是错误地把“质”（付费率）和“量”（用户数）简单合并，是一种想当然的行为。</p><p>因为还有可能出现这样一种情况：Android无论是平板还是手机的付费率分别都比iOS低，但是整体上因为安卓手机（注意，只是手机用户）的用户比较多，所以把Android付费率整体拉高了。但其实细分下去iOS、Pad和手机的付费率都比Android高，只是整体付费率低而已。你要是还有疑虑，可以对照上面NBA的例子，自己再推演一下。</p><p><strong>所以，我再来总结下，看到一个平均值的时候，你一定要留个心眼，看看它的数据构成情况，而不是简单地用平均值去代表所有的整体。</strong>生活是具体的，如果你想看到更为准确的数据，你应该分组拆开来看。因为辛普森悖论告诉我们，有的时候，在分组比较中占优势的一方，在总评中反而可能是失势的一方。但你要注意，只是“有的时候”。</p><p>就像最近我看到一些文章，说税率改革之后我们的整体工资的税率反而是变高了，而不是变低了。这也是同一个道理，我们用整体的平均值去掩盖个体每一个不同区间段的税率变化，是不对的。我们应该更细分的数据去评定实际的好坏。</p><p>除此之外，辛普森悖论也给我们一个启示，就是：<strong>每次小范围内的输赢，其实和你在整体上的输赢没有太大直接的关系。</strong>这也是为什么在打麻将或者打德扑真正赢的那些人，不是那些小牌把把赢的人，而往往是赢一把大的人。</p><p>这也是这个辛普森悖论衍生出来的一个推论，将来你要用数据分析做决策的时候，小到打牌、大到做投资，不要过于计较局部的得失，而是要在关键时刻对大概率有把握的事情放手一搏。</p><h2>小结</h2><p>好了，今天这篇文章就到这里。我在最后再来给你串讲下这节课的知识点。</p><p>首先，当别人给你说平均值的时候，你要和他确认下说的是哪个平均值。当然，生活中，我们提到的平均值基本都是在说<strong>算术平均值</strong>。其次，算术平均值特别敏感，它很容易受到<strong>极端数据</strong>的影响，所以在很多选秀节目里，你经常会听到最后计算分数时要去掉一个最高分和一个最低分，这是一个道理。</p><p>你也一定要意识到，整体平均值是在<strong>数据均匀分布或者正态分布</strong>下才会有意义，如果忽略整个数据的分布情况，只提平均值是没有价值的。</p><p>最后，我和你聊了辛普森悖论。工作生活中，我们经常会遇到这样的悖论，甚至我见过很多传销人员就在用这个悖论在忽悠人，如果你遇到这样的案例，别忘了那句话：<strong>分组结论和整体平均值结论可能会大相径庭</strong>。</p><p>在我们的生活里，我们总提“质量”这个词，但是拆开来看，“质”与“量”是不等价的。所以当你不被大部分人所理解时，有可能是因为你选的路是一条少数人走的路。平均值和辛普森悖论告诉我们要抓大放小，不要因为某一个单项优势就洋洋得意，也不要因为局部失败就一蹶不振。生活，要有一颗平常心，我们的目标是让我们这一生的“人生平均值”逐步提高。</p><p>数据给你一双看透本质的双眼，让我们持续学习，持续提高。</p><h2>课后思考</h2><p>最后我给你留一个课后思考题：你在你的生活里，你还遇到过哪些平均值和辛普森悖论的例子吗？欢迎你分享出来，我们一块讨论。</p><p>欢迎在留言区与我分享你的想法，也欢迎你在留言区记录你的思考过程，如果你能有其他案例，那就更好了。感谢阅读，如果你觉得这篇文章对你有帮助的话，也欢迎把它分享给更多的朋友。</p>",
                "article_title": "01 | 平均值：不要被骗了，它不能代表整体水平"
            },
            {
                "title": "02 | 大数定律与小数陷阱：生活是随机还是有定数的？",
                "id": 401316,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>不知道在生活中，你是否想到过这样的问题：生活到底是随机的还是有定数的？</p><p>按理来说，在生活中很多事情应该像抛硬币一样，50%的部分向好的方向发展，另外50%的部分向坏的方向发展。但是，你可能连续努力了好几次，结果却都没有向着你想象的方向去发展。于是你开始怀疑人生，说自己最近“水逆”。或者你去应聘岗位，有的时候一下子一周来了好几个Offer，有的时候却连续两三周都没有任何进展，你把它归纳成上天的安排，这真是上天的安排吗？</p><p>今天我就来给你讲解下这背后的数据规律——大数定律和小数陷阱。希望你明白了这两个数据规律后，在遇到一些所谓的“水逆”或者不如意时，站在数据分析的层面，正确看待我们的生活。</p><h2>什么是大数定律？</h2><p>我们先讲讲大数定律，你肯定遇到过这样的场景：抛硬币看正反面。理论上来说，抛十次硬币应该是五次正面、五次反面，但结果九次却都是正面。又或者你在拉斯维加斯玩轮盘赌，连续十次押小，十次都输了。你就是不服，第十一次接着押小，但还是输了。</p><p>上面的两个场景的背后就是大数定律在发挥作用。大数定律是由瑞士数学家雅各布·伯努利提出来并验证的，它的核心逻辑是说<strong>当随机事件发生的次数足够多时，发生的频率才会趋近于预期的概率</strong>。</p><!-- [[[read_end]]] --><p>再回到我们刚刚提到的抛硬币的例子，随机抛硬币理论上正面和反面出现的次数应该是一样多（正反面的预期概率均为50%），也就是一半正面一半反面。所以上抛十次应该是五次正面、五次反面。</p><p>但是这有一个前提，就是大数定律中提到的“随机事件发生的次数足够多”。那怎么叫做“足够多”呢？</p><p>理解这个“足够多”，其实也就是我们理解这个问题的关键。“足够多”数学上叫“无穷大”，生活里也会叫做“足够大”。你有没有想过，那么数量多大才叫“足够大”呢？10次肯定是不行的，那应该是100次，还是1000次？</p><p>历史上还真有一个数学家做了这么一个实验，他就是丹麦概率论学者克里克。二战时克里克曾被拘留，当时在监狱中他也没有什么事情可做，于是就做了这个抛硬币的实验来打发无聊的时间。他一共抛了1万次硬币，他把每次抛下来的硬币是正面还是反面做了一个统计，统计图大概就像下图的这个样子。</p><p><img src=\"https://static001.geekbang.org/resource/image/cd/44/cd80a689115a8efa57a5dd2502191744.jpg?wh=1876x1417\" alt=\"\"></p><p>从这个统计图中你会发现，在最开始的几百次里，抛硬币的概率波动是非常大的，也就是说有的时候连续若干次都会正面或者连续若干次都会反面。到后面随着次数的增多，正面和反面的概率才越来越各自趋向于50%。</p><p>所以看了这个图你可能就理解了，为什么我们在去抛硬币的时候，虽然每次抛出正反面的概率应该各是50%，但是我们抛10次却不一定是5次正面、5次反面——因为我们抛硬币的次数不够多，最后反映出来的结果也并不够客观。换句话说，你看到的结果都是各种偶然的极端情况。</p><p>这时候你可能会萌生出一种想法，那就是觉得既然胜负概率都差不多，我不用努力，只要不停地去尝试，总会赢的。</p><p>请注意，这可完全不同。因为相对大数定律，还有一个小数定律。小数定律是科学家阿莫斯·特沃斯基等人在研究“赌徒谬误”时做出的一个总结，我把它叫做“小数陷阱”。</p><h2>什么是小数陷阱？</h2><p>前面你了解大数定律后，你大概率会认为，既然随着数据的增多，整体趋势会趋向50%-50%，那么我们在赌场里玩轮盘赌大小时，如果前面开的都是“大”，那我们接下来应该向“小”去加倍下注。因为理论上长期来看出现“大”和“小”的概率应该是趋于一致的，所以未来出现“小”的概率应该增大。</p><p>是不是事情真会像我们想的那样呢？</p><p>还真不一定，这就是一个典型的对大数定律的误读，它叫<strong>赌徒谬误</strong>，我把它叫做“<strong>小数陷阱</strong>”。</p><p>就拿轮盘赌来讲，虽然前面轮盘转出几轮“大”了，但其实后面每一次转出来“小”的概率还是不变的50%，也就是说每次的事件其实和上一次的事件是<strong>独立且随机</strong>的，并不是前面都是“大”，后面开“小”的概率就会高。</p><p>我们的大数定律里面最重要的是“<strong>大数</strong>”，也就是说你得出现足够多的次数，才能够趋近于它的期望概率。</p><p>这个大数要求非常大，所以一般的赌徒都没有赌到足够多的时候就已经输成穷光蛋了，并且一个人也不可能不间断地几百个小时看一台赌博机的趋势。</p><p>而赌场其实是在利用大数定律赚钱，一般的赌博机都会被设计成为51%比49%的这种预期概率，赌场其实只多赢2%，而你却会输100%。</p><p>这也就是为什么赌场乐于提供各种免费的好东西，去吸引源源不断的客户。因为在赌场里某些赌徒可能偶尔赚钱，但从整体的趋势来讲，所以只要赌博机不断地转动下去，赌场都是稳赚不赔的。</p><p>同理，如果你要去买彩票，然后费尽心力去做数据分析，选出那些中奖号码以前出现少的数，认为这些数字在下次开奖的时候就会出现几率高，那么在学过今天的小数陷阱后，你应该就知道，这完全是一个错误的认识，运气永远只是运气而已。守株待兔，究竟能有多少只兔子撞到你的木桩上，答案其实是显而易见的。</p><h2>大数定律和小数陷阱给我们的启示</h2><p>前面我通过一些生活中比较常见的例子，给你讲解了大数定律和小数陷阱。那么我们具体应该如何应用大数定律，又要如何避免落入小数的“陷阱”呢？</p><p><strong>首先，对于大数定律来说，我们做事不要轻易跟风。</strong></p><p>在开始某件事之前，你要想好，自己是否已经有了持续投入的能力？例如，现在炒币很火，不少人跃跃欲试准备进场分一杯羹。但我希望你学了我们这节课后，在做任何投资之前，做好持续精力和金钱投入的准备，否则就不要轻易去跟风了。</p><p>因为很可能你羡慕的“他”，已经不再是简单地通过赌博博弈获得收入，而是因为他有着大量的失败和经验，已经进入到了大数定律的规律部分。如果你只是盲目地去跟风，哪怕开始赚了一些钱，最后也会“靠运气赚的钱，最后靠实力全亏回去”。</p><p><strong>其次，对于小数陷阱来说，我们要保持一颗平常心。</strong></p><p>当我们在做一件事情的时候，如果失败了，要有平常心态。气馁或者赌徒心理都是不可取的。你需要意识到，我们在生活中的数，绝大多数都不够大，所以我们的偶然只是偶然，并不是我们这段时间就该倒霉。</p><p>当你想“梭哈”或者完全放弃时，不妨想一想，我们是否已经持续努力足够久了？要学会把一件事情放在足够长的时间轴上去评判（尤其是当这件事对你特别重要时）。当你遇到各种不如意时心态不要崩，要持续在你认为成功的路线上持续努力，并且努力足够长的时间足够多的次数，相信你最终会有一种“拨云见日”的感觉。</p><p><strong>最后，希望你建立自己的“大数据定律”来规避“小数陷阱”。</strong></p><p>做法其实很简单，就是多利用前人的经验，站在前人实验的结果和规律上，多去学习、阅读（比如多学数据思维课这样的课程），多去经历、总结自己想从事的事业。相信绝大多数人是做不到在赌博中拥有足够大的“大数”，但是没关系，你可以根据自己的生活去建立属于自己的“大数定律”，赋予偶然的生活必然性。</p><p>任何时刻都不要放弃自己的追求，人生只有努力才是向上的，这才是你一生的“大数定律”。我想在这里送你一个成语，叫做“慎始敬终”。“慎始”指的是要想清楚，有没有持续投入的准备，没有想清楚就不要开始。“敬终”指的是，一旦做了，持续投入，从头到尾踏踏实实落实。</p><h2>小结</h2><p>好了，最后我们再来总结一下，今天我主要给你讲了一个数据分析的关键理论：“大数定律”和“小数陷阱”。</p><p>大数定律说的是当随机事件发生的次数足够多时，发生的频率就趋近于预期的概率。对于一件事情，你需要持续不断努力，才可以达到你的期望值。而“小数陷阱”则告诉你，每个事件都是独立的事件，“否极泰来”需要足够多的次数才可能出现，做事情要少一些“赌徒心态”，多一些平常心，不要盲目跟风和下注才能获得最后的成功。</p><p>生活里最难的就是如何辨别什么是偶然，什么是必然。我们期待把生活全部变成必然，但其实你会发现人的一生很短暂，我们一生的经历很难都是必然。但是学了今天这节课，希望给你一颗平常心，明天上班开车的时候，无论遇到一路红灯还是绿灯，都不会影响你心情，因为这都是“小数陷阱”而已。</p><p>人生也总会红灯和绿灯，你不会老顺利或者老倒霉，但如果你不断努力，你确实会更容易成功。这听起来好像是一句鸡汤，但是站在数据分析的角度来看，生活本来就充满着各种不确定性，你如果不去努力，那经历的样本就太少了，你经历的可能就会是各种偶然的极端情况（比如一路上老是遇上红灯）。</p><p>数据给你一双看透本质的眼睛，希望“大数定律”和“小数陷阱”可以帮助你未来的工作和学习。数据知识学无止境，让我们一起持续学习，一起共勉。</p><h2>课后思考</h2><p>在你的人生学习和工作经历里，哪些例子是符合“大数定律”，哪些例子是经历的“小数陷阱”的？希望你在留言区分享出来，让我们一起站在大家的“大数定律”上成长得更好。</p>",
                "article_title": "02 | 大数定律与小数陷阱：生活是随机还是有定数的？"
            },
            {
                "title": "03 | 数据的期望值：为什么你坐的飞机总是晚点？",
                "id": 402945,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>生活中，你是不是也经常遇到这样的场景，夏天你平时都带着伞，偶尔一天没带伞，结果就正好那天下雨了；不打车时街上到处都是空出租车，但等你需要打车时发现全是满员的；别人的飞机都是正点，你坐飞机永远都是晚点（我自己就是这样）……</p><p>类似的事情还有很多，<strong>总之你越不希望某件事情发生，这件事情往往就会发生</strong>，而在发生之后，有的人就会抱怨说自己运气不好。那真是运气不好吗？这背后有什么原因吗？</p><p>其实业内我们经常称这样的“效应”为<strong>墨菲定律</strong>。今天我们就先来说说它的起源，然后再来聊聊它背后反映的数据分析知识。</p><h2>墨菲的一个玩笑</h2><p>1949年，美国的一位航空工程师爱德华·墨菲与美国空军共同研究高速载人火箭“雪橇MX981”，需要把16个精密传感器装在超重实验设备上测试耐压性。可即便是超重实验设备在巨大压力下都变形了，传感器也没有任何的指示。检查后才发现，原来是负责装配的三个同事把这16个传感器全都装反了。</p><p>对此，墨菲不经意间开了一个玩笑：“如果一件事情有可能出错，让他去做就一定会弄错”。随后的记者招待会上，他的上司斯塔普把这句话称为“<strong>墨菲定律</strong>”，并表述为：“<strong>如果有两种或两种以上的方式去做某件事情，而其中一种选择方式将导致灾难，则必定有人会做出这种选择。”</strong></p><!-- [[[read_end]]] --><p>随后，人们对墨菲定律又做了更多诠释，比如：</p><ul>\n<li>任何事情都不会像它表面上看起来那么简单；</li>\n<li>所有任务的完成周期都会比你预计的长；</li>\n<li>任何事情只要有出错的可能，就会有极大的概率出错；</li>\n<li>如果你预感某件事可能出错，它一定会出错。</li>\n</ul><h2>背后的数学原理</h2><p>那么墨菲定律背后的数学原理是什么呢？这里就要引入一个数学概念叫做<strong>期望值</strong>。</p><p>什么是期望值？<strong>期望值就是对可能出现的结果以概率为权做加权平均</strong>。举一个简单的例子，你买了一张彩票，有10%的概率中100元，40%的概率中50元，50%的概率不中。</p><p>那么期望值是 10%*100+40%*50+50%*0=30元。</p><p>这30元做什么用呢？买1张彩票或者100张彩票都看不太出来，但是如果你买10万张彩票，那么你中奖的钱很可能会接近300万，也就是30*10万。所以，这个30元的<strong>回报期望值，衡量了你在足够多的次数下，平均每一次事件的获得的数值。</strong></p><p>很多人在数据分析中，往往把“均值”和“平均值”混为一谈。这里我告诉你一个简单区分的方法，那就是用英文来区分：</p><ul>\n<li>均值（也叫做期望值）英文是Mean，它是事前预测的，这个值完全是由概率分布决定，也就是我们前面所说的“对可能出现的结果的概率加权平均”；</li>\n<li>平均值叫做Average，它是事后统计，统计样本值的总和除以样本的个数。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/48/de/484355ed9d163b3a95c73d68492ebdde.jpg?wh=1988x901\" alt=\"\"></p><p>带你了解了二者的概念区分后，我们接着来看二者的关系。我想请你先琢磨下这句话：当样本量N趋近无穷大的时候，样本的平均值无限接近数学期望（日常计算时时候相等）。这句话是不是听着很熟？对，这就是上节课我们讲到的大数定律（Law of Large Numbers，LLN）。</p><p>简单来讲，<strong>期望就是反映在大数定律下多次执行某件事情之后，得到的一个最可能的收益结果。</strong>例如，我们刚才例子用到的买了10万张彩票获利300万，平均值（Average）和期望值（或者说均值Mean）都是30元，其实就是利用了大数定律来解释这个现象。</p><h2>解释墨菲定律</h2><p>聊完平均值、期望值（均值）和大数定律三者的关系后，我们再回到今天要用数据分析解释的现象：墨菲定律。</p><p>人都有一个特殊的心理机制，那就是倾向于记住一些不好的事情。就像航班晚点的概率对每一个人而言都是一样的，但对我来讲，每次飞机晚点的等待就会让我印象深刻，而平时没有晚点的时候，我的注意力都集中在其他事情上。</p><p>现在，我们可以把坏事情的期望定义成M，它代表着你记住这个坏事情的概率，坏事情的心理影响定义成X，概率为R1；再把好事情的期望定义成N，它代表着记住这个好事情的概率，好事情的心理影响定义成Y，概率为R2。根据今天所学，我们就有了如下两个公式。</p><p><img src=\"https://static001.geekbang.org/resource/image/fd/35/fd10624967673e85e2aa6fb9b92ca035.jpg?wh=1689x807\" alt=\"\"></p><p>抽象一下，你经常担心一个坏事的发生，比如说事情A，我们假设A发生时对你产生的心理作用是X，事情A不发生对你产生的心理作用是Y。这个时候显然X是大于Y的，所以当发生A这件事情的时候，你受到的心理影响X就比Y大。</p><p>其实，你在担心一件事情的发生之时，这件事情已经具备了发生的大多数条件。我们假设事件A发生的概率是R，那么当你担心这件事情发生（R1）和不担心这件事情发生（R2）的时候，两个概率是不一样的，R1一定大于R2。</p><p>这样一来，把我们的讨论代入前面的公式，一个我们担心的坏事的发生期望就像下面这个图所显示一样，对比一下你就会发现，<strong>墨菲定律的原理其实是由我们对于好事情和坏事情的期望值差异造成的。</strong>简单讲，印象深刻再加上担心的时候概率高，自然也就担心什么发生什么了。</p><p><img src=\"https://static001.geekbang.org/resource/image/9e/f1/9e20242b9ee1be856efd559320d43df1.jpg?wh=1860x1025\" alt=\"\"></p><p>我们现在用墨菲定律来解释一下这节课开头的情景：</p><ul>\n<li>夏天是个多雨的季节，所以你会记得要随身带伞。但恰好有一天你没带伞，并且看天阴沉沉的好像会下雨，于是你十分担心，最后真下雨了，印象自然深刻；</li>\n<li>你着急打车的时候一般都是高峰期，再加上你平时高峰期也经常打不到车，于是就更加担心，最后发现全是满员，对打不到车这件事印象深刻；</li>\n<li>你在很忙的时候，为了赶时间总选晚上的飞机，前面只要有一个航班晚点了，晚上这一班一定晚点，再加上一旦晚点，你回家就基本半夜了，所以印象尤其深刻。</li>\n</ul><p>于是，墨菲定律就产生了。</p><h2>如何规避墨菲定律</h2><p>了解了墨菲定律的成因后，你是不是想问，那我们怎么才能避免掉入“墨菲定律”的陷阱呢？</p><p>其实影响期望的变量分为两个部分，分别是心理影响大小以及发生概率大小，所以我们可以从这两个方面入手。</p><p>对于心理影响来说，我们要做的就是不断调整事情对你心里影响的预期，让它们趋同。特别是遇到坏事情的时候，你可以通过<strong>增加B计划等方式，调整预期以降低坏事情发生对你的心理影响</strong>。</p><p>对风险的概率来说，你可以<strong>优化流程，提高自身能力，尽可能减少事件出错的概率</strong>。</p><p>这么说可能还是有些抽象，我们来看几个工作与生活中的运用。</p><p><strong>“为大概率坚持，为小概率备份”</strong>——创业的时候，我们要努力为好的期望（N）去坚持，同时考虑为坏的影响（X）备份，应该尽力降低坏期望（R1）的风险。</p><p><strong>“已知的是成本，未知的才是风险”</strong>——如果坏的影响（X）为已知，那么即使你按照坏事件发生概率（R1）100%来准备资金，这批资金也算是你付出的成本；但如果坏影响（X）未知，那么无论坏事件发生概率（R1）为多少，都是风险，因为你不知道这个坏事件究竟会造成多大的影响。</p><p><strong>“项目风险控制”</strong>——项目管理当中有各种风险管理和预防措施，把风险分为很多类，例如静态风险、动态风险、局部风险、整体风险，同时也会把风险应对措施细分为很多类，其实背后的核心是为了去避免墨菲定律的发生，让整体项目在项目经理的期望值下正确运行。</p><p><strong>“生活中的风险控制”</strong>——我们在生活中，其实也是可以借用这种风险控制的方法论，识别生活中的风险并做好准备，这样才能够在墨菲定律发生的时候不会手忙脚乱。例如提前看看天气预报，查看这趟航班的过往准点率，预估自己乘坐航班情况。在去重要会议的时候，多提前一些时间。这些生活里的小事你或许平时不会太过于在意，但请相信，一旦你把这些小事落到实处，你对生活的掌控力会大大提升。</p><p>数据分析解释给你的是现实背后的规律，学以致用才可以让它们发挥最大的价值。</p><h2>小结</h2><p>好，总结一下，今天我们通过墨菲定律给你介绍了一个有意思的概念叫期望值（Mean），它是对可能出现的结果的概率加权平均，期望值完全是由概率分布决定。而我们之前讲的平均值一般是指算数平均值，也就是一组数据中所有数据之和再除以数据的个数<strong>。</strong>某个事情长期不断发生，次数足够多后会达到我们预设的期望值，这就是大数定律。</p><p>这几个概念相互依存，又相互不同。其实你可以把平均值、大数定律和期望值这三节课看成一个小整体，对照进行学习。</p><p>对平均值来说，你要学会为不同事物去分组，用更细分的数据来看待问题。对于大数定律来说，要成事，其实需要我们不要有赌徒心态，要学会持续投入。而对于期望值来说，平衡预期和未雨绸缪这两个词，希望你能够在生活中灵活运用。</p><p>其实，这几个数据分析的概念都告诉我们一个最朴实的道理：没有事情可以一蹴而就（平均值），我们需要努力足够多的次数（大数定律），学会规避风险（期望值）。这样最终在若干年后，企业和个人才能有一份满意的企业/个人数据报表。</p><p>数据给一双看透本质的眼睛，调整好自己的期望，持续学习持续进步。</p><h2>课后思考</h2><p>今天我们把平均值、大数定律和期望值给你串讲了一下，你最近在生活中遇到过墨菲定律的事情么？你觉得怎么做可以减轻和规避这些风险？希望你分享在留言区，我们一起共同成长。</p><p>另外，如果你对墨菲定律还有一些其他的认知，也可以写在留言区，我们一块讨论。感谢阅读，如果你觉得这篇文章对你有帮助的话，也欢迎把它分享给更多的朋友。</p>",
                "article_title": "03 | 数据的期望值：为什么你坐的飞机总是晚点？"
            },
            {
                "title": "04 | 随机对照试验：章鱼保罗真的是“预言帝”么？",
                "id": 403845,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>你在生活中是否遇到过这样的现象：你参加了个小型聚会，竟然遇到了同月同日出生的人，你慨叹有缘的时候，可能并不知道这只是一个高概率事件？新做的一个界面UI，用户调查显示客户满意度明显高于老版本，你的领导却跟你说这是“幸存者偏差”？以及，你觉得曾经在南非世界杯上“成功预测”德国小组赛赛果的“预言帝”章鱼保罗，真的有预测能力吗？</p><p>要真正了解这背后的玄机，就要理解作为数据分析界最伟大的原理之一的“<strong>随机对照试验</strong>”。不过在进入正题之前，你先要弄清楚一个重要的概念——“<strong>随机</strong>”。你可能觉得这个很简单，“随机”不就是要确保每个个体被抽取的概率相同么？但是生活中充斥着太多的“伪随机”，会影响我们的判断结果。那到底什么是伪随机呢？我们接着往下看。</p><h2>你认为的随机其实都是“伪随机”</h2><p>我们来玩一个小游戏：你现在闭上眼睛，马上在0到20之间想一个数，然后我来猜。好，想好了吧？我可以告诉你，大概率你不会选5和15这两个数字。不信的话，你不妨试一试，或者和朋友们玩一下这个小游戏。</p><p>为什么我会这么确信你大概率不会选5和15呢，<strong>因为人脑在选择随机数的时候，会刻意规避一些有规律的数字，这反而让这些随机数变得“不随机”了。</strong></p><!-- [[[read_end]]] --><p>同样，刚刚说的用户反馈的例子就很典型。大部分用户其实并不愿意花时间填写设计的调查问卷，一般愿意填写的都是对这个产品比较感兴趣的人，或者使用度比较高、希望产品能有一些改进的人。因此这样让用户填写反馈，往往会产生“伪随机”这个问题。</p><p>所谓伪随机，就是看上去产生的过程似乎是随机的，但实际上是确定的。例如计算机的随机数，这是通过确定性的算法计算出来的，让你随意想一个数字，这也是根据你个人习惯偏好想出来的，它们都属于伪随机数。</p><p>也就是说，如果我们选择样本的随机程度不够，或者我们自己对数据的理解程度不够，就经常会出现一些“小确幸”的事情：我们可能会认为幸运和缘分这样的东西，出现的概率还挺高的。</p><p>其实不然，就拿开头提到的聚会来说，如果聚会超过50人，那有两个人是同一天生日的概率高达97%，即使是20人的小聚会至少两人生日相同的概率也高达41%，你可以参考下图的计算过程。</p><p><img src=\"https://static001.geekbang.org/resource/image/2b/6d/2bc50dc468772d098499afb946d7d66d.jpg?wh=1484x1125\" alt=\"\"></p><h2>随机对照试验帮助你去伪存真</h2><p>了解完“随机”这个概念后，我们就进入到今天的主题——<strong>随机对照试验</strong>。现在无论是医疗行业的临床医学、生物科学的基因遗传学，还是互联网黑客增长理论当中的A/B测试，都运用到了这个理论。它帮我们解决了一个问题，就是<strong>当我们不知道客观世界里一个问题的真正答案的时候，可以通过少量的数据来验证非常大的数据规律</strong>。</p><p>随机对照试验是由“现代统计学之父”、数据分析的鼻祖——罗纳德·艾尔默·费希尔在《试验设计》一书中提出的，他用了一个很简单的例子来验证一件事情是否真实可信。</p><p>这就是著名的<strong>奶茶试验</strong>，它很简单地讲述了“随机对照试验”的原理。20世纪20年代，英国有一位女士说道：“先放红茶和先放牛奶的奶茶的味道完全不一样，我一下子就能尝出它们的区别来。”这时刚巧数据分析界的大神费希尔也在场，他就提议通过试验来鉴别这位女士所述的真伪。</p><p>于是，费希尔设计了一个试验：他在那位女士看不见的地方，为她准备了两种冲泡方法不同的奶茶。之后把奶茶随机摆成一排，共10杯，让女士随机品尝奶茶并说出其冲泡方式，结果那位女士的回答完全准确。这时费希尔得出结论：这位女士真的有某种方法可以分辨出按不同方法冲泡的奶茶。</p><p>注意这一点，为什么费希尔要用<strong>随机排列</strong>的方式来做这个试验呢？你想想看，假设只是给女士一杯先放红茶的奶茶，即使她判断正确也不能证明她有准确的分辨能力，因为这位女士有50%的概率是可以猜中的，不能排除运气的成分。</p><p>那么将两种奶茶交替给那位女士，如果她每次都能说中，这能证明她的分辨能力吗？我的答案还是否定的。因为只要有某种规律存在，她只需猜中第一杯奶茶的结果，自然也就能知晓后面的结果了。同理，类似连续给五杯先放红茶的奶茶，然后再连续给五杯先放牛奶的奶茶这样的方法也是不行的。</p><p>因此<strong>只有在随机的情况下</strong>这个公式才能成立：</p><ul>\n<li>如果给女士一杯奶茶，偶然猜对的概率是1/2，也就是50%；</li>\n<li>如果随机给女士五杯奶茶，那么她都偶然猜对的概率就是1/2的5次方，大概3.1%；</li>\n<li>如果这位女士随机品尝了十杯奶茶，那么偶然猜对的概率，也就是2的10次方分之一，也就是约0.1%。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/ed/b5/ed987d265b488ef323137c8bba84dbb5.jpg?wh=1738x1045\" alt=\"\"></p><p>试验结果是这位女士将随机选的十杯奶茶都说对了，如果她没有分辨方法，纯粹靠猜的话只有1‰的猜对概率，这是很难实现的。所以，费希尔认为这位女士的确有某种方法可以分辨奶茶的冲泡方法。</p><p>“奶茶试验”就是随机对照试验的鼻祖，正式的随机对照试验会把研究对象进行随机化分组，并设置对照组。随机分组遵从双盲设计的前提条件，也就是研究者和受试者双方均无法知晓分组结果，最终通过结果来证明到底测试试验是否真的有效。</p><p>你要记住，这种试验的重点有两个：一是“<strong>随机</strong>”，二是<strong>对照试验</strong>。</p><h2>幸存者偏差并不是随机对照试验</h2><p>这时候你可能就开始晕了，我们开头提到的章鱼保罗的预测不就是随机对照试验吗？如果随机的十组比赛它全部都猜对了，那保罗是不是就是真有预言能力呢？</p><p>并不是这样的。接下来我要给你介绍一个特别容易和随机对照试验混淆的概念，它叫<strong>幸存者偏差</strong>。</p><p><strong>幸存者偏差就是</strong>当取得资讯的渠道仅来自幸存者时，我们得出的结论可能会与实际情况存在偏差。因为这样做看上去结果的确是由随机对照试验产生，但在逻辑上是错误的，这其实是在用结果来倒推整个前期数据的产生过程。</p><p>幸存者偏差这个概念来源于二战时期，那时候有各种地面防空作战和空战，在密集的炮火下，战机机身上几乎所有地方都可能中弹，因此需要用统计学研究战机被击中的部位，从而确定哪个部分需要额外加强装甲。</p><p>人们对返航的战机进行弹痕分析后发现，飞机机翼和尾部被打穿的弹孔较多，由此得出应该是加强机翼的装甲防护会更好。</p><p>但对返航的飞机样本来说，其实是说明即使机翼中弹，飞机也有很大的几率能够返航。对于那些弹孔不多的部位来说（比如驾驶舱、油箱和机尾），当这些部位中弹的时候，飞机很可能连飞回来的机会都没有了，而这并没有统计出来，这就是所谓的“看不见的弹痕最为致命”。最后事实也证明，加强弹孔较少部位的装甲防护是正确的。</p><p><img src=\"https://static001.geekbang.org/resource/image/42/86/42245c9c240a3f5073cda82d51b5d786.png?wh=1142x640\" alt=\"\"></p><p>我们再回到“预言帝”章鱼保罗的身上，它其实并非如我们想象一般拥有如此神奇的预测能力。</p><p>你要知道：只要样本量足够大，就一定会出现一个“幸运儿”，能够“碰巧地”预测对所有的场景。世界杯的预测也是如此，这样大规模的赛事，会有很多人、很多生物参与赛果预测，如此大的样本量自然就诞生了本次预测的“幸运儿”，只是它的名字碰巧叫章鱼保罗罢了。没有章鱼保罗，我们还会有另一个“幸运儿”猫咪汤姆（这当然只是我杜撰的名字）。</p><p><img src=\"https://static001.geekbang.org/resource/image/cf/c5/cf275562a24a3b3f27be0865334d9dc5.jpg?wh=1142x640\" alt=\"\"></p><p>在章鱼保罗之外，其实有很多的预测者“牺牲”在了随机概率里，它们不够“幸运”不能被我们看见，只有章鱼保罗足够幸运，成为了能够被我们看到的“幸存者”。另外，从章鱼保罗自身的预测结果来看，你会发现其实我们只是看到了它预测成功的部分，忽略了它也有预测不成功的时候，这也是另一种幸存者偏差。</p><p>还记得前面我们在讲大数定律试验时的一个现象吗？我们找全世界的人来玩抛硬币游戏，每人抛10次，总会有人连续10次都是正面，然后我们就可能称他为“赌神”，误以为他可以控制抛硬币的结果，这和章鱼保罗是一样的道理。</p><p>其实，<strong>并没有“预言帝”和“赌神”的存在，我们看到的只是大规模数据背后的“幸存者”。</strong></p><p>所以我们要验证章鱼保罗能力的话，我们应该从一开始就把它安置在一个没有任何信号干扰的环境里让它连续预测十次，这样它的成功概率是1%，我们还可以提高预测次数来检测它是不是真的有那么神奇的预测能力。</p><p>所以当你再看到类似“读书无用论”、“工作都是别人的好”之类的说法时，请你留个心眼，想想我们这节课讲的知识，这些说法到底是不是一种幸存者偏差？</p><p>以及当你看到一些“成功学大师”向你兜售一些成功心法时，不要盲从所谓的权威，如果有可能，我们最好站得高一些，从多个经济周期的维度去评判某件事物或者某个人。</p><p>最后，不要总想着如何从成功者那里学习如何成功，也要从失败的人那里总结为什么会失败，因为成功很大程度上来说，就是一个去避免失败的过程。毕竟别人的成功你不一定能复制，但别人踩的坑，你若不注意，很大几率你也会摔一跤。</p><h2>总结</h2><p>回顾一下今天所讲的内容，我给你讲了<strong>随机</strong>和<strong>随机试验</strong>，也介绍了一下<strong>幸存者偏差</strong>。</p><p>现在，随机对照试验被广泛用于临床医学、遗传学以及我们日常的A/B测试当中，来验证一个理论和假设是否真实，这其实是一个很伟大的进步。但你知道吗？连我们都很熟悉的植物学家孟德尔的遗传学理论的实验都存在着问题（尽管他的理论是正确的）——因为他只选取了对他有利的豌豆样本支撑他论文的观点，而不是采用随机对照试验。</p><p><strong>在我们工作和生活当中，一定要注意不能犯同样的“错误”——采用非随机的结果来证明我们的观点，更不能用幸存者偏差——拿结果倒推原因来解释我们的一些结论。</strong></p><p><strong>注意自己“不犯错”是一方面，另一方面我们也要学会“发现错误”，学习前人失败的经验教训。</strong>当你在工作生活里别人和你兜售一些貌似合理论调时，希望你对“沉默的数据”留一个心眼，在看向那些闪闪发光的成功数据时，也要意识到有很多“话少”甚至“不说话”的数据存在。</p><p>也正因为有这么多“沉默”的数据，我们很难在现实世界得到完整的数据结果。因此我的愿景不是照本宣科地教会你各种各样的数据知识和理论，而是希望能让你对这些数据的分析方法和缘起有更好的理解，最终帮助你在生活中做出更有效的决策。</p><p>数据给你一双看透本质的双眼，让我们不断精进，去伪存真。</p><h2>思考题</h2><p>最后，我们来做个思考题吧。你在工作和学习当中遇到过哪些幸存者偏差的事情呢？后面你是怎么辨认出来这是幸存者偏差的？欢迎你在留言区分享关于幸存者偏差的想法，我们共同探讨！</p>",
                "article_title": "04 | 随机对照试验：章鱼保罗真的是“预言帝”么？"
            },
            {
                "title": "05 | 直方图与幂分布：为什么全世界1%的人掌握着50%的财富？",
                "id": 404779,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>我们之前讲了各种从数据结论中去伪存真的办法，我们今天更进一步，来看看当数据摆在你面前的时候，你应该如何从数据当中发现特征？</p><p>今天我就教给你一个最简单的办法——直方图。</p><p>你可能会有类似这样的想法：直方图还不简单，不就是柱状图吗？一个Excel就搞定了，我天天画柱状图。</p><p>但这种想法是错误的，因为直方图并不等于柱状图。现在请你花一分钟时间，仔细看看下面这两个图表，你能分辨出哪个是直方图，哪个是柱状图吗？</p><p><img src=\"https://static001.geekbang.org/resource/image/ab/70/abf6c16bdb3c8dbda520a62b373de970.png?wh=632x441\" alt=\"\" title=\"北京动物园日平均参观时长\"></p><p><img src=\"https://static001.geekbang.org/resource/image/10/c2/100bea855b9788143d89a922f3f5dfc2.png?wh=1080x698\" alt=\"\" title=\"北京动物园日场馆平均参观人数\"></p><h2>直方图与柱状图</h2><p>答案是第一个图（动物园平均参观时长）为直方图，第二个图（动物园平均参观人数）为柱状图。</p><p>看上去上面这两幅图都是用直直方方的图形来展示，但其实它们是两种完全不同的图形展现和数据分析方法。那问题来了，我们如何才能分清楚直方图和柱状图呢？</p><p>我教你一个最简单的办法：<strong>直方图是展示数据的分布，而柱状图是比较数据的大小。</strong></p><p>更具体点来说，直方图的X轴是定量的数据或者区域数据（用于看分布），而柱状图X轴是分类的数据。就拿刚刚的这两个图来说，第一个图其实是 X轴是<strong>人们观光动物园的时间分布</strong>，而第二个图的X轴是<strong>人们去动物园场馆的具体分类</strong>。</p><p>直方图是针对定量数据分布的定性分析，柱状图是对分类数据的定量数据分析，这两兄弟长得很像，用途也是互为补充。在第一个图里你能看到有40%的游客是停留了4个小时，但无法知道每天有多少游客去动物园。而在第二个图里，你能够知道大概每天会有95万名游客去了熊猫馆，但不能够看到游客的游览时间分布情况。</p><!-- [[[read_end]]] --><p>你也可以从表现形式上来对直方图与柱状图加以区分。</p><p>从柱子的间隔上来说，直方图的柱子和柱子之间没有间隔，而柱状图之间柱子是有间隔的。从柱子的宽度上来讲，直方图的柱子宽度可以不一样，而柱状图的柱子宽度必须一样。</p><p>对直方图来说，它的柱子宽度代表区间的长度，根据区间的不同，柱子宽度可以不同。但柱状图的柱子宽度没有数值含义，所以宽度必须一致。你可以看看下面的这张图，这是美国人口普查局（The U.S. Census Bureau）调查12.4亿人的上班通勤时间的直方图，最后右侧的直方柱子就像一个矮胖子一样，直接蹲在地板上了。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/cf/276c4630dba5d6585863f9db2d8c4bcf.png?wh=985x642\" alt=\"\" title=\"图片来源：福布斯《A Histogram is NOT a Bar Chart》\"></p><h2>神奇的直方图</h2><p>教你分辨完直方图与柱状图后，我们再来聊聊直方图。直方图最早是由数据统计学家Karl Pearson在1891年引入，它可以用来统计现实生活中各种各样的数据分布情况。</p><p>那具体直方图我们要怎么使用呢？你在搞不清楚某些数据的情况的时候。就可以把它画成一个直方图，然后就能够看到其中的规律了。举个例子，你可以看看<a href=\"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations.csv\">下面</a>这组数据，这是来自2021年截至4月底，所有的新冠肺炎疫情国家的累计发病人数。</p><p><img src=\"https://static001.geekbang.org/resource/image/6b/f7/6bf5c051120254e3712821af59b48bf7.png?wh=1250x792\" alt=\"\"></p><p>是不是如果只看这幅图，你会感觉满屏都是数字，不知道如何下手，更别说得出什么结论了。</p><p>但是当我们用直方图把这些数字给表示出来的时候，神奇的事情发生了。你会清晰地发现，拿全球所有的国家这个范围来看，其实绝大部分的病例都发生在极少数的国家里，就像下面这幅图一样。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/a4/27c7768186433dbc5ffa74fb79b2a1a4.png?wh=1164x706\" alt=\"\"></p><p>而且这样的分布并不是个例，我们现在把目光转向亚马逊丛林。</p><p>亚马逊地区有着全球树种最丰富的雨林，科学家已将亚马逊地区将近16000种树种编入物种目录。尽管亚马逊雨林呈现出如此多彩的物种多样性，科学家们还是发现在其中有227种树种牢牢占据主导地位，这些树种的分布面积几乎占到了整个亚马逊雨林面积的一半，也就是说仅1.4%的树种就占据了整个地区的50%，画出图来也和上面的图形类似。</p><p>这种从直方图体现出来呈指数下降或者上升的分布形式，科学家们把它叫做“幂律分布”。</p><h2>幂律分布与帕累托法则</h2><p>幂率分布也叫做指数分布，你会发现在这种分布里，X轴的开始的地方数值很高（或很低），然后以指数级的下降（或上升）到X轴的末尾段，按照统计学定义叫做：“分布密度函数是幂函数的分布”。</p><p>这样的规律其实无处不在，拿我们日常使用的词汇来说，你自己最常用的词汇往往就是那些500~1000个词，其余的词汇少量或者更少量在书面时候使用，如果你把你自己的用词数做一个直方图，你会发现语言的词汇使用率也是呈幂律分布的。</p><p>不止中文、英文，其实全球语言使用的词汇其实都是服从幂律分布的。所以我们在学外语的时候，经常看到要背会最常用的多少个单词。比如大学英语你去考4级6级8级，很多词汇书上会写着“超实用XX词速记”“XX词随身带”，这些词汇书就是基于语言的幂律分布，来帮助我们更好地学习外语。</p><p>那么这种现象是怎么产生的呢？</p><p>病毒、树种和语言其实都有一个共性——传播性。比如在亚马逊雨林里，两株植物长在了一块，那么每天这两株植物就要为阳光和土壤中的养分去竞争。如果其中一株能比另外一株植物每天稍微长快一点，那么它就能长得更高，从而获得更多的阳光、吸收更多的养分。</p><p>如果每天都有这些额外的能量，这株植物就更加有能力把种子给传播出去，然后复制这种模式。一直持续下去，这种植物就会积累出得天独厚的优势。</p><p>在语言的使用和病毒的传播当中也是同理。开始的微妙的优势会随着时间逐步加强，最后就能占领绝对优势，就像滚雪球一样，越滚越大。拿美国来说，它的医疗水平能力确实很强，但是由于美国对待疫情的态度并不够重视，病毒在美国其实是占据传播的优势的。所以强如美国，最后也被新冠给好好上了一课。</p><p>说到幂律分布，那就不得不提一下帕雷托法则了。你或许对帕累托法则有些陌生，但我要是说二八法则，你肯定听过。</p><p>二八法则简单来说，就是20%的人占了80%的资源，剩下80%的人分最后20%的资源。这个法则诞生于帕累托的花园。有一天帕累托偶然发现，自己园子里绝大部分的豌豆是由园子里极少部分豌豆荚产生。</p><p>作为一名擅长数学的经济学家，帕累托意识到这里面大有玄机。于是他马上把这种现象应用到了生活的其他领域，他惊奇地发现，意大利人80%的土地仅掌握在20%的手的人的手中，就和园子当中的豌豆荚类似，于是发表了著名的“帕雷托法则”（也被人称之为“二八法则”）。这个法则的背后的规律就是幂律分布。</p><p>企业的竞争力也同样符合帕累托法则。举个例子，如果我们把全网短视频APP的月活用户用柱状图表示出来，你会发现同样符合幂律分布。就像文稿里的这张图这样，比较高的APP的月活会高于均值很多倍，第一名、第二名分掉了整体赛道流量的90%。所以在互联网领域里才会有这么一句话：一个领域只有第一、第二，没有第三。</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/83/a2bfd8c3489840c9b9de37e774120183.png?wh=1626x1085\" alt=\"\"></p><p>幂律分布与帕累托法则其实都强调了重要的少数和琐碎的多数，从某种意义上来讲，世界从来都不是平衡的。</p><p>所以在日常生活里，不要把所有事都放在同一个优先级上，而是学会用帕累托法则去看待问题，找出最重要的20%的问题，并最优先解决。同时，你也要留个心眼：为什么这20%的问题对你来说最为重要？</p><p>对应到工作中，你可以多想想以下几个问题。</p><ul>\n<li>在你一天的工作分配当中，由于80%的工作都是日常反馈，你是否安排了自己最清醒的时间去处理最重要的20%工作？</li>\n<li>你所在的公司，是不是由20%的客户来为公司提供了80%的利润，如果是，应该如何留住这些客户？</li>\n<li>在团队里，杰出贡献是20%的人做的，80%的人是配合，那么针对这20%的人，你应该如何留住他们？</li>\n<li>能否通过弥补20%的质量缺口去获得80%的收益（或者避免80%的客户投诉）？</li>\n<li>在最有效的20%的时间内，如何引导团队做出80%的相关分析？</li>\n</ul><p>最后再来说说我们个人的发展。为什么有的人一开始和普通人差不多，但是他们后来渐渐地把同龄人甩在了身后？</p><p>有的人可能会觉得是因为这些人运气好，运气也是实力的一部分，但毕竟“幸运只光顾有准备的人”。你比其他人更努力，每天多积累1%哪怕是0.1%的优势，这样把优势不断积累下去，你就会占据越来越多的资源，成为这个领域里面的专家。</p><h2>小结</h2><p>好了，今天的课程到这里也就接近尾声了，我再来带你复习一下今天讲的内容。</p><p>今天我给你讲了两个重要的概念。一个是非常简单但有效的工具——直方图。直方图可以让你从混沌的数据里面找到其中的规律。很多的数据分布（包括下面几节课要讲的正态分布和拉普拉斯分布）都会用到这个工具。</p><p>紧接着我们从直方图讲到了幂律分布。这个统计学规律告诉我们，我们身处的世界是赢者通吃的世界，开始时细微优势最终将带来无穷多的回报。反之，最初的细微劣势也将导致最终一无所有。这个现象也有人称之为“马太效应”，在圣经《新约·马太福音》中是这样描述的：“ 凡有的，还要加给他，叫他多余。没有的，连他所有的也要夺过来 ”。</p><p>我们耳熟能详的帕雷托法则（也就是二八法则）、马太效应都是来自幂律分布。这个数字分布其实有很多点值得我们去思考，你可以尝试多在日常的工作以及生活里用一下它，或许能够给你一些意想不到的惊喜。</p><p>当然，帕累托法则给我带来最重要的一个认知更新是：每天在我们自己的专业领域里面，或者你的企业在所在的赛道里，只要你比其他人或者其他企业多成功1%，最终积累起来的竞争优势将使别人无法超越，你就会变成那个能够大声说“我全都要”的少数派。</p><p>不积跬步，无以至千里；不积小流，无以成江海。数据给你一双看透本质的眼睛，让我们每天在数据这个领域里面比别人多1%的认知，最终看到一个和别人完全不同的世界。我们一起学习数据的规律，一起共勉！</p><h2>课后思考</h2><p>在你的工作生活当中，还有哪些事情你觉得符合帕累托法则或者幂律分布？背后的原因是什么？分享出来，我们一起共同提高！</p>",
                "article_title": "05 | 直方图与幂分布：为什么全世界1%的人掌握着50%的财富？"
            },
            {
                "title": "06 | 数据分布：房子应该是买贵的还是买便宜的？",
                "id": 405241,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>在上一节课里，我们聊了聊直方图和幂分布。其实一提到数据分布，你首先会想到过去在课堂上学的二次分布、柏松分布等等分布。学习的这些分布对你考试很有帮助，但是在生活当中我们其实用得不多。</p><p>其实在实际生活当中，我们最常见的是正态分布和拉普拉斯分布，这两个分布反映了现实生活当中隐藏在数据背后的“势”。了解这些数据的趋势，才可以让你更好地了解实际的工作和生活本身。</p><p>为什么说这两个分布会更实用呢？</p><p>比方说，一座城市的市民身高或者体重分布就是符合正态分布的。再比如说，极客时间所有用户的日均播放时长，它也会是一个正态分布的曲线。</p><p>正态分布既然这么常见，那么一个城市的房价也应该和这个城市市民的身高一样，是正态分布的。但现实往往是明明只隔了一条街，房价相差巨大，有的时候差价甚至会高达数倍。这就像100人里，突然出来10个姚明一样让人费解。这个时候，就轮到拉普拉斯分布出场了。</p><p><strong>今天这节课，我就以正态分布和拉普拉斯分布为例，给你讲下数据分布以及怎样用数据分布理解我们生活和工作中的“大势”。</strong></p><h2>正态分布</h2><p>我们先来看正态分布。正态分布就是你在课本里曾经学过的那个<strong>两头低、中间高然后左右轴对称的钟形曲线</strong>。最早用正态曲线描述数据的人，就是那位你我都熟知的德国著名数学家高斯，为了纪念他，有时候我们也把正态分布称为<strong>高斯分布</strong>。在德国，十马克的纸币上都留有高斯的头像和正态分布的曲线，如下图所示。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/49/f0/4940be6e3d0a4deef4b34b94109664f0.jpg?wh=1142x640\" alt=\"\"></p><p>但正态分布这个名字不是高斯取的，而是由达尔文的表兄弟弗朗西斯·高尔顿命名。高尔顿开创了遗传学的统计研究，并用正态曲线来表明他的研究结果，这个名字后来广为流传。</p><p>学术上是这么来定义正态分布的：“<strong>如果一个量是由许多微小的独立随机因素影响的结果，那么就可以认为这个量具有正态分布</strong>”。听完这个定义，你能不能联想到我们前面讲的平均值和大数定律呢？</p><p>结合平均值和大数定律，我来给你举一个我们现实生活中的例子。比如我们知道中国人的平均身高大概是1米7，那么实际上我们随机找100个人，把每个区间的身高累个计数画出来一个直方图，它就会是一个正态曲线。</p><p>对这个曲线来说，他们平均值1米7就是最高的那个点，1米6几和1米7几的人数会分布在最高点的两侧。随着身高的增长或降低，人数会逐渐减少，最后就呈现出了钟形曲线两边的下降。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/52/2739517d5a74cf6f404938cbb8726a52.png?wh=718x437\" alt=\"\"></p><p>我们来看个具体运用正态分布的例子。比方领导说要访谈调研下用户整体对你的产品的反馈，于是你通过发调研问卷的方式，拿出100个调研结果给领导。但没想到领导说，你这太不专业了，都是片面回答，你要给我95%的准确率。你很委屈，你不知道多少人才会有代表性，才能达到领导要的95%准确率。</p><p>那么我们具体需要多大的人群来进行测试，才可以符合领导的要求呢？</p><p>答案是400人。具体推算的方法，你要是感兴趣可以参考这节课最后的附录部分，并自己动手来算一算。现在我先给你讲一下整体的推算思路：</p><ul>\n<li>由于我们选择的身高、A/B测试、用户反馈都是随机分布的（符合正态分布），所以我们可以用正态分布来进行推算；</li>\n<li>领导说要95%正确率，其实就是说正态分布钟型曲线中间这个中段要95%，在计算的时候其实我们可以转换下思路，95%的正确率也就是指误差在5%以内。</li>\n<li>紧接着我们套用附录公式，去查正态分布表进行计算后就可以得出结论。</li>\n</ul><p>你从附录的计算结果中可以看到，如果是要95%的正确率，那么需要385人参与测试。但是我们选人数一般不会这么有零有整，所以通常来说，选400人会比较合适。</p><p>如果你的调研还要针对地域、年龄再进行进一步的细分，你也可以通过正态分布来把它计算出来，不过你需要注意的是，你用于调研或者测试的样本就不是两种而会变成多种了。</p><p>我们要根据某一个数据进行运营估计的时候，也可以用到正态分布。</p><p>比如我们现在要根据极客时间用户每天收听音频的平均时长来打造一个用户等级，那这种用户等级分布和所需要的福利金额费用大概是什么样子呢？</p><p>其实只要我们算出来极客时间的<strong>每一个用户的日均平均时长</strong>（就是所谓的总体均值），再根据误差范围设定标准差，就可以根据随机抽样和中心极限定理，得出来每个不同等级的用户的数量。这样，我们做积分的估算补贴和使用的时候，心里就有数了。</p><p>我看到网上很多人都把<strong>中心极限定理</strong>和<strong>大数定律</strong>放到一起来谈，你可能听过这样一句话：“在随机原则下，当抽样数目足够多的时候，样本就会遵照大数定律而呈正态分布”，这其实是不对的。</p><p>大数定律研究的是随机变量序列依概率收敛到其均值的算术平均，<strong>说白了就是为了说明频率在概率附近摇摆</strong>，也为我们将频率当作概率提供了依据。</p><p>可能这么说还是有些绕，我拿抛骰子给你举个例子。在抛骰子这件事上，大数定律说的是只要你抛的次数足够多，骰子每一个面向上的概率应该都是1/6。</p><p>而中心极限定理要求的是独立随机样本，<strong>在中心极限定理下，随着样本数量趋于无穷大，独立随机样本和独立随机样本和的分布会越来越像正态分布。</strong></p><p>还是用抛骰子的例子来给你解释一下中心极限定理。比如你抛6次骰子发现求和是18，你又抛6次发现加起来是20，你又抛了6次，这次发现加起来是25。如果你抛的次数足够多，你把18、20、25等这些数据画出一个图来，这个图是符合正态分布的。</p><p>所以大数定律和中心极限定理说的不是一个维度的事情。大数定律算的是概率，中心极限定理算的是样本和的分布。</p><h2>拉普拉斯分布</h2><p>还记得我们这节课开头提到的房价这件事吗？理论上房价应该和人的身高一样，在某一个地区有一个均价，并且整体的房价和身高是一样呈正态分布。但为什么在某一个区域可能就隔了一条街，房价却翻了好几倍，而且数量也不少？这不符合刚刚说的中心极限定理呀。</p><p>关于这个问题，我的答案是：我们的房价其实和我们的身高是不一样的，它不是我们想象当中的<strong>正态分布</strong>，而是我下面提到的<strong>拉普拉斯分布。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/f8/5c/f8cb337e54yy038ef42ff012ac60a15c.png?wh=649x605\" alt=\"\"></p><p>拉普拉斯分布就和上图一样，是一个“凸”字形的塔尖儿曲线，从左到右，斜率先缓慢增大再快速增大，到达最高点后变为负值继续先快速减小，最后再缓慢地减小，所以有点像“往里边凹陷的金字塔”<strong>。</strong></p><p>对比正态分布的概率密度函数图像，我们可以看到拉普拉斯分布图像是尖峰厚尾的，塔尖上的那些，就是我们看到的稀缺资源。比如拿全球顶尖程序员的薪资（塔尖对应的横坐标值是均值）来说，全球顶尖的程序员年薪是100万美元，但这部分群体可能只占全球城市人口的1%，程序员中的人数不足10%。但是，90%的资源其实都在他们的身上，够刺激吧。</p><p>那我们怎样去理解这个拉普拉斯分布呢？它经常用在金融领域，尤其是衡量股票收益的时候。起初我们认为股票收益率是服从正态分布，但是由于股票价格波动与时间变化有关，有波动聚集性，最后实际股票的收益率都是符合拉普拉斯分布的，也就是赚大钱的日子其实特别集中，余下的都是赚小钱的日子。</p><p>现在随着市场和互联网的发展，信息越来越透明，我们相关的数据分布其实变化还是挺大的。</p><p>比如说在改革开放之前信息不对称，资源也相对没有那么聚集，人们拿到的工资是一个正态分布的。但是到了现在，就我们程序员的工资来说，一个顶尖的程序员和普通的程序员的工资收入可能会差十倍都不止，这就会导致更厚的尾部和更高的峰度。</p><p>而全国的城市房价分布、一个城市当中的小区房价分布现在也是符合拉普拉斯分布的。因为在信息透明和市场竞争的情况下，工资、房价、股票都会符合一个特点：<strong>越塔尖的个体越具有资源吸附能力。</strong>那么在整体资源恒定的情况下，这已经不是一个简单的符合随机分布的市场了，简单来讲，“大势”变了。</p><p>所以当你在做数据分析的时候，一定得先考虑一下，原有的数据分布模型是否还适用于现有的市场情况？</p><p>准确把握住数据分布这个大势，我们才能够做出更为正确的决策。就拿买房这件事来说吧，买房是一个我们基本都绕不开的话题，在你买房前，你可以先判断一下你要买的房屋的房价在这座城市里是正态分布还是拉普拉斯分布。</p><p>也就是说你可以去评估一下，你所在城市资源是否比较平均？会不会出现聚集效应？如果你认真用这两个分布去判断一下，你会发现如果你所在的城市是三四线城市，那么房价的分布大概率会呈正态分布。那么在这种情况下你要投资买房就可以选择价格在曲线腰部的房子，这种房子的房价将来涨跌以及抗风险性都比较适中。</p><p>而如果你准备买大城市里的房子，情况就不一样了。因为对于一线城市的房价而言，大概率是呈拉普拉斯分布的，这也就意味着越贵的房子周边资源越好，进而这些房子将来增值空间越大。那我们买房子的时候就应该买资源最好的最贵的房子，未来的收获也最大（当然，如果最贵的已经天价了，那么我们可以退而求其次）。</p><p>反之，当你看到一些铺面房非常便宜的时候，你要留个心眼了：是不是这些铺面房处于拉普拉斯分布的最两侧？如果是，那么这些铺面房不但增值空间小，将来还有可能买了亏本的风险。所以，只有了解整体市场的分布我们才能够更好地把握市场大势，顺势而为。</p><h2>小结</h2><p>好了，这节课到这里也就接近尾声了。最后我来给你总结一下这节课的要点。</p><p>今天我给你讲了正态分布和拉普拉斯分布，这是我们在现实生活当中最常用到的两个分布。希望这两个分布能够帮助你分析工作生活里数据背后的“势”，做好对生活、工作的决策。</p><p>将来无论在什么场景下做数据分析，数据的分布应该能贴合地描述我们社会上的“大势”，所以当你面临生活中的决策时，而不能就数据套数据、为了算法而算法，领域背后的知识对于我们更加重要。</p><p>就像今天我给你讲的正态分布和拉普拉斯分布的例子一样，现如今我们的生活中，有的事物符合正态分布，有的事物符合拉普拉斯分布。就比如说我们在买房的时候，没有判断好我们所处城市的房价到底是正态分布还是拉普拉斯分布，很有可能会导致你错误的投资决策。</p><p>更进一步来说，这两个数据分布其实给我们的工作生活也有一个大的启示，那就是为什么会有这样一句话的流行：“Work Hard, Play Hard”，因为这句话背后的含义其实是指当你要获得更多的自由的时候，你也要付出同等的甚至更多的自律（控制自己既能使劲玩也能使劲工作）。当今社会的人才分布是呈拉普拉斯分布的，我们要争取做顶尖，这样才会有更多的资源和机会。</p><p>数据给你一双看透本质的眼睛，我们要持续努力学习，一起共勉！</p><h2>课后思考</h2><p>在你工作和生活当中，你遇到的哪些事情的分布是正态分布，哪些是拉普拉斯分布？遇到这些数据分布的情况的时候，你应该做些什么？欢迎你留言我们一起讨论。</p><h2>附录：A/B测试需要多少人才有意义的推算</h2><p>我把推算的过程做成了图片的形式，你可以长按保存，然后打印下来，对照着自己用笔算一算。</p><p><img src=\"https://static001.geekbang.org/resource/image/d7/54/d74c52cc736f982ab4e3b78506b65454.jpg?wh=2016x2112\" alt=\"\"></p>",
                "article_title": "06 | 数据分布：房子应该是买贵的还是买便宜的？"
            },
            {
                "title": "07 |  散点图和相关性：怎样快速从数据当中找到规律？",
                "id": 406706,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>前面我们讲了怎么从一个数据累计量当中，发现它的分布规律。但其实很多时候我们遇到的数据并不是累计的分布数据，而是连续的一些数据，并且我们需要基于这些数据做一些总结和推断，甚至是预测。</p><p>比如在工作中，我们要根据成本和收入来预测下半年的投入和产出；在生活里，需要看下自己投资的基金、股票金额和回报的整体关系，又或者看自己体重增长和摄入热量的关系，这些其实都是要从数据当中去找趋势规律。</p><p>今天我就来教你一个最简单的发现数据趋势规律的工具，以及这个工具的使用方法——散点图和相关性分析。</p><h2>散点图的历史</h2><p>散点图被称之为万图之王。在1913年，美国一个叫做亨利·诺利斯·罗素（Henry Norris Russell）的天文学家用散点图把宇宙的趋势给揭示了出来。怎么揭示的呢？罗素同学利用散点图把2200颗恒星按光谱和亮度两个参数进行分析，将恒星光度（或绝对星等）为纵轴、以恒星的光谱类型（或表面温度）为横轴，就像下图这个样子。</p><p><img src=\"https://static001.geekbang.org/resource/image/a9/ac/a9a25c00eb88a3bdcaf163d49054cfac.png?wh=731x841\" alt=\"\"></p><p>通过这个散点图，罗素画出了一条趋势线，这条趋势线揭示了恒星从原恒星到红巨星到红白矮星、黑矮星的一个演变的过程，这就是著名的赫罗图。换句话说，这个散点图揭示了恒星这一生的秘密。</p><!-- [[[read_end]]] --><p>看，散点图可以帮我们解释宇宙的秘密。但这还没有结束，后来哈勃（对，就是以他的名字命名哈勃天文望远镜那位），也利用散点图找到了大爆炸理论和解释宇宙膨胀思想的一个关键证据，如果你对这个故事感兴趣，可以去本节课的附录里进一步学习。</p><h2>散点图的制作原则</h2><p>散点图能够帮助科学家在这么复杂的宇宙里找到一些客观的规律，更不要说我们日常去预测销售量和成本投入之间的关系、分析自己投资和回报的关系了。</p><p>那么我们怎样做出一个正确的散点图呢？其实我们用Excel就可以非常方便地去做出散点图。我在后面的实操课程里会进一步手把手地带你去操作，我们今天先重点关注散点图的制作原则。</p><p>无论你用什么工具，做散点图有三个最基本的规则。</p><p><strong>第一，散点图反映的是两个变量之间的关系。</strong>因此你要把两个变量分别放在X轴和Y轴上面，不要有第三个变量放进来进行混淆。当然，散点图的变种——气泡图有更多维度，但是从趋势角度来看，还是要把最重要的两个变量分别放在X轴和Y轴。</p><p><strong>第二，为了能够明确展示数据之间的趋势，我们的Y轴必须要从零开始。</strong>这点就和很多的柱状图不同了。很多柱状图的坐标轴为了表示数据的清晰，Y轴可以从一半（比如说500）开始。<strong>另外，散点图坐标轴颗粒度要合适</strong>，最终聚成一团或者散列太大，都会让我们无法快速找到趋势。</p><p><strong>第三，为了表示趋势的清晰，我们一般都会添加一条趋势线来表明背后的规律。</strong>说明一个趋势的趋势线只能有一条，不能有多条特别是出现趋势相交的情况。可别小看这个趋势线，这就是画龙点睛的一笔，背后其实是你对业务、数据、算法深刻的理解和认知。画得好，你就是哈勃和罗素，画不好你就成了我接下来会讲到的得克萨斯的伪神枪手。</p><p>比如对网站广告投入成本和销售量增加的趋势来说，散点图是要让你看到销售金额随着网站投放成本投入增加逐步增长的情况。它应该有标准的横轴和纵轴，分别代表销售金额和投放成本投入，有每一个月份对应成本和金额的离散点以及给出的趋势线。可能会有少部分点是离群点，离趋势线有一定的距离，但属于正常情况，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/6e/1a/6eca48yy6ffaac259210607d604d141a.jpg?wh=1576x1153\" alt=\"\"></p><p>这样我们可以看到何时我们投放网站最有效，而不是所谓的“增长黑洞”：一直广告投入最后回报率很低。</p><h2>通过散点图寻找规律</h2><p>有这三个原则的指导，我们画出来的散点图一般不会错。但是光有图肯定不行，我们如何在图中去找到数据之间的关系呢？下面我给你介绍几个散点图里面最常见的数据趋势。</p><p>首先是<strong>正相关</strong>，这个你很容易理解，它就是两个系数的变化基本上画出来以后都在一个直线分布上，此增彼涨，两个变量都一起增加，比如我们上下班的距离和时间。同样，<strong>负相关</strong>是一个此增彼减斜着向下的趋势，这种方式也比较容易判断。</p><p><img src=\"https://static001.geekbang.org/resource/image/38/76/3856073f88b9a462d80d4490fa741076.jpg?wh=1817x932\" alt=\"\"></p><p><strong>指数增长</strong>和上节课的指数分布有些类似，只不过指数分布计算的是一个加起来的累计分布值，而指数增长指的是两个具体数值的关系。这块如果你还是有些分不清楚的话，可以再复习一下上一节课。你看到这个曲线，一般会很高兴，因为它代表你抓住了一些别人没有的机会。指数级别的变化，一般背后都酝酿着极大的商机和机会。</p><p><img src=\"https://static001.geekbang.org/resource/image/bd/10/bdb3328c07a7f31fd7182826993d8010.jpg?wh=1154x917\" alt=\"\"></p><p><strong>正U型</strong>趋势和<strong>反U型</strong>趋势，这两个也是比较常见的趋势线。它的样子其实就像字母的U，或者是倒过来的U（从零开始从零结束）。一个比较著名的反U型趋势就是经济学里面的“拉弗曲线”（ Laffer curve），这条曲线最典型地反映了政府税收收入和税率之间的关系。</p><p>当税率开始增加时，税收一开始也会随之增加，但是当增加到一定程度，大家就交不起税了，重税导致企业开始倒闭和破产，这时候整体税收反而开始减小，到最终税率为100%时，其实企业会全部破产，税收反而是0了。</p><p><img src=\"https://static001.geekbang.org/resource/image/50/ee/50cf29fb2d691f3dbcf44e678f60e0ee.jpg?wh=1392x973\" alt=\"\"></p><p>U型曲线在很多场合也适用，例如员工工作时长和公司收入的关系（适度996，不要007），客户满意度与公司利润的关系（没有口碑的公司破产了，不加控制让客户全部高度满意的公司也都破产了）。</p><p>而<strong>数据分析的艺术就在于通过数据分析和管理经验找到反U型最高点</strong>，如果你能很好把握你所在公司的反U型曲线高点，你大概率是公司的管理层了。</p><p>还有一种情况就是所有的点全都分布在一条平行于X轴的横线两侧，就像下面这张图一样。其实这恰恰也表明了一个规律，就是这两个数据基本没有太大关系。也就是说不管X轴怎么变化，Y轴的指标它就是我行我素，在这种情况下，如果X轴表示的是成本投入，你就不要再自欺欺人说将来还可以有收入增长了。</p><p><img src=\"https://static001.geekbang.org/resource/image/c7/19/c7b2e07cd4cecyy5dbd57264424bd219.jpg?wh=1092x1017\" alt=\"\"></p><p>最后一种情况就是<strong>散点图呈一个非常复杂的图形</strong>。这个时候，我们不能轻易下结论，它需要我们根据所在的领域、行业的知识进行更细致的划分。</p><p>比如下面这张图就是挺著名的一幅散点图，这里面的数据分布就像一个心脏一样，心脏的两个左右上角的点聚集都比较密。但是你说它是什么趋势呢？貌似也看不出来。</p><p>这其实是当时美国大选进行民意调查时，选民主党和共产党的选民对50个不同调研问题的回答反馈总结出来的散点图。尽管我们看不出来这里面的趋势规律，但是我们还是能明显看到共和党和民主党选民的不同。</p><p>将来给你在算法部分讲聚类算法的时候，会再去给你深入讲这种情况怎么去划分。它不是用简单的线性、指数、二次项式等等趋势来表明的，它背后规律需要更复杂的计算机算法才能够揭示出来。</p><p><img src=\"https://static001.geekbang.org/resource/image/ca/74/caf0013ac4b0b38e6d484eb94998e774.png?wh=726x609\" alt=\"\"></p><h2>散点图的易错点</h2><p>看了这些，你会不会感觉散点图好像真挺万能的。但是你要注意，过度依赖散点图会造成你的判断错误。</p><p>最常见的三个错误就是趋势误判、得克萨斯神枪手谬误和幸存者偏差，接下来就是我们的“排雷时间”。</p><h3>趋势误判</h3><p>趋势误判是指在你看到了一个数据之后，因为数据整体还不够完整，你错误判断了这个数据的未来增长趋势。</p><p>这里我给你举个例子，曾经一位约翰斯·霍普金斯大学学者，给出了一个美国人体重增长趋势预测的散点图。这个散点图表示，在最近几十年内，美国人的超重现象越来越普遍。20 世纪70年代初，体重数超重的美国人不足半数；到 90 年代初，超重人数接近 60%；到2008年，几乎有3/4的美国人都超重了。</p><p>这个学者进行线性回归，其分析结果大致为：到2048年，这条线会达到100%。因此，这个学者在论文中断言，如果这种趋势继续下去，到2048年，所有美国人都会超重，也就是2048年在美国每个人都会是胖子。这个论文受到了大肆吹捧，各种媒体都争相报道，连中国媒体都进行了转载，你如果感兴趣的可以点击<a href=\"http://news.sohu.com/20080804/n258569154.shtml\">这里</a>，进一步了解一下。</p><p>这明显是个错误的结论。因为最终肥胖人群的增长趋势不是线性的，你现在看到的增长点似乎是线性，但其实它会是一个像抛物线一样的数据趋势（如下图）。</p><p><img src=\"https://static001.geekbang.org/resource/image/65/b4/65866ff4162838a17ab6505d0517e5b4.jpg?wh=1676x981\" alt=\"\"></p><p>你看看，对于全球这么著名大学的学者来说，如果错误使用了散点图，都会得出错误的结论。所以当你在拿到一个散点图，要去判断它是哪种数据趋势的时候，一定要看最终的数字偏差和实际情况，才能做出准确判断。</p><p>趋势线这个画龙点睛的一笔，不是那么容易给出的。通过散点图最终判断是什么模型是非常不容易，很多时候需要非常多的数据和复杂的模型，这也最终导致了人工智能算法的出现，当然这是后话了。现在你只要记住，<strong>没有正确的数据验证，千万不要轻易下结论</strong>，要不你也会和这个学者一样，闹一个大笑话。</p><h3>得克萨斯神枪手谬误</h3><p>在说这个谬误之前，先给你分享一个故事。</p><p>当年在美国西部得克萨斯州发现一个神枪手，他经常在各地的民居的墙上练习射击，几乎他所有的弹孔都集中在十环左右这个中心的区域。他已经成为了神话，人们一直在寻找他。</p><p>但是当人们真的找到了这个神枪手后，发现他自己打枪其实一点都不准，也不敢跟其他人去决斗。那他墙上的这些靶子和子弹点是怎么形成的呢？后来人们才发现，原来他是先朝墙上开很多枪，然后在弹孔最密集的地方画上了十环的靶子，再把散布在其它地方的弹孔用原来的泥土补起来。这样看上去，他每个地方打的靶子都很准确，因为先有弹孔，再有靶子。</p><p>在我们日常生活当中也很容易出现这种情况，当你看到一个数据散点报告的时候，你一定要看清<strong>背后所蕴含的实际数据是不是涵盖了所有的数据，还是只给你看了最有这种数据规律的数据。</strong></p><p>前者就像先有靶子来瞄准再去射击，后者就好比先射击完最后再画上靶子，这样结果会完全不同。依据数据决策很重要，但是也不要被数据给骗了。</p><h3>幸存者偏差</h3><p>幸存者偏差这点我们在<a href=\"https://time.geekbang.org/column/article/403845\">前面</a>提到过，这里我再基于散点图给你强调一下。</p><p>我们小的时候，邻居家的小孩永远比我们要更厉害，其实孩子都是差不多的，只不过最后我们看到的是邻居家小孩当中的那些优胜者；自古红颜多薄命，也是因为我们只把目光放在了少数的红颜身上；天妒英才也是因为我们没有过多关注普通人究竟寿命几何。那对应到我们画散点图上也是一样的，<strong>你在分析散点图的时候看到了规律，还要了解最终这个规律形成的原因和背后的场景，不要简单通过一个图表就得出你的结论。</strong></p><p>在工作和生活当中，每天都会有各种各样的事发生，如果我们只是关注事情本身，而没有看到背后的规律，那么我们就会像没有趋势线的散点图一样，都是零散的点，抓不住背后隐藏的那根线，感觉每天都是忙忙碌碌，但其实自己碌碌无为。</p><p>画这根线就是要找到你生命里的规律，在数据科学里我们叫做算法，生活当中我们叫做哲学。小小预告一下，在下一章算法里，我会和你继续深入探讨数据和客观世界背后的规律。</p><h2>小结</h2><p>好了，今天的这节课到这里也就接近尾声了，最后我们来总结一下。今天给你讲的是万图之王——散点图。小到我们自己投资和回报，大到整个宇宙里面星体之间的分布，我们都可以通过散点图来找到背后隐藏的规律。</p><p>要做一个正确的散点图，我们需要注意三个要点：</p><ul>\n<li>确定两个变量坐标轴；</li>\n<li>坐标轴的起始值和颗粒度要合适；</li>\n<li>要找到合适的趋势线和趋势模型进行描述。</li>\n</ul><p>紧接着我给你分享了几个在使用散点图时，容易犯的错误：</p><ul>\n<li>利用散点图做深入数据分析的时候不要轻易下结论（身高和体重在生长期是成正比的，你成年了自然也就不会再是正比了）；</li>\n<li>不能由现有结果给出趋势判断（做事情无论成功了还是失败了，都不要用上天的安排来麻痹自己），还需要了解规律形成的最终原因和背后的场景。</li>\n<li>不要用片面的数据来证明你的规律（不要片面看问题，别人家的孩子真的不比我们好多少）；</li>\n</ul><p>你不妨试试用最近48个月投资股票和基金的累计回报来画出一个散点图。你来看看自己的投资的散点图到底是正相关、负相关、无相关还是指数增长呢？结合前面学习的<a href=\"https://time.geekbang.org/column/article/401316\">大数定律</a>，这个散点图也就会告诉我们处于投资经验的哪个阶段。</p><p>我们要根据实际自己的业务领域知识以及后面讲到的算法模型找到接近事实的最佳解，这样才能够帮助你去预测这个世界，而不要错误利用模型最后导致我们出现错误的决策。</p><p>数据给你一双看透本质的眼睛，希望你可以通过散点图加上准确的数据模型和业务知识，真的让数据帮助到你的日常生活和工作决策。数据知识学无止境，让我们一起持续学习，一起共勉。</p><p><img src=\"https://static001.geekbang.org/resource/image/e3/02/e3aa4afdb79526c1e8baefe2d2ef4602.jpg?wh=2000x1221\" alt=\"\"></p><h2>课后思考</h2><p>你过去经验里，还有哪些是利用散点图发现的规律？哪些是错误利用散点图的教训？你生活中最常见的散点图是什么？欢迎分享给大家，我们一起学习。</p><h2>附录-哈勃定律</h2><p>哈勃（对，就是以他的名字命名哈勃天文望远镜那位） 也是用散点图展示了星系的退行速度和他们离地球距离之间的关系。下图里横轴是这些星系与地球的距离，纵轴是这些星系的退行速度。</p><p><img src=\"https://static001.geekbang.org/resource/image/2e/5b/2e767d8yye69861f0ed0187629e28c5b.jpg?wh=1648x1180\" alt=\"\"></p><p>这个散点图里图上每个点都代表了一个星系，通过这个图哈勃发现，与地球距离越远的这些星系退行速度越大，也成就了哈勃在天文学里找到的最重要的天文规律之一——哈勃定律。哈勃定律认为，星系可见的退行速度与它们和地球的距离成正比。总结出来的公式就是：退行速度=H0 × 距离，其中H0就是哈勃常数。这个定律是支持大爆炸理论和解释宇宙膨胀思想的一个关键证据，也让哈勃成为近代最著名的天文学家之一。</p>",
                "article_title": "07 |  散点图和相关性：怎样快速从数据当中找到规律？"
            },
            {
                "title": "08 | 标准差：这人是不是“靠谱”其实看标准差？",
                "id": 407445,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>前面我们讲过平均值不能够代表整体的水平，也给你讲了大数定律、散点图这些知识。接下来我们再进入一个常见的问题：<strong>怎样能快速看清一组数据的大概情况？</strong></p><p>对于这个问题来说，我们不必用非常复杂的散点图或者文字来进行表述，这个时候就轮到标准差登场了。标准差和数据分布、平均值一起就可以很方便地描述一组数据的大致情况。</p><p>标准差还有一个孪生兄弟叫做标准误差，这两个兄弟确实很像，我们也会经常能听到说“这个问题在误差允许的范围里。”感觉一旦说了这句话，好像这个东西就很靠谱了，但真的这样吗？今天我就给你展开讲讲标准差和标准误差。</p><h2>标准差</h2><p>标准差的概念比较简单，它代表一组数值和平均值相比分散开来的程度。也就是说，标准差大代表大部分的数值和平均值差异比较大，标准差小代表这组数字比较接近平均值。</p><p>标准差的计算公式我给你放在了附录里，公式看上去稍微复杂一点，但主要就是算每一个数据和平均值之间的差异距离。你经常听说某市平均薪资是X万，你很纳闷我和周边人薪资这么少，为啥平均薪资那么高，我是怎么“被涨薪”的？我们可以看一下下面这个例子，假如两个小组的月薪大概是如下这个样子，单位都是“万”。</p><!-- [[[read_end]]] --><p>第一组：[1.72，1.70，1.68，1.71，1.69] ；第二组：[1.70，5.20，0.60，0.2，0.8]。</p><p>这两组人你可以简单计算一下，你会发现平均月薪都是1万7。但很明显，第2组人的薪酬高低差异要比第1组人大很多。第一组人都是1万7左右的薪资，差异不大。你很不巧在第二组里，你月薪6000，周边都是2000、8000的小伙伴，但是实际上，你这组里有月薪5万的人你不认识，于是，你就“被涨薪”了。</p><p>通过公式或者Excel函数（我在最后一章会教你如何方便地计算），你能算出来第一组标准差是0.014，第二组是1.818，差异能有一百多倍。如果每次只给你某地区或者某部门的平均薪酬，但是不告诉你这个地区部门它的标准差有多大，那我们难免就会觉得困惑，“不患寡而患不均”用在这里依旧很合适。</p><p>所以看薪资的时候，<strong>你不仅需要知道一个平均值，同时还需要知道一个标准差</strong>，你才能知道整体薪资水平、你自己的水平以及你将来的天花板在哪里。</p><p>但是只有这个概念还不够，假设对于第1组的薪资单位来说，我用的是不是“万元”，而是用“百元”甚至“元”作为单位的话，它的标准差就会到1.414和141.4。这个时候再和第2组人员去比，感觉好像标准差的离散度更高，但是实际数据却不是如此。</p><p>所以一般我们真的在做数据分析的时候，我们会常用另外一个数据来规避这种问题，它叫做离散系数CV（coefficient of variation）。它的计算公式很简单，就是用标准差除以平均值（<strong>离散系数=标准差/平均值</strong>），这样的话就规避了单位或者其他因素的这些差异。我们直接看离散系数这个数据，就能知道这几组数据之间的离散程度和差异是什么样的。</p><p>下次你再去问人力资源部门的平均薪酬的时候，你可以多问一句“这个部门的离散系数有多少？”你大概就会知道，你可以要到最高多少的薪酬和你将来的涨薪空间会有多大了。</p><h2>标准差的具体使用</h2><p>标准差除了衡量一个群体里面具体数值之间差异有多大，比如说衡量我们的薪酬、身高、体重这些差异之外，它还有什么用呢？</p><p>它也会用于衡量一个人或者一个团队的稳定性，比如说。在你常见的NBA里我们会用<a href=\"https://zh.wikipedia.org/wiki/NBA%E4%B8%AA%E4%BA%BA%E5%8D%95%E8%B5%9B%E5%AD%A3%E5%B9%B3%E5%9D%87%E5%BE%97%E5%88%86%E8%AE%B0%E5%BD%95\">平均数据</a>来衡量一个球员的战斗力，比如场均得分，盖帽，抢断助攻等等。</p><p><img src=\"https://static001.geekbang.org/resource/image/d2/9d/d2a716d67977bf7d77f8475cbe94669d.png?wh=858x424\" alt=\"\"></p><p>同时，我们会使用<a href=\"http://sports.163.com/special/anglezero/nbaqp.html\">标准差</a>来衡量一个球员的稳定性。</p><blockquote>\n<p>如果只看场均得分达到20+的球员中，当属勒布朗-詹姆斯最稳定，标准差为5.8分，遍历他本赛季所有的比赛，他既没有超过40分的狂飙，也无低于13分的低迷。</p>\n</blockquote><p>类似的，我们在衡量一个团队的销售业绩整体情况的时候，我们会使用平均值。但是如果我们要看的是一段时间内团队成员的收入稳定情况和能力，我们就会看他最近成单的标准差。</p><p>同样，对应到做管理上，比如我做CTO管理程序员的时候，我会去留意大家提交代码的节奏。有的人就是喜欢所有事情都到最后一天才完成提交，有的人就喜欢平均用力，在各个时间段里都有提交。</p><p>用标准差来看，你就会发现有的人<strong>标准差非常大，属于突击型选手</strong>；有的人<strong>标准差很小，属于细水长流型选手</strong>。对于标准差比较大的人，他的风险就比较高，因为他有可能最后关头完美完成任务，也有可能拖延症拖到最后事情没有完成，最后整体的平均值都没有达到；而按部就班的人，他的标准差比较小，优势是比较稳定，但是突破性可能不够强。学到这里，你也可以试着评估一下你的工作节奏，你是属于哪一种选手呢？</p><p>而在做投资的时候，标准差也是一个重要的风险/收益衡量指标。你看我们在银行储蓄，这个利率波动就很小，相应地标准差很小；股票的波动就会大一些，收益的标准差也会比较大；你再看比特币，一会儿马斯克一句话翻好几倍，一会儿跌30%，炒币收益的标准差可能是银行收益标准差的上万倍，股票的上百倍。</p><p>所以如果你把钱放在银行，标准差较小，收益稳定；而如果你要去炒币，标准差这么大，你有可能大赚一大笔也可能赔得血本无归。标准差，其实就是代表着一个行业里面的波动情况，特别面对一个你不理解的投资产品的时候，可以看一下这个产品历史的标准差，和你常用的投资品比对一下，你心里就有数了。像黄金这种很稳定的产品，几个标准差就很大了。比如2013年04月16日黄金大跌，路透社分析师约翰·肯普（John Kemp）感叹黄金波动率<a href=\"https://business.sohu.com/20130416/n372827470.shtml\">超过6个标准差</a>，觉得非常不可思议。</p><p>像黄金一类很少波动的东西出现了这么大的波动，达到6个标准差的波动的时候（本来稳定的标准差发生了巨大改变），我们就把这种事件叫做“<strong>黑天鹅事件</strong>”。这次事件也被后来的人叫做“黄金黑天鹅事件”，所以你下次再看到黑天鹅事件的时候，你要知道这个说法是从标准差这里衍生出来的概念。</p><h2>标准误差</h2><p>说完标准差，我们来说一下它的孪生兄弟：标准误差。误差这个词我们经常在生活和工作当中提到，说“这个是在我们误差范围里可以接受的。”那么这句话里面提到的“误差范围”说的到底是什么呢？它和标准差是啥关系？</p><p>这两个概念经常在很多地方被混淆，以至于很多的统计模型里说的标准差，其实说的是标准误差。这两个概念之间最大的差别其实就是在于，标准差是针对确切一次的已知统计结果，反映的是在一次统计中，个体之间的离散程度，也可以说<strong>标准差是针对具体实例的描述性统计</strong>。</p><p>而<strong>标准误差代表一种推论的估计</strong>，它反映的是多次抽样当中样本均值之间的离散程度，也就是反映这次抽样样本均值对于总体期望均值的代表性，它主要是用于推断整体情况预测和推算使用。如果这么说你还是有些分不清这两兄弟，你可以用下面这个两个公式来对照分辨一下。</p><p>标准差（Standard deviation）= 一次统计中个体分数间的离散程度，反映了个体对样本整体均值的代表性，用于描述统计。</p><p>标准误差（Standard error）= 多次抽样中样本均值间的离散程度，反映了样本均值对总体均值的代表性，用于推论统计。</p><h2>标准误差的具体使用</h2><p>标准误差经常会被用于拿出一部分样品去判断整体产品线的产品质量，或者判断一个事情是不是属于常见范围。</p><p>比如说我们常见的六希格玛（Six Sigma），其实就是指所有的产品质量问题需要控制在6个标准误差里面。你听到的产品质量或者运维故障控制在3个9或者5个9，说的也是误差范围。5个9的意思就是99.99966%的产品是没有品质问题的。</p><p>这个是99.99966%怎么算出来的呢？这就涉及我们06讲里正态分布的知识，你要是记不清了，可以回过头再复习一下。</p><p>比如说我们用下面这个图做质量控制，那么这些值就是标准误差范围。例如，我们说在一个标准误差范围里，大概就是图里面的68.3%；两个标准误差范围里也就是距离均值（标准件）的95.4%；三个标准误差就是99.7%；6个标准误差（也就是6-sigma）也就代表着要控制到在生产的产品中，有99.99966%的产品是没有品质问题的（每一百万件产品中只有3.4件有缺陷）。</p><p><img src=\"https://static001.geekbang.org/resource/image/4e/76/4ef30be06631dc0e2a439ecd55eb1676.png?wh=963x516\" alt=\"\"></p><p>所以说我们从标准误差来看，系统的稳定性要保证5个9、6个9或者说我们开发的代码的质量控制是6-sigma，这个质量就非常好了。这么说可能你还没有感觉，我再给你做个比喻，帮助你理解一下。</p><p>帅哥美女其实在社会里面是非常难得一见的，毕竟我们绝大部分都是普通人。我们先假设人类美丽和帅的程度随机分布（整容的人没那么多），如果你每天见到一个美女（帅哥），那么有如下公式成立：</p><ul>\n<li>1个标准误差的美女约为3天一遇；</li>\n<li>2个标准误差的美女为约22天一遇；</li>\n<li>3个标准误差的美女约为370天一遇；</li>\n<li>4个标准误差的美女约为43年一遇；</li>\n<li>5个标准误差的美女约为4779年一遇；</li>\n<li>6个标准误差的美女约为139万年一遇；</li>\n<li>7个标准误差的概率约为10亿年一遇。</li>\n</ul><p>这样看，你就知道6个标准误差有多么严格了。你下次遇到一个特别美丽的女孩子，你觉得她是万年一遇的美女的时候，你可以和她说：“啊，你是6个标准差一遇的美女啊！”这肯定比说“你真美丽”要有深度得多，她肯定会对你学识非常敬仰（开个玩笑，真说估计会被打出去）。这样你应该知道标准误差是一个什么含义了。</p><h2>小结</h2><p>好，回顾一下今天的内容，今天主要给你讲了两个概念：标准差和标准误差。</p><p>标准差针对已经发生的事情，它是平均值的一个补充标准。而标准误差是多次抽样当中对样本离散程度的描述，用于推论中使用。在后面的内容里，我们还会用到这两兄弟来评估和衡量一个算法的稳定性以及实现结果的好坏。</p><p>看一个人、一个企业、一个投资产品靠不靠谱，除了人办事情的成功率、企业收入平均值和产品的盈利率，你还要看它标准差是怎样的。有可能这个所谓的“成功人士”只成功了一次，赚了一大笔钱，但是其实别的事他都失败了，那说明这人的标准差很大，有可能他就是靠运气，不太靠谱。我们中国人其实是比较喜欢“中庸”的这种感觉，用标准差的视角来看，就是自己做事做人的标准差要小。</p><p>对标准误差来说，我送你一个成语，叫做“严于律己，宽于待人”。前半句是指我们在工作和生活中，要尽量少出错，甚至是不犯错，这样不仅做事漂亮，领导喜欢，而且这种不断追求完美的理念，会一直推着我们往前跑。你可以试试，把六西格玛的思想不仅用在工作中，也用在生活里，对自己高标准、严要求一段时间，相信你会获得更进一步的成长。后半句是说，躺平无罪，奋斗有理。我们可以用六个标准误差来要求自己，但是别人也有用一个标准误差要求自己的自由。</p><p>如果用一句话来概括，<strong>希望你尽量把自己做人做事的标准差变小，提高对自己的标准差预期。</strong></p><p>数据给你一双看透本质的眼睛，数据知识学无止境，让我们一起持续学习，一起共勉。</p><h2>课后思考</h2><p>你过去遇到过什么黑天鹅事件吗？从你的角度看，它是几个标准误差的范围呢？欢迎你在评论区分享你的想法，我们一起提高。</p><h2>附录：方差及标准差公式</h2><p><img src=\"https://static001.geekbang.org/resource/image/a0/48/a035dcaaaccd8bfc7d9b8a69a0ac9548.png?wh=2228x424\" alt=\"\"></p>",
                "article_title": "08 | 标准差：这人是不是“靠谱”其实看标准差？"
            },
            {
                "title": "09 | 数据抽样：大数据来了还需要抽样么？",
                "id": 408181,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>今天我们来聊聊数据抽样。无论在小数据时代还是大数据时代里，数据抽样都是非常常见的数据分析手段。人口普查、调查问卷、人工智能训练的过采样等等都是抽样的方式。我们之前学到的随机对照分布、直方图，散点图等等内容，它们数据的来源其实大部分也都是来自抽样数据形成的数据。</p><p>用好了数据抽样，你就不必大费周章去拿到每一个人的数据，可以“四两拨千斤”，在非常复杂的数据环境里面找到合适的数据结论。所以我把数据抽样称作数据分析方法的“涡轮加速器”，用好它你可以快速地收集到你想要的数据，从而更好地指导你的工作和生活。</p><h2>小数据下的抽样</h2><p>数据抽样其实可以分成小数据抽样和大数据抽样，我们先从最常见的小数据抽样入手。小数据抽样有4种比较常见的方式，它们分别是简单随机抽样、系统抽样、分层抽样和整群抽样。为了便于你理解，我把这四种抽样放在一个情景下来给你讲解。</p><p>大情景是这样子的：印度的新冠肺炎疫情现在很严重，我们想知道大概印度新冠肺炎疫情发病率是多少。</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/fe/c0257f6a45a1b6116ca743a8f9de99fe.png?wh=592x353\" alt=\"\"></p><p>这件事情我们该怎么做呢？让所有印度人都做一遍新冠测试是不太可能的，我们只能选取其中一小部分人来做测试。具体涉及选哪部分人的问题上，我们可以有四种不同的方式去选择：</p><!-- [[[read_end]]] --><p><strong>简单随机抽样</strong>：我们设印度总人口是N，我们可以在印度大街上，随机地抽取 m个访问对象来去做检测（m的数值可以根据前面的算法模型来进行确定）。最后根据这m个对象的测试结果，再根据前面的算法模型推算出整体印度新冠患病率。</p><p>抽象一下，<strong>简单随机抽样就是从总体N个单位中随机地抽取m个单位作为样本，使得每一个样本被抽中的概率相同。</strong>这种抽样的特点在于每个样本单位被抽中的概率相等，每个样本单位完全独立，彼此间没有关联性和排斥性。</p><p>但是简单随机抽样这种方法有一些执行层面的问题。比如在印度大街上很有可能具体执行的时候，调查人员图方便，仅仅在某几个街区来做调查。然后这几个街区恰好不具有全局的代表性，数据偏差的问题就随之出现了。</p><p>针对这种偏差，有一种抽样方法改善了简单随机抽样里执行步骤的规则，它就是系统抽样。</p><p><strong>系统抽样</strong>：为了避免调查人员全都扎堆到某几个地区去做抽样，我们可以立下一个规则，让每一个街区只能有10个人进行调查，并且街区和街区之间不得少于10公里。这样的话，在执行上就会更加容易，也能够更好地确保数据的随机性。</p><p>把上面的这个方法再抽象一下，<strong>系统抽样方法就是依据一定的抽样距离，从整体中抽取样本。</strong>这样做的好处是比较简单而且不容易出错，组装工厂里对手机质量进行抽样检测用的就是这个方法。</p><p>系统抽样解决了在随机抽样执行过程中无法真正随机的问题。但是这个方法依然有缺点，比如我们即使在每个街区上去找人抽样，你会发现在印度外出的男人比较多，而且大部分都是成年人。孩子、老人和妇女可能都在家中，这样随机抽样的结果其实也不能够完全代表全部人员患新冠的比例。</p><p>这个时候为了保证我们拿到的是全印度人民的新冠患病比例，我们就会再用下面这种分层抽样的方式来确保整体的样本是均匀分布的。</p><p><strong>分层抽样</strong>：我们在系统抽样的结果之上可以再加一个人口分层，根据年龄、性别、地区这样的规划分成不同的层。随后我们在每一个细分的层里面，再去随机地抽取样本进行测试。这样的结果会更接近最终的事实，但是它的执行的复杂性也更高了。</p><p>我们再把分层抽样来抽象一下，<strong>分层抽样就是将抽样单位按某种特征或某种规则划分为不同的层，然后从不同的层中独立、随机地抽取样本，从而保证样本的结构接近于总体的结构，提高估计的精度。</strong></p><p>这里特别要说的是，在为了避免“<a href=\"https://time.geekbang.org/column/article/400764\">辛普森悖论</a>”的时候，我们通常把不同维度的人群都抽样一部分进行计算。</p><p>用了分层抽样这个方法，的确统计精度更高了，但是问题又来了：分层抽样的可执行性太差了，根本没法在印度当地细分出这么多的层，然后再让调查人员去分不同年龄段、不同地区、不同性别分别统计。</p><p><strong>整群抽样</strong>：针对在印度没法细分这么多层的情况，我们得把刚才的这些层合并起来形成一些大组，然后针对这些大组进行抽样。这种方法叫做整群抽样，在企业单位进行人力调查反馈的时候经常会用到。</p><p>抽象一下，<strong>整群抽样就是将总体中若干个单位合并为组（这样的组被称为群），抽样时直接抽取群，然后对所选群中的所有单位实施调查。</strong>抽样时只需要群的抽样框，可以简化工作量。你会不会觉得分层抽样和整群抽样不太好区分？告诉你一个分辨小技巧：分层抽样是先分层再从各层抽样本，整群抽样是先分群再抽一个群调查。</p><p>整群抽样方法也有很明显的缺点，那就是精度较差，很可能出现一些偏颇的情况。所以如果你发现你在员工调查问卷里被贴了一些不切实际的标签，也不用感到特别奇怪——因为整群抽样不是那么精确。</p><p>所以你学到这可能会有点懵，这四种抽样方法都各有优劣，那么我们在日常使用过程中，应该如何选择呢？</p><ul>\n<li>如果你要抽样的样本总量比较小，你对人群比较了解，人群构成也比较单一，你就可以直接使用简单抽样方法进行统计；</li>\n<li>如果针对某一些场景下且这些人群你接触概率基本相同，你就可以用系统抽样来做统计。例如，现在北京大街上看到做问卷的人，基本上都是针对逛街一族或者上班一族的系统抽样统计；</li>\n<li>如果你想要比较精确地统计，同时你的抽样动用的资源比较多时，你可以使用分层抽样，这样得到的结果会比较科学，但是动用的资源比较多；</li>\n<li>如果你的资源不够，可以通过各种方式把一些分层或者一些组织机构合并成群，针对群来抽样，当然代价就是降低了整体的准确度。</li>\n</ul><h2>大数据是否要抽样？</h2><p>给你讲完了小数据抽样后，我们现在把目光放到大数据抽样。大数据抽样是现在科技界的热门话题，不知道你有没有读过维克托·迈尔·舍恩伯格的<a href=\"https://book.douban.com/subject/20429677/\">《大数据时代》</a>呢？如果没有的话，我推荐你学完这节课后去读一读。</p><p>舍恩伯格提出的三种大数据时代的思维变革：要全体不要抽样、要效率不要绝对精确、要相关不要因果。这三种思维变革被大多数人所接受，大数据也被很多人冠以数据抽样终结者的称号。</p><p>这种观点和我现在要讲的大数据下如何去做数据抽样格格不入，所以我要先花一点时间讲清楚为什么大数据时代还需要抽样这个问题。</p><p>大数据时代为什么还需要抽样呢？我来给你讲讲三个主要原因，你也可以自己思考一下。</p><p>首先从数据分析目标上讲，大数据之所以是大数据，是因为可以分析到每个人的行为，从而进行计算和推荐。如果我们针对的是千人千面的个性化推荐，那一定是将每个人的数据进行分别存储和计算的，否则就失去了大数据的意义。而针对数据的统计分析和BI分析指标，还是可以复用原先的数据分析方法和抽样原则。因为大数据也没有逃脱数学的法则，<strong>在允许一定误差的情况下，抽样可以大幅缩减参与计算的数据量</strong>，这和舍恩伯格提到的“要效率不要绝对精确”是一致的。<strong>所以在大数据下的统计分析可以沿用小数据的抽样算法，这一点是具有理论基础的。</strong></p><p>其次，在做数据分析的时候，对数据质量的要求是要远远大于数据量的，所以数据并不是越多越好。而<strong>抽样过程能帮助我们控制有效数据的比重</strong>，我们可以用各种各样的规则去做数据处理，而不是不假思索地将所有数据都纳入其中，否则一个看似从大数据里找到的规律，很可能只是一个计算口径或者数据质量的问题。<strong>因此大数据也要了解数据的构成，也可以进行合理的抽样。</strong></p><p>最后，从数据量级来看，每年的数据量级都以指数级增长，当IoT数据时代来临后更是爆炸式增长。数据的迅速增长对于普通公司甚至于大型公司来讲都并不全是好事，以大数据全量计算一些需要实时反馈结果的数据分析任务也是不划算的。毕竟每一次全量计算动辄1个小时，多则1天，这会非常影响数据分析师的分析思路。我们期待的数据分析是可以数秒内反馈的，这样能提高数据分析师的分析效率，<strong>合理的抽样方法可以有效提升计算效率。</strong></p><p>上次遇到舍恩伯格时，我问了他类似的问题。他给我的回答是：“大数据并不是否定统计学，大数据是一个综合了统计学、工程学、人工智能等的综合学科，扩展了这些学科的边界。”我想这也是对这个问题的正式回应，<strong>大数据并不是否定原有的统计学原理，而是用工程能力扩展了统计学和数学。</strong></p><p>回到舍恩伯格这句话，“要全体不要抽样”，舍恩伯格其实针对的是因为大数据采用了更大的计算能力，可以对每一个个体进行分析和统计，然后采取相关行动（例如对推荐来说，你在抖音里每个视频都是针对你个人的一个推荐）。指的是全体当中个体，他说是针对每一个人都有特殊的解决方案，而不是抽样某几个人就把针对这几个人的解决方案给全体人员。</p><p>对于过去统计学涉及的整体统计指标、趋势分析、分布分析这些知识来说，依然可以使用抽样的方式来解决整体人群的趋势问题。所以，舍恩伯格没错，我说的也没有问题，这只是针对大数据的两个不同的分析场景而已。</p><h2>大数据中的抽样算法</h2><p>现在你知道了，在大数据分析中，我们也经常会用到统计学的抽样方法。在大数据环境下，抽样统计方法会有什么不同呢？我举两个常用的在大数据情况下使用的抽样算法给你讲解一下。</p><h3>蓄水池算法</h3><p>在大数据环境下抽样最典型的就是一个叫<strong>蓄水池</strong>的抽样算法。它非常有名，甚至被写入到全球领先的大数据公司Cloudera公司数据平台的 Clouder ML中，成为常用函数。同时，它也是硅谷面试数据工程师时最流行的面试题。</p><p>那蓄水池算法指的是什么呢？它说的是这么个问题：“给你一个长度很大或者长度大小未知的数据（流），并且你只能访问一次该数据（流）的数据。请写出一个随机选择算法，使得选中数据流中每个数据的概率都相等。”</p><p>对于文科生听上去有点是天书，我用大白话再给你翻译一下。</p><p>还是用刚才印度新冠肺炎疫情这个例子，假设印度现在人太多，没人知道印度有多少人口，也不知道印度的整体情况是什么，我们要去通过抽样调查统计新冠的比率，我只能遇到一个人去统计一个人，然后要有个算法看是不是抽中这个人来调察。但是怎么能够让每个人被选中的概率相等呢？</p><p>这时蓄水池算法应运而生，我给你简单分享一下它的算法思路。我们需要把抽中做统计的印度人都放到一个游泳池（蓄水池）里。假设我目标是只抽n个人，这就有一个有n个人容量的游泳池，抽中的人都站在这个游泳池里面。当游泳池站满了以后，再往里加人的话有一定的概率会把游泳池里面的人给挤出来，也有一定的概率是新加的人根本挤不进去游泳池（想象一下上班时间的北京地铁）。</p><p>这样无论一共有多少人进来，他都有一定概率挤进游泳池里或者被挤出去，游泳池里面最后留下来的人，就是我们要的随机的n个人，这些就是我们的抽样结果。我们最后统计这些人的新冠阳性情况时，就可以说我们是随机抽样的，而不用管印度一共有多少人口了。</p><p>这就是大数据下的蓄水池抽样算法，详细的推导我放在了这节课的附录，你如果感兴趣可以去附录里进一步学习。通过这个硅谷最热门的面试算法题，你就知道了：大数据计算时也是经常会抽样的。</p><h3>过采样和欠采样</h3><p>大数据里因为数据非常多，所以往往某一类的数据远高于另一类数据，而这些数据都直接给我们下一章讲到的人工智能算法的话，我们造出来的人工智能可能就学坏、学歪了，因为人工智能就像一个小孩子，你教给它什么，它就学什么，你天天告诉它麻子脸的人是美女的话，将来它的审美就是如此。</p><p>所以在大数据里，除了刚才提到的蓄水池抽样算法之外，还经常会遇到两种抽样方法：<strong>过采样</strong>和<strong>欠采样</strong>。过采样就是在一个池子里反复去抽样，本来应该抽样10个人，我们把这10个人反复抽样，变成50个人。欠采样就是在一个池子里本来我们应该抽样100个人，现在只抽样10个人。</p><p>举个例子，我们现在想训练我们的人工智能去分辨什么是美女。这件事情可挺难的，因为世界上的美女比较少，长相比较普通的女生比较多。如果我们给人工智能真实世界里边的女生样本去训练，他可能就认不出来哪些是美女了。因为美女太少，它学的不够。</p><p>在这种情况下，我们就会采用“过采样”的方式，将美女的数据复制为多个以供人工智能去学习；而对于普通女生，我们就可以采用“欠采样”的方式，保持两者数据量的平衡。这样在人工智能这个小孩看来，世界都是1:1的，他更容易去区分美和丑，就像下面这个图的样子。</p><p><img src=\"https://static001.geekbang.org/resource/image/67/62/67ddcd1a6cd8072b7b89039e371f1062.png?wh=1720x894\" alt=\"\"></p><p>所以，抽样其实在大数据计算当中是普遍存在的，特别是一些大数据计算高手或者数据科学家都会娴熟地利用各种抽样方法，事半功倍地解决大数据分析问题。由此可见，前面提到的“大数据是数据抽样终结者”的传言，基本上是不明真相的吃瓜群众杜撰出来的。</p><h2>小结</h2><p>好了，这节课到这里也就接近尾声了，我们再来总结一下。这节课首先给你讲了数据抽样的概念，通过一个统计印度新冠肺炎疫情的例子，给你讲了小数据抽样里最常见的四种方法：简单随机抽样、系统抽样、分层抽样和整群抽样。</p><p>然后我们讨论了“大数据是否需要抽样”这个问题，我给出的答案是需要。主要有以下三个原因：</p><ul>\n<li>大数据下的统计分析也可以沿用小数据的抽样算法，这一点是具有理论基础的；</li>\n<li>大数据也要了解数据的构成，可以进行合理抽样；</li>\n<li>从数据量级看，合理的抽样方法可以有效提升计算效率。</li>\n</ul><p>最后我们还聊了聊大数据中的抽样算法：蓄水池算法（当然我给你讲的是游泳池算法）、过采样、欠采样。通过这节课的讲述，我想让你明白一个道理：<strong>大数据其实不是数据抽样的终结者，无论是大数据还是小数据，它都无法逃离统计学、数学、集合论、数据结构等这些基础理论的约束。</strong>所以我之前给你讲的数据分析的原理，也同样适用于大数据环境。</p><p>如果你能把数据抽样的这个“涡轮加速器”运用到你自己的工作和生活当中，那么你就可以事半而功倍，通过针对一小部分的人和事情的观察而看到整个事物的整体情况。古人说“管中窥豹，可见一斑”，那么对应到我们的数据分析上，说的就是<strong>合适的数据抽样算法能够由点及面地看到事物的全貌。</strong></p><p>数据给你一双看透本质的眼睛。希望你能通过抽样算法，事半功倍地解决你工作和生活当中的问题。数据知识学无止境，让我们一起持续学习，一起共勉。</p><h2>课后思考</h2><p>你在日常生活当中有运用过抽样的方法吗？如果有，你具体是如何运用抽样的方法来解决你工作与生活的问题的？希望你分享出来，给我们大家一起开拓下眼界！</p><h2>附录：蓄水池算法明细</h2><p>1.将1~n条数据，存入待定长为n的集合序列，从这个序列里随机抽取k条数据，每条被抽取的概率为：k/n。</p><p>2.读到于第k条数据时：</p><ul>\n<li>定义第k条数据选中的概率为：k/n；</li>\n<li>如果被选中，在原集合序列中的n条数据中随机选择一条，替换为第k条的新数据；</li>\n<li>前k条数据被选取后，第k+1条数据要么被选取替代为前k条中的一条，要么不被选取，概率为k/n。再依此规则遍历所有的数据。</li>\n</ul><p>整体证明这个算法是公平的过程，你可以参考知乎的<a href=\"https://zhuanlan.zhihu.com/p/44154029\">这篇文章</a>。</p><p>单机版本实现起来可以如下实现，直接调用Sampling(k)，就可以得到蓄水池中的k个数据。</p><pre><code>public class ReservoirSampling {\n    private int[] ALL; // 整体的水池中的数据\n    private final int N = 100000; // 整体数据规模\n    private final int K = 1000; // 水池规模\n    private Random random = new Random();\n    public void setUp() throws Exception {\n        ALL = new int[N];\n        for (int i = 0; i &lt; N; i++) {\n            ALL[i] = i;\n        }\n    }\n    private int[] Sampling(int K) {\n        int[] Pool = new int[K];\n        for (int i = 0; i &lt; K; i++) { // 前面K个印度人直接进入水池\n            Pool[i] = ALL[i];\n        }\n        for (int i = K; i &lt; N; i++) { // K + 1个元素开始进行概率采样\n            int r = random.nextInt(i + 1);  //这就是K/N的概率\n            if (r &lt; K) {\n                Pool[r] = ALL[i]; //如果被选中了，那么这个人就被从蓄水池中挤出来，用新人进去\n            }\n        }\n        return Pool;\n    }\n}\n</code></pre>",
                "article_title": "09 | 数据抽样：大数据来了还需要抽样么？"
            },
            {
                "title": "10 | 指数和KPI：智商是怎么计算出来的？",
                "id": 408750,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>在日常生活中，我们经常希望用一个数字去衡量一个特别复杂的事物，这样即使是外行也能一下就了解某件事情的程度和分布。</p><p>那什么数字可以满足这个苛刻的要求呢？答案是指数。</p><p>简单来讲，<strong>凡是用指数描述的东西，都是一个长期存在或者需要大范围衡量的事情。</strong>指数就像一把尺子，把指数放在这里一量，你就能知道现在这个事情所处的状态是怎样的。于是我们经常在生活当中看到各种各样的指数，从空气的污染指数到股票的上证指数，从用户忠诚度指数到智力指数（IQ）等等均是如此。</p><p>指数本身的定义很简单，就是变量值除以标准值再乘以100。</p><p><img src=\"https://static001.geekbang.org/resource/image/c0/7c/c05b0eb180df22062295d64ae422847c.jpg?wh=1142x640\" alt=\"\"></p><p>接下来你可以想想，如果让你来设计一个数字去代表上海证券交易所整体的行情，你会怎么做呢？</p><p>如果你只选一只股票来代表整个上海证券交易所的行情，就会出现很多问题。比如你找的这家公司的股票退市了，那怎么办？或者是它进行了一些股票的增发/除权，突然之间价格变化非常大，那它能代表着当时所有股票的行情吗？</p><p>很明显单只股票是无法代表整体行情的，这个时候就轮到指数登场了。</p><h2>简单的指数：上证指数</h2><p>接下来我就以上证指数为例，带你看一下一个标准的指数应该由什么构成。</p><p>首先它得有标准值，也就是分母。你要注意，这个标准值不仅是一个数字值，也代表一个具体的时间点。比如，新的上证综合指数就是以2005年12月30日为基日（即基准日），以当日所有样本股票的市值总值为基期，以1000点为基点来做的分母。</p><!-- [[[read_end]]] --><p>其次，一个指数还要有一个加权的计算公式，这个计算公式是这样子的。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/4b/a09607b058f6aae6c57cb46708f3d24b.jpg?wh=1142x640\" alt=\"\"></p><p>也就是以基期和计算日的股票收盘价(如当日无成交，沿用上一日收盘价)分别乘以发行股数，相加后求得基期和计算日市价总值，再相除后乘以100即得股价指数。</p><p>看上去很简单，就是当前市值除以基期市值，但这还没完，上证指数还有<strong>一套修正的规则</strong>，这是非常重要的。因为一个指数不仅仅是一个数学公式，它背后还代表着一套管理规则。</p><p>所以对于上证指数来说，股票要有样本池，样本池可不是闭眼随便一选，而是需要由上海证券交易所选择的若干只大盘股和蓝筹股综合计算。</p><p>仅仅用上面这个公式还不够，因为样本池中的单一股票会由于非市场交易因素发生变动（例如配股和送股等），但是这些非交易因素发生变动而产生的价格变动都不计算在这个指数的变化范围内，这个时候就得用下面这个公式来做一下修正。</p><p><img src=\"https://static001.geekbang.org/resource/image/c2/97/c2a6d69b5c7f34b5c76496f94dff2597.jpg?wh=1142x640\" alt=\"\"></p><p>通过上证指数这个小例子希望你能够明白，其实指数公式本身很简单，关键在于指数公式的背后，你要如何去制定一个能够保持指数有效性的规则。指数不是一条一使劲就变长的橡皮筋，而是一把相对精准的尺子。</p><h2>较复杂的指数：用户忠诚度指数</h2><p>我们现在来看一个比上证指数要更复杂一些的例子。在互联网分析当中，我们经常会看到一个数据叫做用户忠诚度指数。</p><p>用户忠诚度指数顾名思义，它用来衡量用户做某种行为的忠诚度。这个指数和上证指数就不太一样了，它和大多数日常使用的指标一样，<strong>复杂度在于你对于业务的定义</strong>。例如我把忠诚度定义为第N日/周/月后回访的用户行为指标对于初始行为指标的占比，那么这个忠诚度指数就会变成下面这个样子。</p><p><img src=\"https://static001.geekbang.org/resource/image/3c/c3/3cf2cd9e6aa1bb931a0226b8cb3639c3.jpg?wh=1142x640\" alt=\"\"></p><p>这个公式看上去也很简单，但是这个公式在理解层面上相比于上证指数的公式，其实更难了。</p><p>比如说，什么叫初始行为指标？例如我们把这个行为定义成访问这个App或者网站的活跃用户数，这个忠诚度指数就是留存率。</p><p>但是问题又来了，什么是活跃用户数呢？我打开视频App看一秒钟算活跃吗？我要是第二秒就退出了，那我应该不是一个活跃用户。那是不是看五秒钟以上的用户就可以算活跃用户了呢？这些问题其实非常复杂。</p><p>并且对于用户忠诚度而言，我也可以说我今天在京东上面买了大闸蟹，我过了一周又去京东上买了大闸蟹，那么我在京东上对大闸蟹的用户忠诚度就很高。就像下图里一样，我们可以选择各种各样的条件来进行用户忠诚度分析。</p><p><img src=\"https://static001.geekbang.org/resource/image/ab/1f/abe87e14361da78828a2157dd4d13f1f.png?wh=1165x763\" alt=\"\"></p><p>类似用户忠诚度这样的指数，在我们日常工作当中经常会出现。这样的指数往往会有这样一个明显的特征：看上去公式很容易定义，但是对于公式的解释往往非常复杂，而且需要大量业务经验的人员和经验通过“<a href=\"https://www.infoq.cn/article/ubch5bdk2twgdo5x*uzn\">数据治理</a>”这个过程才能把它定义好。</p><p>而这个数据治理的过程可以用外部专家或者内部项目，建立一套每年要有公司级别的共识和变化的策略（和上证指数修正方法类似），才可以把一个指数真的延续下去。</p><h2>复杂的指数：智商（IQ）</h2><p>刚刚我们讲的上证指数和用户忠诚度指数都是用一个数字去衡量一组数字，那么现在难题来了：我们怎样用数字化手段去衡量一个复杂的事物呢？<strong>比如我们要怎样去衡量一个人的聪明程度？</strong></p><p>这件事情听上去就更复杂了。首先，就像我们前面提到的，制定某些维度去衡量一个人本身就是比较困难的。其次，人不是一成不变的，随着年龄的增长人的聪明程度也会发生变化。</p><p>我们能用一个固定公式来去囊括所有年龄的人吗？显然是不可行的。因为如果用大人的聪明程度去死板地衡量一个孩子，很可能就把一些特殊的聪明孩子给耽误了。</p><p>在20世纪初，法国心理学家比奈和他的学生编写了世界上第一套智力量表，后来心理学家推孟把这套量表介绍到美国，将其修订为斯坦福-比奈量表，并用标准测试题得出的心理年龄与生理年龄之比，作为评定智力水平的指数，这个比被称为智商。</p><p><img src=\"https://static001.geekbang.org/resource/image/7a/c2/7ae3281d1a7e82705ebca08f7e1460c2.jpg?wh=1142x640\" alt=\"\"></p><p>上面这个公式就是现在网上大多数人会告诉你的智商的算法，但这个算法其实是不对的。通过这个公式我们虽然能看到神童的IQ很高，但也会发现随着我们经验阅历的增长，用这个公式算出来的智商反而越低，也就是说我们人会越活越笨，这不符合实际情况啊。</p><p>所以目前最流行的智商计算方法是叫做韦克斯勒的离差智商，它的基本原理就如同正态分布的原理一样。</p><p>韦克斯勒的量表是一个平均值为100，标准差为15的一个正态分布曲线。在用韦克斯勒的方法测量智商的时候，你得先做一组标准的测验题，然后再将你的得分套用到韦克斯勒正态分布表（韦氏量表）中对应，这样就能得出你的智商值了。</p><p>当然，由于年龄差异的问题，韦氏量表也分为韦氏成人智力量表、韦氏儿童智力量表和韦氏幼儿智力量表这三套量表，可以用于检测所有年龄段的智商。</p><p><img src=\"https://static001.geekbang.org/resource/image/da/5a/daa87dacea5630178bc845e0cda3615a.png?wh=1383x903\" alt=\"\"></p><p>根据前面标准差的知识可知，正负3个标准差也就是6个σ能覆盖人类99.97%的情况。也就是说，100±15×3（也就是55到145之间）是大多数人的智商分布。所以当你的智商测试得分在100分以上，可以说你已经比较聪明了；如果是130分，你已经是相当聪明；如果你是150分，感谢你还在看我的专栏，因为你就是那个6个σ万世不遇的奇才，这就是现代智商的算法。</p><p>学到这，相信你也发现了，智商的计算在指数计算中是非常复杂的：既要有复杂的标准测试题，还要和全人类的实际情况进行比对，最终才能够得到一个合理的标准分值。</p><p>要做一把尺子来衡量人这种复杂动物的聪明程度，很难。</p><p>所以在咱们工作和生活当中，<strong>当我们要制定某个指数，比方说设定KPI的时候，我们要注意不要光看公式的建立，而是要把一系列定义调整的制度算法规定出来，</strong>否则很多KPI项目最后KPI完成了，但其实公司目的并没有达成。</p><p>可能这么说你还是有些不清楚，给你讲个小故事。话说有一天，小王发现路边上有两个人在热火朝天地干活：一个人在前面挖坑，土坑挖完后，后面的那个人赶紧跑上去把坑重新填上。小王就很疑惑，这不纯属在瞎忙活嘛！于是小王上前询问二人为什么要这么干。最后一问发现，原来是负责种树的那个人请假了，只剩下挖土填坑二人组自己完成自己的KPI，而没有完成种树这个目标。</p><p>所以最近新流行的管理方法OKR，其实是为了规避KPI管理的一些缺点，在某种程度上借鉴了指数建立和调整的规则：建立好目标O之后， KR可以进行动态监测和调整，并为之建立一套分层和计算调整体系。这里最关键的是对K（也就是key messuarement）的定义和相关的针对O的调整方法，和今天所讲的指标的定义和管理方法很类似，这套方法没定义好，不管是KPI还是OKR都很难有好的管理效果。</p><h2>小结</h2><p>讲到这，我们今天的这节课也就接近尾声了，最后我来给你总结一下今天的要点。</p><p>我们今天讲了指数，指数其实是把我们现实社会数字化的最常用的一种方式。仔细想一想，其实从我们个人的高考标准分到衡量我们每一个人工作的OKR或者KPI，再到现在衡量国家发展状况的居民消费价格指数CPI，其实这些数字都是指数在各种不同场景的表现。</p><p>我们聊了三个具体的指数例子，希望你能明白<strong>指数不是一个简简单单的加权平均值，它背后映射了一套管理的思维逻辑。</strong>即使是像上证指数一样有着复杂多变的股票的情况下，我们也得有一个标准的规则来去统计。而对于更复杂的情况（比如我们要衡量人的时候），我们更需要结合前面所学的多种数据分析方法和工具，来设计一个基于实验结果的指数计算方法，这样才能够客观地把活生生的人变成一组数字。</p><p>但在我们的生活和工作中，很多人往往会为了做一个可衡量的数字，不负责任地拍脑袋决策出一个结果。比如说我知道很多公司在做员工360度评估的时候，就是简单地套用一个标准公式，这样的评估往往是失败的。一定要基于细致的业务流程和实验，才能得到合理科学的结果。</p><p>因此我希望今天你学了指数这节课后，一方面当你在衡量一个事物的时候，不要轻易地拍脑袋造出一组数字来代表它。另一方面，希望你能够更加坚定地相信，数字是可以衡量这个世间所有事物的。毕竟如此复杂的我们都可以用数字来衡量，还有什么是不能衡量的呢？</p><h2>课后思考</h2><p>最后我们一块来做个思考题吧。你在日常生活和工作当中还会遇到哪些指数呢？它们属于我们这节课讲的指数类型的哪一种？它的定义和调整规则是什么？欢迎你分享出来，我们一起提高。</p>",
                "article_title": "10 | 指数和KPI：智商是怎么计算出来的？"
            },
            {
                "title": "11 | 因果倒置：星座真的可以判定你的性格吗？",
                "id": 409828,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>前面给你讲了很多数据分析的基本方法，在有了这些基本方法之后，其实还有很重要的一步是确定数据背后的逻辑，否则分析数据就和算命一样，看了下手相就直接告诉你一个结论。比如以下根据“数据分析”形成的耳熟能详的结论，你想想看究竟有多少是值得推敲的呢：</p><ul>\n<li>学术派：打篮球会让人长高，喝咖啡能长寿，不吃早饭会导致肥胖；</li>\n<li>网红派：爱笑的女孩子通常运气都不会太差（很暖心，对吧），《奇葩说》讨论的“会撒娇的女人更好命”。</li>\n</ul><p>这些结论感觉上都很有道理，甚至很多还有一些数据统计的报告来作为佐证，但其实仔细看背后的数据和逻辑，往往缺乏依据或者会出现因果倒置、因果无关的这种情况。</p><p>这种对于数据的用法其实是最危险的，因为这里面的问题往往隐藏得非常巧妙，你如果不深究其中的逻辑，往往会被数据所欺骗从而得出错误的结论，甚至指导你进行一些错误的行为。</p><p>所以我在这节课里，为你总结了最常见的6种误用数据导致错误因果结论的陷阱，希望你在今后的工作和学习当中，不要因为学了分析数据，最后却在分析数据时被数据所欺骗。</p><h2><strong>相关因果倒置——鸡叫导致天明</strong></h2><p>第一种就是最常见的因果倒置，这在公务员考试里也有专门的考题。</p><!-- [[[read_end]]] --><p>典型的因果倒置就是天亮了鸡就开始打鸣，但是我们不能说是因为鸡打鸣导致了天亮。但是实际的应用当中，我们往往会忽略这个逻辑。比如，我们在一些医学统计上会看到说不吃早饭会导致人肥胖，甚至还有大量的统计数据表明这些肥胖的人都没有吃早饭。</p><p>问题是，数据的确是同步发生的，但是不代表这些数据之间有因果关系。而且有可能会出现因果倒置——肥胖的人胖所以早上不饿，所以他不吃早饭。而比较瘦的人自身代谢比较快，晚上消耗多，早上就会比较饿，所以他要吃早饭。</p><p>所以如果你没有了解这个原因，然后只是很简单地觉得吃早饭就不会变胖（然后早上包子油条糖油饼），可想而知你的体重肯定涨的更快了。</p><p>同样，很多统计数据表明，选择多种投资方式的人往往比只从事本职工作的人更富有，现在都流行做投资，做一个有“睡后”收入的人。</p><p>相应地，很多人会认为多种投资方式会让人更加富有，其实这也是因果倒置。实际上只有人们拥有一定财富之后，才会去选择多种方式投资。所以如果你现在很穷，你直接去尝试多种投资方式，你大概率不会更加富有，有可能赔得更多了。</p><p>往往由于我们对事实的逻辑不清楚，我们会把事件的结果当成原因，这就会导致我们得到一些荒唐的结论（鸡打鸣导致天亮）。最终，如果我们按照这个数据结论进行操作，往往得不到我们想要的结果，还可能造成严重的危害。</p><p><strong>所以当我们看到数据结果的时候，一定要仔细推敲其中的业务逻辑，同时进行反向测试。</strong>例如对于吃早饭是不是会让人减肥这件事，我们就可以选两组类似的人去做随机对照实验，一拨人吃早饭，一拨人不吃早饭，其他的时间用餐的量和他们活动的量都一致，最终看不吃早饭到底能不能够减肥。如果发现他们的体重没有太大差异，那就说明吃不吃早餐和减肥之间没有任何因果关系。</p><h2><strong>相关性而非因果——吸烟真的致癌么</strong></h2><p>第二种我们经常看到的数据分析结论错误是数据相关而并非因果。这里面的例子非常多，比如曾经流行一个说法叫做喝咖啡能够长寿，海外和国内的官方报道都报道过此事。</p><p><img src=\"https://static001.geekbang.org/resource/image/f6/f3/f64cd9a4642a0263bd655a4a8b0165f3.png?wh=821x302\" alt=\"\"></p><p>但结论未必如此。因果是一个非常强的逻辑，我们初中学过因果叫充分条件，而不是必要条件。也就是说，因果意味着我们如果做了A，那么一定会导致B的发生。这在数据的领域里面其实是非常难证明的，我们可以通过数据实验去证明B发生和A没有关系，但是很难证明A就是B的发生的充分条件也就是原因，因为有可能他们之间只是数据相关关系，而不是因果关系。</p><p>是不是感觉有点晕？没关系，现在我用一个你非常熟悉的例子，再给你解释一下。我们经常能看到吸烟会致癌这个理论。但是吸烟真的能致癌吗？</p><p>当然，我不是要替吸烟的人辩护，从健康程度来讲，吸烟的确是有害于健康的。但是从科学角度上来讲，尽管医学家、统计学家在过去的几十年里做了非常多的试验，但到目前为止，我们还没有确凿的统计学证据可以说明吸烟致癌。因为致癌的因素太多了，你无法判断吸烟能够直接导致癌症。</p><p>现代统计学的奠基人费舍尔对香烟会导致肺癌结论表示了强烈的质疑，他只确认了吸烟和患有肺癌之间有相关性，但是从科学的角度上来讲，的确不能说因为吸烟，所以会导致肺癌。</p><p>看上去数据是正确的，但是如何解释数据其实非常需要动脑子。两件事情虽然相关，但是往往无法说明它们之间有因果关系。而因为我们的大脑容易记住有逻辑性的东西，所以我们经常把相关的东西“套上”一个因果的外壳，但这其实是不对的。</p><p>因果关系需要大量实验的验证证明，只要有A，B一定会发生（且没有其他因素的干扰）才能说明A可以导致B的发生。而这在现实里其实是非常难做到的，就像前面提到的吸烟导致肺癌，如果要严格意义证明这一点，我们必须要找到若干组同卵双胞胎（确保他们的基因类似），饮食结构完全一样，活动也完全一样。然后让他们一组人吸烟，另外一组不吸烟，还要让他们相互不知道在测试（确保对照试验公正性），最后还得吸烟组得了肺癌才有可能通过数据证明吸烟真的会导致肺癌。</p><p>这个困难度可想而知。<strong>所以以后在工作和生活中，不要轻易下因果关系的结论，相关并非因果。</strong></p><h2><strong>遗漏X变量——找到背后真实原因</strong></h2><p>我们在做数据探查之后发现了几个数据之间的相关性，虽然我们无法确认它们是因果关系，但真正在数据的探查和分析过程中，我们很有可能会找到相关的真实原因，从而去解决问题。这里我把它叫做找到遗漏的X变量。</p><p>举一个很有意思的例子，在英国瓦努阿图岛上的居民有一个奇怪的信仰：他们相信虱子有益于身体健康。因为经过数百年的观察，这里的人发现身体健康的人身上通常都有虱子，而生病的人就没有。</p><p>数据本身是准确无误的，科学家们也发现同样的数据，但不代表着岛上居民这个“虱子让人健康”的信仰就正确。后来经过自然学家实地考察发现了真相，原来这里几乎所有人的身上都有虱子，但是如果有人发烧，随着体温升高，虱子会因为受不了高体温而离开。</p><p>所以看上去是虱子使人健康，其实是体温高导致虱子不栖息在人身上。所以，岛上居民的结论应该是看到没有虱子的人应该让他去就医，因为他发生了疾病。在原始部落并没有体温计，这个结论的确可以帮助到他们，而不是盲目的相信“虱子让人健康”。</p><p>再给你举个例子，现在都非常讲究母乳喂养，但究竟母乳喂养应该多久呢？世界卫生组织在《婴幼儿喂养指南》中建议母乳喂养两年或更长的时间。相关研究也表明，与非母乳喂养的婴幼儿相比，母乳喂养的婴幼儿患某些传染病的风险更低，也有更低的死亡率。</p><p>然而，在一些研究中研究人员发现，对接受母乳喂养时间更长的婴幼儿来说，营养不良的风险更高。这是对的么？应该缩短母乳喂养的时间么？1997年，来自美国约翰斯·霍普金斯大学的研究人员专门就此进行了分析，发现真实原因是收入比较低的家庭通常其他食物非常有限，更倾向于接受更长时间的单一母乳喂养。</p><p>所以没有充足的辅食才会导致婴儿营养不良，现在新生儿家庭都已经知道除了母乳喂养，在后期要增加辅食才可以让孩子更健康。</p><p>所以，<strong>当我们在日常生活和工作当中看到两个数据强相关的时候，即使不能把它们当成因果关系，也可以顺藤摸瓜找到可能的原因，再用业务逻辑或者实验去验证这个可能的原因是否为真实原因。</strong>缺乏业务逻辑的数据，永远只会是数据。缺乏数据的业务逻辑，也永远只是在纸上的一个业务逻辑图而已。</p><p>即使我们在找对了两件事情前后的因果关系，我们也会因为整体的选择对象、覆盖范围以及时间长度导致出现因果关系的推断错误。下面我再分别给你讲解一下这三种误区。</p><h2><strong>以偏概全——伯克松悖论</strong></h2><p>第一个就是统计数据本身因果逻辑成立，但是以偏概全。统计学里对这个现象有一个特别著名的理论叫做“伯克松悖论”。</p><p>伯克松悖论指的是当不同个体被纳入研究样本的机会不同时，研究样本中的两个变量 X 和 Y 表现出统计相关，而总体中 X 和 Y 却不存在这种相关性。听上去是不是有点拗口？没关系，我举两个具体例子来帮助你理解。</p><p>第一个例子是著名的“海军与平民死亡率”的例子。在1898 年“美西战争” 期间，美国海军的死亡率是9%，而同期纽约市市民的死亡率为16%。后来海军征兵部门就拿这个数据跟大家讲，待在部队里其实比大家待在家中更加安全。</p><p>这逻辑肯定是错误的，但是错误不在具体数据，而是这两组数据其实没有什么可比性。因为海军主要是年轻人，他们身强体壮、不会出现太多身体疾病；而纽约市民里面包含了新出生的婴儿、老年人、病人等等，这些人无论放在哪里，他的死亡率都会高于普通人。</p><p>所以，参军不能说比大家待在家中更加安全，但反过来你也无法证明待在家中就比参军更安全，因为比对的对象不是在同一个人群里，这就是伯克森悖论。</p><p>同样，现在的城市女孩会觉得，对他很热情的男生往往都长得不帅，长得很帅的男生往往对她都不够热情。但其实帅和不帅并不是导致男孩热不热情的原因，只是因为只有长得帅或者对女生够热情的男生，才有更多机会和女孩子接触，你看下图就明白了，还是从局部看整体的逻辑不对。</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/5f/e2bf92256bd32367bbaf8758653f075f.png?wh=1276x924\" alt=\"\"></p><p>在我们工作当中也会遇到这样的情况。我们经常会通过一些调查问卷去访谈一些使用者，看看营销效果如何。</p><p>比如，现在我们有一个用户访谈的数据结果：购买某品牌产品的 100 人中，有 72% 的人说在一个月内看过该品牌的广告 ；而在未购买商品的 300 人中，有 76% 的人说一个月内没看到过这个品牌的广告。</p><p>通过这个数据我们能看到什么呢？我们可以下结论说是广告提高了我们的用户转化率吗？这是不可以的，因为实际购买的人会对广告更有印象，而没有购买的人也许也看了广告，只不过他没有印象而已。因为统计范围不同，所以不能够根据这个数据给出转化率比较高的结论，然后大肆提高广告投放。</p><p><strong>看上去有因果关系的数据，还要看数据集的比对性才可以给出数据最终的结果。</strong></p><h2><strong>控制数据范围——神枪手谬误</strong></h2><p>前面给你讲<a href=\"https://time.geekbang.org/column/article/406706\">散点图</a>的时候，讲过神枪手谬误，这是一个典型的控制数据范围导致错误的数据结论逻辑。我们在生活中也很容易遇到这种陷阱，所以我在这里再给你强调一下。</p><p>很多统计结果其实是被操纵的，他们把某些机缘巧合之下比较好的结果的相关数据放到一起，去证明一个不可能的事情，但是如果你再换一组数据，那么你就没有办法证明这个因果关系。例如曾经在国内炒的火爆的全国牙防组故事就和这样的数据有关。</p><p>在海外也有一些小众的牙膏制造商，为了证明自己的牙膏比其他牙膏有效果，只把好的结果公之于众。包括很多“伪学术论文”引用的数据，也不是多次统计的结果，而是选取最优的结论给出来。</p><p><strong>所以你在看最终数据分析报告的时候，一定要看它的数据是不是先有枪眼再画靶子，或者先找到满意的结果再给你看统计数据，我们需要的是通过大量的随机样本给出的结果。</strong></p><h2><strong>时间长度不足——替代终点问题</strong></h2><p>还有一些数据在分析和统计的时候，由于时间长度不够，会造成数据统计的结果不准确。这个在学术上我们叫做“替代终点问题”（ surrogate endpoint problem）。</p><p>比如我们要检测某种药物是不是可以延年益寿，这其实就需要投入大量的时间和资金，因为我们必须得等到人们去世以后才能知道他们的寿命。</p><p>所以对于现在各种各样的保健品，如果它的宣传的作用是可以延年益寿的话，那大部分都是收你“智商税”的，因为这种测试非常难以完全实现。即使服用这些药物的人最后长寿了，那也不能够代表这两种之间存在着因果关系，很有可能只是前面讲到的相关性。</p><p>同理，你看这么多风险投资人在选择创业公司的时候，其实是<strong>靠大的方向和辨识团队来进行投资，而不是靠具体某些数据来表明这个创业公司是否靠谱。</strong>因为相对一个创业公司来讲，公司的成立时间太短了，公司的数据不代表趋势，这就是替代终点问题。</p><h2>小结</h2><p>学了这些场景以后，我们回过头来再看看开头的那些问题。</p><ul>\n<li>打篮球真的能让人长高吗？这很有可能是因为长高的人都会去打篮球，而不是打篮球让人长高——因果倒置。</li>\n<li>喝咖啡可以长寿？常喝咖啡的人一般都是白领阶级，他们的营养供给更高，所以他们可以长寿，而不是因为咖啡让他们长寿——相关性而非因果关系。</li>\n<li>吃不吃早饭其实和你肥不肥胖没有什么关系，运动健康才和你的肥胖有关系——相关性而非因果关系。</li>\n<li>爱笑的女孩子通常运气都不会太差？爱笑的女孩其实运气也有差的，最后她就不笑了，事实是因为运气好的女孩她们才会爱笑——因果倒置。</li>\n<li>会撒娇的女人更好命？女人好不好命其实与另一半或者周围的人和环境更有关系，而不是和你会不会撒娇有关系——需要找到遗漏的X变量。</li>\n</ul><p>这节课是我们数据分析基础篇的最后一节课了。在前面的课程里，我给你讲了非常多的数据统计的方法，你可以很快地把这些数据分析方法应用到自己的工作当中。今天我们其实是换了个思路，给你主要讲的是数据本身的局限性。数字相关并不等于因果关系，对于做数据分析和做数据决策来讲，我们更要懂业务才能够去了解真相，不然很容易就被数据忽悠了。</p><p>数据分析就像是一门中西医结合的医学，既要有本章前面给你的这些数据分析办法，也要有接下来的章节会讲到的算法模型和工具。最终还是需要你这个人像老中医一样，能够对这个业务本质有深刻的理解和把握，才能给出最终正确的结论。让我们一起持续学习，一起共勉。</p><p><img src=\"https://static001.geekbang.org/resource/image/75/04/7593ce1ae67e58e09d15b062a26a5c04.jpg?wh=1688x1417\" alt=\"\"></p><h2>课后思考</h2><p>最后还是我们的课后思考环节。我们这节课里讲了这么多因果相关性的问题，最后回到今天的标题：星座真的可以判定你的性格吗？你觉得它是一个什么样的问题呢？欢迎你在评论区一起讨论，加入到“中西医结合”的数据分析行业里来。</p>",
                "article_title": "11 | 因果倒置：星座真的可以判定你的性格吗？"
            }
        ]
    },
    {
        "chapterTitle": "数据算法基础",
        "children": [
            {
                "title": "12 | 精确率与置信区间：两种预测，你究竟应该相信哪一个？",
                "id": 410422,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>从今天开始，我们就要进入数据算法基础部分了。一说到算法，很多人都会觉得神秘、复杂、高大上……那究竟什么是算法呢？</p><p>官方把算法定义为一个计算过程，这个过程输入某一个值或一个值的集合，终会产生一个值和一个值的集合作输出，这就是一个算法。官方的说法比较抽象，简单来说，你可以把算法当成一个具有科学依据的算命箱子，你给这个箱子输入你的面相、体重生辰八字，最终它会根据你的需求给你算出一个很有可能的结果，比如最近你买比特币会发大财，生的孩子是男孩一类的。这个输入输出的箱子就是一个算法，箱子里面装的我们就叫做算法模型。</p><p>看到这，你可以停个五秒钟想一想，这种感觉是不是似曾相识？我们前面讲了很多的统计分布，假如我们知道收入和投资是成正相关的，我们是不是就可以知道在未来某一个投入情况下，收入会有多少了？之前我们介绍的统计分布是不是算法模型呢？</p><p>是的，我们在数据分析基础里介绍的各种分布，就是算法模型的一种。其实数据算法模型包括很多大类，简单说来可以分为统计分析、数据挖掘和人工智能几大类，聚类、分析、关联、神经网路等等很多种算法。我们有非常多的算法模型，到底哪个算得准呢？今天这节课，我就给你讲几个衡量这些算法模型的重要指标：准确率、精确率、召回率和置信区间。</p><!-- [[[read_end]]] --><h2>准确率/精确率 /召回率</h2><p>衡量一个算法准不准，我们的第一感觉就是要看这个模型的准确率。的确，在算法衡量里就有一个指标就叫准确率，英文叫做Accuracy。顾名思义，准确率就是看整体里预测准确的概率是多少。</p><p><strong>准确率 = 预测正确的样本数量/预测总的样本数量</strong></p><p>这个公式乍一看很有作用，但是用这样的方式来评估一个算法模型是有问题的。假设我设计了一个算法来辨别鹿的照片。我准备了100张图片，图片里边有1张鹿，99张马。现在，我要让算法来识别这个图片里到底是鹿还是马。</p><p>假如这个算法模型很准确，把一个鹿识别出来了，然后我们看这个准确率是多少呢，用刚刚的那个公式，你容易得出是1/100，也就是说只有1%的准确率。这个和我们当时预期的明显不对。</p><p>那怎么样更好的去衡量这个算法模型呢？我们就有了一个新的概念，叫做精确率，英文叫做precision，也叫作P值、查准率。这个概念稍微复杂了一些。还用刚才预测鹿和马的这个例子，我们先把几种预测结果的情况都列出来，整体上就是4种：预测马，它的确是马；本来是鹿，预测成马；本来是马，把它预测成鹿了；本来是鹿，预测对了还是鹿。你可以参考下面这个表，会更为直观一些。</p><p><img src=\"https://static001.geekbang.org/resource/image/6e/5c/6ea3ffb7f8d180cd5c6c8c361cee525c.jpg?wh=1773x756\" alt=\"\"></p><p>官方说法是精确率为预测正确的正例(TP)在<strong>所有预测为正例的样本</strong>中出现的概率，即分类正确的正样本个数占分类器判定为正样本的样本个数的比例。是不是有点绕？你可以把表格和下面这个公式对照起来看，会更容易理解一些。</p><p><strong>精确率=TP（指马为马）/(TP（指马为马）+FP（指鹿为马）)</strong></p><p>比如说，现在有马和鹿共100匹，其中40只鹿，60匹马。预测出来的结果，如下面这个表。</p><p><img src=\"https://static001.geekbang.org/resource/image/82/c8/82b3ceed0b5146b64c191554beaa73c8.jpg?wh=1768x769\" alt=\"\"></p><p>那么AI算法模型精确率就是40/（40+10）=80%。</p><p>光有精确率不够，如果我们现在下个指令，要把那些指鹿为马的AI算法都给干掉，这样可以把精确率直接提到100%（指鹿为马变成0）。</p><p>这样做，看起来精确度足够高、足够精确了。但却会导致最后很多的马识别不出来，因为AI看到很多稍微长得像鹿的马，完全不敢识别成马，宁愿说这些马是鹿。</p><p>那我们怎么能避免这种情况出现呢，我们就会用到另外一个指标——召回率（recall，也叫作查全率）。召回率用官方的说法是预测正确的正例(TP)在<strong>原始的所有正例样本</strong>中出现的概率，即分类正确的正样本个数占真正的正样本个数的比例。用公式来表示就是下面这样。</p><p><strong>召回率=TP（指马为马）/(TP（指马为马）+FN（指马为鹿）)</strong></p><p>那么上面这个AI算法模型召回率就是40/(40+20)=66.7%。</p><p>简单来说，召回率就是看你查得全不全。目标就是不让你太过于严查指马是鹿，出现上面说的AI即使看到真的马也不敢指出来它是马的情况。</p><p>我们现在把精确率和召回率放在一起看，精确率80%，召回率67.7%。这个数据说明什么呢，说明AI算法怕把马认错了，宁可指马为鹿，也不指鹿为马。在这样一个结论下，接下来我们可以适当优化模型，去找一个最优解。</p><p>精确率和召回率（也叫查准率和查全率）是一对孪生兄弟，一般情况下它们是成对出现，用来衡量一个算法模型到底好不好。<strong>单一指标高并没有意义，避免指鹿为马也避免指马为鹿才是最好的模型。</strong></p><h2>置信区间</h2><p>光有精确率和召回率就可以衡量一个算法到底好不好么？其实还是不够的，我们现实中很多时候不是光看鹿和马的，而是要去预测一些连续的数字。举个例子，你高考完不知道多少分，你找算命先生帮你预测一下高考成绩。有一个算命先生告诉你，我有100%的把握，你考的分数在0到750分之间。另外一个算命先生说，我有95%的把握，你在600到630之间。</p><p>这两个算命先生，谁强谁弱，一眼就看出来了，对吧？为了解释每个算命先生（算法）的识别能力范围，我们有了一个新的衡量指标，叫做置信区间。</p><p>用官方说法来说，置信区间估计是参数估算的一种，它是用一个区间来估计参数值，英文叫做confidence interval 也就是一定信心下的区间。这个信心我们可以用前面讲到的准确率来去衡量，这个时候准确率有了一个新名字，叫做置信度。刚刚提到的95%、100%就是置信度，[0，750]和[600，630]就是置信区间。</p><p>一般来讲置信度和置信区间是同向的，啥意思呢？就是置信度和置信区间一般是相同趋势。当置信度很高时，置信区间也会很大；当置信区间很大时，置信度也会很高。不过越高其实这个算法越没有用处。如果一个算命先生告诉你，我有100%把握你生命是在1岁到200岁之间，虽然置信度高，但显然是一句废话。所以<strong>置信度和置信区间是一组参数，来告诉你这个算法模型误差有多大。</strong></p><p>我在附录部分给你举了一个置信区间计算的例子，你要是感兴趣，可以去进一步学习。</p><h2>取舍的艺术</h2><p>精确率、召回率、置信区间这三个参数是衡量一个数据算法的核心指标，算命先生既要算得准、算得全还不能范围猜得太大，这才是好的算命先生。但是现实工作中，要想达到这样的效果，其实是很难的。</p><p>就拿最近比较火爆的“自动驾驶遇到行人自动刹车”这个算法来说，精确率代表着识别出来一个人他就是人的准确度（不要指鹿为马）；召回率代表着算法不会把人当成其他物体而不判断（不要指马为鹿）。置信区间代表着置信度比较好的时候，能识别多少种物体（人行道红绿灯、卡车、广告牌里的人涵盖不涵盖，置信度是多少）。</p><p>现在自动驾驶这么难，就是因为对于现在的算法来说，这几个指标很难同时都达到最高。这时候，我们就要学会取舍。</p><p>如果你的精准度低了，代表着你遇到不是人的物体时，算法会把它判断成人，然后刹车。这个系数太低，你开车就经常会出现莫名其妙的刹车的情况。如果我们召回率低了，代表着本来路上有一个人，我没有把人识别出来，直接撞上去了，这个也不行。置信区间代表着能识别出多少物体，广告牌上的人像要不要考虑？如果考虑了，会不会影响模型的召回率和精确率？</p><p>所以如果让你只能选择一个参数作为最关键的核心调优指标，你会选择哪一个参数呢？如果是我，我会优先选择召回率，这样算法如果不好，至多也就会和新手一样，宁可多刹点车也不要撞到人。毕竟对于汽车驾驶来讲，安全最重要。</p><p>所以在实际的场景当中，<strong>我们要结合当下的情况来设置这些参数，结合你自己的业务场景来选择最合适的算法。</strong>如果有数据科学家对你说某个算法精确率特别高时，你可以追问两句，召回率如何？置信区间如何？</p><p>当然在数据挖掘和人工智能领域还有很多复杂的方法去衡量一个算法的好坏，例如AUC曲线、F1 Score、PR曲线、增益和提升图等等。你要是感兴趣，我们可以在留言区进一步交流。</p><h2>小结</h2><p>最后依旧是我们的小结时间。今天我们主要讲了准确率、精确率、召回率和置信区间、置信度，这些是在衡量算法好坏时，使用频率最高的指标：</p><ul>\n<li>准确率衡量整体准确情况；</li>\n<li>精确率规避指鹿为马；</li>\n<li>召回率是保证马都能认出来，避免指马为鹿；</li>\n<li>置信区间和置信度是用来表示识别出来的范围以及你在这个范围内的信心。</li>\n</ul><p>其实在具体场景里，没有十全十美的算法，总是要做一些取舍。这个时候我们就更要去理解这些指标背后的含义，做到“断舍离”，根据我们实际的业务场景去选择最优的算法。</p><p>生活和工作做决策的时候也是如此，现实世界里很少有“两好选其优”的机会，大部分都是“两害取其轻”。究竟哪个害处更大不可接受，我们要自己衡量好。这样才可以在我们自己的生活和工作当中逐步的优化自己生活工作的算法，提高我们自己生活的最终的精确率，召回率和置信区间。</p><p>数据给你一双看透本质的双眼，<strong>做好断舍离，选好自己生活的精确率和置信区间。</strong></p><h2>课后思考</h2><p>你在你的工作当中遇到某些算法和一些业务场景需要做取舍的时候，对于精确率，召回率和置信区间你的选择是什么？同时，你觉得在你生活里，什么时候也是可以用到这些指标的？分享出来我们一起共同提高。</p><h2>附录：置信区间计算过程</h2><p>现在我们要去调查某一地区男性的平均身高，通过抽样得到100人的身高样本，样本平均值为170cm，样本标准差为0.2cm。</p><p>如果我们现在要95%的置信度，我们就可以算出来置信区间在[169.9608，170.0392]之间，也就是说，我们用100个人去推测这个地区的男性平均身高，尽管我们只调研了100个人，但是我们有95%的这些男性的平均身高是在[169.9608，170.0392]之间。</p><p>计算过程如下。</p><p>1.样本大小大于30，符合正态分布，我们要通过样本的平均值来估计总体的平均值。</p><p>2.标准误差：标准误差为se=0.2/√100=0.02。</p><p>3.置信度95%，左右标准误差各2.5%。查正态分布表，标准分z=-1.96；</p><p>置信区间下限=170-1.96*0.02=169.9608；</p><p>置信区间下限=170+1.96*0.02=170.0392。</p><p>因此，此区域男性平均身高在置信度95%情况下，置信区间为[169.9608，170.0392]。</p>",
                "article_title": "12 | 精确率与置信区间：两种预测，你究竟应该相信哪一个？"
            },
            {
                "title": "13 | 趋势分析与回归：父母高，孩子一定高么？",
                "id": 412094,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>在<a href=\"https://time.geekbang.org/column/article/406706\">散点图</a>那节课里，我们其实留下了一个问题：我们想找一个趋势线把这个散点图的趋势画出来，那么趋势线我们怎么才可以找到呢？最常见的做法就是用我们今天要讲的回归算法。</p><p>回归（Regression）是由英国生物学家弗朗西斯·高尔顿（FrancisGalton）提出来的。简单来讲，<strong>回归就是研究一个变量和另外一个变量的变化关系。其中一个变量我们叫做因变量，另外一个叫做自变量。多元的回归，就是研究一个因变量和多个自变量之间的关系。</strong></p><p>一般来说，当我们知道了某一种情况或现象，想要去了解这个结果和前面哪些因素发生了怎样的关系（例如体重和年龄的关系），或者想验证某一些数据其实和结果没关系，这个时候我们就可以用回归验证。当我们知道了过去的一些数据情况，我们想根据以前的经验值，预测将来可能出现的结果，这个时候我们也可以用回归分析和相关的算法。</p><h2>回归的算法种类与使用</h2><p>根据回归使用的场景不同，我们可以把它分成线性回归、逻辑回归、多项式回归、逐步回归、岭回归、套索回归等等。这些回归的整体逻辑比较类似，今天我给你重点介绍最常用的三种回归算法。</p><p><strong>第一类是线性回归。</strong>线性回归里最简单的一种就是一元线性回归，它有两个变量，一个叫做因变量（Y），一个叫做自变量（X）。我们可以用  <strong>Y=a+bX</strong> 这个公式来拟合一元线性回归方程。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/5d/a2/5d540cb414ece1aec1592eafe10ba0a2.jpg?wh=1492x1136\" alt=\"\"></p><p>例如我们要计算体重和年龄之间的回归关系，这里的年龄就是自变量X，体重就是因变量Y。</p><p>这里需要注意的是，判断两个变量是不是线性关系这是从业务上面去判断的。如果我们从业务上看是多元回归的话，我们的目标是要最少的自变量，也就是找到影响结果最核心的几个因素来生成这个公式，抓到影响一个事物的关键点。</p><p>同时线性回归对异常值影响非常敏感，往往一个异常值就把一个预测带歪了。所以我们在做分析的时候，经常会先通过聚类或者后续其他算法剔除这些异常点。当然，很多时候你并不确定这些点到底是异常值还是实际数据的规律，所以你需要非常有经验的数据分析师和算法专家来参与。</p><p>学到后面你就会发现，数据挖掘难的不是算法，而是准确去掉异常点、找到影响因子这些算法之前的数据准备工作。</p><p><strong>第二类是逻辑回归。</strong>逻辑回归被广泛用于做分类问题，也就是把“成功/失败”“哪一种颜色”这类问题变成线性回归的样子。基本逻辑就是把离散的因变量Y变成了一个连续值，然后再做回归。</p><p>怎么把离散的Y值变成连续的Y值呢？这里我们把事件发生的概率比上事件不发生的概率，取Log值，这样做就把一个非连续的数据变成连续数据了，具体公式如下。</p><p><strong>Logit（Y）=Log （Odds Y）=Log（（Probability of Y event）/（Probability of no Y event））</strong></p><p>这个变化我们也叫做Logit变化，然后再通过各种各样的线性回归或者分类算法，我们可以找到对应关系，就像下图这样。</p><p><img src=\"https://static001.geekbang.org/resource/image/9c/84/9c914b23c5yy1252086ed77906b99a84.jpg?wh=1504x1133\" alt=\"\"></p><p><strong>第三类是多项式回归。</strong>顾名思义，它可能出现多个指数的数据，这种回归最佳拟合的线也不是直线，很可能是一个曲线。比如我们预测人类身高增长速度和年龄的关系，最终回归出来的曲线方程可能由多次项组成，就像下图这样是一条抛物线（我们在婴儿时成长最快，岁数越大增长速度越慢）。</p><p><img src=\"https://static001.geekbang.org/resource/image/f4/0d/f46472f7b8337809f42a46193525390d.jpg?wh=1212x1091\" alt=\"\"></p><p>在使用这种多项式回归的时候，最常见出现的问题就是<strong>过拟合</strong>和<strong>欠拟合</strong>。这在将来做任何预测算法的时候都会遇到，这里先给你着重讲一下。</p><p>这两个概念是什么意思呢？假设我们找到一些数据画在了散点图上，我们实际背后蕴含的数据画出来之后它就像个对勾（如下图所示），是实际背后数据规律的正确答案（我们也把这个公式叫做算法模型）。</p><p><img src=\"https://static001.geekbang.org/resource/image/8d/52/8d1dd212b616363c3cfed887392d6052.jpg?wh=1320x1165\" alt=\"\"></p><p>而欠拟合是画这个线（也就是推算这个公式）的时候，我们把很多细节给忽略掉了，直接画成了一根直线的线性回归，有很多趋势都没有很好地反馈出来。因为细节丢得实在是太多了，所以我们把它叫做欠拟合，这个名字意味着需要更复杂的多项式回归，才可以更准确地描述这个规律。</p><p><img src=\"https://static001.geekbang.org/resource/image/98/b7/985b2c9006c48dec9dfb352e2947f0b7.jpg?wh=1536x1273\" alt=\"\"></p><p>而过拟合是指我们太纠结于其中的细节，以至于这个数据模型计算出来的曲线变成了一条特别曲折的线（本来应该是一个相对光滑的对钩）。这样的数据模型适配性很差，换句话讲，它的查全率不高，用它做预测很可能就会指鹿不为鹿了。这就是过拟合的结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/12/9f/12f108486eaa4b5dbebf8ce8fcdb8f9f.jpg?wh=1272x1153\" alt=\"\"></p><p>权衡是过拟合还是欠拟合的情况需要根据实际业务情况来做选择，不是光看数据就可以解决的。</p><p>有了这个回归公式以后，是不是就代表着因变量就是因为自变量的变化而导致的呢？换句话讲，自变量和因变量是不是存在因果关系？前面因果倒置那节课你学过，其实我们还不能下这样的定论。</p><p>计算出这个数据模型，我们只能够推断出一个变量对另一个变量有依赖关系，但并不代表他们之间就会有因果关系，因果关系的确立必须是来自统计之外的一些业务依据。因果这个话题你要是记不清了，可以去<a href=\"https://time.geekbang.org/column/article/409828\">11讲</a>里再复习一下。记住，<strong>两个变量之间有回归逻辑，不代表着两个变量之间有因果逻辑。</strong></p><h2>均值回归</h2><p>我们通过各种计算得到了回归模型之后，就可以在工作和生活当中利用这个公式很好地预测出未来的结果吗？答案是否定的，<strong>现实生活不一定有我们在算法当中预测得那么好。</strong>这就是我们接下来要讲的话题：均值回归。</p><p>谈到回归，我拿我们非常熟悉的身高来给你举个例子。根据达尔文进化论，子代会越来越基于父代进行进化。也就是说理论上父母越高，孩子也会越来越高。而一般高个子的女孩子只会找比自己身高更高的男生结婚，生的孩子也应该更高。</p><p>以此类推，理论上经过千百年的进化，人类应该分成巨人族和矮人族才对。但我们都知道现实情况其实不是这样的，人类并没有分成巨人族和矮人族，高尔顿在实验中也发现了这一点。</p><p>高尔顿找到了100组家庭测量了他们父母和孩子的身高，通过一元线性回归分析建立了一个公式来预测孩子和父母身高的关系，如下图。</p><p><img src=\"https://static001.geekbang.org/resource/image/55/b8/55687d74ea2475f7c6d4eb6ae99c66b8.jpg?wh=1412x1221\" alt=\"\"></p><p>你可以通过这个图很明显地看到，通过公式计算出来的值和实际孩子最后成长的结果是不太一样的，最终孩子的身高其实趋向于平均身高。身材高大的双亲，子女不一定高；身材矮小的双亲，孩子也不一定矮。</p><p>高尔顿把这个现象叫做回归平凡，后来的统计学家把它叫做“均值回归”，意思就是<strong>实际发生的数据比我们理论上的预测更加接近平均值，整体趋势上会慢慢向一个平均值发展。</strong>比如最近比较火的一个例子，就是北大的教育学院的丁延庆教授的吐槽。</p><p>丁教授自己6岁时就能背一下整本新华字典，本科在北大，后来在哥伦比亚获得了教育学博士学位，他的妻子也是北大毕业的。丁教授与妻子都非常学霸，按理来说孩子也会走一条学霸的道路。但是丁教授的女儿却几乎完美规避了父母所有的学霸基因，在学渣的道路上越走越远。以至于丁教授在视频里面吐槽女儿“不辅导作业父慈女孝，一辅导作业鸡飞狗跳”。其实这就是均值回归的一个典型例子。</p><p>还有一个著名的例子就是美国《体育画报》的“封面诅咒”。《体育画报》是美国非常著名的一个体育杂志，但是每次杂志封面登了哪个队伍胜利之后，后面一定会有一场大败在等着这个队伍。</p><p>比如当年在俄克拉何马队连续赢得47场大学橄榄球比赛之后，《体育画报》刊登了《俄克拉何马为何战无不胜》的封面故事。紧接着在下一场比赛中，俄克拉何马队就以 21∶28输给了圣母大学队，这样的事情还发生了好几次。</p><p>其实这也是一种均值回归的情况，对于任何优秀的人和团队来说，很多时候其实是运气、能力、时机多种因素来造就成功的。好的没你想得那么好，差的也没有你想得那么差，最终还是会回到平均水平。就像我接触了很多大佬，我发现我们和最优秀的人之间，也没有那么大的智商和情商的距离，但是人家一直在坚持努力，同时再加上天时地利人和，所以他成功了。我们如果三天打鱼两天晒网，那就很难成功。</p><p>实际上，我们每天都会遇到均值回归的情况。我们不要过分夸大优秀者的能力，也不要因为某几次失败就一蹶不振，过度小看自己。<strong>只要你不懈努力，就算你现在在谷底，也最终会到达平均值水平，甚至超过平均值。</strong></p><h2>小结</h2><p>小结一下今天的内容。今天我们主要讲了回归分析，回归就是研究一个变量和另一个变量的变化关系。现在有非常多的回归算法，我着重给你讲了线性回归、逻辑回归和多项式回归这三个比较常见的算法。</p><p>紧接着，给你分享了过拟合和欠拟合这两个在数据挖掘和人工智能里常用到的概念。我们既不能过于纠结细节陷入到过拟合里，也不能神经大条错过太多的细节最后导致欠拟合。最后我还讲了均值回归的概念，万物最终都要回归自然平均。</p><p>在生活和工作里，我们可以通过回归分析找到很多简单的规律，它们能够帮助我们去预测一些常见的数据问题。但是在真正使用的时候，我们也不能盲目相信算法模型推导出来的结果，因为现实其实要比我们预测出来更加的贴近于平庸：好的没有我们预测当中的那么好，差的也没预测当中的那么差。</p><p><strong>所以对我们自己的工作和生活来讲，用一颗平常心不断去提高自己的平均线水平才是正确选择。</strong>人和人之间的差异没有那么大，不存在着优生学，也不存在着“龙生龙凤生凤，老鼠的儿子会打洞”这样的说法。</p><p>数据给你一双看透本质的眼睛，最终所有的成果，都会回归到我们每分每秒的努力当中，我们一起努力。</p><p><img src=\"https://static001.geekbang.org/resource/image/dc/1c/dce631b814459df539794198059f5b1c.jpg?wh=2000x985\" alt=\"\"></p><h2>课后思考</h2><p>你在工作和生活当中遇到过“均值回归”的情况么？你从中学到了些什么呢？分享出来，我们一起共同提高。</p>",
                "article_title": "13 | 趋势分析与回归：父母高，孩子一定高么？"
            },
            {
                "title": "14 | 初识聚类算法：物以类聚，让复杂事物简单化",
                "id": 412828,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>“物以类聚”这个成语想必你肯定不陌生，我们会自然地把很多类似的事物放到一起，给出一个统一的定义。因为我们的大脑空间有限，无法接收太多零碎的信息。</p><p>比如我们会把动物按照门纲目科属种来进行归类：对于一只小狗来说，无论它是白毛还是黑毛，秋田还是藏獒，我们都会知道它属于狗。这其实就是我们面对纷繁复杂的世界的一种算法。</p><p>对于数据来说也是如此，如果大量的数据没有一个很好的算法来进行整理，那么这些数据可能我们就无法理解。如何将大数据分门别类聚集起来让人理解，就是今天要给你讲的算法——聚类。</p><h2>聚类问题与场景</h2><p>花对你来说肯定很熟悉，我们在生活中会看到各种各样的花。无论是梅花、菊花还是鸢尾，我们都会把它称作是花，而不是把它叫做叶子。因为它们身上有类似的特征，和叶子有比较大的区别。</p><p>简单来说，不同的花之间有一些比较相近的特性：花都有花瓣也有花蕊，颜色也都比较鲜艳。我们把这种现象叫做<strong>内聚</strong>。而花和叶子相比，叶子在大多情况下形状不会特别复杂，并且大多是绿色，所以花和叶子之间的差异很大。我们把这个特性叫做<strong>分离</strong>。</p><p><strong>聚类就是通过一些算法，把这些事物自动全都聚集起来，让这些聚好的类别（花类和叶子类）达到内聚和分离的特性。</strong>你可以从下面的图里更直观地看到，一个好的聚类算法算出来以后，可以把相近的东西全都聚到一起，并且不相近的全都能区分开。</p><!-- [[[read_end]]] --><p><img src=\"https://static001.geekbang.org/resource/image/5c/e8/5ce2b2f394b035f484fe0c355fe257e8.jpg?wh=2000x893\" alt=\"\"></p><p>做人群探查的时候，我们可以先用聚类的方式，把你不知道的这些用户先分出几个类别，然后再看每个类别的一些特性。如果直接看每一个用户的特性，分析不出来什么结果。先聚类再分析，这样我们不会一叶障目，不见森林了。</p><p>在投资过程当中，我们经常会把股票通过一些特征值（利润、收入等财务数据）进行归类，再进行一些风险的评估。最典型的就是股市里我们经常听到“蓝筹股”“白马股”都是通过类似聚类的方法总结出来的。</p><p>所以当你面对一堆数据，担心其中特性差异过大的时候，你可以先使用聚类算法把不同的小类聚集出来，再通过其它的统计手段，针对每一个类别里面的数据进行描述。</p><p>因为这个过程是我们让这些数据自己去聚集出组别来，所以我们也把聚类算法叫做无监督学习。顾名思义就是没有人告诉你最终正确答案是什么，你自己看着办，把它们分成比较合适的类别就可以了。组内的相似性越大，组间差别越大，聚类就越好。所以在你面对很多数据想探查其中的规律时，先用聚类算法再进行深度分析可以事半功倍。</p><p>抽象一下，<strong>聚类算法输入就是一群杂乱无章的数据，输出是若干个小组，并且这些小组里面会把数据都分门别类。组内的对象相互之间是相似的（内聚），而不同组中的对象是不同的（分离）。</strong>组内的相似性越大，组间差别越大，聚类就越好。</p><h2>聚类算法初探</h2><p>人类本身就具备这种归纳和总结的能力，能够把类似的事物放到一起作为一类事物识别，尽管它们之间还是有细微差别，但是我们心里有一个“差异距离”。只要在这个差异距离内，特征稍有区别无关大碍，它们仍然还是这一类事物，超过这个“差异距离”我们就会当做另外一个事物。例如下面这个图中的点，我们可能一眼就能看出来，这个点是可以分成两堆的。但是计算机怎么能学会把这些点分成两堆呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/21/82/21811d77bea9b6819fea5fec30745682.jpg?wh=1559x874\" alt=\"\"></p><p>这里我给你讲一个最常见的聚类算法K-Means，具体实现方法我称作“选大哥”。</p><p><strong>第1步，我随意挑两个点，作为开始的大哥。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/8a/0f/8a20a42658be039d41c00361314ae60f.jpg?wh=1614x905\" alt=\"\"></p><p><strong>第2步，“拉帮结派”。</strong>算每一个点和大哥的距离，这些点里谁离哪个大哥更近，我们就给它归到这个大哥的团伙里去。</p><p><img src=\"https://static001.geekbang.org/resource/image/15/60/15d7de6fee9cec2e916f1aef9f33d660.jpg?wh=1498x839\" alt=\"\"></p><p><strong>第3步，我们开“帮派大会”重新选大哥。</strong>每个大哥的团队里小弟，都算一下这个团队里面最中心点在哪里（也就是X坐标和Y坐标的平均值），离中心点最近的那个点成为新大哥。</p><p><img src=\"https://static001.geekbang.org/resource/image/6d/ed/6d252653588c0a921c6bf7125e8be4ed.jpg?wh=1498x840\" alt=\"\"></p><p><strong>第4步，重新回到第2步，根据帮派选出来的新大哥再去分自己的小队伍。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/74/c5/74a21b557f0ecbfd75fe0c1bc3dbaec5.jpg?wh=1392x780\" alt=\"\"></p><p>这样重复下去，直到最后这个帮派稳定下来，那我们就能看到这些群组的点到底应该怎样区分了。</p><p>总结一下，K-Means“选大哥”算法，就是先把一群点分成K类，根据K类中间均值的距离去选择（Means就是均值）到底它属于哪一个聚类。最终当聚类稳定下来的时候，聚类也就完成了。</p><p>可能你会问，刚才这个例子里，我们怎么知道一开始我应该分成两类呢？这其实就是业务专家和个人的经验选择了。你拿到这些数据的时候，背后业务逻辑可能会告诉你大概率要选择几类。或者你可以多尝试几次，聚成几类更容易来解释你的业务，你就可以最后聚成几类。</p><p>可能你还会问，从第4步回到第2步的过程中，我们会不会陷入死循环，一直在第2步和第3步当中选大哥找小弟，永远选不出来最后的结果呢？放心，有<a href=\"https://zhuanlan.zhihu.com/p/149597282\">数学证明</a>，我们的这种方法一定会收敛出结果。</p><p>还有一个问题，图上表示的这些点可以看得很明白，但实际工作过程当中很多事情很难表示成点和点之间的距离。例如用户群的划分，这怎么来计算呢？简单来讲，在算法的世界里，我们可以有各种方法把人和人之间的属性和行为的差异数字化，然后把它们算成“欧几里得距离”或者“余弦相似度”，你现在只需要理解，<strong>最终任何事物的特征属性都可以变成类似距离的东西来计算</strong>就可以了。</p><p>常见的聚类算法除了K-Means，还有KNN、DBSCAN、EM等等，所有的这些聚类算法其实都可以和K-Means类似简化成三种问题：</p><p>1.选大哥，找聚类中心的问题；</p><p>2.找小弟，解决距离表示的问题；</p><p>3.帮派会议，聚类收敛方法问题。</p><p>这里要注意的是，<strong>使用聚类算法的时候要先把一些异常点尽量剔除掉，或者单独把它们单独聚成一类。否则有一些很异常的数据就会影响我们聚类算法最终的准确性。</strong></p><h2>未来场景的展望</h2><p>聚类已经逐步由过去的只是针对数据的聚类，变成现在可以实现图片、声音、视频的聚类了。最常见的比如我们手机相册现在可以把你过去拍的人脸照片聚类，然后再让你贴上标签。比如下图里，里面有每个人都是一类，背后都有他们的很多照片。</p><p>手机先帮我先计算出来，我再统一标注成我自己，这样做直接省去了每一张照片都要告诉手机这个照片是谁的时间，将来也能让我很容易找到自己的照片。</p><p><img src=\"https://static001.geekbang.org/resource/image/1c/b9/1ce7b4453e584621597259b403783cb9.jpg?wh=1464x765\" alt=\"\"></p><p>我们在做用户画像的时候，也会用聚类把一个人最常见的行为属性聚集出来。比如下面这个我自己的用户画像就来自于我在万达的时候，通过大数据聚类算法建立起的一套大数据用户画像系统。你能看到我喜欢住威斯汀和希尔顿，我喜欢吃韩悦烤肉，我喜欢安妮海瑟薇和尼古拉斯凯奇的电影，这些都是从我日常琐碎行为里面聚出来的一些行为特征。</p><p><img src=\"https://static001.geekbang.org/resource/image/77/e8/77c52fbc8438523eb0635f0cd9eb36e8.jpg?wh=1180x1045\" alt=\"\"></p><p>同样在一些线下的行为轨迹当中，也可以用一些聚类的方法找到人群最密集的地方，比如下面这个图就是当年我们在万达广场做过的一个聚类实验。你能看到，我们可以用聚类算法来推测出来到底哪些地方是人群最聚集的（红色的地方）。这样的话，我们就可以有针对性地去放置广告牌或者进行一些活动，这样就有效避免这些广告牌或活动放在不合适的位置上。</p><p><img src=\"https://static001.geekbang.org/resource/image/c1/fc/c1b766bceb7a11babc32485e07b7fafc.jpg?wh=1400x781\" alt=\"\"></p><p>聚类在很多领域都非常有用，例如辅助医疗科研研究、辅助医疗管理、辅助医生的临床诊断、辅助生物学里的蛋白质表达等等。<strong>聚类是一个最基础的数据挖掘算法，也是最经久不衰的算法之一。</strong></p><h2>小结</h2><p>好了，今天的课程到这里也就接近尾声了，最后我们来小结一下。今天我们讲了聚类算法，物以类聚，这是我们天生就有的一种思维方式。</p><p>聚类算法可以帮助我们在非常复杂的数据环境里面快速聚出一些类别，从而看到这些数据里面的特征。同时，聚类能够避免直接使用平均值去看事物发生<a href=\"https://time.geekbang.org/column/article/400764\">辛普森悖论</a>，也能避免我们过度深入细节看不到事物的全貌。在图像、基因、医疗等方面都有聚类算法的身影。聚类的算法原理也很简单，我给你介绍了K-Means算法，也就是“选大哥”的算法。</p><p>不知道你会不会有这样一种感觉：总是每天很忙，全都深入在不同的生活、业务细节里，但一天忙下来，却不知道自己到底忙了些什么。</p><p>你不妨试试用类似聚类算法的思路，把你觉得纷纷扰扰一些小事统一归到一个篮子里去，用一整块的时间或者类似通用的方法去解决它们，说不定会有奇效。因为<strong>多用聚类算法的方式去思考，可以把你的思维锻炼得更加结构化，助你更快理清琐碎的生活。</strong></p><p>数据给你一双看透本质的眼睛，希望我们可以通过聚类，把纷繁复杂的世界变得简单一些，最终看清这复杂的世界。</p><h2>课后思考</h2><p>请你想一想，在工作或者生活中，你遇到的哪些复杂事物可以用聚类算法或者聚类思想来解决，分享出来我们一起提高。</p>",
                "article_title": "14 | 初识聚类算法：物以类聚，让复杂事物简单化"
            },
            {
                "title": "15 | 初识分类算法：分而治之，不断进化",
                "id": 413734,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>通过上节课讲的聚类算法，你应该知道了我们经常把一些复杂的事物通过聚类来进行简化处理。但是，不一定所有事物在一开始我们都要把它们进行聚类。有的东西我们一开始就知道一些正确和错误事例，例如我们知道什么是好人什么是坏人，然后得让孩子慢慢明白好人和坏人的差别，让孩子去学会鉴别哪些人是好人还是坏人。</p><p>又比如说在上海做垃圾分类的时候，有这么一个段子：你去倒垃圾，一个阿姨就会在那里看着你，看到你就会问“你是什么垃圾？”你如果把垃圾分类做错了，她会告诉你榴莲壳属于干垃圾，瓜子壳属于湿垃圾。下次如果你去倒垃圾还不对，她还会纠正你，直到你最后学会为止。刚刚给你举的这两个例子其实就和我们这节课的主角分类算法脱不开干系。</p><h2>分类算法定义与场景</h2><p>和聚类算法不同，分类算法是有训练数据集的，也就是我们在一开始就已知有一系列正确的数据和正确的分类结果，然后你需要经过不断地学习去找到其中的规律，然后做一些测试数据，最终在生产环境里去帮你去判断一些事物的分类。</p><p>可能这么解释有点绕，其实这就像我们让孩子去做算术题一样，先告诉他计算正确的一些案例，让他去领悟其中的一些规则，然后继续做一些算术题练习，最后再去做考试。</p><!-- [[[read_end]]] --><p>所以分类和聚类算法不同，分类算法会不停告诉你这个分类是哪种，直到你学会，最后再让你自己单独去进行区分。所以分类也叫做<strong>有监督学习</strong>，也就是得有人看着你做。</p><p>我们来看个例子。比如现在你想知道有哪些客户可能会流失到竞争对手那里去。这个时候我们可以用叫“客户流失预警”的分类算法来解决这个问题，也就是你的客户流失之前，算法会提前先给你一个预警。</p><p>具体是怎么做的呢？我们先是输入很多过去流失的客户信息，让这个算法学习大概哪些特征是流失客户会有的，这个分类器算法学会了分辨哪些客户会流失后，你再来一个客户给它，算法就会告诉你这个人流失的概率有多大。这样你就可以有备无患，针对这些要流失的客户进行营销活动来挽留住他们。</p><p>你在停车场会用到的车牌的自动识别也是用分类算法做到的。把各种各样的车牌告诉这个分类算法，说这个图像是1，这个图像是A，经过不断训练和学习，最后当你的车到一个停车场的时候，它就会自动把你的车牌识别出来了。</p><p>其实我们自己也是一个非常精妙的分类器，它能够处理非常复杂、抽象的输入（图像、文字、触觉、味道等），我们都可以根据当时的情况进行合理输出（躲闪、愤怒、皱眉或者情感上的喜怒哀乐）。所以从某种意义上来讲，我们作为一个精密的分类器，其实就是在根据世界的不同情况来做出我们自己的分类决策，最终形成了我们各自的生活。</p><p>概括一下，分类的算法也叫做有监督的学习，它是先拿一些正确或者错误的案例给分类算法，让这个分类算法学会了以后，再给它一些新的输入，那么这个算法就会根据它前面的学习到的结果，对这些新的输入进行分类。</p><h2>分类算法初探</h2><p>那如果我已知一些条件和试验的结果，具体怎样能让计算机像人一样发现其中的这个逻辑呢？我来给你分享一个最常见的分类算法C4.5——决策树。</p><p>我们可以把一个分类器抽象成一棵倒着生长的树，它就是一些不同条件走向了不同的分支，最后走到叶子得出一个分类的结果。比如我们设计一棵树来区分鸡、鸭子、鹿和马，我们可以用下面这个树来进行表示分类。</p><p><img src=\"https://static001.geekbang.org/resource/image/74/ya/74b291bf671e4567704f6bedfcd09yya.jpg?wh=1781x929\" alt=\"\"></p><p>任何一个人或者机器拿到这棵树，都可以根据这个规则把这些动物区分出来，我们把这棵树叫做决策树。顾名思义，根据这棵树我们就可以做出决策了。这棵树就是这个分类算法的最核心的部分。</p><p>但是我们怎么能让计算机把这棵树生成出来呢？关键就在于<strong>我们应该拿什么条件去判断这棵树上的分支节点。</strong></p><p>哪些属性是有用的，哪些属性是没用？究竟应该先拿哪个条件作为最初始的判断条件呢？这些问题的答案就在我下面要给你介绍的C4.5决策树算法中。</p><p>C4.5决策树算法我把它也叫做“逐级找领导”算法。</p><p>这个分类算法的整体逻辑很简单，最开始计算机也不知道用哪个条件区分出来最好，于是干脆把每个属性都当“领导”全试一遍，能够做出最明显区分的就当这一级的领导，然后逐级“找领导”，最后再“剪枝”。具体的步骤如下。</p><p><strong>第1步，我们把每一个属性都当领导全试一下</strong>，你参考下面这个图会更直观一些，也就是把各种属性测试一遍。</p><p><img src=\"https://static001.geekbang.org/resource/image/f5/32/f59b1d2fdeab2050a15f85a0aa86c032.jpg?wh=1908x853\" alt=\"\"></p><p><strong>第2步，把按这个情况分群出来的差异性通过一个叫信息熵的指标计算出来。</strong>信息熵这个词在算法里会经常用到。它表示每一个消息里面所包含信息的平均量有多少。简单来说，言简意赅的人说的话每个字信息熵比较高，废话连篇的人说的每个字信息熵就比较小。在这里，我们希望根据这个领导给出的决策逐步减少下一步整体的信息熵，这样将来的小领导更好干活，直到最后做出接近事实的分类。</p><p><strong>第3步，我们要比对一下这几个领导做完决策之后各自信息熵的大小。</strong>我们发现这些动物全都长毛也全都有眼睛，用这两个属性来当领导做决策完全没用。那这两个属性我们就不会选到决策树里。同时，长几条腿这个“领导”的信息熵最小，我们就把它放在第1个节点的大领导位置上。</p><p><strong>第4步，大领导有了，现在我们需要一些小领导。</strong>我们来重复前面的123步，你就有可能会画出下面的这样的一棵树。</p><p><img src=\"https://static001.geekbang.org/resource/image/49/f7/49f7c1f69e500c8c4eae9bdcdf0fa8f7.jpg?wh=1588x1069\" alt=\"\"></p><p><strong>第5步，精简领导班子。</strong>上面的这棵决策树看上去还是有点冗余，怎么办呢？决策树算法里面还有一个东西叫做“剪枝”，就是把一些没有用的节点去掉。经过剪枝之后，就得到了我们最终要的这个决策树。</p><p><img src=\"https://static001.geekbang.org/resource/image/db/27/db5c112a051a55b330f4fa1586445c27.jpg?wh=1582x865\" alt=\"\"></p><p>最终我们可以用一组测试数据来验证一下我们这棵树分得好不好，衡量的标准就是<a href=\"https://time.geekbang.org/column/article/410422\">精准率和召回率</a>。这棵树到底应该有多少个特征和属性呢？这就是前面讲到的过拟合和欠拟合的问题，你需要结合业务具体问题来分析。关于精简领导班子这个点，我们要把它减恰到好处，才最能适应现实状况。</p><p>分类算法除了C4.5决策树（现在有C5.0算法了）外还有很多算法，例如朴素贝叶斯、支持向量机SVM、随机森林，还有我们之前讲过的逻辑回归等等。简单来说，所有的分类算法主要是要解决两个问题：一个是用什么样的算法决定用哪个属性区来做分类（也就是选领导），一个是怎么来计算不同属性的信息价值（信息熵，也就是领导管不管用）。其实只要解决这两个问题，其实这个类就很容易分出来了。</p><h2>未来场景的展望</h2><p>分类算法现在也被广泛地应用在人工智能图像识别等场景中，例如自动驾驶中针对人、路的识别，其实都是分类算法。我们要通过大量的训练模型告诉电脑什么是人、什么是车、什么是路，再告诉它每一个场景应该怎样去做处理，这其实就是一个复杂的分类算法。</p><p><img src=\"https://static001.geekbang.org/resource/image/db/31/db36d1823c6c8e20a8123d792a306431.jpg?wh=1328x826\" alt=\"\"></p><p>现在最新技术也可以通过识别一个图片里面的场景，从而实现一些自动的问答。例如给到一个长城的图片，分类算法能告诉你这就是长城，给算法一个故宫的图片它会告诉你这是故宫，然后还会给你各种各样针对长城和故宫的介绍。实现这些动作的基础其实都是分类算法，只不过不仅是要识别图片中的物体，还要识别图片当中的场景。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/b4/a05ea1856be054d367be21a0e077d7b4.jpg?wh=1792x1117\" alt=\"\"></p><p>现在还有通过分类训练让机器去模拟小狗的鼻子的。例如麻省理工学院就做一个AI嗅觉探测器，让它模拟小狗去判断最后人类是得了哪种癌症。现在这种“嗅癌犬”已经达到了70%左右的准确率，灵敏度比狗鼻子要高200倍，这背后也是通过分类算法来实现的。</p><p><img src=\"https://static001.geekbang.org/resource/image/98/82/98865103601ff5bf2f3a812c2628a682.jpg?wh=1876x909\" alt=\"\"></p><p>更先进的分类算法可以支持用脑机接口加上深度学习的方式去训练脑电波，让我们可以用意念来控制两只机械臂独立完成类似吃蛋糕这样的复杂任务，帮助四肢瘫痪的人重获自由。</p><p><img src=\"https://static001.geekbang.org/resource/image/25/29/2550b6e461bb94b791e5ba3e8fc2e629.jpg?wh=1940x825\" alt=\"\"></p><p>所以和聚类算法不同，分类算法结合人工智能可以有大量的更深层次的应用，最终可能会造出一个类似人类的智能模型来。因为归根结底，我们人类自己其实也不过就是一个超级复杂的分类器而已。</p><h2>小结</h2><p>回顾一下，分类算法其实就是机器模拟人类学习的过程，通过各种各样的案例帮助计算机去学习，最终形成一个类似人类做单独决策的过程。</p><p>其实，<strong>分类算法的核心就是在于经验不断积累，不断迭代自己的规则，从而得到最好的答案。</strong>而我们在工作和生活当中，其实就接触的场景和得到反馈的结果来说，要比电脑当中的分类算法多得多。但我们有像分类算法一样，把这些场景和反馈结果分类整理记录下来，然后下次遇到情况时再去优化么？其实我相信大多数的人都是没有的。</p><p>所以很多人会经历了很多事情后依然庸庸碌碌。我们需要让大脑这个超级分类器不仅去接收好结果、差结果，还要在结果之外找背后的原因来不断优化自己的算法。而那些成功的人，就是通过不断地思考，不断地学习优化自己的思维，最终他们的大脑进化成为超级分类器当中的佼佼者，通过现象看到了本质。</p><p>所以今天这节课我希望能够教会你用分类算法的视角去看待“<strong>复盘</strong>”这件事。只有我们不断思考、不断积累，才能不断进化，否则我们真的可能被人工智能进化出的某一个分类器所超越。</p><p>数据给你一双看透本质的眼睛，我们要持续迭代自己的分类规则，持续进化！</p><h2>课后思考</h2><p>关于分类算法 C4.5 这种分层找领导分而治之，最终得到优秀结果的方式，你在生活和工作当中有过类似的体验么，分享出来我们一起提高。</p>",
                "article_title": "15 | 初识分类算法：分而治之，不断进化"
            },
            {
                "title": "16 | 关联规则：为什么啤酒和尿布一起卖？",
                "id": 414442,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>世间万物都有一定的联系，你应该听说过这样一个说法：一只南美洲热带雨林的蝴蝶扇动了几下翅膀，两周后美国得克萨斯州就形成了一个龙卷风。</p><p>我们不停地搜索一些公司情况，最终很可能会影响这个公司的股价的波动；你打一个喷嚏，第二天发现中了一个彩票；你今天右眼皮起床时跳了跳，结果今天打麻将一直输。</p><p>每天都会发生各种各样的事情，我们怎么能发现在这么多的事物之间到底谁和谁有关联性，从而能去描述一些事物出现的规律和模式呢？这就是今天要给你讲的关联规则算法。</p><h2>关联规则定义和使用场景</h2><p>关联规则挖掘经常会应用在各种各样的数据场景里，用于检测数据和数据之间的潜在关系。最早也是最著名的案例，就是我当年所在的Teradata公司提出来的一个案例，也就是啤酒和尿片的故事。</p><p>这个故事是这样的，当你去美国沃尔玛超市，你会看到一个非常有趣的现象：<strong>货架上啤酒和尿布经常放在一起售卖。</strong>这两个看上去是完全不相关的东西，为什么会放到一起卖呢？</p><p>Teradata公司针对人们每次去超市一次交易清单里的物品进行关联挖掘，发现啤酒和尿布经常会在一次购买清单当中购买。这件事情上沃尔玛的管理者也非常不解，后来经过调研发现，妈妈们经常会嘱咐她们的老公下班后去给孩子买一点尿布回来（你知道孩子用尿布的速度是非常快的）。而丈夫买完尿布的时候，大多会顺手给自己买一瓶喜欢的啤酒。</p><!-- [[[read_end]]] --><p>Teradata通过针对一年多原始交易的关联规则挖掘，发现了这个神奇的组合，于是就推荐沃尔玛将啤酒和尿布摆到一起销售。结果这两个产品放到一起后，造成了啤酒和尿布销售量整体增长，这个摆放的位置也就延续至今。你现在去超市经常能看到很多商品也不是按照类别摆放的，例如卖方便面的地方经常有一些泡椒鸡爪、火腿肠、榨菜等等。这些其实背后都是关联规则数据挖掘在起作用。</p><p>当然，这个故事有很多人说是当时的人们杜撰出来的，因为那个时候数据分类无法那么精确，数据量也不够大。我觉得不用去讨论故事的真伪，它的意义在于在那个时代，让人们知道原来关联规则通过数据挖掘，我们能够发现一些我们自己完全想象不到的知识。</p><p>当然，刚刚我们讲的这个案例只是一个起点，现在关联规则挖掘已经被广泛应用在各行各业中。例如在金融行业当中，它可以预测银行客户的需求：某个高信用额度的客户更换了地址，可能表示他近期购买了一个更大的豪宅，因此可能需要更多的信用额度或者需要一个住房贷款，这些信息可以帮助银行做二次营销。</p><p>同样，在股票分析当中，美国高盛投行公司以及其他的量化交易公司会经常监测人们在Twitter和Facebook上发的一些新闻，根据这些新闻来动态调整股票的售卖。</p><p>在互联网里使用的案例就更多了，在亚马逊书城里面你能看到“浏览此商品的顾客也同时浏览”的推荐，其实这背后就是关联数据挖掘出来这本书和其他书之间的关联关系，促进你购买更多类似的书籍。</p><p><img src=\"https://static001.geekbang.org/resource/image/21/2a/2186d156c070c572f23712a7816bf52a.jpg?wh=1875x920\" alt=\"\"></p><h2>关联规则算法初探</h2><p>刚才看了很多案例，那么我们怎么能发现这些强关联之间的数据逻辑呢？先给你介绍三个比较简单的概念。</p><p><strong>支持度（support）</strong>：某个商品组合出现的次数与总次数之间的比例，也就是这个商品组合整体发生的概率怎样。</p><p>5次购买，4次买了啤酒，啤酒的支持度为4/5=0.8；</p><p>5次购买，3次买了啤酒+尿布，啤酒+尿布的支持度为3/5=0.6。</p><p><strong>置信度（confidence）</strong>：购买了商品A后有多大概率购买商品B，也就是在A发生的情况下B发生的概率是多少。</p><p>买了5次啤酒，其中2次买了尿布，(尿布→啤酒)的置信度为2/5=0.4；</p><p>买了4次尿布，其中2次买了啤酒，(啤酒→尿布)的置信度为2/4=0.5。</p><p>还有一个叫做提升度的概念，你可以简单了解一下。</p><p><strong>提升度（lift）：</strong>衡量商品A的出现对商品B的出现概率提升的程度，A和B</p><p>提升度(A→B)=置信度(A→B)/支持度(B)。</p><p>提升度&gt;1，证明A和B的相关性很高，A会带动B的售卖；</p><p>提升度=1，无相关性，相互没作用；</p><p>提升度&lt;1，证明A对B有负相关，也就是这两个商品有排斥作用，买了A就不会买B。</p><p>如果支持度很小，证明大多数人不会将这种组合进行购买。如果置信度低，代表即使两个商品销量都不错，但他俩的关系也不紧密。<strong>我们想要做的是要找到置信度高且支持度高的场景。</strong></p><p>给你举个例子，在下面这个表格里，每个商品下面出现的1代表购买了，0 代表没有购买。</p><p><img src=\"https://static001.geekbang.org/resource/image/5d/5a/5d4d9142d9fb5d19ae1b1b2edd038d5a.jpg?wh=1848x781\" alt=\"\"></p><p>根据前面的定义，交易1、2、3、4、6购买了啤酒，交易1、2、6同时购买了啤酒和尿布。我们可以计算出支持度为0.5，置信度为0.6。如果我们把支持度和置信度定义成50%的话，就会认为啤酒→尿布是一个有关联性的规则。</p><p>根据这个关联的规则的定义，有一个特别原始且粗暴的方法找到关联规则：找出所有组合并加以计算，然后根据每一种组合的支持度和置信度去提取整体符合关系的规则。但这个方法的计算强度是几何级上升的，几乎是一个阶乘的逻辑，这个致命的问题让我们很难通过暴力计算来获取关联规则。</p><p>有一个叫Apriori的算法可以解决我们的问题。它的基本的逻辑其实也不复杂，我把它称为“<strong>连坐算法</strong>”。我们的目标是去掉过多的组合，如果按个去统计有价值的组合，那么在所有组合中有关联性的组合会有如下逻辑：</p><ul>\n<li>如果一个组合是频繁组合，则它所有的非空子集也是频繁组合——连坐，一家子都是明星组合，任何跳出来两个人也都是明星组合；</li>\n<li>如果一个非空组合是非频繁组合，则其所有的父集也是非频繁组合——连坐，如果有一个人不是明星，他和谁组合都不会是明星组合。</li>\n</ul><p>例如，如果123是频繁组合，则12、13、23也是频繁组合；若12是非频繁组合，则123也是非频繁组合，即其他数据集里只要含12都可直接判定其为非频繁组合。<strong>这种方法能够帮我们去掉很多没有必要测试的组合。</strong>这样我们再去分析余下组合的支持度和置信度，就可以得到我们的最终要的规则了。</p><p>Apriori算法的优点是可以产生相对较小的候选集，而它的缺点是要重复扫描数据库，且扫描的次数由最大频繁项目集中项目数决定，因此Apriori适用于最大频繁项目集相对较小的数据集中。后续的FP-growth算法修正了这些问题。当然用于关联规则挖掘算法还有很多，例如setm、Eclat等等，你要是感兴趣，可以去进一步了解这些算法。</p><p>目前关联规则的挖掘过程大致可以总结为两步：</p><ul>\n<li>找出所有频繁组合；</li>\n<li>由频繁组合产生规则，从中提取置信度高的规则。</li>\n</ul><p>当然关联规则有它的一些局限性，它需要有足够的数据才能发现这些规则，而在现实世界中想获得这些足够的数据可不容易。而且如果获取的数据出现偏差，关联规则会容易得到错误的结果，还可能生成太多无用的规则。</p><p>所以在使用关联规则算法之前<strong>一定要通过业务的梳理，先规避掉有偏差的脏数据，选择最终真正对业务有用的规则。</strong></p><p>当然，我们也反复强调过，关联规则挖掘出来的结果只是代表这两件事情有很强的相关性，但不能代表有因果关系，因果关系的确定要结合实际的业务经验。</p><h2>未来场景的展望</h2><p>关联规则已经不仅仅使用在交易当中，而是根据物联网和人工智能算法的发展，出现在越来越多有意思的场景中。</p><p>例如下面这个图就是我在万达的时候，在某万达广场通过每一个会员客户在不同商店停留的的情况，分析出的一个关联规则的图。这个图里面，两个商店之间线颜色越深的代表它们之间的关联性越强，线颜色越浅的代表它们之间的关联的性越少。</p><p>你能惊奇地发现原来喜欢去星巴克的人也经常会喜欢去必胜客，而且在那个时候喜欢去星巴克的人经常会逛H&amp;M。同时你也会发现经常去麦当劳的人他不一定去必胜客，也不怎么去喝星巴克。这些都是一些有意思的发现，如果要做促销，我们就可以在星巴克客户里发一些必胜客的优惠券，这样就可以相互去引流，能够帮助门店创造更多收入。</p><p><img src=\"https://static001.geekbang.org/resource/image/1b/f4/1ba29c09585739b708d50404fb4bbff4.jpg?wh=1496x949\" alt=\"\"></p><p>同样，现在在医学领域里也有很多用关联挖掘的案例。我们知道中医针灸非常神秘，比如在这些针灸的穴位之间到底有什么关系呢？</p><p>现在就有很多人去通过针灸药方挖掘去寻找一些针灸的规律。比如下面这个图就是一个老中医的针灸穴位之间的关联关系图。如果将来这些数据积累到一定程度，是不是未来我们就可以用一个人工智能的老中医来给我们开药和针灸呢？我觉得随着科技的发展，这件事情一定可以实现。</p><p><img src=\"https://static001.geekbang.org/resource/image/ac/9f/ac1fe8bdc150ccb25ab0f9ccbe8a0c9f.jpg?wh=1648x1053\" alt=\"\"></p><p>还有，对于我这种理科直男来讲，选衣服搭配简直比让我去做一个关联算法还要难。现在简单了，很多的门店里面会有类似下面这样的“魔镜”帮你去推荐衣服的穿搭。你穿上某一件衣服，一照镜子就会自动生成配套的搭配，如果满意的话，直接点击就可以在店里面一下能买好几件衣服，这对于我这种没有审美的直男简直太方便了。</p><p>这背后其实是通过百万级购买的记录去找到这些衣服之间的搭配的规则，然后再推荐给你个人。这样的话可以给你提供更加个性化的优质穿衣搭配方案，能够提高整体商品的销量。</p><p><img src=\"https://static001.geekbang.org/resource/image/60/56/60ac20943a6362525c36ac02d97fdf56.jpg?wh=1732x1141\" alt=\"\"></p><h2>小结</h2><p>简单回顾一下，今天给你讲了关联规则的一些定义，也给你分享了怎样去发现事物之间关联规则的算法（Apriori），也展望了一下未来，和你分享了一些最新的应用场景。</p><p>利用关联规则挖掘，我们可以找到复杂事物当中有强相关的一些组合，根据这些组合的分析，我们可以提高整体的销售的销量或者进行有效的关联促销。利用关联规则挖掘也可以去做一些深度的科学计算，发现事物之间背后隐藏的规律。</p><p>关联规则的算法其实对我们自己也很有启发。人的一生其实很短暂，我们会经历很多事情，感觉很多的事情有关联又不关联，就像开头提到的，眼皮跳真的和你今天的运气关联性很高吗？</p><p>其实我们要和关联算法一样，把和你关联关系最强的那些事情把握住，把关联不强的这些事情舍弃掉。我们的一生非常短暂，学完这节课，你可以试试<strong>用关联算法的思想，盘一盘你现在手里的资源，看看能不能用“连坐”算法把整体无关的事务、人脉做到断舍离，留下精力把和你最强的关联关系的事情做好。</strong></p><p>如果你分不清什么事情对你关联关系最强，什么事情对你无关紧要，你的生活很有可能变成一团毛线球，不知道从哪下功夫，就算发力也有可能忙活一些不痛不痒的小事。人的一生重要的事情和重要的人脉可能就这么几个，你抓住了，人生才能成功。</p><p>数据给你一双看透本质的眼睛，利用好关联规则思路找到和自己生命置信度、支持度最高的频繁集，规划好自己的人生。</p><h2>课后思考</h2><p>在你工作和生活当中遇到像“啤酒和尿布”这样看似没有道理，但是通过数据算法发现他们有很强相关性的故事么？分享出来我们共同提高。</p>",
                "article_title": "16 | 关联规则：为什么啤酒和尿布一起卖？"
            },
            {
                "title": "17 | 蒙特卡洛与拉斯维加斯：有限时间内如何获得最优解？",
                "id": 415120,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>前面给你讲了回归、分类、聚类、关联等一些基础算法，其实如果有足够的时间和计算资源，我们其实能通过这些基础算法做出很多特别精确的预测和分析。</p><p>但实际我们在现实工作和生活中，没那么多的资源和时间来得到最佳的结果。那么在有限时间里，怎么样才能够获得比较好的计算答案，或者有没有好的办法能够在比较短的时间求得正确的答案呢？今天我就给你分享两个比较有代表性的算法：蒙特卡洛算法和拉斯维加斯算法。</p><h2>算法定义和场景</h2><p>这两个算法的目标都是利用随机的方法来简化整体的算法过程，解决一些看上去我们没有办法通过正常算法解决的实际问题。</p><p>先给你讲讲蒙特卡罗算法，这个算法是在20世纪40年代，由S.M.乌拉姆和J.冯·诺伊曼首先提出来（对，就是那个世界上最早的通用电子计算机ENIAC创作者冯·诺伊曼）。</p><p>这个算法的名字由来其实很随意。那个时候，正值美国在第二次世界大战，乌拉姆和诺伊曼都是“曼哈顿计划”（美国原子弹计划）计划的成员，而第一台电子计算机ENIAC在发明后就被用于“曼哈顿计划”。在参与这个计划过程中，乌拉姆想到在计算机强大计算能力的帮助下，可以通过重复数百次模拟核实验的方式来对核裂变的各种概率变量进行演算，而不用实际进行那么多次实验。</p><!-- [[[read_end]]] --><p>冯·诺伊曼立即认识到这个想法的重要性并给予乌拉姆充分的支持，乌拉姆将这种统计方法用于计算核裂变的连锁反应，大大加快了这个项目的节奏。由于乌拉姆常说他叔叔在摩纳哥的赌城“Monte Carlo”输钱，他的同事Nicolas Metropolis戏称该方法为“蒙特卡罗”，这个名字也就沿用到了现在。</p><p>蒙特卡罗算法原理其实很简单，就是每次计算都尽量尝试找更好的结果路径，但不保证是最好的结果路径。用这样寻找结果的方法，无论何时都会有结果出来，而且给的时间越多、尝试越多，最终会越近似最优解。</p><p>举个例子，我们现在要用蒙特卡洛算法找到一个有500个苹果的筐里，最大的苹果。正常来讲，我们每次从筐中拿一个苹果A， 然后下一次再随机从筐中拿出另一个苹果B， 如果B比A大的话，就把A扔到另一个筐里，手里只拿着B。这样如果我们拿了500次的话，最后留在手里的一定是最大的那个苹果。</p><p>但如果我们的时间和资源不够拿500次苹果呢？</p><p>我们就可以用蒙特卡洛算法，无论我们选择多少次，每次手里依然保留比较大的苹果，直到资源不够让我们截止的时候，留在我们手上的苹果也是我们力所能及接近最大的。也就是说我们持续保留较好的答案，一直执行N次（N&lt;500），最终拿到的一定近似正确解。<strong>N越接近500，我们的苹果越接近最大的那个。</strong>其实蒙特卡洛方法的理论基础就是我们前面讲过的<a href=\"https://time.geekbang.org/column/article/401316\">大数定律</a>。根据这个定律我们知道当随机事件发生的次数足够多时，发生的频率就会趋近于预期的概率。</p><p>和蒙特卡罗算法截然相反的另一种算法就是拉斯维加斯算法，它是在1979年<a href=\"https://en.wikipedia.org/wiki/L%C3%A1szl%C3%B3_Babai\">László Babai</a>在解决图同构问题的时候，针对蒙特卡罗算法弊病提出的。拉斯维加斯算法原理也很简单，就是<strong>每次计算都尝试找到最好的答案，但不保证这次计算就能找到最好的答案，尝试次数越多，越有机会找到最优解。</strong></p><p>举个例子，假如有一把锁，给我100把钥匙，其中只有1把钥匙可以开锁。于是我每次随机抽1把钥匙去试，打不开就再换1把。我尝试的次数越多，打开锁的机会就越大。但在打开之前，那些错的钥匙都是没有用的。这个挨个尝试换钥匙开锁的算法，就是拉斯维加斯算法。</p><p>准确来讲，蒙特卡罗算法和拉斯维加斯算法其实并不是两种算法，而是两类算法的统称。</p><p>蒙特卡罗算法的基本思想是精益迭代，进行多次求解，最终让最后结果成为正确结果的可能性变高。而拉斯维加斯的算法是不断进行尝试，直到某次尝试结果让你自己满意，当然这个过程中也会一直产生你无法满意的随机值。</p><p>所以拉斯维加斯的算法效率通常比蒙特卡罗的算法低，但是最终得出的解一定是这个问题的正确解，当然也有可能无法得到问题的解。这两个算法之间的差别你可以通过下面的这个图表来进行区分。</p><p><img src=\"https://static001.geekbang.org/resource/image/21/85/2198b0209d69be129d39e4a63489e185.jpg?wh=1904x629\" alt=\"\"></p><h2>蒙特卡洛和拉斯维加斯算法举例</h2><p>刚刚从概念上带你了解了蒙特卡罗算法和拉斯维加斯算法，下面我实际给你举两个具体的例子来看看这两个算法的进一步运用。</p><p>首先我们来看看利用蒙特卡罗算法计算圆周率。</p><p>圆周率是通过n个多边形周长来推导计算出来的（可以参考附录），不过我们通过蒙特卡罗算法，也可以把圆周率计算出来。</p><p><strong>首先，我们构造一个正方形，里面套一个内切圆。</strong></p><p><strong>然后，我们在这个正方形的内部随机打上1万个点。</strong></p><p><strong>最后，根据它到中心点的距离来判断这个点是否落在圆的内部。</strong>这个落在圆内部的概率其实和这个圆与正方形之间的面积有一个比例关系。也就是假设落在圆内的概率为P，则P=圆面积/正方形面积。<code>P=(π*R*R)/(2R*2R)= π/4</code>也就是 π=4P。</p><p>如果我们的这些点是足够均匀分布的，那么圆内的点应该占到整个正方形里面点的π/4，所以只要把这个概率P乘以4就是π的值。</p><p><img src=\"https://static001.geekbang.org/resource/image/c8/70/c8a31eba918409a37bdb9f1c2ebe2970.png?wh=500x501\" alt=\"\"></p><p>具体步骤如下。</p><p>1.将圆心设在原点，以R为半径作圆，则第一象限的1/4圆面积为<code>π*R*R/4</code>；</p><p>2.做该1/4圆的外接正方形，坐标为（0，0）（0，R）（R，0）（R，R），则该正方形面积为R*R；</p><p>3.随机取点（X，Y），使得0&lt;=X&lt;=R并且0&lt;=Y&lt;=R，即点在正方形内；</p><p>4.通过公式<code> X*X+Y*Y&lt;RR</code>判断点是否在圆内；</p><p>5.最后一共模拟了N次试验，一共有M个点在圆内，则P=M/N，而π=4*M/N。</p><p>这个N就是蒙特卡洛算法的特点，N越大，越接近π的真实值，但是你可以设置任何一个时刻停下来都会有一个接近正确答案的值。我在一个平台上用这个算法进行计算，发现如果N是1万个点的话，它的结果是3.1424。是不是很神奇？我们并没有通过数学推导的方式，而是通过一个随机变量的方式来计算出我们的结果。如果你要提高精确度，我们可以打上更多个点，那么它最终会越来越接近π真实值。</p><p>而拉斯维加斯算法就不一样了，它是针对一个确定性的答案去不断进行随机尝试，我再给你举一个国际象棋里“摆皇后”的例子。</p><p>我们的目标是在一个N*N国际象棋棋盘里摆下N个皇后，让她们相互不会被吃掉。例如，下面这个图我们就摆了8个皇后在标准的8×8的国际象棋棋盘中，在这棋盘里，她们可以不相互伤害，和平共处。</p><p><img src=\"https://static001.geekbang.org/resource/image/95/df/953105yy31ba7072f013b0c954561cdf.png?wh=353x351\" alt=\"\"></p><p>这个摆法我们是怎么摆出来的呢？</p><p>一般解法是先在最左边（1,1）摆上第1个皇后，然后再把第2个摆放到第一个不被吃的位置（2,3），再把第3个摆进去不被吃的位置……这样一直延续下去，直到无论下一个皇后摆在哪都会被吃掉的时候，证明上面几个皇后摆放的位置不对。那么你就要去挪上一个皇后的位置，如果还不行还得再挪上上个皇后，然后再摆下一个皇后。</p><p>这样不停尝试下去，才能把N个皇后都摆进这个N*N的格子里。可以想象，这个算法毛病就在于你得不停地去做尝试。这个算法的代价就很大，经过数学的<a href=\"https://sites.google.com/site/nqueensolver/home/algorithm-results\">推理</a>，找到最终解决方案的尝试次数，数量级在N的N次方。这样如果当皇后数超过15个的时候，这个数字就会达到437893830380853000次——基本上现在普通电脑的计算能力短时间内就计算不出来了。</p><p>怎么解决这个问题呢？我们首先看前面小规模<code>的8*8</code>、<code>10*10</code>棋盘里，皇后在棋盘上摆的正确位置，其实并没有什么规律可言，就像随机放在上面的。于是我们就可以想象一下，如果用拉斯维加斯算法把皇后类似于随机地摆放在棋盘上，然后在用前面的算法进行调整，是不是就会比我们一个一个放速度要快呢？也就是说我们<strong>先利用拉斯维加斯算法在前面若干行随机摆放皇后，后面的行再利用前面传统的算法去完成。</strong>实际结果证明可以节约很多计算的时间和资源。</p><p>一旦用拉斯维加斯算法找到一个解，这个解就一定是正确解，但有时用拉斯维加斯算法找不到解。拉斯维加斯算法找到正确解的概率随着它所用的计算时间的增加而提高，那么，对于某一个难题来说，如果你用同一拉斯维加斯算法反复尝试足够多次，可使求解失败的概率任意小，最终还可以获得正确解答。</p><p>通过这个算圆周率和“摆皇后”的例子，不知道你对这两个算法各自的优点有没有进一步的认识呢？</p><h2>算法应用场景与展望</h2><p>现在，蒙特拉罗和拉斯维加斯算法在金融工业和人工智能领域都有很广泛的应用。特别是蒙特卡罗算法，在当今社会有各种各样不确定性的情况下，它给我们提供了很多解决方案。</p><p>比如金融市场本身充满了确定性和不确定性，就非常符合蒙特卡洛面对数字化变量的确定性和随机性这两种特征。使用蒙特卡洛算法利用尽可能多的模型采样，就可以寻求近似最优解。所以在金融领域里，蒙特卡洛算法得到非常广泛的应用。</p><ul>\n<li><strong>计算风险价值</strong>（value at risk，VaR）：VaR试图以一个明确的数值来对投资组合进行风险评估，在计算这个价值的时候就会经常用到蒙特卡洛方法去模拟各种各样的市场的变化，从而得到最终近似最优的风险价值。</li>\n<li><strong>自动化交易</strong>：股票和期货之中利用蒙特卡洛算法的双均线系统，模拟各种买进、卖出以及其他操作，最终得出一个近似最好的执行方案。经过测试，这样做可以比正常的双均线系统自动化交易要高10%-30%。</li>\n<li><strong>衍生品定价</strong>：针对市场上发生的各种各样的情况对衍生品的价格进行模拟，最终也可以将特别复杂的衍生品价格计算出来。</li>\n</ul><p>在人工智能领域，蒙特卡洛也必不可少。现在人工智能领域里为了简化复杂的计算而产生了一个很重要的算法叫做蒙特卡洛树。以现在特别火的人工智能下棋的算法来讲，基本思路是每一步AI去判断的下一步的运算时间、内存空间都是有限的，而且不能要求最优解，所以阿尔法狗和类似的AI下棋算法，一定会利用蒙特卡洛方法来简化其中的步骤，获得相对最优下棋的方法。毫无疑问，蒙特卡洛算法会是这个场景下的核心算法之一。</p><p>如何在这两类随机算法之间选择，那就要具体问题具体分析了。<strong>如果问题要求在有限时间和尝试次数内必须给出一个解，但不要求是最优解，那就用蒙特卡罗算法。反之，如果问题要求必须给出最优解，但对时间和尝试次数没有限制，那就用拉斯维加斯算法。</strong></p><p>把这两种算法对应到工作和生活中，对拉斯维加斯算法来说，有些事情我们是需要精益求精，无论花多少时间都得把这件事情做细致做准确，否则后果可能会非常严重；有些地方反而是需要蒙特卡洛算法，在事情有大概比较清晰的方案的时候，要快速决策，否则如果把时间耽误了，反而最后获得的结果会更糟。</p><p>给你举个具体的例子，现在在工作上有一种创业方法叫做“精益”创业，其实核心思想就是和蒙特卡洛算法类似：在有限的时间和有限的资源情况下，不要一直思考或者规划找到“最优解”，而是通过快速迭代原型产品，通过用户的反馈不断地修正自己产品的方案，以达到在有限的时间和有限的资源情况下得到较为不错的结果。</p><p>虽然这个结果不一定是最优的，但是总比使用拉斯维加斯算法创业，闷在家里闭门造车寻找最优解，直到耗尽了资源和时间要好。</p><h2>小结</h2><p>总结一下，今天主要给你讲了两个算法：蒙特卡洛算法和拉斯维加斯算法。</p><p>蒙特卡洛算法是我们一直去努力，努力到自己满意了就可以停下来；而拉斯维加斯算法就要一直去努力，如果找不到最佳答案就誓不罢休。这两个算法其实是两类算法集合，代表着两种不同处理事情的思路。</p><p>我们要根据自己手里的资源、时间，灵活选择是使用蒙特卡罗式的方法还是拉斯维加斯式的方法来处理事情，毕竟人的一生时间和精力都是有限的。</p><p>我们每天都会面临到各种各样的问题，学完这节课后，你可以仔细思考一下你现在手里哪些事情不达目的誓不罢休（拉斯维加斯式算法）；哪些事情需要精益的方法和思路，多次尝试不断修正，事情发展到一定程度见好就收（蒙特卡洛式算法）。</p><p>对于管理企业来说，我们要高维度思考，不要把我们的有限的时间和精力浪费在不必要的事情上，整体的做事思路是抓大放小。而重要的事情要用拉斯维加斯算法一通到底，任何细节都不要放过，确保随机事件的正确性。</p><p>一次次不同的决策，决定了每一个企业成功和失败。同样，一次次我们自己不同的决策，也决定了我们别具特色的人生。</p><p>数据给你一双看透本质的眼睛，针对具体的场景问题选择好具体的算法解决方式，把我们有限的时间和精力投入到真正要做的事情当中。</p><h2>课后思考</h2><p>你在工作和生活当中用过蒙特卡洛和拉斯维加斯算法的思路来解决问题么？分享出来，我们大家相互启发。</p><h2>附录：多边形推导圆周率</h2><p>π数值的算法最早是公元前250年由希腊数学家阿基米德所发明，算法逻辑很简单，也就是在圆内接和外切套入两个多边形。理论上，圆的周长在这两个多边形之间，多边形的周长我们有公式计算，圆的半径已知，多边形的边长就已知。那么只要把这个多边形的边数增加越多，那么多边形的周长也就越来越接近圆的周长，反推出来的π也就越精确。</p><p><img src=\"https://static001.geekbang.org/resource/image/d9/80/d9d119961fba8090b394yy7eca91a180.png?wh=1263x406\" alt=\"\"></p><p>阿基米德利用96边形推算出来的π值在3.1408和3.1429之间，在公元前150年，希腊罗马的科学家克劳狄乌斯·托勒密在《天文学大成》一书中提到π的数值是3.1416。在1630年多名数学家利用多边形的方式计算π到第39位小数，一直到1699年，其他数学家才利用无穷级数的方式打破其纪录，计算到第71位小数。多边形计算法是第一个有纪录、严谨计算π数值的算法。</p>",
                "article_title": "17 | 蒙特卡洛与拉斯维加斯：有限时间内如何获得最优解？"
            },
            {
                "title": "18 | 马尔可夫链：你的未来，只取决于你当下做什么",
                "id": 415893,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>上节课讲了拉斯维加斯和蒙特卡洛算法，结合前面的基础算法你会发现这些算法的特点是来解决某个时间点的问题，但没有解决那些和时间先后次序相关的预测问题。</p><p>我们现实生活当中其实充满了很多和事情顺序相关的过程。也就是说一件事情发生后会影响另外一件事情的结果，而这些事往往是按照某一个规律次序发生的。今天我们就来聊聊和时间序列预测相关的一个算法：马尔可夫链。</p><p>马尔可夫链专门研究在现实生活当中这一系列的事件，<strong>找到它们的内部运行规律，从而预测当这一系列事件达到平衡的时候，当前状态的下一步最可能发生的情况。</strong>这样我们就可以知道，当一件事情发生的时候，未来有多大可能会发生另一件事情。</p><h2>马尔可夫链算法定义与场景</h2><p>马尔可夫链因俄国数学家安德烈·马尔可夫得名，它的定义是：状态空间中经过从一个状态到另一个状态的转换的随机过程。该过程要求具备“无记忆”的性质，也就说下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。</p><p>看完这个定义，你会不会有种一头雾水的感觉？我用一个简单的例子给你解释一下。天气就是一个状态，比如昨天是阴天，今天是晴天。如果今天的天气只和昨天天气有关（也就是和昨天之前的任何一天的天气都没有关系），那么，天气的这个系统就是一个符合马尔可夫链的完备系统，我们就可以通过今天的天气来预测明天的天气，甚至预测未来1个月、1年的天气。</p><!-- [[[read_end]]] --><p>而马尔可夫同学在最开始建立马尔可夫链的时候，最著名的应用就是从一份俄罗斯诗歌作品中数出几千个两字符对，他使用这些两字符对计算了每个字符出现的概率。也就是在这诗歌里我们给一个字符，就能预测关于下一个字符可能是什么。</p><p>通过这个方法，马尔可夫可以模拟这个诗歌一个任意的长字符序列，这就是马尔可夫链。所以，如果这个概率很准确的话，在这个诗歌里看到前面的这句话，你大概率就知道下一句会用什么样的词和句子了。我们甚至可以让计算机自己创造作品，例如现就就有计算机算法自己学习巴赫的作品，然后生成一首巴赫的曲子，感觉神韵还很像，你可以点击<a href=\"https://b23.tv/LJlxku\">这里</a>去这里听一下。</p><p>有非常多著名的算法例子都使用了马尔可夫链。比如著名的谷歌创始人拉里·佩奇和谢尔盖·布林在1998年提出的谷歌搜索最核心的网页排序算法PageRank就是由马尔可夫链定义的，而这个算法造就了整个谷歌在搜索引擎里的霸主地位，至今为止你去谷歌搜索内容的准确率还是远高于其他搜索引擎的。</p><p>又比如在经济金融领域，詹姆斯.D.汉密尔顿在1989年用马尔可夫链来对高GDP增长速度时期与低GDP增长速度时期（也就是经济扩张与紧缩）的转换<a href=\"https://www.nber.org/system/files/working_papers/w11422/w11422.pdf\">进行建模</a>，帮助美国在经济萧条中对GDP的恢复情况进行预测，直到今天马尔科夫链依然是经济学当中预测一个国家GDP重要方法之一。</p><h2>马尔可夫链算法举例</h2><p>马尔可夫链这么厉害，我们再更具体地来看一下，马尔可夫链的原理是什么，以及我们可以怎么用。</p><p>假设你现在住在一居室里，这房子里有卫生间、卧室、厨房，你把你从一个房间到另一个房间的概率统计了一下。例如你现在在卫生间，你有 75% 的概率会留在卫生间，有 10% 的概率会走到卧室，有 5% 的概率会走到厨房。你把你从每一个房间到另一个房间的概率都统计清楚了，这就可以形成一个马尔可夫链，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/a7/0e/a7d44629ee1230522bf6c72d9594d20e.jpg?wh=1944x1177\" alt=\"\"></p><p>上图中的箭头和旁边的数字表示从一个状态转移到另一个状态的概率，例如，从卧室到卧室是90%，从卧室到厨房概率5%，从卧室到厕所概率5%。我们可以通过大量的统计分析或者算法预测来完善这个马尔可夫链里边的概率。最终我们会看到你要去哪一个房间，和你最开始在哪个房间其实并没有关系，只和你上一个所处的房间有关系的时候，这时就可以通过马尔可夫链来计算你的个人行为的长期趋势了。</p><p>比如假设我初始的时候，在卧室、厕所、厨房的概率分别是70%、10%、20%，那么我可以预测移动三次之后，我去每个房间的概率是多少，就像下面这个图展示出来的。这个图就叫做“转移矩阵”，有了它我们就可以对整个我在房间里的行为有一个规律性的判断，例如，从前面的规律和初始概率，从下面的推算会发现，我在厕所的时间越来越长……</p><p><img src=\"https://static001.geekbang.org/resource/image/f5/9b/f5e49f45618fc830b3b57d9c7b03c19b.jpg?wh=1904x961\" alt=\"\"></p><p>这个时候，你可能会问了：“预测房间这件事情没有什么实际意义啊？”那什么才会更有实际意义呢？我们可以把上面的三个房间替换成股市的三个状态，分别是牛市，熊市和横盘，就变成现在下图的样子。</p><p><img src=\"https://static001.geekbang.org/resource/image/ae/75/aeb55f938caf18f259a6d9dfbd54eb75.jpg?wh=1916x1159\" alt=\"\"></p><p>再计算一下股市的“转移矩阵”，如下图。</p><p><img src=\"https://static001.geekbang.org/resource/image/4d/3c/4d5f43yyf1416f12eaf2ae86f836a83c.jpg?wh=1904x945\" alt=\"\"></p><p>这个时候我们是不是就可以根据现在的股市的状态，看将来会是熊市还是牛市了呢？其实在金融行业里，这就是马尔可夫链最常用的一个案例。只不过在股市里，每个状态转换的概率要复杂得多，计算机很难计算出来。于是，结合前面我们讲的蒙特卡洛算法，就有了大名鼎鼎的<strong>马尔可夫链蒙特卡罗算法（MCMC）</strong>。</p><p>MCMC由梅特罗波利斯于1953年在洛斯阿拉莫斯国家实验室提出，本质上是将马尔可夫链用于对蒙特卡洛方法的计算过程中。那时美国洛斯阿拉莫斯是当时少数几个拥有大规模计算机的城市，梅特罗波利斯利用这种计算优势，在蒙特卡洛方法的基础上引入马尔可夫链，用于模拟某种液体在气化之后的平衡状态。</p><p>1984年Stuart和Donald Geman兄弟对吉布斯采样进行了描述，形成了我们今天所熟悉的版本，这些算法在自动化交易和临床医学上都有很多的应用，比如当测试数量趋向无穷时，MCMC方法可以将病人症状与方剂药效持续配对，直到最后完全逼近出一个虚拟的人体模型作为状态观测器，并总结按照输入输出关系模型反馈给药的规律。</p><p>同样，在互联网公司里，要去做一些推荐的时候，也会用到马尔可夫链的一些算法。我们去浏览网站，其实无外乎就是在浏览、购买、收藏商品。其实这些行为也可以变成和上述移动房间类似的马尔可夫链形式，这样我们可以根据每一个不同的行为状态来预测下一步用户可能会做什么，然后这个时候我们给用户最方便的一些行为指导和预测，就可以促进用户的购买。</p><p>这也就是你在淘宝上看到的“猜你喜欢”和首页推荐列表里其中的一个核心算法。我们可以根据用户的“特征喜好状态转移矩阵”，得出用户可能在下个时刻的操作列表，然后把它做成推荐列表。最后将多个推荐列表进行其他算法的加权融合，得出最终的列表结果。</p><h2>算法应用场景及展望</h2><p>马尔可夫链的应用非常广泛，例如天气的预测、食品销售的预测、GDP的涨幅预测、企业人员的变动预测等等问题，都可以通过马尔可夫链来解决。当这些复杂系统某些条件进行变化的时候，马尔可夫链就可以根据前面的转移矩阵先推算未来最可能的状态，从而对政府和企业的决策产生非常重大的影响。</p><p>在人工智能领域里，Siri里面自然语言的识别就经常会用到马尔可夫链的预测。因为我们说的话里上一句和下一句，上一个词和下一个词，基本上也是遵循马尔可夫链的规律的。所以<strong>我们会通过马尔可夫链来修正计算机识别的一些问题。</strong></p><p>比如说使用马尔可夫的算法根据前一个状态识别出下一个状态正确单词，就会比单独识别某一个单词准确率高得多。这样根据上下文你讨论着某一个职位“Vocation”，最后Siri就不会理解成你要去度假旅游“Vacation”，最终给你的回答和答案也更加准确了。</p><p>又比如说，我们在自动驾驶识别前面路况时，到底识别出是道路、天空还是学校？通常做法我们会使用它的颜色用项数据标记，但这个时候可能就会有各种各样复杂的变量和因素，如果只看局部不加上下文马尔可夫链算法的判断，就会决策出现一些问题，例如在天空里面识别出一段公路或者是把前面的卡车当成了天空。</p><p>其实我们知道在图像当中，前后时间比较近的这些像素通常都使用同一个物体，这个时候我们就可以把在前后时间相近、特征相邻的像素识别为相同的东西，就不容易识别错误，避免突然在空荡的马路上停车，或者看着一个卡车当作天空直接撞上去了。</p><p>现在有人把马尔可夫链用于分析生物的DNA序列，还有人用马尔可夫链算法来预测双色球和其他彩票，以及做炒币的自动化交易，以及我们在前面讲的用马尔可夫链来作曲等等。</p><p>总之在跟序列相关的反馈机制预测问题上，马尔可夫链是非常有帮助的。不过<strong>马尔可夫链和其他数据算法联系非常紧密，它的预测结果好坏其实都依赖于我们刚才提到的概率转移矩阵是否准确，而这个概率转移矩阵的准确性最后又依赖于算法估算方法的合理性。</strong>所以马尔可夫链要算准确，需要建立在前面我们提到的基本算法（回归、分类、聚类、关联等）预测概率的准确性上。</p><p>马尔可夫链除了受到其他算法的限制之外，本身也有它的局限性。马尔可夫链的假设是后一个状态值和前一个状态相关，而和更靠前的状态无关。而这个假设在一些情况下是不太符合实际的。例如我买一个品牌的衣服，发现质量特别差，可能未来买100次衣服我都不会去考虑这个衣服品牌了。所以<strong>虽然马尔可夫链应用这么广泛，是不是要用马尔可夫链算法，还是要结合具体业务场景。</strong></p><h2>小结</h2><p>这节课的内容到这里也就接近尾声了，最后我来给你总结一下。今天我们主要讲了马尔可夫链，它是非常著名的有序状态相关算法，可以帮助我们从一系列的事件里面找到内部运行规律，从而预测未来的情况。从Google搜索引擎到预测股市，从语音识别到自动驾驶，甚至是自动作曲作画、预测国家GDP的增长都可以使用马尔可夫链算法。</p><p>其实，在我们工作和日常生活当中也有很多“马尔可夫链”：你现在的状态其实大部分都是由你上一个状态决定，没有人会走背字一直失败，也没有人能幸运到一直成功。</p><p>你可以仔细想想，真正的失败，很多时候都是自己遇到失败后从此一蹶不振，走不出来失败的这个状态才造成的。“没有迈不过去的坎”这句话用马尔可夫链的视角来看，那就是现在自己的状态，只和自己上一个状态相关，和整体无关。所以吸取完教训后，调整好现在的心态，用现在去影响你的未来。</p><p>我特别喜欢《飘》电影结尾郝思嘉说的那句话，我觉得它诠释了“马尔可夫链”在生活哲学中的真谛：“Tomorrow is another day”——<strong>你的未来只取决于你当下在做什么，而不是过去你曾经做过什么，毕竟“明天，是新的一天”。</strong></p><p>数据给你一双看透本质的眼睛。让我们一起从数据世界里参悟到一些人生哲理，让数据“驱动”我们的生活。</p><h2>课后思考</h2><p>你曾经遇到过哪些事情是只由上一个状态（而不是过去状态）来决定你下一个状态的么？最后你收获到你想要的了吗？它能总结成一个马尔可夫链么？分享出来我们一块过过招？</p>",
                "article_title": "18 | 马尔可夫链：你的未来，只取决于你当下做什么"
            },
            {
                "title": "19 | 协同过滤：你看到的短视频都是集体智慧的结晶",
                "id": 416739,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>学到这里，其实你已经了解了不少复合算法的使用，包括和时间相关的马尔可夫链，加速我们进行选择的蒙特卡洛和拉斯维加斯算法等等。</p><p>在实际算法的应用过程当中，还有一种通过集体智慧来构成的复合算法，它可以寻找大量人群当中的行为数据模型规律，达成普通算法从单体上无法达到的效果。这种算法当中，最著名的一个算法就是协同过滤算法。</p><h2>协同过滤算法定义与场景</h2><p>协同过滤算法顾名思义，就是指用户可以齐心协力，通过不断地和算法互动，在多如牛毛的选择当中，过滤掉自己不感兴趣的选择，保留自己感兴趣的选择。</p><p>协同过滤算法源于1992年，最早被施乐公司发明并用于个性化推送的邮件系统（施乐公司就是那个发明了GUI界面，被乔布斯发现并创造了MAC OS的公司）。最早这个算法是让用户从几十种主题里面去选3~5种自己感兴趣的主题，然后通过协同过滤算法，施乐就根据不同的主题来筛选人群发送邮件，最终达到个性化邮件的目的。</p><p>到1994年的时候，协同过滤算法开始引入集体智慧的概念，也就是用更多的人群和数据去获取相关的知识。它允许用户贡献自己的一些行为和反馈，从而创造一个比任何个人和组织更强大机制，自动给用户发送喜欢的文章。</p><!-- [[[read_end]]] --><p>基于这个思路，施乐发明了著名的GroupLens系统。在这个系统里面，用户每读完一条新闻都会给一个评分，系统会根据这些评分来确定这些新闻还可以推送给谁。你看，今日头条的想法其实施乐在1994年就实现了。</p><p>当然当时的算法还没有那么精准，不过这个系统完全颠覆了过去只能通过编辑人工规则推送文章的机制，它是基于用户自己的每次反馈自动找到和该用户类似的人，再发送新闻邮件。通过GroupLens系统大获成功之后，协同过滤算法迅速占领了推荐系统的市场。因为<strong>推荐系统需要同时具备速度快和准确度高两个特点（需要在用户打开网站几秒钟就要推荐所感兴趣的内容或者物品），而协同过滤算法正好满足了这两点要求，这也是这个算法经久不衰的原因。</strong></p><p>使用协同过滤算法里最著名的网站就是亚马逊的网络书店，你每次去选择一本你喜欢感兴趣的书籍，马上就会看到下面有关于“浏览此商品的顾客也同时浏览”的推荐。</p><p><img src=\"https://static001.geekbang.org/resource/image/54/38/544e187717c64372f771242535576438.png?wh=1591x1017\" alt=\"\"></p><p>又比如我们去逛B站，你会看到B站会根据你自己的资料和类似的人浏览的视频来帮你找到可能感兴趣的视频，例如你喜欢二次元，你看到的推荐大部分都是二次元的视频；像我这样技术宅的，给我推荐的就都是各种技术类型的视频。</p><p><img src=\"https://static001.geekbang.org/resource/image/c8/47/c8a2605f07830796ae2fa6b34b05af47.png?wh=1660x867\" alt=\"\"></p><p>这样协同过滤系统从单一系统内的邮件文件过滤到跨系统的新闻电影，再到最后我们看到的短视频。虽然它们推荐的东西不同，但给我们的体验都是类似的：你总是能看到你喜欢的产品、感兴趣的服务、喜欢的视频、想读的文章。</p><h2>协同过滤算法简述</h2><p>协同过滤算法是怎么样能够知道你所喜欢的东西呢？我来给你介绍三个最常见的协同算法，它们分别是：<strong>基于用户的协同过滤算法</strong>（User-based Collaborative Filtering）、<strong>基于物品的协同过滤算法</strong>（Item-based Collaborative Filtering）以及<strong>基于数据模型的协同过滤算法</strong>（Model-based Collaborative Filtering）。</p><h3>基于用户的协同过滤算法</h3><p><strong>基于用户的协同过滤算法就是基于用户和用户之间的相似性，推荐你喜欢的东西，过滤你不喜欢的东西。</strong></p><p>例如你喜欢看海贼王，然后和你相似度很高的一个用户他喜欢火影忍者。我们应该把火影忍者推荐给你吗？还不能确定。因为只有一个和你类似的人喜欢火影忍者，不代表着你就会喜欢火影忍者。协同过滤算法是有和你相似的N个人都喜欢火影忍者，算法就会把火影忍者推荐给你们这群人。就像下面这个图，首先得先找到和你有类似喜好的用户，然后根据你喜欢和这些这类用户都喜欢的物品来给你推荐。</p><p><img src=\"https://static001.geekbang.org/resource/image/82/56/82913ac55eeb4610dcd6aa86be2c3256.png?wh=939x567\" alt=\"\"></p><p>在下面这个场景里小A小B小C都喜欢海贼王，根据用户协同过滤算法公式判断小A小B小C相似距离小于阈值；而小A和小B都喜欢火影忍者，因此根据基于用户的协同过滤的算法，我们把火影忍者也推荐给小C，认为他也喜欢看火影忍者。</p><p>基于用户的协同过滤在实际的使用当中为了提高生产效率，还会用到一些倒排的算法、数据特征选取（例如选取冷门商品而非热门商品，比如都要买高考习题集锦并不一定代表着用户相关性，但是喜欢看宅舞的用户相似度应该很高）、还有特征权重算法等等。</p><p>基于用户的协同过滤在使用当中有优点也有缺点，它的优点在于：</p><ul>\n<li>基于用户的协同过滤是找到用户之间的相似程度，所以能够反映一些小群体当中的物品的热门程度；</li>\n<li>它可以让用户发现一些惊喜。因为是根据类似用户的喜好来推荐，用户会发现自己对一些过去不知道的东西是感兴趣的；</li>\n<li>对一些新的有意思的物品比较友好。一旦某一个新的商品和电影被某一个社群的用户购买了，我们马上就可以推荐给他圈子当中的其他用户。</li>\n</ul><p>它的缺点在于：</p><ul>\n<li>如果你是一个新的用户，你可能不能马上找到和你类似的人，所以无法马上获得准确的推荐；</li>\n<li>对于推荐出来的结果虽然会给你带来惊喜，但是它也不太有解释性；系统不知道推荐给你的这个物品是什么，只知道你的相关的朋友都在使用；</li>\n<li>对于用户群比较大的公司，去计算用户之间的相似度的话，计算的耗费会比较高。</li>\n</ul><h3>基于物品的协同过滤算法</h3><p>接下来我们来看看基于物品的协同过滤算法。<strong>这种算法就是根据用户群对于物品的购买或者评价发现物品和物品之间的相似程度，然后再根据具体用户历史使用的类似物品推荐给这个用户。</strong>这么说可能有些绕，我举个例子你就明白了。比如华为的手机和华为手机壳经常被一起购买，这两个物品之间就存在比较强的相关性。那么当一个用户去新购买一个华为手机的时候，我们就会给他推荐一个华为的手机壳。整体的推荐逻辑和算法如下面这个图。</p><p><img src=\"https://static001.geekbang.org/resource/image/34/2b/34dc3b36e812a8cea011957993bb032b.png?wh=895x600\" alt=\"\"></p><p>在这个场景里小A小B在购买华为手机的时候都购买了华为手机壳，而根据物品协同过滤算法公式判断华为手机和华为手机壳的相似距离小于阈值。那么小C在买华为手机的时候，根据基于物品的协同过滤的算法，我们把华为手机壳也推荐给小C，认为他也可能购买华为手机壳。</p><p>基于物品的协同过滤算法同样也要计算物品之间的相似程度，也要用到一些倒排算法和物品的特征选取以及过滤噪音的算法，它的优点是：</p><ul>\n<li>推荐更加针对用户自身。它反映了每个用户自己的兴趣的决策，根据你自己每买的一个商品来给你做推荐，而不是一类人给你做推荐；</li>\n<li>实时性比较高。用户每次点赞和购买商品都可以对其他购买此商品的用户推荐；</li>\n<li>推荐的结果很好解释。因为它们都是类似或者是关联度很高的商品，推荐结果显而易见。</li>\n</ul><p>这种算法的缺点在于：</p><ul>\n<li>对于新加入进来的商品反馈速度比较慢，因为没有人购买也没有人互动，所以可能有一些很好的商品没有被很好地推荐；反过来没被推荐买的人更少，推荐的可能性更低，出现“产品死角”；</li>\n<li>不会给用户惊喜：大部分的物品其实都是关联度比较高，可以被想象到，惊喜程度不高；</li>\n<li>对于商品或物品更新情况比较快的领域比较不适用，比如新闻。因为你没有推荐到别人看，可能这个新闻就过期了。</li>\n</ul><p>具体在生产环节使用的时候，一般对小型的推荐系统来讲，基于物品的协同过滤是大家使用的主流。因为基于物品的协同过滤算法计算量比较小，上手程度比较快。随着你的用户变得更多、用户的期待更高，一般都会过渡到基于用户的协同过滤算法。</p><h3>基于数据模型的协同过滤算法</h3><p>我们很容易能想到，不一定非要通过协同过滤的公式来计算用户之间的距离，<strong>我们完全可以复用前面所学到的算法，先做出来模型，再进行相关的协同过滤。</strong></p><p>例如，用关联算法来去做物品之间的相似度评估，然后根据置信度、支持度、提升度或者其他评分规则推荐给用户。我们也可以用聚类算法来找到用户之间的关联程度，把用户之间的距离计算出来，然后把这些用户群相似度比较高的用户之间的商品确定给同样聚类比较清楚的用户。类似的我们还可以用分类算法回归算法，用神经网络做协同过滤、用图模型做协同过滤、用隐语义模型做协同过滤等等。</p><p>所以协同过滤它是一个利用“集体智慧”复合算法的思想，可以用前面我们介绍的所有类似的算法找到物品和物品或者用户和用户之间的关系来去做协同过滤。</p><h2>协同过滤的使用场景与缺点</h2><p>协同过滤算法已经被应用到互联网的方方面面，通过这些基于协同过滤算法的推荐算法，在2016年的双十一，阿里巴巴平台取得了20%的增长；Youtube上70%的用户时长都是协同过滤算法贡献的；Netflix 75% 的播放也来自推荐系统，帮助Netflix 每年节省10亿美元的广告费，可见协同过滤算法多么的强大。</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/d7/e2d2b25cd9eyyb2686bae769dbdc7fd7.png?wh=1204x704\" alt=\"\"></p><p>同样，你在网易音乐听到的私人FM这也是通过协同过滤的推荐算法来实现的，它可以给你推荐你从来不认识的歌手，但你听这个歌手的音乐也会很喜欢。</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/8f/a008cdd9ae113ab145b824ace3ebf48f.png?wh=1033x736\" alt=\"\"></p><p>不过协同过滤算法并不是万能的。因为它是考虑集体智慧给你带来新鲜的推荐和最适合感兴趣的东西，因此对具体某一个个体的实际情况并没有更多的判断。</p><p>例如你会经常看到，你浏览手机之后购买了一个手机，但是接下来几周，某些电商网站里还是会坚持不懈地给你推荐手机，这是因为协同过滤不是针对你个体进行的推荐。同时，因为基于集体智慧，所以对于一些很冷门的商品来说，最初始的这些用户流量是需要有引导的，否则会导致有些很不错的商品一直放在角落里无人问津。这对一些优秀但冷门的产品，例如小制片人的电影其实就不是特别友好。</p><p>同样因为协同过滤只是考虑到了物品和用户之间的关系，没有考虑到用户所处的场景，所以推荐的内容可能就不太有效。例如在上班的时间给你去推荐一些餐厅，但你那个时候并不能去；你带着孩子出去游玩，开车的路上不停给你推荐一些课程，这其实都只是考虑到了用户之间物品之间的关系，没有考虑到场景这个点。这就需要数据分析师、算法科学家结合具体的业务场景和实际所有的数据再进行特殊的算法优化，这样协同过滤在场景当中才能有更高的使用性。</p><p>而使用协同过滤的算法最大的弊病在于，<strong>这个算法就像是一个溺爱你的妈妈，永远会给你想要的东西，它并没有价值观，你会被“惯”得越来越没有节制，把时间全都花费到各种各样的短视频、小文章、和你钟爱的小圈子里，但最终你并没有什么拓展和收获。</strong>它不是一个严肃的爸爸，能告诉你你应该去学什么、哪些价值观是对的，这些其实是协同过滤算法无法做到的，只有通过人的选择和经验才能告诉你，你应该去学什么，而不是拼命满足你自己的某些爱好。</p><p>对于这方面的缺陷，现在有不少科学家尝试通过深度学习的方法模拟价值观、人类的思考来进行修正，这个算法会不断地精进。</p><h2>小结</h2><p>今天给你整体讲了基于集体智慧的协同过滤算法。它最大的价值就是打破了过去的一个我们常见的规则，就是前面讲过的帕雷托定律（也就是二八法则）：通常是20%的大品牌占据了80%的市场，而小品牌正占据剩下的20%。</p><p>协同过滤根据每一个人自己的品牌偏好充分传播和扩展，让长尾品牌“聚沙成塔”。协同过滤让和主流有所不同的一些小众的品牌，慢慢地让喜好的人群去接触到。抖音、头条等把一些很小众但很有特色的视频和新闻带给最需要的人，这打破了我们过去看到的以主流流量为主导的新闻体系，将长尾效应发挥到了极致，改变了原来市场上的规则。这也是为什么抖音和头条在新浪、网易、搜狐等巨头垄断的情况下还可以发展壮大的原因。</p><p>协同过滤算法也给我们很多启示。</p><p>首先，你自己的心态应该更加开放，不要一股脑地追主流，毕竟主流和大众的不一定是最适合自己的，我们的圈子当中应该有个性化的东西。</p><p>同样，我们的价值观也应该更加地开放，不能就沉浸在自己的小圈子里。因为协同过滤给我们的都是我们所喜欢的东西，它的价值观并不一定是最好的，我们应该开放心态去接受和尝试各种各样新的主流的非主流的物品，用我们自己的经历和人生去判断。</p><p>我们更不要沉浸在某些短视频或者网站根据我们兴趣推荐的碎片化文章里。因为它给我们带来的不是推荐，而是去束缚、固化我们的思维，让我们成为这个时代里的“井底之蛙”。毕竟我们要主导自己的人生，而不是让算法去主导我们的人生。</p><p>数据给你一双看透本质的眼睛。协同过滤把集体智慧带入了算法世界，同时，我们也要警惕，因为推荐只是推荐，要持续去扩宽你的思维边界。</p><h2>课后思考</h2><p>协同过滤是一个“人人为我，我为人人”的集体智慧算法，在你的生活当中，你有观察到哪些事情和协同过滤算法比较类似吗？分享出来，我们一起提高。</p>",
                "article_title": "19 | 协同过滤：你看到的短视频都是集体智慧的结晶"
            },
            {
                "title": "20 | 人工智能初探：阿尔法狗是怎样的一只“狗”？",
                "id": 417460,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>前面几节课给我们讲了各种各样的算法，分类、聚类、关联规则、蒙特卡洛、协同过滤、马尔可夫链……这节课是我们数据算法这章的最后一节课了，我们来聊聊到目前为止人工智能领域里的终极算法——深度学习算法。</p><p>现在一提到人工智能算法很多人就默认它是深度学习算法，其实严格意义上来讲，人工智能算法是涵盖了前面我们讲的所有算法的集合。也就是说，前面我们讲的所有算法都是人工智能算法的范畴（是不是一下子觉得高大上了）。人工智能、机器学习、深度学习之间的关系如下图。</p><p><img src=\"https://static001.geekbang.org/resource/image/84/84/84c4714c60180085dd795000b92c7984.png?wh=1023x418\" alt=\"\"></p><h2>人工智能算法历史与深度学习算法</h2><p>说到人工智能，其实人类对这种智慧的追求已经有七百多年的历史了。最早可以追溯到1308年加特罗尼亚的诗人神学家雷蒙卢尔在《最终的综合艺术》（Ars GeneralisUltima）当中提到要用机械的方法从一系列的概念组合当中创造新的知识，这是有确切记载的类似人工智能想法最早的记录。</p><p>在1726年，英国小说家乔纳森斯威夫在《格列佛游记》里面提到一个叫做 Engine的机器，这台机器放在Laputa岛上，可以运作实际而机械的操作方法，改善人的思辨和认知。最无知的人只要适当付点学费，再出一点体力，就可以写出关于哲学诗歌、政治法律数学和神学的书来。</p><!-- [[[read_end]]] --><p>后来在1914年，西班牙工程师莱昂纳多·托里斯克维多展示了世界上第1台可以自动下国际象棋的机器，当然水平那是相当差。而在1921年，捷克作家卡雷尔·恰佩克在他的作品《Rossum’s Univeral Robits》里第一次使用了Robot这个词，机器人开始进入人类的视野。</p><p>你能从这个发展史中看到，<strong>人类一直在寻求一套能够替代人类自身的机制</strong>。</p><p>到1950年，图灵发表了《Computing Machinery and Intelligence》其中提到了仿真游戏，这就是广为人知的图灵测试。图灵测试是指如果有一台机器能够与人类展开对话，且不能被辨别出来是机器的身份，那么就称为这个机器具有智能。</p><p>在1956年，马文·闵斯基、约翰·麦卡锡和另两位资深科学家克劳德·香农以及内森·罗彻斯特组织的达特茅斯会议里正式把人工智能提出来，自此AI（Artificial Intelligence）的名字和任务得以确定。</p><p>在这之后几十年里，人工智能得到了飞速发展。在1970年，日本早稻田大学开发了一个可以控制肢体视觉和绘画系统的机器人WABOT-1（下图左）。</p><p><img src=\"https://static001.geekbang.org/resource/image/2d/f2/2d0fea67e36c2ba1aecc70fe20f5e8f2.png?wh=702x519\" alt=\"\"></p><p>在1979年，在没有人干预的情况下，Stanford大学的Stanford Cart可以在房间内规避障碍物自动行驶，这相当于当时的无人驾驶系统。同一年早稻田大学发明了WABOT-2，开始可以和人做简单沟通，阅读乐谱还可以简单的演奏普通电子琴（上图右）。</p><p>在1997年，IBM研发的深蓝击败了人类象棋冠军卡斯帕罗夫。2011年IBM研发的计算机沃森在Jeopardy！击败了两名前人类冠军。同一年苹果发布了Siri，可以给用户导航播报天气，还可以和用户进行简单的聊天。</p><p>2014年6月8日，图灵测试终于被计算机尤金·古斯特曼通过。在场有超过30%的人认为它是一个13岁男孩。</p><p>2016年谷歌Deep Mind研发出来的阿尔法狗击败了人类围棋冠军李世石。同年年底阿尔法狗以master为名横扫了各大围棋网站，取得60局连胜。与此同时，无人驾驶汽车开始纷纷上路。以美国加州为例，政府开始发放无人驾驶汽车牌照，允许具备一定技术能力的无人驾驶汽车厂商把无人驾驶汽车投入道路使用。700年来，人类在追寻人工智能的道路上从未停歇。</p><p><img src=\"https://static001.geekbang.org/resource/image/a2/fd/a201e0254584e7b5f3f4e631568ff4fd.jpg?wh=2000x1125\" alt=\"\"></p><p>最近10年出现可以打败人类自身的算法，是得益于2006年加拿大多伦多大学教授、机器学习领域泰斗、神经网络之父—— Geoffrey Hinton 和他的学生 Ruslan Salakhutdinov 在顶尖学术刊物《科学》上发表了<a href=\"https://www.science.org/doi/abs/10.1126/science.1127647\">一篇文章</a>，该文章提出了深层网络算法，并在2012年利用CNN算法碾压了过去数年的分类等机器学习算法，取得AlexNet第一名，引起了人工智能的新一轮潮流。</p><h2>CNN和RNN</h2><p>还记得我们在<a href=\"https://time.geekbang.org/column/article/413734\">分类算法</a>里讲过，人类本身就是一个非常复杂的分类器。深度学习算法简单来说就是模拟人的脑神经网络来制造一个和人特别接近的分类器。它可以识别人们说的话、识别具体的视频中的图像内容，最终可以去应对各种各样的情况。</p><p><img src=\"https://static001.geekbang.org/resource/image/5e/49/5ed1dbc4324a8a618435c60df6cd4749.png?wh=424x294\" alt=\"\"></p><p>而现在最流行的两个深度学习的算法就是<strong>RNN</strong>（Recurrent Neural Network）循环神经网络和<strong>CNN</strong>（Convolutional Neural Network）卷积神经网络，它们都是模拟人脑的多个神经元多层次连接方式，通过大量反复的反馈和计算来实现最后效果。</p><p>我们先讲一下循环神经网络RNN。你还记得前面课程里讲过一个特别能有效处理序列数据的算法吗？这种算法叫做<a href=\"https://time.geekbang.org/column/article/415893\">马尔可夫链算法</a>。</p><p>马尔可夫链只能够处理上一个状态到这个状态的选择，在一些事件的影响比较深远的时候它就无能为力了。而RNN算法可以针对更长的序列数据进行模拟和决策，例如我们去识别文章的内容或者去识别股票的价格的走势。</p><p><strong>之所以RNN能够处理这种序列的数据，因为它其中有一个“反馈环”，能够模拟人脑使得前面的输入也能影响到后面的输出，相当于在模拟人脑当中的记忆功能。</strong>RNN的整体模型结构就像下面这个图一样，是带着一个循环的神经网络结构。</p><p><img src=\"https://static001.geekbang.org/resource/image/74/e3/748fa727151693a5f784a5a0ec0148e3.png?wh=653x297\" alt=\"\"></p><p>当然这种算法缺点也很明显，就是RNN就像是一个记性不好的人，只对最近的事情印象深，也就是说越靠后的数据影响比较大，而前期的数据影响很小。这样哪怕前期有一些很重要的教训和知识，这个算法它都记不住。于是很快就出现了一些变种的深度学习算法来弥补这个缺点，例如LSTM和GRU 等等，这里你知道它们是来自RNN算法就可以了。RNN算法被广泛地用于现在的语音识别机器翻译，例如我们使用的Siri，背后其实就是利用了RNN的语音识别和对话系统进行训练。</p><p>和RNN不同的另外一种深度学习算法叫做卷积神经网络CNN（Convolutional Neural Network）。它的特长是能够分层次地提取各种各样的特征，从而能够将大量的数据（比如大量图片和视频）有效抽象成比较小的数据量，而且不影响最后训练的结果。这样既能够保证原来图片和这些视频的特征，也不会在识别的时候占用巨大的计算资源。</p><p><strong>CNN其实模拟的就是人眼睛和头脑识别的原理。</strong>我们看到的世界其实是由各种各样的像素组成，而我们眼睛不会识别这些像素，而是会看到各种各样物体的边界，然后我们大脑会自觉把它们变成一些部件，把这些部件识别成到底是人脸还是物体。最后对人脸或者物体再调取记忆，识别出来这个人或物。</p><p>CNN的抽象逻辑基本原理如下。</p><p>1.卷积层神经网络，主要作用是保留图片的特征；</p><p>2.池化层神经网络，主要作用是把数据降维，可以有效避免过拟合；</p><p>3.全连接层神经网络，根据不同任务输出我们想要的结果。</p><p><img src=\"https://static001.geekbang.org/resource/image/76/0d/76e2383d7baf1333ca2c87aab7f6ac0d.png?wh=768x302\" alt=\"\"></p><p>所以CNN经常会被用来做我们的图片分类、检索视频的识别、目标的分割与识别。咱们现在比较火的抖音上面的美颜、让你变得年轻的组件、让你合成一些明星脸，这些其实都是使用的CNN的算法。我们在美国大片儿里面看到的黑客帝国的对决场面，它背后其实也是使用CNN的算法将目标进行切割出来的。</p><p><img src=\"https://static001.geekbang.org/resource/image/84/yy/849e6af1217b8b5cd09c191deb1ec5yy.jpg?wh=1257x1166\" alt=\"\"></p><h2>深度学习算法使用实例——AlphaGo</h2><p>刚才我们简单介绍了深度学习算法的一些基本算法和概念，但当我们要真的要把深度学习变成人工智能的时候是非常复杂的，这个过程不是单一算法就可以满足。</p><p>我以AlphaGo为例，带你看看它是怎样用深度学习算法，组成了一个人工智能来打败人类的大师。</p><p>首先说一下为什么计算机下起围棋来非常难？因为所有的棋类的玩法基本上计算机都是通过探索每一种可能性，最后看到哪个可能性赢的概率最大。你可以参考一下下面这个表格，你会发现，围棋是最复杂的，需要10的360次方的计算才能够知道我们下一步应该怎么来做，这对于现在所有的计算机计算水平来说，基本都是不太可能，更何况围棋比赛有时间限制。</p><p><img src=\"https://static001.geekbang.org/resource/image/42/f5/42ace893e6bb319397c755a6f53328f5.jpg?wh=1876x793\" alt=\"\"></p><p>那么怎样构造一个围棋的算法系统来打败人类呢？其实任何一个算法在面对真正的实际问题时，我们都要有三步来走。</p><p><strong>第1步，把问题抽象成计算机可以理解的问题。</strong>计算机并不能看懂围棋，他只能看得懂图片，不知道什么是输赢，更不知道怎么来计算每一步的优劣。所以第1步我们要把现实抽象成计算机可以懂的问题。</p><p><strong>第2步，设计和选择整体的算法组合和方案。</strong>这一点就是AlphaGo的过人之处。</p><p><strong>第3步，不断训练和调优。</strong>最终经过不断的打磨，让我们的人工智能算法超过人类。</p><p>我们更具体一点来说。第一步，我们先要让计算机理解围棋。我们看围棋的棋盘是一个19×19的线，一共有361个交叉点，然后每个交叉点上面可以有各种各样的黑子和白子。在围棋里面有气、眼，在某种规则情况下我们可以去提子，在某种情况下有禁着点。</p><p>刚刚说的是我们对于围棋的理解，那对于计算机来说，要怎么来理解这个围棋盘呢？</p><p>答案让计算机把每个点的数据都变成二维码，从棋子的颜色到围棋的气、轮次等等一共有12张二维码来代表此时此刻这个棋盘的状态。</p><p><img src=\"https://static001.geekbang.org/resource/image/92/ac/92bb96a5b83ee045238d01e102bb09ac.png?wh=548x535\" alt=\"\"></p><p>第二步，有了这些数据后，怎么来构造算法训练模型呢？AlphaGo这点非常优秀，它不仅利用了我们前面讲到的CNN算法构造了快速感知“脑”、深度模仿“脑”、 自学成长“脑”以及全局分析“脑”四个大脑，还在这之上使用了蒙特卡洛树来优化整体的下棋策略。</p><p>这里面特别有意思的是，AlphaGo开创了自学成长“脑”，它就像周伯通一样，可以左右手互搏，自己和自己下棋。所以，和人类下一盘棋后，他自己可以下无数次复盘的棋，24小时不停地提高自己。整个AlphaGo算法很有意思，我用比较简单的语言总结在了咱们这节课的附录里，你如果感兴趣可以去看一下附录中的算法。</p><p>第三步，有了这些算法还不行，和所有人工智能算法一样，AlphaGo就像一个小孩子，需要不断训练。于是AlphaGo团队的科学家们选择了网络对战，先后在KGS、Crazy Stone、Zen等网络平台上找高手对战，不停学习和迭代模型。在这几个平台都稳居第一之后，开始线下挑战人类的围棋冠军，这就有了AlphaGo和李世石的成名之战。</p><p><strong>所以当我们遇到类似像围棋这种非常复杂的博弈类问题的时候，我们其实很难用单一的某种算法来解决。我们会做一个算法系统，发挥每一段不同算法的优势，最终得到我们想要的答案。</strong>所以阿尔法狗最终的形态是由4个深度学习算法的大脑，加上一个蒙特卡罗树搜索的算法组成的。</p><h2>深度学习算法最新案例与未来</h2><p>到现在，你能看到深度学习不仅仅可以帮助我们建立一个可以打败人类的围棋算法模型，还可以做很多更前进的事情，比如可以<a href=\"https://arxiv.org/pdf/2011.12692.pdf\">模拟一个人去打王者荣耀</a>。</p><p><img src=\"https://static001.geekbang.org/resource/image/dc/b6/dc2bd73b8b317734674df3d7aa516fb6.png?wh=638x378\" alt=\"\"></p><p>也可以帮我们去实现自动驾驶和识别。</p><p><img src=\"https://static001.geekbang.org/resource/image/fe/97/fe061b2720abd43b5067c08013f51397.png?wh=780x550\" alt=\"\"></p><p>还可以学习人类去<a href=\"https://arxiv.org/pdf/2011.05552.pdf\">画水墨画</a>，而且可以画的以假乱真。</p><p><img src=\"https://static001.geekbang.org/resource/image/8e/e4/8e80442890d40927b393569b7ac9e9e4.png?wh=1412x799\" alt=\"\"></p><p>它还可以帮助人类去<a href=\"https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery\">探索生命的根基</a>，探索我们细胞内的蛋白质的结构变化，最终能够治愈现在所有的疾病，也许将来可以让人们永葆青春。</p><p><img src=\"https://static001.geekbang.org/resource/image/ff/e1/ff10b5f2161f4a9a24a31c826dba36e1.png?wh=1429x788\" alt=\"\"></p><h2>小结</h2><p>到这节课为止，我们的算法章节也就告一段落了。你会发现，在人工智能的算法世界里，计算机正在以它的强大的计算能力不断去模拟和接近人类的判断。甚至在某些有规则的场景里，它可以完全超越人类。</p><p>由于现在我们的计算能力节节攀高，我们这一代人正在把过去七百多年来人类的幻想一步一步变成现实。深度学习算法会在我们所接触的一切领域里面发挥颠覆性的作用，如果你的工作还是基于规则的重复劳动没有丝毫创新，那么你所做的工作很有可能将来就会被某一个人工智能的算法所替代。</p><p>尽管人工智能算法可以在很多有规则的竞争里超过人类，甚至现在很多人对人类十分悲观，觉得总有一天人工智能会像电影里那样奴役人类，但我一直都不这样认为。因为人工智能算法是没有灵魂的，因为它所有的计算其实本质上还是一个分类模拟器。</p><p>人工智能算法是一个有监督的学习算法，无论通过什么样的方式去模拟，它都无法通过一个有规则的算法去适配当今无规则的现实世界，更无法去模拟人们的感情、灵感和创造力。所以我们不要“机械”地活着，要往生活里多注入一些热爱和创新才好。数据给你一双看透本质的眼睛，算法让你看清数据背后现实世界的规律。</p><h2>课后思考</h2><p>你所见的场景里，还有哪些是用人工智能的算法打败人类的？你认为它打败人类的优势是什么？欢迎你在留言区分享，我们共同提高。</p><h2>附录：文科生也可以读懂的AlphaGo算法</h2><p>现在我们把正文里的AlphaGo算法进一步展开。第一步，我们先要让计算机理解围棋。我们看围棋的棋盘是一个19×19的线，一共有361个交叉点，然后每个交叉点上面可以有各种各样的黑子和白子。在围棋里面有气、眼，在某种规则情况下我们可以去提子，在某种情况下有禁着点。</p><p>刚刚说的是我们对于围棋的理解，那对于计算机来说，要怎么来理解这个围棋盘呢？</p><p><img src=\"https://static001.geekbang.org/resource/image/92/ac/92bb96a5b83ee045238d01e102bb09ac.png?wh=548x535\" alt=\"\"></p><p>AlphaGo采用的是一个非常聪明的做法，它把19×19的棋盘里面每个地方都标上了12个数字，每一个数字其实都是有不同的含义。你可以这样理解，计算机把这个棋盘变成了12个19×19的二维码，叠加到一起，变成一个计算机图像去做识别。这样的话，我们就把它变成了计算机可以看懂的棋盘了，你可以参考下表。</p><p><img src=\"https://static001.geekbang.org/resource/image/9a/21/9acb318215c40cd8628b5309fe234121.png?wh=858x519\" alt=\"\"></p><p>第二步，在我们让计算机看懂了这个棋盘之后，我们要设计一个算法系统，让他可以打败人类，这是DeepMind设计AlphaGo最核心的地方，他们用的不是一个算法，他们给AlphaGo设计了4个大脑，也就是实际上有4个不同的算法来支撑这个打败人类的“狗”：</p><ul>\n<li>快速感知“脑”：Rollout Policy ，用于快速的感知围棋的盘面，获取较优的下棋选择，类似于人观察盘面获得的第一反应，准确度不高；</li>\n<li>深度模仿“脑”：SL（Supervised Learning） Policy Network ，通过人类6-9段高手的棋局来进行模仿学习得到的脑区。这个深度模仿“脑”能够根据盘面产生类似人类棋手的走法；</li>\n<li>自学成长“脑”：RL （Reinforcement Learning）Policy Network以深度模仿“脑”为基础，通过不断的与之前的“自己”训练提高下棋的水平；</li>\n<li>全局分析“脑”：Value Network，利用自学成长“脑”学习对整个盘面的赢面判断，实现从全局分析整个棋局。</li>\n</ul><p>他们背后都是使用的 CNN网络来进行训练的，但是使用的方法各不相同。快速感知脑（Rollout Policy） 网络比较简单，要求落子速度更快，但准确率更低。</p><p>深度模仿脑（SL Policy Network）是有监督的神经网络，就像分类算法一样，以人类棋手的对弈记录进行训练，越和人类接近，证明这个模型越好。这个网络训练出来就是集人类棋谱和棋局的集大成者。</p><p>但是如果只是如此，AlphaGo还是无法超越人类的。于是就有第3个大脑：自学成长脑（RL Policy Network）。这个大脑就像周伯通的左右手互搏一样，它是模仿一个新的对手，自己和自己开始对弈，如果自己把自己赢了，那么就以赢的这一局的结果来训练自己而不是人类的棋谱训练自己，这样不断更新的自己的权重。</p><p>这样AlphaGo自己左右手的这两个算法都越训练越好，所以说人类无法打败阿尔法狗，因为它一天24小时不停地在几千万次地训练自己，而人的大脑没有那么多的时间和容量来训练这件事情。</p><p>最后一个是全局分析脑（Value Network），这其实就是训练每一个旗面的胜率到底是怎样，通过前面自我博弈的这些棋局的数据来训练一个棋面胜率。那它为什么不用人类棋手对局来做这种价值训练呢？因为人类的对局数据很少，也就意味着有效样本很少，很容易出现前面咱们讲过的“过拟合”。所以它通过周伯通自我博弈的各种招式去看，到底我们这场比赛现在这个阶段的价值是好还是不好。</p><p><img src=\"https://static001.geekbang.org/resource/image/e2/4c/e2ab78ed5ddbf81d3bdb3084058ba94c.png?wh=633x315\" alt=\"\"></p><p>的确，如果给无限长的时间的话，AlphaGo这个四脑狗一定可以打败人类，但是你知道真正在下围棋的时候，每个选手旁边都有一个闹钟要记录他自己所用的时间，时长最长为每方6小时。所有比赛都会保留读秒时间，超时就会判负了。</p><p>所以这是在一个有限时间里面，我们要面对10^360次方的可能性计算。</p><p>这怎么办呢？这里就提到了前面我们所学的一个知识，在无限多的可能性里面找到近似于最优解的算法，它就是蒙特卡罗算法。我们这里使用这种算法解决我们下棋问题的时候，我们使用的就是蒙特卡罗搜索树。</p><p>你可以回顾一下蒙特卡罗算法的特点，它就是在一个大苹果布袋里面挑苹果，每次把这个比较好的苹果留下来，不好的苹果扔掉。在时间结束的时候，每次的结果不一定是全局里面最优的这个解，但一定是跟你当前消耗时间类似的情况下，相对比较好的结果。</p><p>整体来讲，这个AlphaGo的蒙特卡罗树会通过4步来确定一个比较好的结果：</p><ul>\n<li>通过选择模拟下一步要走的子；</li>\n<li>通过扩展模拟走子策略；</li>\n<li>评估来看走子效果；</li>\n<li>回溯来把结果向上传递。</li>\n</ul><p>这样就可以在有限时间内让四个大脑找到相对最优解。同时这里面的一个关键点在于，深度学习消耗的算力和时间是和它面对的问题复杂度成指数增长的。所以如何拆解问题、如何有效使用蒙特卡洛算法，往往是一个人工智能系统的关键。</p><p><img src=\"https://static001.geekbang.org/resource/image/15/47/150f5b18dcbdb58ea369c67155bd9347.png?wh=1126x360\" alt=\"\"></p><p>第三步，先学习人类现有的棋谱和所有人类对战的历史，然后在网上和围棋爱好者进行对战，然后开始线下和围棋高手进行对战：</p><p>1.初始训练：KGS；</p><p>2.模拟对手：Pachi；</p><p>3.模拟对手：Crazy Stone；</p><p>4.模拟对手：Zen；</p><p>5.模拟对手：Fuego；</p><p>6.人类对手：Fanhui（欧洲冠军）；</p><p>7.人类对手：李世石；</p><p>8.人类对手：柯洁。</p><p>注意，这里不仅学习对象是各种各样的对手，因为AlphaGo还有左右手互搏算法的存在，其实它是不停在24小时对战和复盘，提高自己的水平。最终AlphaGo打败了人类的围棋冠军。</p><p>总结下AlphaGo这个狗的全貌，在面对围棋这种非常复杂的博弈类问题的时候，我们其实很难用单一的某一种算法来解决它。我们会做一个算法系统，发挥每一段不同的算法的优势，最终得到我们想要的答案。</p><p><img src=\"https://static001.geekbang.org/resource/image/b5/5a/b50238bcb5369eb3618c955544b38e5a.png?wh=997x599\" alt=\"\"></p>",
                "article_title": "20 | 人工智能初探：阿尔法狗是怎样的一只“狗”？"
            }
        ]
    },
    {
        "chapterTitle": "如何用数据说话",
        "children": [
            {
                "title": "21 |  确定问题：与利益无关的问题都不值得数据分析和挖掘",
                "id": 418334,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>前面给你讲了数据分析的基础概念和算法，这有些像西医的检测和器械部分，紧接着来到“如何用数据说话”这章，我将试图用比较简单的逻辑给你讲清楚怎样对一个事物进行系统的数据分析，也就是我们之前说的中医部分。</p><p>其实学完数据分析基础和数据算法基础后，你很容易觉得自己有很多的“武器”了。但这个时候就会出现我们在开篇词里提到的一个问题：我们已经掌握了最先进的人工智能冲锋枪，但是在企业数据这个大森林里面，我们究竟应该向哪里开枪？具体怎么去狩猎？</p><p>这是本章要重点关注的部分。本节课，我们就先讲讲到底应该选择哪些问题进行数据分析。</p><h2>和利益无关的问题都不值得做数据分析</h2><p>观点先行。我的观点很明确：<strong>和利益无关的问题都不值得做数据分析。</strong>我们经常能看到很多数据分析报告，除了博人眼球之外都是一些无关痛痒的结果。这样的报告看了也就图一乐，并不能够给企业和个人带来实际的业务价值。</p><p>那么哪些方向可以给企业和个人带来业务价值呢？其实不外乎有两个，一个是带来更多的收入，一个是帮着节约成本。那么对一个企业来讲，我们要用户、公司两手抓。这样一组合就出现了下图里的四个象限，你可以在这个图里看到我们最常见的一些企业数据分析方向。</p><!-- [[[read_end]]] --><p>你可以这样去理解，<strong>但凡不在这些象限里面的数据分析问题，其实都可以忽略不计，因为它不是在公司的主干线上要解决的问题。</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/fb/74/fbbca4cd0a1594325a7069a5384b2574.png?wh=1875x1014\" alt=\"\"></p><p>你从图中会发现，如果要去做业绩增长，在客户层面我们就要会做用户洞察、用户推荐、用户运营；而在公司层面我们就要基于数据分析来做销售策略、渠道策略、产品策略、复购和增购策略，以及投资策略等等相关的分析。</p><p>从成本控制来讲，在客户层面，我们可以降低获客的成本、挽留客户的流失、识别客户的欺诈；在公司层面我们可以提高企业的效率，通过风险分析降低整体的风险以及做财务分析。当然这些话题都有子话题，我把子话题也放在了图中，你要是感兴趣可以再琢磨一下。</p><p>对于一个数据极客来说（数据极客是我们数据分析行业的一种个人发展方向，如果你想进一步了解可以去看看这节课的附录），针对一个具体问题，正确的步骤是确定问题、探索数据、总结讨论，实践、迭代你的理论。这个过程是把问题逐渐收敛聚焦到关键问题上，而且并不是单向的，后面在执行步骤过程中，可能还会反复到上一个步骤里进行数据优化或者数据补充。</p><p><img src=\"https://static001.geekbang.org/resource/image/06/e3/062e7916ed324a56fb50b38c352905e3.jpg?wh=1142x640\" alt=\"\"></p><p>不知道你有没有经常遇到这样一个场景，在工作和生活当中往往遇到要分析的问题只是领导或家人的一句话：“现在XXX情况不太好，你来给我们分析总结下问题在哪里。”这种问法其实只有一个大致方向，而没有具体任务。这时候你往往会无从下手，怎么快速去梳理出要分析的具体问题呢？我给你推荐一个十分简单的两步法。</p><p><strong>第一步，把理想与现状对比。</strong>这个做法其实有点咨询的味道在里面，因为一开始在找到问题的关键前，你需要先要知道你的需求方也就是老板（或者家人），他的心里到底是怎么想的？他的计划是什么？你可以列出如下这么一个表格，一个是现状，一个是理想状况。</p><p><img src=\"https://static001.geekbang.org/resource/image/f3/29/f31ed57819dd3d834a65a1c537735229.jpg?wh=896x452\" alt=\"\"></p><p>这里要注意对于提出来的问题，我们不能只去关注问题本身，还要留意问题之外的问题，你可以从以下这几个角度来扩展下思维。</p><ul>\n<li>当前是理想值的多少？</li>\n<li>如果理想值提高10%，你可以从哪些方面下手？</li>\n<li>如果理想值提高100倍，你可以从哪些方面下手？</li>\n</ul><p>其实思考到一些新的问题之后，你就可以重新定义这些问题了。然后你可以进行更深入一些的访谈，去完善你的现状和未来的列表，比如我把上面的表格扩展之后，就变成了下面这样。</p><p><img src=\"https://static001.geekbang.org/resource/image/f7/06/f71101fd26515007ec623a69ab418e06.jpg?wh=924x406\" alt=\"\"></p><p>完善之后，整体感觉还是太高层次了，看到了这些大的方向，我们现在怎么来落地到具体的问题呢？这个时候我们就要<strong>进行第二步了，那就是6W2H法。</strong></p><p>这个方法主要可以帮助我们拓展思考的范围，去逻辑性地梳理各种基本问题。</p><ul>\n<li><strong>Who</strong>：指的是涉及这件事情的人、组织职务等等，一般会涉及到决策者、行动者、客户等；</li>\n<li><strong>What</strong>：列出跟我们讨论相关的这个方向整体的事实或者架构，这些问题和哪些因素有关？他们的条件是什么？重点是什么？与什么有关系？</li>\n<li><strong>Whom</strong>：紧接着列出这个目标是针对谁来做的，工作对象是谁？关键干系人有哪些？谁会受益？</li>\n<li><strong>When</strong>: 明确实施的时间周期，预期何时能完成？需要几天才合理？</li>\n<li><strong>Where</strong>：确认渠道、地点位置、周边的环境，资源在什么地方；</li>\n<li><strong>Why</strong>：列出可能的原因，一些前提条件或者意图；</li>\n<li><strong>How</strong>：思考一下现在的问题，未来有可能用哪些手段、方法提高和改进这个问题；</li>\n<li><strong>How Much</strong>：确认最后要花的时间、人力资源、费用等。</li>\n</ul><h2>具体场景</h2><p>下面我们进入一个具体的假设场景当中，来看看一个简单的数据分析过程应该怎么来做。</p><p>假设我们现在供职于一个做销售工具的SaaS公司，老板让我们针对现在运营投入的情况做一份数据分析，我们应该怎么下手呢？</p><p>我相信大多数人遇到这样的问题时，第一反应都会想到先把过去运营的数据做一下统计，然后用柱状图和折线图对比一下每年的增长，接下来再根据不同的产品和用户群进行分类做相关分析。</p><p>但这样做其实是错误的，你做了这些分析之后，经常就会陷入到一个困境里，那就是接下来应该怎么做呢？就像我们面临生活中的买房问题一样：你可以拿到各种数据，却不知道该如何决策。</p><p><strong>之所以我们会陷入这种困境中，是因为我们只看到了一些代表结果的数据，没有分析具体问题。</strong>销售额、利润率这些数据其实很容易收集，也容易得到我们的关注，但是紧盯着这些数据结果进行分析，你的效率会非常低下，基本没办法进行结果改进或解决问题。</p><p>所以，数据驱动不是只是利用“数据”做驱动，而是要用数据思维来驱动。我们要先确定分析的问题，再采集数据。我们利用前面的As Is-To Be方法来进行迭代。通过和领导的访谈，你发现在领导心目中，现在的问题是运营获客效率低，开销占成本一半，他期待的是提高运营效率，成本降低到50%。</p><p>这个问题只是大方向，我们可以想象，降低到50%其实并不是最终目标，我们跳出这个框架，来想一下理想状态下，这个目标应该是什么。这个时候其实你可以和老板一起头脑风暴一下，沟通过后未来的目标更清楚了，理想（To Be）为：“形成自动化获客体系、提高运营效率、长期获客成本逐年降低”。这些目标虽然看上去宏大，但是即使短期内无法达到，也不会整体方向上错误，让我们陷入短视的陷阱里。</p><p>有了这些目标，我们再进行第二步，用6W2H法进行拆解。整体上运营客户效率低，其实涉及的部门很多，从老板的角度来看这个问题，就会有下面这个图。</p><p><img src=\"https://static001.geekbang.org/resource/image/48/7a/4833de271a2ca9ee604679b625496d7a.jpg?wh=782x504\" alt=\"\"></p><p>然后我们去每一个相关部门带着领导的As-IS和To-Be的设想以及6W2H来访谈，细化问题，例如我们现在去市场部门进行访谈，进一步拆分问题如下。</p><ul>\n<li>Who：市场部；</li>\n<li>Whom：新客户；</li>\n<li>When：从公司成立以来；</li>\n<li>What：购买大量关键字费用很高；</li>\n<li>How Much：费用在每月100万元；</li>\n<li>Where：搜索引擎和抖音；</li>\n<li>Why：关键字转化ROI没法获得，没有数据支撑；</li>\n<li>How：希望前后台数据拉通，评估数据。</li>\n</ul><p>类似的，我们还可以去走访运营部、电销部、产品部，还可以访谈部分客户，可能有些数据情况还不清楚，不过没有关系，我们可以在第二步采集数据之后再设计具体目标，现在我们先把具体方向列出来。</p><p>这时候如果还用As-Is To-Be的图表就会不够清晰了，所以这个时候我们可以用一个叫<a href=\"https://baike.baidu.com/item/%E9%B1%BC%E9%AA%A8%E5%9B%BE/6514245?fr=aladdin\">鱼骨图</a>的新工具来梳理一下我们整体的思路。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/13/63c82e51ea5691c128570664db03cb13.jpg?wh=1142x640\" alt=\"\"></p><p>有了这个鱼骨图，基本上我们把领导的这一句让你找“运营问题”的话，已经拆解成若干部门的若干问题了。注意，就像开始的流程图一样，所有的这些工作流程并不单向的，在我们根据这些问题去采集数据的时候，很可能会发现新的问题，我们依然可以把新问题补充在这个鱼骨图里。</p><p>这样一来，我们把上面的大问题进行拆解，将这些问题再细分，然后用下节课“采集数据”的方式逐步找到相关的数据再进行分析，最后就可以解决问题了。</p><p>如果今天的课程你只能记住一句话，我希望你记住，<strong>数据分析重点在要分析的问题，而不是在数据，不要一上来就先用手头数据进行分析，要先针对问题利用As-Is To Be和6W2H方法进行细化。</strong></p><h2>小结</h2><p>讲到这里，今天的内容也就快结束了。我们回顾一下今天的内容，在开始一个数据分析问题前，我们会先确定和利益相关的数据分析问题范围。这里你要注意，我们要提高一个维度去留意问题之外的问题。在高层次问题向下细分的时候，我们可以通过As-Is To-Be以及6W2H的方法去细化问题，这个过程中我们还用到了一个叫鱼骨图的工具。</p><p><img src=\"https://static001.geekbang.org/resource/image/66/a1/6678c9e8b48185e91caaf0eda7bdefa1.jpg?wh=1142x640\" alt=\"\"></p><p>我们把所有的问题先罗列出来后，其实在数据探索当中，还可以在这个鱼骨图上增加新的问题，或者发现有些问题不是重要问题后进行删减。这个思考问题和数据探查的过程，本身也是数据分析的意义所在。</p><p>这个过程就像在画一个数据地图，我们先把大方向确定，然后一步一步把城区画出来，然后画街区、每个小区，紧接着我们用道路把它们穿起来进行试运行，去调整道路和街区的设计，最终得到最合适这个业务的地图与道路。如果一开始就陷入细节，你很容易走弯路，甚至无法到达目的地。</p><p>其实要在企业的森林里找到我们的目标，需要有更多的经验和知识。这一章的内容更多地是给你讲数据分析的思维方式（也就是中医的部分），希望这种思维方式能够成为你工作生活的一部分，它会随着你自己对行业了解的加深、经验的积累，越来越值钱。</p><p>数据给你一双看透本质的眼睛，希望我们最后都能成为一个中西医结合的大咖。</p><h2>课后思考</h2><p>你自己生活和工作当中有哪些As Is和ToBe？ 升维思考后，你能画出鱼骨图吗？期待你的分享，我们在这一章接下来的课程里，会逐步教会你用数据思维的方法解决问题。</p><h2>附录：数据行业个人发展方向</h2><p>我把数据分析行业个人发展大概方向给你介绍一下，你可以看下将来自己会走向哪里。数据分析领域非常宽阔，整体来讲未来顶尖的专家可以分成三类人。</p><p>第一类人是算法科学家。这是一群算法开发和自动化的专家，他们擅长的是利用手中的算法或者自创的算法，发现现实当中的规律并把它们程序化，最终形成自动化的机制，从而为企业、个人源源不断提供价值。典型代表就是投资银行里的自动化交易设计师（《征服市场的人》当中的西蒙斯）或者是互联网公司当中的算法科学家（像李飞飞这样的教授）。</p><p>第二类人是增长黑客。他们熟练掌握数据分析基础知识，同时可以把业务的想法以及创意通过数据的方法进行试验、测试迭代，最终帮助公司提升业务。他们结合了创意营销、数据分析、产品迭代多项技能，最终用数据和运营手段帮助公司实现收入和用户数的快速增长。</p><p>第三类人是数据分析极客。他们熟练掌握各类数据工具，有非常强的数据思维。他们可以根据业务的各种情况来进行数据实验和数据分析，有些人走向数据分析师的岗位，有些人走向运营和产品的岗位。他们可以通过数据洞察业务的走向，结合数据分析的基本知识和算法，快速对业务进行调整，最终达到可以洞见业务和世界趋势的境界（投行或者企业当中的数据分析师）。</p><p>这三类人就像下面这个图一样，技能结合到一起的就是一个企业的CDO，也就是首席数据官，哪一条路径都可以让你走到最顶点的位置，取决于你坚持学习的程度和认知的广度。</p><p><img src=\"https://static001.geekbang.org/resource/image/d2/e5/d203783f424e44def6ced2e1da3a51e5.jpg?wh=744x446\" alt=\"\"></p>",
                "article_title": "21 |  确定问题：与利益无关的问题都不值得数据分析和挖掘"
            },
            {
                "title": "22 | 采集数据：用好一手数据和二手数据",
                "id": 419188,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>在上面一节课里，我们讲了如何确定我们要分析的数据问题，为整个数据分析的过程指明了方向。整个数据分析过程就像规划设计一个大的数据地图（就像玩Simcity），先有了大的城市框架，再去规划每一个街区。</p><p>在规划这一步，测绘、逐步细化迭代非常重要。所以今天我就来给你讲讲测绘——也就是我们的数据采集。</p><p>我们进行问题决策的时候，如果没有数据采集，就会陷入经验主义，通过拍脑袋来进行决策，这不是数据分析思维的主张的方向。</p><p>现在我们有了方向和问题列表，那么数据会从哪里来呢？</p><p>我们在收集数据的时候，数据的来源会分为两大类：一手数据和二手数据。根据这些数据，我们会进行数据探索并产生一些衍生数据，最终为我们下一节课的数据分析思路组织与撰写提供弹药。</p><h2>采集数据类型</h2><p><strong>我们先来看采集数据中的第一类数据来源：一手数据。</strong>一手数据主要来自企业内部的大数据平台、数据仓库以及相关系统，还有部分数据来自用户访谈和调研问卷以及内部沉淀的历史文档。</p><p>一手数据的特点就是数据可控，也正是因为数据都掌握在自己企业手中，理论上只要付出成本，我们可以拿到所有的想要的数据。也就是说，我们可以通过数据采集、建立相关流程业务系统来进行录入，或者开展大规模的用户访谈以及调研问卷去采集到我们想要的数据。这是一个企业数字资产积累的过程，现在很多企业都已经在关键业务流程上实现了数字化升级和转型。不过在数字化转型升级过程当中，有三点我觉得尤其需要注意。</p><!-- [[[read_end]]] --><p><strong>第一，数字化升级转型应该先从核心或者创新业务流程开始。</strong></p><p>这也就是前面一节课说的和收入、支出直接相关的系统优先升级。例如现在传统企业做互联网升级，所有相关的互联网用户画像、用户行为采集、广告投放以及相关的财务数据系统就要优先建立。同样，智能制造企业会优先建立物联网数据采集、物联网大数据平台、供应链决策支撑系统等。现在数据技术手段已经非常发达，下面我给你总结了当前最新的企业大数据分析架构，你可以参考一下。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/f4/633b9effcd1a6c0a7bb51346dba087f4.png?wh=1305x619\" alt=\"\"></p><p><strong>第二，数据的采集和计算一定要从最明细的数据开始。</strong></p><p>不要使用企业内部的二手数据，也就是不要拿加工后的数据再进行加工分析。因为但凡这样做了，数据质量和数据治理这部分的问题往往会花费我们特别多的时间。</p><p>其实获得一份精美数据的效率是一个企业能否成为典型数据驱动型企业的明显标志，你可以看到像阿里、腾讯这种典型的一线互联网大厂，都可以提供给数据分析和运营部门相关权限的所有明细数据。数据分析师都是可以在分钟级甚至秒级来给出相关数据统计分析答案，而不是通过层层数据二次加工获得。数据分析师可以直接自己定义计算口径，针对明细数据进行数据探索，这是数据分析的基础要求。</p><p><strong>第三，在做数据分析的时候，数据质量的要求要大于数据量的要求。</strong>不要迷信于大数据的量大，而是要关注高质量的小型数据，往往几个Pb的大数据会比小数据更难获得知识（你可以去复习一下<a href=\"https://time.geekbang.org/column/article/408181\">数据抽样</a>这节课的内容）。</p><p><strong>我们接着来看采集数据中的第二类数据来源：二手数据。</strong>二手数据主要是来自行业内的数据，它们不是自己企业内部产生的。</p><p>一般二手数据用于让我们看到行业内的竞争对手或者整体行业的趋势。例如，如果你是互联网行业的，你可以看到互联网里面用户活跃到底怎样，留存度如何？或者某些广告投放的转化率以及均值如何。这些数据可以帮助我们分析自己公司在行业里整体的水平，从而提高我们自己的目标值。</p><p>一般二手数据来自政府部门的报告、行业协会、企业财报、投资机构还有企业官网和一些新闻稿，同时也会来自圈内的沟通或者行业内专业咨询公司出的专业分析报告。我把自己常用的一些网站和信息来源渠道列在了附录里，你如果想找一些二手的渠道的数据，可以到附录去进行搜索。</p><p>你要特别注意鉴别二手数据当中的可信度，因为很多企业为了扩大市场影响力，经常会使用“数据技巧”来修饰数据，这样可能会出现因果倒置或者前面讲到的各种数据问题。比如我们从新闻稿里看到某企业收入复购率提升了100%，如果我们不看细节会觉得这个提升很高，但是如果仔细看文章和企业年报的数据，你会发现它的复购增长率是从第一年的10%上涨至第二年的20%，尽管确实上涨了100%，但整体上对于企业来讲，这个复购率还是非常低的。</p><p>这也是为什么我们在企业内部使用数据的时候，我要求不要使用二次加工的数据的原因。为了鉴别这些数据的真伪，你可能需要熟练掌握数据分析基础这一章里所有的数据工具和方法，才能不被数据所欺骗。如果我们根据数据来源的可信度进行排序，会得到下面这样一个图。</p><p><img src=\"https://static001.geekbang.org/resource/image/88/d2/881b80566272aa0822b6434997e842d2.jpg?wh=2000x1079\" alt=\"\"></p><h2>数据探索</h2><p>经过上面这一步，现在你获得了大量的原始数据，但这对于你解决你最终的问题依旧不够，我们要进行数据探索，将前面采集到的多种数据进行横向纵向的深度挖掘，才能发现其中的一些原因和知识。在这里我给你介绍常用的三种拓展方法：趋势分析法、快照扩展法和衍生指标法。</p><p><strong>趋势分析法</strong></p><p>趋势延伸法就是我们找到某一个类型的数据之后，捕捉这个数据一个时间段以内的变化。通过这些数据变化，我们去知道曾经有哪些变化、对结果数据会有哪些影响，这样可以找到其中关键的问题和原因。</p><p>这个时候我们经常会用前面介绍的折线图、散点图和回归来分析趋势并确定离群点。我们要尤为关注离群点，因为这些离群点发生的原因往往就是解决问题的答案。</p><p>看整个趋势的时候，我们要注意到那些呈指数分布增长的数据，他们往往是对我们非常有意义的。而对于比较平直的曲线来说，我们需要关注整体数据的波动情况，也就是看离散系数是不是很大，因为这代表着这个业务的稳定性。</p><p>如果上面说的这些你有些记不清了，建议你带着现在的问题去复习一下我们第一章数据分析基础里的内容。</p><p><strong>快照扩展法</strong></p><p>快照扩展法是截取某个时点的情况，然后通过下钻的方式来扩展这个指标的分布情况。我们会看在这个时点里面我们各部分对于整体的占比和影响程度。</p><p>这里我们会经常用到曾经讲过的直方图、散点图、聚类分类和数据分布当中的方法，来看各个细分渠道、细分部门分布情况，从而找到我们重点要分析的部门、渠道或一些重点的原因。这样做其实是为了明确我们分析范围的目的，把所有的数据信息全都放到一起就像一笔糊涂账，一个有效的数据信息也无法拿到。</p><p><strong>衍生指标法</strong></p><p>如果用上面两种分析方法还没有找到其中的原因，我们可以进一步进行数据的加工，制造出一些衍生指标来拨开迷雾，这也就是衍生指标法。</p><p>优秀的衍生指标就像几何当中的辅助线一样，会帮助我们看到更有意义的数据。例如当我们看到售卖产品的数量和我们的广告投入几乎无关，那么我们应该意识到，只是看收入和投入的这个表面关系，很难做出恰当的评价。</p><p>那么要想衡量这样的数据，我们就会建立新的指数——用户忠诚度指数。我们通过这个指数去衡量我们获客之后，这个客户会不会再次购买我们的产品。关于建立衍生指标的方法，你可以去复习一下<a href=\"https://time.geekbang.org/column/article/408750\">第10节课</a>，我们要学会像建立智商指数和上证指数一样，自己建立新的衍生指标去定义和分析数据里面的相关内容。</p><p>在进行数据探索的时候，有三个点你需要重点注意一下。</p><ul>\n<li>关注数据质量的把控。例如我们在进行新冠统计的时候，往往你会发现统计死亡率要比统计得病率更加准确。</li>\n<li>注意避免辛普森悖论。这就要求我们在看快照扩展法状态值数据的时候，尽量细分领域和时间。</li>\n<li>注意避免因果倒置。例如你在整体沿着大思路进行分析的时候，看到了看广告用户的转化率和没看到广告的用户的转化率，你要能够客观去做衡量。</li>\n</ul><h2>具体示例</h2><p><img src=\"https://static001.geekbang.org/resource/image/8f/f7/8fac1b697517f82f4be488a92517b0f7.png?wh=1143x496\" alt=\"\"></p><p>在上节课里，我们其实已经梳理了所在企业可能的一些数据分析方向和问题。这里我们选择其中一个方向进行深度的数据挖掘和探索来看一下。</p><p>下面我就以获客购买流程为例，首先根据前面的数据访谈和内部沟通的情况，我们先把流程梳理一下。因为是举例，我们简化变成下图这样一个流程。你能从图中看到我们现在主要是通过购买百度关键字、直播活动和抖音的投放进行获客，然后通过电话销售的方式来进行促销，最终达成整体的购买。</p><p><img src=\"https://static001.geekbang.org/resource/image/b5/97/b5c8edac1e140722ee25411fb088cb97.png?wh=804x431\" alt=\"\"></p><p>这里边我们涉及以下几类数据。</p><ul>\n<li>百度的投放数据明细；</li>\n<li>渠道的投放数据明细；</li>\n<li>直播的活动数据明细；</li>\n<li>电话销售的成单数据明细。</li>\n</ul><p>从我们数据分析来看，这个流程其实还不完整，因为我们缺少了一些中间过程的数据，例如用户的注册数据、用户的访问网站的数据、用户打开demo的数据……这些数据就是我们要的采集点，我们可以把它细化为如下的数据进行分析。</p><ul>\n<li>用户访问明细；</li>\n<li>用户销售数据明细。</li>\n</ul><p>这样我们就可以统计用户访问量和销售量，然后我们可以使用快照扩展法，继续进行细分。比如现在我们拿到某一天的相关数据，发现用户访问量还是过于粗犷了。我们应该分成落地页访问、注册页访问、demo访问三个不同的指标。</p><p><img src=\"https://static001.geekbang.org/resource/image/bc/c2/bc7fa108cef4c36830cbd3b9809374c2.png?wh=1192x498\" alt=\"\"></p><p>然后每一个指标我都可以把它分到不同渠道的访问用户量和成单量，也可以针对某一个渠道再细分。比如我们可以把百度投放的数据，细分到关键字的成单数据以及落地访问量。这样我们的指标又扩展一步，变成如下的情况。</p><p>用户访问量：</p><ul>\n<li>落地页访问（不同渠道，不同百度关键字）；</li>\n<li>首页访问（不同渠道，不同百度关键字）；</li>\n<li>demo访问（不同渠道，不同百度关键字）。</li>\n</ul><p>用户销售数据（不同客服，不同渠道，不同百度关键字）。</p><p>光有这些数据其实并没有解决老板提到的大方向投入成本问题，还需要过程数据。因此我们要衍生出来一些指标去和我们的最终目标进行挂钩，我们可以根据不同活动和渠道购买的量给出一个成本情况，再根据不同渠道访问量以及销售数据给出一个平均每次访问的成本价格。</p><p>我们这里面还有很多可以扩展的指标，比如销售的转化率、整个访问的留存情况、新客户的转化和老客户转化情况……最后根据我们的下节课数据讲故事的情况，可能还需要再进行调整。</p><ul>\n<li>百度渠道成本（关键字）；</li>\n<li>抖音广告成本；</li>\n<li>直播活动成本；</li>\n<li>销售转化率；</li>\n<li>客户注册转化率。</li>\n</ul><p>有了这些快照扩展之后，我们拿到了更详细的一些数据指标，我们就可以使用趋势延伸法来看到这些指标在不同情况下的一些波动，比如下面的这个图。</p><p><img src=\"https://static001.geekbang.org/resource/image/cf/94/cf992948cb0302d3193ce5821a6e7094.png?wh=823x415\" alt=\"\"></p><p>除了这些一手数据，我们还要有一些外部的二手数据。我们可以通过圈内人士知道同行业SaaS的获客的成本在3~5万、一次活动的注册转化率应该高于10%、成单转化率应该多于2%……这些其实都可以作为衡量的指标。</p><p>有了这些数据，我们其实还没有完成整体的数据分析思路，因为这个思路需要我们梳理分析后，再提供新的数据反复迭代。小小预告一下，这就是我们下节课要来重点探讨的内容。</p><h2>小结</h2><p>小结一下，今天主要给你讲了怎么把这些数据采集起来。我们主要先从企业内部的一手数据进行相关的数据采集，这里要注意，一手数据要用明细数据直接进行数据分析，不要在企业内部还使用二手数据来混淆自己的视听。</p><p>只有企业自身的数据还不够，我们很多时候还要参考业内的二手数据来做一个衡量准绳，通过整体行业趋势给我们更多的指引。</p><p>在做数据探索的时候光有裸数据还不够，我们还要进行一些数据探索和数据延展。今天我给你介绍了三个比较常用的方法：趋势分析法、快照扩展法和衍生指标法。这几个方法可以帮助我们再从裸数据里面看到更多的延展相关数据，为我们下一步编写数据故事打好基础。</p><p>最后我举了一个具体的例子，延续前面课程的内容来给你简单剖析了一下，我们如何做深度的相关分析，这里是想带你体验一下怎么去扩展和筛选相关的重要指标。</p><p>其实我们在工作和生活当中的决策也离不开这个采集数据的过程。例如我们要决策投资、准备跳槽选工作，那我们就既要了解自己的一手数据（资金情况、学历情况、收入情况），也要拿到二手数据（市场情况、国家政策、老板和同事反馈、职位在市场中的价位等）。我们也可以做一些横向和纵向衍生指标（投资回报/风险比、跳槽收益率=跳槽成功概率*跳槽收益）。我们自己做决策不要只凭经验拍脑袋，收集更多的好数据才有利于我们更有效决策。</p><p>数据给你一双看透本质的眼睛，希望你可以在这个充满数据的世界里，采集到对你决策有帮助的数据，更加客观地进行决策。</p><h2>课后思考</h2><p>你经常采集数据的方法还有哪些？哪些外部数据资料是你经常使用的？分享出来，我们一起提高。</p><h2>附录：常用的一些网站和信息来源渠道</h2><p><strong>宏观数据</strong></p><p>经合组织开放的数据网：<a href=\"https://stats.oecd.org/\">https://stats.oecd.org/</a></p><p>世界银行公开数据：<a href=\"https://data.worldbank.org.cn/\">https://data.worldbank.org.cn/</a></p><p>中国统计年鉴：<a href=\"http://www.stats.gov.cn/tjsj/ndsj/\">http://www.stats.gov.cn/tjsj/ndsj/</a></p><p>统计局网站：<a href=\"http://www.stats.gov.cn/\">http://www.stats.gov.cn/</a></p><p>新华社-全球经济数据:<a href=\"http://dc.xinhua08.com/\">http://dc.xinhua08.com/</a></p><p>中国互联网络信息中心：<a href=\"https://www.cnnic.net.cn/hlwfzyj/hlwxzbg/\">https://www.cnnic.net.cn/hlwfzyj/hlwxzbg/</a></p><p>中财网：<a href=\"http://data.cfi.cn/\">http://data.cfi.cn/</a></p><p><strong>互联网数据</strong></p><p>Alexa： <a href=\"https://alexa.chinaz.com/\">https://alexa.chinaz.com/</a></p><p>百度指数： <a href=\"https://index.baidu.com/\">https://index.baidu.com/</a></p><p>微指数： <a href=\"https://data.weibo.com/index/\">https://data.weibo.com/index/</a></p><p>淘宝指数： <a href=\"https://shu.taobao.com/\">https://shu.taobao.com/</a></p><p>阿里价格指数：<a href=\"http://topic.aliresearch.com/\">http://topic.aliresearch.com/</a></p><p>Similarweb：<a href=\"https://www.similarweb.com/\">https://www.similarweb.com/</a></p><p>netmarketshare：<a href=\"https://netmarketshare.com/\">https://netmarketshare.com/</a></p><p>Statcounter：<a href=\"https://gs.statcounter.com/\">https://gs.statcounter.com/</a></p><p><strong>行业数据库</strong></p><p>数据汇： <a href=\"http://www.shujuhui.com/database/\">http://www.shujuhui.com/database/</a></p><p>数据圈： <a href=\"http://www.shujuquan.com.cn/\">http://www.shujuquan.com.cn/</a></p><p>镝数聚：<a href=\"https://www.dydata.io/\">https://www.dydata.io/</a></p><p>联合国图书馆：<a href=\"http://www.oecd-ilibrary.org/\">http://www.oecd-ilibrary.org/</a></p><p>票房数据：<a href=\"https://www.boxofficemojo.com/charts/\">https://www.boxofficemojo.com/charts/</a></p><p>中国票房数据：<a href=\"http://cbooo.cn/\">http://cbooo.cn/</a></p><p>行业分析机构：Gartner、Forrester、Bloomberg、易观、艾瑞、新榜</p><p><strong>企业数据</strong></p><p>巨潮资讯：<a href=\"http://www.cninfo.com.cn/new/index/\">http://www.cninfo.com.cn/new/index/</a></p><p>EDGAR：<a href=\"http://sec.gov\">http://sec.gov</a></p><p>企业招股说明书、年报、半年报、季报、券商分析报告</p><p><strong>投融投资数据</strong></p><p>IT桔子：<a href=\"http://www.itjuzi.com/\">http://www.itjuzi.com/</a></p><p>投资中国： <a href=\"http://www.chinaventure.com.cn/\">http://www.chinaventure.com.cn/</a></p><p>创业邦： <a href=\"http://www.cyzone.cn/\">http://www.cyzone.cn/</a></p><p>36氪： <a href=\"http://www.36kr.com/\">http://www.36kr.com/</a></p>",
                "article_title": "22 | 采集数据：用好一手数据和二手数据"
            },
            {
                "title": "23 | 写好故事线：你能用好数字推翻众人的理解吗？",
                "id": 421384,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>经过前面分析问题的定义和数据的探索，现在到了最关键的一环——总结讨论。之前有个很火的美剧叫做CSI犯罪现场，其实我们整个数据分析的过程也和破案类似，我们需要在梳理各种证据和思路之后，用清晰的逻辑、严谨的语言去深入浅出地把整个事情讲清楚。</p><p><img src=\"https://static001.geekbang.org/resource/image/04/4c/04f4eb375399b402c843cf9b8cfe984c.png?wh=1193x471\" alt=\"\"></p><p>所以总结讨论这一步非常关键，我们既要把前面所有的问题和收集到的数据串联起来，有时候还得重新进行数据补充和问题优化。如果做得好，这一步可以让后续数据分析实践的工作事半功倍，但这就需要你把这份报告做得既要有高度还要亲民。</p><h2>回顾之前的发现</h2><p>我们进一步来看具体的操作。首先在规划故事线之前，你要回顾之前各种数据发现。在前期广泛的思考是非常重要的，但是到了后期你需要把思维聚焦，必须对面临的问题形成清晰的判断，特别是对关键问题的关键变量要有明确的定义。</p><p><img src=\"https://static001.geekbang.org/resource/image/8f/f7/8fac1b697517f82f4be488a92517b0f7.png?wh=1143x496\" alt=\"\"></p><p>例如在我们之前课程的例子中，针对老板提出获客成本高的问题，经过访谈和数据采集，在前期规划的6个方向当中，我们发现上图下半部分的三个因素是导致公司成本高的主要原因。因此，我们将前期发散考虑的问题收敛到获客的购买流程、客户意愿度以及产品设计方面，这就是一次问题的收敛。</p><!-- [[[read_end]]] --><p>在经过数据采集后，我们已经获得了足够多的明细的数据。假设现在我们可以直接从数据得出的初步现象有这样的几点：</p><ul>\n<li>通过内部的数据分析，发现我们购买关键字的成本没有进行优化，没有打通关键字到购买转化率的数值问题。而经过数据统计，我们发现大量热门关键字虽然转化率很高，但是它们的价格高居不下，加上在其他转化率较低的关键字购买，造成了我们的市场投入过高。</li>\n<li>根据同行产品的二手数据研究发现，从demo到注册的转化率应该在3%左右，而我公司只达到了0.5%，证明我们的demo体验的流程并不够好，也说明产品注册的转化和流程也不够好。</li>\n<li>同时经过客户访谈和调查问卷发现，客户购买5万以上金额单的销售流程都比较长，这是通过电话销售无法购买高客单价产品。</li>\n</ul><p>这些是从数据里面看到的情况，如果你只是把这些数字直接摆到老板的面前，老板肯定会问“然后呢？”所以现在你要设计整个的故事线，你要多想几步：</p><ul>\n<li>我们把目标提升10%，我们可以做哪些事情？</li>\n<li>如果我们想获得100倍的成果，那我们应该怎么办？</li>\n<li>我们这些分析背后是有哪些假设，在什么条件下我们的模式和假设是无效的。</li>\n</ul><p>多想了这几步之后，我们回到在前期数据探索方面的发现。从线索转化成本来讲，我们发现理论上可以加大部分关键词购买，貌似就可以解决这些问题。这个问题的假设条件是“<strong>这些关键字价格不变</strong>”，但其实随着关键字的大量购买，关键字的价格会被抬高。所以整体上来讲，我们不能轻易下结论给出建议去大量购买关键字。</p><p>根据业内的二手数据调研，我们发现当一个客户的用户生命周期价值大于等于2~3倍的获客成本时，生意模型就可以持续下去。所以我们可以给每个线索设定一个成本上限，如果线索成本不超过10万元的时候我们继续进行投放，一旦超过10万元我们要去改变关键字和营销人员的成本。</p><p>如果问题只分析到这里，我们只做了提升10%的事情，那我们如何能获得100倍的效果呢？</p><p>根据前面的分析可知，单价一定的情况下，我们的线索成本是不可能降到这么低的。所以我们就要提高整体的客单价，那么高客单价的线索获取还是通过线上获取就可以吗？这个时候其实可以<strong>重新做一次未成单的目标客户访谈</strong>。</p><p>这也就意味着我们要回到数据采集这一步。经过调研发现，由于没有线下销售和服务团队，对于这些高客单价客户我们无法成单。进一步分析这些客户的接触点，我们可以设计新的获客和产品定价体系，例如产品+服务进行区分销售、招聘有客户资源和行业知识的高级销售、参加线下专业行业讨论会、对客户推荐进行大力补贴等等。</p><p>“回顾”这一步是将前面问题、分析部分以及可能引出的结论，给出比较踏实的数据基础和逻辑基础，避免出现因果倒置、数据不准确或者是考虑维度不全面、思考高度不够等问题。同时，对于重点问题可以深入调研，有必要的时候可以回到数据采集这一步进行相关的数据补充。有了这些坚实的基础，我们可以进入下一步：设计故事线。</p><h2>设计故事线</h2><p>如果只是罗列事实，不能够通过平易近人的方式让大家理解你的观点，很可能会造成你正确的观点没有办法推广、坐失良机，可见设计故事线是多么重要。</p><p>你应该或多或少听说过孟德尔这个名字，虽然孟德尔如今在遗传统计学的研究非常著名，但世界对他数据分析报告的了解是在他去世几十年后了。如果你不想成为这个时代的孟德尔，你就要在设计故事线这里多下功夫。</p><p><strong>最成功的分析师就是那些会“用数据讲故事的分析师”，好的故事在呈现调查结果时往往会采用对方可以听懂的方式。</strong></p><p>之所以我把数据分析报告的最后内容编排这部分叫做“写故事线”，是因为我们要通过一个完整的故事把分析报告讲给那些没有参与这项数据研究的人（例如你的老板、其他部门的同事），同时还要给他们留下深刻的印象。</p><p>就像你现在依然会记住小时候听过的小红帽的故事，但是你可能很难记住当时背诵的朱子清这篇散文里都讲了什么。我们的目标是基于我们的数据讲一个好的故事，吸引到相关方的注意，唤起对方在情感和理智上的共鸣，从而让对方在我们分析报告汇报结束的一天、一周甚至一个月之后，他还可以简要地把我们数据分析主要内容重复给相关人士来听。这是我们想要达到的目标。</p><p>在这里我给你分享一个经典的故事三段论结构，也就是<strong>情节（陈述） - 起伏（惊喜） - 结尾（结论）</strong>，那些广泛传播的寓言故事也是受益于这个结构。在讲我们的数据分析时，也是要陈述我们发现的事实，中间要讲到一些我们发现但其他人还没有发现的知识，然后给出具体实施措施，最终快速给一个明确的结论，这样才能让整个分析报告掷地有声，传播较广。</p><p>其实我每节课的讲课的方式也是这样：先是一些基础知识的讲解，然后升华你的认知，最终快速给出结论，让你有获得感。对应到数据分析报告的呈现上，我给你一个大概的参考框架。</p><p>在<strong>陈述部分</strong>，我们可以由以下内容来进行陈述：</p><ul>\n<li>开场，用30秒陈述痛点和整体问题的背景；</li>\n<li>针对问题本身的分析，也就是我们定义问题的部分；</li>\n<li>结合内外部数据针对问题举例说明。</li>\n</ul><p>在<strong>起伏部分</strong>我们可以采取以下类似内容进行阐述：</p><ul>\n<li>阐述要提升10%的话有哪些办法和选择，并给出不采取行动或不发生变化会怎样？</li>\n<li>阐述更高倍数的提升办法和潜在选择是什么？</li>\n<li>还有哪些你发现而别人没有发现的观点问题？能带来什么？</li>\n</ul><p>在<strong>结论部分</strong>：</p><ul>\n<li>用简要的话或者数据分析思维导图进行总结和升华；</li>\n<li>结尾不要用谢谢，要用召唤型的语言或强有力的金句对整个分析报告进行收尾。</li>\n</ul><p>有了这个大的框架，我们就可以进行数据分析报告的书写了，在书写报告的时候，以下这四个点你要重点关注一下。</p><p><strong>篇幅</strong></p><p>一般来讲根据汇报层次的不同，粒度和整个汇报的篇幅会有所不同。对于数据分析报告来说，高层汇报一般建议在20~30分钟，PPT在10~20页；中层和执行层面汇报可以40~60分钟左右，整体内容可以在30~40页。</p><p><strong>标题</strong></p><p>我看到很多小伙伴在写PPT标题的时候，往往是用一个短语（例如现状分析、系统架构图），这是不可取的。既然叫做故事线，它就是应该用一句话来阐述这一页的中心思想。在IBM的时候我的导师曾经告诉我，你把你写的所有内容去掉，只是看PPT的标题，这几句话串起来应该就能把你这个故事完全讲明白，而不是要看完标题之后还要到每页里面去理解，这才是一份好的数据分析建议书。</p><p><strong>换位思考</strong></p><p>在你的 PPT介绍里面不要有大量的技术架构图、产品功能图等等，因为这些内容往往专业性过强，只能有部分的听众能够理解。我们要换位思考，让参与这场数据分析会的人员可以快速融入到角色中。你需要考虑的是写出的内容是否更有利于对方理解，而不是只顾着炫技。</p><p><strong>干系人态度</strong></p><p>在整个报告内容里你还要注意到干系人的理解程度和态度，因为你还有下一步的实践行动，你的目标是要推动用数据分析结果去解决问题。所以，你需要获得相关部门的共识和认可，最后，再推动大家把所有的问题放在桌面上一起讨论解决。</p><p>例如对于前面我们内部运营分析的这个数据分析报告来说，我们如果给老板和高管汇报可以按如下的故事线来进行（当然，这只是个简单的举例，主要是带你体验一下感觉）。</p><p><strong>现状分析</strong>：运营投入成本过高无法使公司盈利。</p><ul>\n<li>当前市场线索量够大，但质不佳；</li>\n<li>运营活动消耗大，效果有限；</li>\n<li>公司整体获客转化效率较低。</li>\n</ul><p><strong>解决之道</strong>：盈利需要断舍离，提升线索ROI。</p><ul>\n<li>抖音直播与线上活动ROI很低，建议停止；</li>\n<li>现有关键字转化率整体较低，需进一步优化关键字投放；</li>\n<li>Demo转化率低于业内预期，需加强客户引导注册页面。</li>\n</ul><p><strong>特别分析</strong>：如何发现公司的宝藏客户？</p><ul>\n<li>部分高价值客户潜力巨大，未能形成有效收入。</li>\n</ul><p><strong>落地建议与讨论</strong>：打通内部运营数据，深入行业解决方案。</p><ul>\n<li>组建线下行业销售团队，优化电销话术，提高客单价；</li>\n<li>建立市场后向指标，打通成单与投放ROI指标；</li>\n<li>优化产品注册流程，减少流失率；</li>\n<li>讨论建立私有化版本，提高整体产品单价？</li>\n</ul><p><strong>总结</strong>：客户潜力巨大，练好内功，目标投入减半，收入翻番。</p><p>对于这样一个故事线来说，即使你不看每一页里面详细的数据和例子，相信你也知道这一套PPT是要讲一个什么样的故事了。再强调一下，这个过程既要有陈述、解决方案，还要有你特殊的创意和发现、落地的建议，最后用和老板有共识的口号召唤一下大家，为下一步数据实践铺平道路。</p><h2>一图解千愁</h2><p>有了故事线就像人有了骨架，但它还需要有血肉。很多的小伙伴都是茶壶里煮饺子——有货很难倒出来。</p><p>最终你给所有人沟通完的结果，随着时间的推移，<strong>可能很多细节大家已经记不清了，但是你一定会给人留下一个感觉。</strong>而这个感觉正是我们最后要抓住的，因为它很可能直接关乎我们下一步在做实践推广的时候，你面临的阻力和你争取到的权威。</p><p>举个正向的例子，弗洛伦斯· 南丁格尔是护理事业的奠基人，同时也是定量分析法的早期使用者。当时她在推广医院护理这件事情的时候发明了南丁格尔玫瑰图，去统计关于克里米亚战争时期英国士兵死亡的原因。</p><p>通过这个图表，人们会惊奇地发现在医院没有护理时，受伤的士兵被送到医院治愈的少、死亡的多，而在护理的加持下，士兵整体死亡率急剧减少。她利用<a href=\"https://commons.wikimedia.org/wiki/File:Nightingale_Rose_Chart.png\">这个图</a>和定量分析使护理这件事获得了人们广泛的认知。最终在1956年6月克里米亚战争结束之后，护理的这个问题已经被大多数人接受了。她利用数据和合适的展示方法快速推广了自己的想法。</p><p><img src=\"https://static001.geekbang.org/resource/image/81/f7/81a4c958eb5ded83e9bd9dbd515546f7.png?wh=786x470\" alt=\"\"></p><p>你要知道，人脑接受图形要比接受文字快得多，所以，每一页PPT里面的文字不要罗列大段描述，你要尽量只提出要点，而且要用图形化的方式把这些要点之间的逻辑穿插起来，这样做往往会事半功倍。</p><p>小小预告一下，因为这些图和思维方式非常重要，我在接下来的课程里会具体给你介绍15种数据分析思维图，你可以在里面去查找适合自己的图来填充分析报告的血肉。</p><h2>小结</h2><p>总结一下，我今天给你讲解了设计故事线的要点，这其实是一个升华和总结我们前期大量准备工作过程。</p><p>做数据分析是通过你99%定量分析的努力（寻找梳理问题、采集我们所需要的数据、选择和检测相关的指标）打基础，加上1%的创见性思维找到这里面能够解决整个问题的关键。它就像当年牛顿一直苦苦思考重力产生的原因，做了大量的实验和观察，最后在苹果树下被一个苹果砸到，让他顿悟了万有引力的定律。</p><p>我们做数据分析最后呈现出来的这个分析报告，可能会看起来非常简明扼要，好像我们最后只是简单拿出了一个“苹果”。但其实在苹果的背后，是前面大量的调研、梳理和思考，最终还得寻找到一个好的故事线来说明我们的观点。所以“写好故事线”这件事不是那么简单的，充分的定量分析和创见性思维缺一不可。有这样一个例子我个人非常喜欢，分享给你。</p><blockquote>\n<p>联合国一直在公布偷渡溺亡的难民数字，但直到那名叙利亚儿童死后被冲上岸，各国政府和民众才真正改变对待难民的态度，它胜过一切冷冰冰的数据。<br>\n&nbsp;<br>\n我们需要的是故事，因为只有故事，才能达到共情、建立人与人之间的连接、让他们站在你这边。</p>\n</blockquote><p>数据给你一双看透本质的眼睛，如何让我们的数据不再冷冰冰？我想我的答案是写好故事线。希望我们都可以通过自己的努力，让我们的数据更有温度和力量，找到我们工作和生活当中那个数据的金苹果。</p><h2>思考题</h2><p>你在做数据分析或者演讲当中有自己特别觉得优秀思路的例子么？分享一下，我们共同提高。</p>",
                "article_title": "23 | 写好故事线：你能用好数字推翻众人的理解吗？"
            },
            {
                "title": "24 | 实践你的理论：数据驱动最终就是用结果说话",
                "id": 422480,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>前面给你讲了怎样确定好问题、采集好数据、写好一个故事广为传播，现在到了最关键的一环：实践前面的数据理论。</p><p>过去在做数据驱动决策的时候，我们往往会采用自上而下的执行方式，也就是汇报之后让老板先进行决策，然后再推动全公司的全面变革。但是这种方式往往会面临巨大的风险，但凡前面的某一个环节出现一些偏差（或者对于业务的认知出现一些问题），就会差之毫厘，谬以千里。为了避免这种风险，往往各部门会基于一份报告反复论证，但最后等论证结果出来，当时数据假设的时间已经错过了。</p><p>所以现在进行数据驱动实践的时候，都会采用一种方法叫做“精益”的方法。“精”就是少投入、少耗资源、少花时间，尤其减少不可再生的资源的投入和耗费；“益”就是多产出经济效益，实现企业的升级目标。</p><h2>精益的方法</h2><p>精益的方法简单来讲，就是<strong>你在进行数据实践时不要选一个巨大的目标，而是去选择一系列快速的实验，小步快跑来迭代验证你的数据理论。</strong></p><p>这里最核心的部分就是要“快节奏”。只有快了，数据实验的量才能够上去，才会避免一些数据偏差。不要想着憋大招，进行一个巨大的流程或者产品方面的修改，这样很容易当时间都过去之后，才发现方向的错误。</p><!-- [[[read_end]]] --><p>一般来讲，一个设计实验验证的时间不要超过两周，也就是现在在研发里面叫做一个迭代（Srpint）。如果修改时间超过两周，那就证明定的这个实验还是过大了，你需要再把它拆分成更细小的实验，逐步进行迭代。调整往往是通过一个或多个部门并行的几个迭代来观察对数据的影响是否正向，再进行新的迭代。如果出现偏差，那就进行快速调整和迭代。</p><p>理论上，前面所有的设计数据实验过程都会比较愉快，但一涉及落地，一般业务部门都是不愿意去改变的。</p><blockquote>\n<p>无论多坏的改变都会有人受益，不论多好的改变都会使一些人受损。不害人的需求是不完整的需求。<br>\n&nbsp;<br>\n——Gerald M. WeinBerg</p>\n</blockquote><p>于是很多数据分析项目都停留在落地这一步，大多变成了纸上谈兵，无法把前期数据理论实践下去。</p><h2>创新扩散模型</h2><p>那我们应该如何去有效推动实践的落地呢？这里其实需要一个内部推广实践的技巧。</p><p>前期在进行数据故事宣讲的时候，你需要把你的思想沟通给老总以及各业务部门，一方面是宣讲，另一方面也是观察各部门相关方的态度。</p><p>数据驱动实践无可避免地会对公司做出一些内部的改变和创新。而改变和创新的扩散过程是要有一个周期的，你可以参考埃弗雷特·罗杰斯（E.M.Rogers）提出创新扩散模型，如下图所示。</p><p><img src=\"https://static001.geekbang.org/resource/image/0a/28/0aa98dc3f8943c73f9bd0ba9fed96a28.jpg?wh=2000x1077\" alt=\"\"></p><p>在这个模型里，会把针对一个新的想法的接受程度分成了5类人。</p><ul>\n<li><strong>创新者</strong>（Innovators）：他们是勇敢的先行者，自觉推动创新。创新者在创新交流过程中，发挥着非常重要的作用。</li>\n<li><strong>早期采用者</strong>（EarlyAdopters）：他们是受人尊敬的社会人士，是公众意见领袖，他们乐意引领时尚、尝试新鲜事物，但行为谨慎。</li>\n<li><strong>早期大众</strong>（EarlyMajority）：他们是有思想的一群人，也比较谨慎，但他们较之普通人群会更愿意、更早地接受变革。</li>\n<li><strong>后期大众</strong>（LateMajority）：他们是持怀疑态度的一群人，只有当社会大众普遍接受了新鲜事物的时候，他们才会采用。</li>\n<li><strong>迟缓者</strong>（Laggards）：他们是保守传统的一群人，习惯于因循守旧，对新鲜事物吹毛求疵，只有当新的发展成为主流、成为传统时，他们才会被动接受。</li>\n</ul><p>这个模型对于推广我们的想法很有指导意义。你能看到，一般所有新事物的接受都是从创新者开始的。在后期要进一步推广你的新事物时，要得到公司内部的或者是社会内部的广泛共识才可以。</p><p>你在数据分析报告的宣讲当中提出了一些新的理念和新的想法，你如果仔细观察和沟通，总会在公司发现一些创新者（当然，如果你一个都没有发现，重新回到上一步，这说明你的数据分析报告和数据思维宣传没有做好）。这些创新者会认同你的想法，他是你在公司里面推广的种子。</p><p>也许你的想法并不是光靠某一个部门能完全实现的，但没有关系，你可以先在创新者的部门实践，看到效果之后再进行后期的推广。无论多小的进展，这就是你走出的第一步。在得到一些应有的信任和对这个方案的采纳之后，你再去其他部门推广，让他们成为你的早期采用人群，之后逐步再让后期大众和迟缓者接受你的方案。</p><p>当然，在具体说服创新者和早期采用者的时候，也经常会遇到一些困难。例如一些早期的支持者他在会议上很认同你的观点，但是往往没有产生一些具体的配合和行动。这样很多数据分析的实践就只停留在了 PPT里面，“叫好不叫卖”，没有产生实践结果。</p><p>这是因为从观点的认知到具体落实到行动，还有很长的距离。这里我再给你分享一个推动数据驱动落地的方法：理性行为理论。这个理论是在1975年由Fishbein与Ajzen提出的，你可以看看下面这个图。</p><p><img src=\"https://static001.geekbang.org/resource/image/da/fd/daabb05910d92fbdcfc2ce3fdb1494fd.jpg?wh=1946x941\" alt=\"\"></p><p>从这个图里面你能看到，一个人从认知到最后的实践，中间有很长的一段距离。例如我们都认知自己应该去健身，但是大多数人都没有办法坚持下来。那些能够执行下来的人，一般是他对健身有充分的认知，同时他周围的人也会给他一些舆论和示范性的作用（例如健身红包罚款群），这样他的健身的意图就会大大增强，从而最后能够把健身落在实际行动里。</p><p>同样，<strong>前期你对创新者进行大量数据思维和实践的布道，这一步是加强他们对整个数据实验的认知，影响创新者对这个实验付出的努力程度以及承担风险和获得收益的态度。</strong></p><p>同时你需要面向全公司高层进行布道，让高层感受到这是一个主流行为。当这些态度和规范大于他们自己的风险和付出的时候，他们才会有明显的意图并采取实际的行动。</p><p>所以往往想通过一两次开会来简单拍板决策推行一些数据实验的进行，这是很难的。我们得通过大量的沟通去影响相关部门对此事的认知和态度，形成公司内部的一些规范，才能够让大家真的执行下去。特别是对于后期大众和迟缓者来讲，他们往往当在公司内部已经将你的实验和数据结论当做规范的时候，他们才会接受。</p><p>在选择部门和说服部门执行部分，我们多付出一些时间是值得的。<strong>数据实验要快速迭代，所以在没有得到对方深度认可之前，你宁可花一些时间去进行说服和沟通。一旦实验开始，要的就是最后的结果，好的结果哪怕是一点点，也比做再多的PPT都有用。</strong></p><p>整体思维落地的这个过程，国外就叫做“数据精益”。这里我也给你推荐一下<a href=\"https://book.douban.com/subject/26278639/\">《精益数据分析》</a>这本书，这本书是从整个企业的视角来描述整体数据驱动的过程。</p><h2>实例实践</h2><p>讲完理论基础后，我们来进行实战练习。回到上节课的例子，在通过数据分析沟通汇报之后，老总觉得这个改动很有必要进行执行，各总监迫于领导的压力也都纷纷点头认可。但当你具体推行的时候，这些部门都说没有资源落地、人都过忙，把这些实验推缓。</p><p>怎么办呢？你可以先通过前期沟通和会议现场的表现，找到企业当中对你想法接受程度较高的创新者。</p><p>假设你观察到，运营部门总监觉得现有工作已经太忙了，不想发生改变。但市场部门的负责人很早就希望能有一些后期数据，能支持市场优化的过程。这个时候你可以和市场部负责人单独约一次会议，因为他对这件事情的认知已经达到了一定水平，不过他的态度和整体的主观规范还不一定到位。</p><p>你可以设计一个代价比较小的实验，让他来体验一下你设计的数据分析思维的变化。一方面说服他知道这件事情的改变代价较小，获得收益较大；另一方面给他讲目前相比业内其他公司在这个方面的做法，我们相对落后，应该要赶上其他公司的做法。这样通过改变他的态度和主观规范来影响他的行为意图，再把这个实验落地的计划写出来，促进这件事情的落地。</p><p>例如我们就是一次关键字转化的跟踪试验，那么我们可以通过设计一个落地页的方式，针对某几个关键字的效果进行统计。我们不要进行大量的系统的改造，先用手工统计的方式来进行，这样可以快速地在两周获得一些投放的结果，首先解决数据透明度的问题。</p><p>然后我们做一次简单数据分析汇报，给一个第一步的行为反馈。再根据投放的结果和动态的价格和市场的投放优化人员一起进行一些关键字的优化后，再进行一次展示，让负责人对结果有信心。此时就可以推动市场部负责人要求产品技术部领导给出资源，把前期的手动过程固定下来成为公司数据驱动系统的一个部分。类似地，继续在理性行为理论的指导下，再争取其他部门认可，最终把我们整个数据分析方案落实下去。</p><p><img src=\"https://static001.geekbang.org/resource/image/84/d2/84c1735e1c5c7575ab40c611c7c37fd2.jpg?wh=2000x1155\" alt=\"\"></p><p>在整个数据实验过程当中，其实有不小的难度。一方面的难度在于你要去实践你的数据理论，要通过数据驱动最后的结果说话。可能你会遇到一些失败，但不用气馁，因为实验较小代价不大，你要做的是持续进行实验和迭代，最终一定会获得相对比较好的结果。</p><p>另一方面，最大的难度其实在于你要挑战自己。因为你是数据思维的驱动者，为了得到好的结果，你一定要避免“数据确认谬误”。也就是为了自圆其说而引用有偏向性的数据，或者采用不公平的数据计算方法或抽样方法来验证数据结果。</p><p><strong>做数据分析一定要诚实、公平、可信，这样才能够把数据思维贯彻在全公司的员工的心里，不然大家很容易觉得数据只是用来汇报的表面功夫。</strong></p><h2>小结</h2><p>今天所讲的是用数据说话的最后一步，这一步也是最难的一步。你在前面的步骤里，多少也能自己摸到一些门道，写出比较好的数据分析报告。</p><p>但是一份好的数据分析报告不是最关键的，如果数据报告只是一次汇报，那么你的数据报告最后就会放在领导的案头落灰。在我们这个课程里，从确定问题开始的宗旨就是要去做对公司或者个人生活有实际落地结果的事情，不要为了一个纸上谈兵的问题大费周章。</p><p>做数据驱动就是要用结果说话——当然这个过程是非常难的。</p><p>今天给你介绍了一些我过去比较实用的方法：用精益的方法，小步快跑；用拆分实验的方式来降低使用的门槛；用创新扩散模型找到你的第一波实验的企业内部用户；用理性行为理论来说服每一个干系人，让他们从对你的想法的认可落实到具体实践的行动当中。</p><p>在整个过程中，你要坚信用数据分析的方法是可以帮助企业和个人生活去有效提高的。同时，做好沟通，用深入浅出的方法去传达你的理念，不要用知识差碾压别人。要记住，别人对你的尊重，也是通过你对别人的尊重得来的。足够的坚定，足够的谦卑，你一定会用数据实践的结果来证明前期你的努力！</p><p>数据给你一双看透本质的眼睛。用数据说话，其实更是用客观结果说话。</p><h2>课后思考</h2><p>你在工作当中，有哪些用数据说话，最后得到很好效果的例子么？可以把你的心得分享出来么？我们一起学习，共同提高。</p>",
                "article_title": "24 | 实践你的理论：数据驱动最终就是用结果说话"
            },
            {
                "title": "25 |  数据分析：15种数据思维图（上）",
                "id": 423163,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>在数据分析的过程中我们总会有各种的数据的想法，但无论是在确定数据分析问题、采集数据还是在实践理论当中，我们很多时候都很难表达出我们的这一系列的想法。所以在这两节课中，我会把我最常用的15种数据思维图给你总结出来，你可以通过这些数据思维图的框架去整理自己零乱的信息，然后再通过进一步的分析探究事实本身。</p><p>对于这15个数据思维图的讲法，我会先给你讲讲这个图的使用场景是什么，然后介绍一下整体的图形的结构，对使用方法做一个基本的解释，最后再说一下我们还可以在哪些地方去深入解析这方面的问题。</p><p>这节课我们先从大的战略部分（确定问题、分析自身，产品定位）入手，给你介绍一些我常用的数据思维图，它们分别是：</p><ul>\n<li>VRIO分析；</li>\n<li>五力模型；</li>\n<li>SWOT分析；</li>\n<li>同理心地图；</li>\n<li>4P 竞争分析；</li>\n<li>奥斯本检验表；</li>\n<li>SUCCESs表；</li>\n<li>产品组合矩阵。</li>\n</ul><p>那我们就按刚刚说的讲解框架，从第一个数据思维图开始吧。</p><h2>VRIO分析</h2><p><strong>问题场景：</strong>分析自身业务</p><p><strong>图形结构：</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/4c/ff/4c0346b4a87bd6ab057b61980d9e93ff.jpg?wh=1980x1045\" alt=\"\"></p><p><strong>基本解释及使用</strong>：要分析一件事情或者一个产品是否有竞争优势，最基础的分析部分就是资源以及分配方法。</p><p>分析自身的资源和运用方法就是VRIO分析。</p><!-- [[[read_end]]] --><ul>\n<li>V表示价值性（value）；</li>\n<li>R表示稀缺性（rarity）；</li>\n<li>I代表可模仿性（imitability）；</li>\n<li>O代表组织性（organization）。</li>\n</ul><p>VRIO分析就是从以上四个方面来切入，针对各种各样的资源进行打分，评估我们将来的各种方针。</p><ul>\n<li>我们在评估经济价值的时候会评估拥有此项资源是不是就能把握机会，是不是就可以削弱竞争对手的优势来一枝独秀；</li>\n<li>在评估稀有性的时候，我们会评估一下拥有的这项资源是不是很稀缺；</li>\n<li>在评估可模仿性的时候，我们会评估如果其他人想获得这项资源，是不是要付出更高的成本；</li>\n<li>评估组织性的时候，看你自己组织具备的资源和实力能否得到有效开发和利用。</li>\n</ul><p><strong>进一步分析：</strong>在针对这些情况分析之后，我们可以考虑一下，对于自身公司目前的这些情况，你首先想到的资源会是什么？强化哪些资源还可以提升我们的竞争力，加强哪些优势可以补足我们弱势的竞争点？</p><h2>五力模型</h2><p><strong>问题场景</strong>：整体业务赛道与竞争情况</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/6a/f8/6a2c384ef17a86f06d46b894d24125f8.jpg?wh=2000x1197\" alt=\"\"></p><p><strong>基本解释及使用</strong>：五力模型也叫做波特五力模型，这个模型是由迈克尔·波特（Michael Porter）于20世纪80年代初提出。它是一个最常见的竞争分析方式，这个五力的强度越强，代表这个行业里的竞争力越激烈，你面对的挑战越大，也就是你现在的赛道是红海。当然红海也证明这个市场是有刚需的，不代表你不能胜利。你可以找到其中一些突破点来颠覆这个市场，比如今日头条就是通过推荐算法颠覆了以门户网站为主要信息获取的方式，从而获得了成功。</p><ul>\n<li>供应商的议价能力是指供方能通过提高投入要素价格与降低单位价值质量，影响行业中现有企业的盈利能力与产品竞争力。供应商（卖方）的议价能力越强，越证明此时处于卖方市场。</li>\n<li>买方的影响力是指买方可以通过压价或者提高产品需求来压低卖方的利润。例如你的产品同质化程度高，可选择的类似产品比较多，那就是买方市场。</li>\n<li>同行业里的竞争情况指的是这个行业里的竞争对手多不多，竞争强度大不大，一般来说门槛低和利润高的行业会快速涌入大量竞争者。</li>\n<li>创新者带来的威胁是指现在你有哪些挑战者，如果不需要太多的投入，没有太多的门槛就可以进入这个行业的话，那其实你的潜在创新者的威胁就比较高。</li>\n<li>替代品带来的威胁是指有没有可能出现更高维的一种产品来跨界打击你，它满足客户最终的需求，而不用你现在的这种解决方案。</li>\n</ul><p><strong>进一步分析</strong>：如果你重新做一遍这个产品，你还会这样定位产品吗？如果我们要扩大100倍的市场，你会用什么样的解决方案？10年后这个市场会是什么样子？这个五力模型会变成什么样子？你可以和竞争对手合作获得其中的某些能力么？</p><h2>SWOT分析</h2><p><strong>问题场景</strong>：整体业务场景与竞争优劣态势</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/49/7e/499508eca8016aaf8aeef8fdabacc07e.jpg?wh=1944x883\" alt=\"\"></p><p><strong>基本解释及使用</strong>：SWOT分析是一个典型的拿公司和周围环境比对的一个分析，它从内部环境、外部环境、好影响和坏影响做了一个矩阵图，这样的话就可以针对 S （Strengths）优势、W （Weaknesses）劣势、O （Opportunities）机会、T （Threats）威胁这4个元素进行分析。</p><p>SWOT分析是从内部和外部多个角度审视一件事各个层次的结果，可以帮助我们可以从中找出对自己有利的、值得发扬的因素，以及对自己不利的、要避开的东西，发现存在的问题。你可以试试头脑风暴的方式，想到什么就把它写下来，然后下一步进行整理，这样可以看到更多的机会并补足其中不足的地方。</p><p><strong>进一步分析</strong>：不仅是用SWOT给自己公司做分析，同时也给竞争对手做SWOT分析，这样可以补足整体的大环境。</p><h2>同理心地图</h2><p><strong>问题场景：</strong>如何打动你的决策者</p><p><strong>图形结构：</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/3f/47/3f2c2dcbb0d5d12f65b8b45ec911c447.jpg?wh=1888x1225\" alt=\"\"></p><p><strong>基本解释及使用</strong>：同理心地图是一种通过换位思考的方式，了解别人所处的状态和情绪的方法。我们通过想法、所见、所言所为、所闻去分析对方到底会怎么看这件事。这样能让我们深刻理解对方的想法和所处环境，换位思考，最终引导对方做出对自己有利的决策。</p><ul>\n<li>想法指的是他在心里有这个想法去做这件事，但还没有表达出来；</li>\n<li>所见就是他在工作、生活当中遇到的问题，接触的人或产品服务；</li>\n<li>所言，就是他在工作生活中发表的言论及做法；</li>\n<li>所闻，就是他经常能听到的声音，比如在媒体上看到的新闻或者是内部的开会得到的一些结论；</li>\n<li>痛苦就是代表着他对这件事情的承受风险能力、压力、恐惧等；</li>\n<li>收获是代表着他能从这件事中获得的东西，包括物质或者精神上的满足。</li>\n</ul><p><strong>进一步分析</strong>：不仅可以用同理心地图分析重要决策者，我们还要分析重要干系人，包括你的团队的重要成员。</p><h2>4P 竞争分析</h2><p><strong>问题场景</strong>：产品市场营销分析</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/2c/12/2ca7705b30f778f565504262ba706c12.jpg?wh=1700x865\" alt=\"\"></p><p><strong>基本解释及使用</strong>：4P竞争分析是在产品、价格、渠道、销售加上目标和提供的价值这几个层次下，看自身公司和竞争对手之间的关系，制定相关策略来决定我们的产品营销应该有哪一种定位。</p><ul>\n<li>产品（Product）：功能，要求产品有独特的卖点；</li>\n<li>价格 （Price）：根据不同的市场定位，制定不同的价格策略</li>\n<li>渠道 （Place）：经销商培育和销售网络</li>\n<li>促销（Promotion）品牌宣传（广告）、公关、促销等一系列的营销行为。</li>\n</ul><p>我们在收集资料的时候，可以用采集数据的方式，通过第1手和第2手数据去丰富所有相关的内容。</p><p><strong>进一步分析</strong>：在这个竞争环境下，什么样的产品可以让客户最满意？其他公司它的优势在什么地方？也可以参考<a href=\"https://baike.baidu.com/item/STP%E7%90%86%E8%AE%BA/5628768\">STP</a>模型进一步讨论。</p><h2>奥斯本检验表</h2><p><strong>问题场景</strong>：拓展思路，获得新观点</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/39/e7/394d037b09ff2737519ec011dc992de7.jpg?wh=1932x963\" alt=\"\"></p><p><strong>基本解释及使用</strong>：我们在想新方法时，总有那么一些思路枯竭、缺乏灵感的时刻。这个模型就是为了给你像挤牙膏一样，再挤出新的一些想法。</p><ul>\n<li>其他用途指的是现有的东西（如发明、材料、方法等）有无其他用途？稍加改变，有无别的用途？</li>\n<li>借用指的是能否从别处得到启发？能否借用别处的经验或发明？外界有无相似的想法，能否借鉴？</li>\n<li>改变是指可不可以换一种形式？比如换产品形态、改变产品的状态，改变后的效果会如何？</li>\n<li>扩大是指现有的东西能否扩大使用范围？能不能增加一些东西？能否添加部件、拉长时间、增加长度？</li>\n<li>缩小是指如果把这个东西变得更小更轻，是否可以减少一些功能和成本或者产生新的产品？</li>\n<li>取代是考虑一下是不是可以用其他的素材方法取代它；</li>\n<li>重新调整是从调换的角度思考问题，能否更换一下先后顺序？可否调换元件、部件？更换一下，会怎么样？</li>\n<li>重整是从相反方向思考问题，倒过来会怎么样？上下是否可以倒过来？左右、前后是否可以对换位置？里外可否倒换？正反是否可以倒换？可否用否定代替肯定？</li>\n<li>组合是从综合的角度分析问题，如果尝试各种组件合成到一起会有什么效果？</li>\n</ul><p><strong>进一步分析</strong>：其它行业，类似的问题是如何解决的？</p><h2>SUCCESs</h2><p><strong>问题场景</strong>：新观点创意和商业模式评估</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/7e/bd/7e4789b9c5e90f648387ba05bb1409bd.jpg?wh=1888x1001\" alt=\"\"></p><p><strong>基本解释及使用</strong>：这个框架是从Simple（简单）、Unexpected（意外）、Credible（可信）、Combine（整合）、Emotion（情感）、Story（故事）、Secret（神秘）6个视角来客观判断创新点子。这个框架可以发现你的创意哪里不足，方便你立刻补充。</p><ul>\n<li>简单指的是想法是否比较简单，其他人容易懂；</li>\n<li>意外指的是从一般角度来讲，是不是打破了消费者的期望，有没有新的切入点；</li>\n<li>可信指的是有没有通过可信的事实让其他人产生共鸣，从而在市场培育初期就取得认同，为其进一步发展夯实基础？</li>\n<li>整合指的是有没有把相关产品进行捆绑销售。跨界的整合创意往往能带来神奇的效果，例如苹果公司就是将硬件、软件和服务融为一体；</li>\n<li>情感指是否容易让用户产生共鸣；</li>\n<li>故事指是否以故事的方式加强传播，让人容易记住；</li>\n<li>神秘指的是有没有通过制造来之不易的体验让消费者很难得到，从而越发珍惜，例如过去的iPhone发布会。</li>\n</ul><p><strong>进一步分析</strong>：能否用一句话来说明你的创意？一句话无法提炼出来的创意，一般不是好创意。</p><h2>产品组合矩阵（气泡图）</h2><p><strong>问题场景</strong>：产品布局，产品当中的业务布局，它是散点图的变种，气泡图。</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/fe/db/fe701f618cafd64c76328692891de7db.jpg?wh=1516x1194\" alt=\"\"></p><p><strong>基本解释及使用</strong>：一个赛道里会有各种各样的产品，一个产品会有各种各样的功能，我们每个产品的功能和它的活跃度以及这个产品任何两位维度的评估组合起来就是产品矩阵。</p><p>你要有一个产品全局观，可以用气泡的大小表示用户活跃规模，横轴代表变现能力，纵轴是导流能力，让人一目了然公司的产品布局或者内部产品功能矩阵的情况。</p><p><strong>进一步分析</strong>：图中产品和产品或者产品功能之间有什么关系？它们能相互导流吗？</p><h2>小结</h2><p>好了，这节课到这里也就接近尾声了。最后我来给你简单小结一下。</p><p>我们今天从大的战略部分入手，给你介绍了8个思维导图。</p><ul>\n<li>VRIO分析——分析自身业务；</li>\n<li>五力模型——分析整体业务赛道与竞争情况；</li>\n<li>SWOT分析——分析整体业务场景与竞争优劣态势；</li>\n<li>同理心地图——如何打动决策者；</li>\n<li>4P 竞争分析——产品市场营销；</li>\n<li>奥斯本检验表——拓展思路，获得新观点；</li>\n<li>SUCCESs表——新观点创意和商业模式评估；</li>\n<li>产品组合矩阵——分析产品布局，产品当中的业务布局。</li>\n</ul><p>我把这些思维图叫做“思维的榨汁机”，在我们思路不清晰或者思维创意枯竭的时候，你不妨把这些工具拿出来，把自己的头脑“榨”一遍，往往可以收到奇效。我把所有的这些PPT模板已经放在<a href=\"https://pan.baidu.com/s/1XLKbWl9Bua7AAsxcRwH-wA\">这里</a>（提取码vdx4），你需要的时候直接引用填写就好。</p><p>数据给你一双看透本质的眼睛。这些数据思维图就是你的望远镜和显微镜，让你把千头万绪梳理清楚。</p><h2>课后思考</h2><p>关于产品、竞争态势的思维图，你还用过哪些比较好的模型？分享出来，我们一起提高。</p>",
                "article_title": "25 |  数据分析：15种数据思维图（上）"
            },
            {
                "title": "26 |  数据分析：15种数据思维图（下）",
                "id": 424174,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>上节课给你讲了主要用于产品和市场的一些思维图，但这还不够。在形成商业模式前，我们还需要去做获客、拆解和执行。所以这节课里，我将给你介绍几个我最常用的分析模型，帮助你来梳理分析思维，它们分别是：</p><ul>\n<li>商业模式画布；</li>\n<li>AIDMA；</li>\n<li>AARRR；</li>\n<li>SMART；</li>\n<li>PDCA；</li>\n<li>RACI；</li>\n<li>Will, Can, Must。</li>\n</ul><p>还是和上节课一样，我们先说使用这个思维图的场景，然后给出图形架构、讲解基本使用，最后再讲讲如何进一步来扩展分析。</p><h2>商业模式画布</h2><p><strong>问题场景</strong>：分析自身商业模式</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/f1/35/f1caf3995e0491eb2a48ab6f97b42035.jpg?wh=2000x1209\" alt=\"\"></p><p><strong>基本解释及使用</strong>：商业模式画布可以非常方便地对公司的商业模式进行一个整体的梳理。它通过9个关键的因素来分析一个公司整体的脉络，这9个元素分别是 KP（ Key Partnerships）关键合作伙伴、 KA（Key Activities）关键活动、 KR（Key Resources ）关键资源、VP（Value Propositions）价值主张、CR（ Customer Relationships）客户关系、 CH（Channels） 渠道通路、CS（Customer Segments）客户人群、CS（ Cost Structures）成本结构、RS（Revenue Streams）收入来源。</p><!-- [[[read_end]]] --><p>这个画布的最底层是公司的整体的收支逻辑，左侧是公司的组织能力，右侧是针对客户的价值主张和如何采取措施。你可以根据你个人、公司、部门的情况通过这个图把整个业务的逻辑梳理出来。</p><p><strong>进一步分析</strong>：九个因素当中最强和最弱的元素是哪一个？如何发挥优势和补充弱势？</p><h2>AIDMA</h2><p><strong>问题场景</strong>：设计整体客户营销策略</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/de/4a/de10bf386c5bed875670afd26df1744a.jpg?wh=2000x921\" alt=\"\"></p><p><strong>基本解释及使用</strong>：一个客户在购买你的产品的时候是先注意到你的产品，然后产生一些兴趣，当这些兴趣转化成欲望的时候，他才会有购买的行为。或者当他对你的产品有印象后，再见到你的产品时，他会产生购买的行动。</p><p>AIDMA这个策略就是将你换到客户的位置上，根据各个阶段（也就是注意、兴趣、欲望、记忆、行动）来具体分析如何获得用户的关注，最后让用户产生购买行为。我们可以在这个表里写下每个客户在当时的情况以及当时他的需求，针对这种情况和需求，你去设计如何让客户获得你产品的各种特性和信息。</p><p><strong>进一步分析</strong>：可以结合前面的同理心地图换位思考一下，客户是否还存在一些没有说出的需求？客户在每个过渡阶段之间会遇到什么障碍？我们如何去排除？</p><h2>AARRR</h2><p><strong>问题场景</strong>：获取客户的各个阶段</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/c8/b1/c86001ed059900197a56f24e83c1cdb1.jpg?wh=1924x1001\" alt=\"\"></p><p><strong>基本解释及使用</strong>：AARRR也叫做“海盗模型”，它把获得客户到最后变成收入之间分成了5个阶段，包括获得客户阶段、让用户活跃起来的阶段、留存住客户的阶段、产生购买用户的阶段以及用户传播阶段。通过这5个阶段，我们可以把用户从开始和你接触到最后你可以从用户身上盈利的这一整体流程，在模型里阐释清楚。你可以设置每个阶段的目标以及要用户体验到的内容，最终我们可以通过数据分析来看差距。</p><p><strong>进一步分析</strong>：在现在信息过载、产品类别过剩的情况下，获客顺序已经不再是AARRR，而是大多数产品通过朋友的推荐介绍或者平台的推荐被用户看到，用户再去了解和购买。所以在新形势下的模型往往是RAARR，也就是推荐、获取、激活、留存和购买。如何获得客户的推荐，是你的公司存活下去的重要指标。</p><h2>SMART</h2><p><strong>问题场景</strong>：确定目标是否明确</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/ea/29/eac1d5a4401ca62c1d0c1ec34f3b9c29.jpg?wh=1848x1043\" alt=\"\"></p><p><strong>基本解释及使用</strong>：每次我们在制定目标的时候，你可能经常会听到你的领导说这个目标并不SMART，他不是说你不聪明，而是指你的目标无法很明确地传达给下属和团队。</p><p>SMART原则就是首先要具体（Specific），结果可衡量（Measurable），制定的目标应该是可实现的（Achievable），所有的这些动作和言论都是结果导向（Result based），所有的目标都是有时效性的（Time-bound）。符合这5个因素，才能够把我们的目标写得更清楚。</p><p>一个目标如果不符合SMART原则，你也就无法进行数据分析和最后的数据确认。</p><p><strong>进一步分析：</strong>你的目标如果提高10倍它还是SMART吗？100倍呢？如果不是，那么倍数变大就无法达成的因素是什么？有没有可能用奥斯本检查表突破它？</p><h2>PDCA</h2><p><strong>问题场景</strong>：反思和改进自己的业务</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/58/81/587c6357a04983fdff7f0e11aaeffe81.jpg?wh=2000x1209\" alt=\"\"></p><p><strong>基本解释及使用</strong>： PDCA来自著名的戴明环，它是将一个任务按照顺序从计划到执行到检查，再到改善行动，重新去规划，而且不是运行一次就结束，是不停地循环下去。</p><p>你可以在这个框架里填写要去反复执行来提高的目标，做相应的计划（Plan），再根据设计和布局进行具体运作，实现计划中的内容（Do），再检查和总结我们能否达到目标，找到哪些对了哪些错了（Check），最后，对总结检查的结果进行处理（Act），然后再做新的行动计划（PDCA）。注意每一个动作里面的每一个目标都要有明确的数字，而不是简单去定性问题。</p><p><strong>进一步分析</strong>：在这种不断的循环当中，有没有大方向上直接可以产生的变革？局部的最优解往往不是全局的最优解。还记得第<a href=\"https://time.geekbang.org/column/article/400764\">01讲</a>里的辛普森悖论吗？局部优化可能无法全局优化，我们需要跳出来高维度思考问题。</p><h2>RACI</h2><p><strong>问题场景</strong>：分拆工作职责，进行工作协同</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/71/d3/712cb18b8327e4090a2691c86bc992d3.jpg?wh=1668x905\" alt=\"\"></p><p><strong>基本解释及使用</strong>：在做一件事情的时候，往往会有很多人或者很多部门参与，这时候处理好人和人、部门和部门之间的关系就非常重要了。</p><p>RACI矩阵区分出了4个角色，Responsible是要负责执行具体这个任务的执行者；Accountable是责任人，负责向组织内外说明业务、进度状况，一般是组长或者Leader这个角色；Consulted被咨询者一般是支援的部门和人，也就是在发生困难的时候，可以提供意见或者提供资源帮助你解决的人；Informed被告知者是需要知道这件事情进度最新消息的人，相当于他们需要邮件抄送。</p><p>这里需要注意，在书写每一项任务的时候每一行只会有一个A，也就是只有一个最后负责人，因为有两个A就意味着有两个负责人，这样就会出现踢皮球的情况。</p><p><strong>进一步分析</strong>：RACI在最终确认的时候，一般都是由责任人或者和责任人的老板一起来进行规划的，单纯只是你和其他的人员规划不会有太大意义。其中我们的任务拆解是非常讲究艺术的，如果你没有拆解好，可能会出现有的事情没有人负责或者是有的事情由多人负责的情况。此外还有一个叫<a href=\"https://baike.baidu.com/item/%E5%B7%A5%E4%BD%9C%E5%88%86%E8%A7%A3%E7%BB%93%E6%9E%84/8668423\">WBS</a>的工具，你可以通过WBS把具体任务分解下去，跟踪相关完成情况和状态。</p><h2>Will, Can, Must</h2><p><strong>问题场景</strong>：寻找做事情的优先级和边界</p><p><strong>图形结构</strong>：</p><p><img src=\"https://static001.geekbang.org/resource/image/a0/55/a0a231d04ae7cf66845ef0e45095e855.jpg?wh=1444x1093\" alt=\"\"></p><p><strong>基本解释及使用</strong>：一个人或者一个公司，都会有想做的事（Will）和自己能做的事（Can）和我们必须要做的事（Must），那么我们可以通过这个框架和团队一起头脑风暴，找到我们做事情的优先级。</p><p>我们可以做而且必须做的事情，要马上去做；我们可以做而且想要做的事情，其实可以不着急去做；我们想做而且必须做，但是能力不够去做的事情，我们就要寻找解决方案。</p><p>当然，这三个方向的交集就是我们最高优先级要做的事情。在我们的团队能力提高之后，我们“能做”的这个圈就会越来越大；随着我们业务规模的扩大，我们必须做的事情会变多；随着我们公司市值和愿景上升，我们想做的事情也会越来越多。所以这三个圈中间的交集交得越多越大，我们公司和个人其实发展得也就越好。</p><p><strong>进一步分析</strong>：每一个人想做的事和他能做的事以及他必须要做的事三者之间，往往很难取得最终的一致，但我们不断加强自己的能力，最终会是我们可做和必做事情越来越多，越来越容易（下面两个圈交集变大），这样才能有时间把想做的事情完成，这也就是我们一直学习的原因吧。</p><h2>小结</h2><p>到这里，我已经把我最常用的15个数据分析思维框架分享给你了。注意你在填内容的时候，尽量利用前面我们学过的知识，不要简单写一些定性的语句，要用定量的方法填写出来，这样才能发挥这些框架最大的价值。</p><p>其实常用的还有很多分析思维框架，例如STP、双因素理论、PEST、价值链分析等等，同样，我会把我在整理分析思维中还会用到的一些思维图整理在<a href=\"https://pan.baidu.com/s/1XLKbWl9Bua7AAsxcRwH-wA\">这里</a>（提取码 vdx4），不断去更新。</p><p>到这里，本章的内容也就结束了。不知道学完了这章的内容后，你再拿到一个分析问题，可不可以找到一些逻辑来梳理自己的思路了呢？其实，数据分析有非常多的路径和方法，我给你讲的只是千万道路中的一种，如果你熟悉思维框架的话会知道我的分析思路是基于<a href=\"https://zhuanlan.zhihu.com/p/414694356\">TAPS思维</a>衍生出来的，当然你还可以用<a href=\"https://zhuanlan.zhihu.com/p/414571085\">PREP思维框架</a>衍生的分析思路。</p><p>其实无论使用哪种方法，记住，最终使用数据的是人，数据和这些思维框架都是用来帮助你看穿事情本质的，不要被眼前的数据所迷惑，不要迷信于工具，不断探索追求实质，这才是数据分析人的最终归宿。</p><p>数据给你一双看透本质的眼睛，最重要的还是我们的头脑，希望你可以成为一个数据分析的老中医。</p><h2>课后思考</h2><p>你还遇到哪些特别好的思维框架吗？欢迎分享出来，我将来也可以补充到这门课里。</p>",
                "article_title": "26 |  数据分析：15种数据思维图（下）"
            }
        ]
    },
    {
        "chapterTitle": "分析工具",
        "children": [
            {
                "title": "27 |  我常用的数据分析工具图谱",
                "id": 424564,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>从今天开始，我们就要进入“分析工具”这一章了。在这一章里，我会给你分享一些拿来就可以用的工具以及这些工具最新的一些动态。</p><p>不过说到数据分析工具那可太多了，从个人数据分析工具一直到最后大型企业的大数据平台，各种分析工具千差万别。所以这节课我尝试抽丝剥茧，给你分享我曾经使用过的一些数据分析工具在企业里用到的终极架构，用幼儿园、中学一直到博士来给你类比从一个小的数据分析师、数据工程师最后成长为数据科学家/CDO的道路。</p><h2>幼儿园</h2><p><strong>典型场景</strong>：个人数据分析，小公司进行数据统计</p><p><strong>数据团队规模</strong>：0-2人</p><p><strong>关键词</strong>：Excel、SQL Server、云、Power  BI</p><p>在刚接触数据分析的时候，大多数人接触的其实都是Excel。很多人其实看不起Excel，认为这根本就不是数据分析大咖该用的工具。<strong>在我的眼中，Excel是当今小数据分析最好的分析工具（没有之一）。</strong>它所见即所得，而且产品使用非常方便，支持各种各样的定制化的展示，还支持简单的数据挖掘算法。</p><p>我曾经在工作中遇到的很多看上去非常复杂的数据分析案例，其实都可以用Excel手到擒来，不需要动用特别复杂的大数据系统。即使到后期使用了大型的数据挖掘系统和大数据工具之后，在最后数据报告形成阶段，Excel也是非常好用的。</p><!-- [[[read_end]]] --><p>我认为Excel是小数据分析“神器”，所以我在这个课程里专门安排了两节课，来讲讲Excel怎么来使用。用好Excel，在大数据的千军万马之中取敌将首级如探囊取物一般。</p><p>Excel的缺点是它自己的数据量级还不够大，往往十几万条数据可能就会非常慢了。这个时候我们可以通过Excel连接数据库提高效率，最好的组合就是微软的Microsoft SQL Server。当然这需要你掌握一种叫SQL的新语言，它是操作数据查询和数据库必会的语言之一。作为数据分析领域的人员，这个语言是必须要会的。</p><p>当然，现在这个年代如果你对装数据库或者管理数据库不太得心应手也不用担心，现在云计算非常发达，阿里、腾讯、微软都有SQL Server的云，大概几毛钱一个小时。如果你需要处理比较大量的数据，直接可以买一个云上的实例，花个10块钱基本就可以把我们自己大量数据处理完成了。当然如果你是公司级别的使用的或者对数据很敏感的话，可以要求IT部门装上MySQL作为底层的数据库系统。</p><p><img src=\"https://static001.geekbang.org/resource/image/a3/fc/a3b6a45eb4911c7ee08439215fb7e5fc.png?wh=1077x828\" alt=\"\"></p><p>当然如果你觉得Excel处理和展示还不够强劲，微软还有一个个人版本的数据分析神器：<a href=\"https://powerbi.microsoft.com/zh-cn/desktop/\">PowerBI桌面版</a>。它可以前面连接我们提到的Excel、云端的SQL Server或者是其他的各种数据源做数据处理和展示，还支持R和Python，初级使用已经满足小企业日常所需。</p><p><img src=\"https://static001.geekbang.org/resource/image/b4/f9/b4e2b181709aa9f8bfb272f203553ef9.png?wh=1614x1042\" alt=\"\"></p><h2>中学</h2><p><strong>典型场景</strong>：中型传统企业，200+人规模民营企业</p><p><strong>数据团队规模</strong>：5-10人</p><p><strong>关键词</strong>：数据仓库、MySQL、Oracle、Greenplum、Teradata、Informatica、Datastage、Apache DolphinScheduler、Kettle、BO、Cognos、Tableau、QlikTech</p><p>在你数据分析团队规模超过5个人的时候，前面使用的SQL模式就不能完全满足要求了。这个时候一般老板要看相关的企业分析报表，要做整体内部的数据分析，你就要建立所谓的BI/数据仓库系统。</p><p>这个时候我们可以选择使用开源或者收费的系统来建设（这节课我提到的收费和免费的组件都列在附录里了，你可以去参考一下），但我还是建议你不要着急上所谓的大数据平台或者复杂的非结构化系统，因为在这个阶段，企业的小数据往往比企业的大数据要有价值。</p><p>如果有比较简单的互联网相关业务，完全可以使用网上免费的互联网分析系统。这里数据分析人员光掌握Excel和SQL就不够了，需要掌握一种新的语言叫做Python。这个语言也非常简单易学，它可以帮助我们快速处理复杂数据（包括未来的数据挖掘），Python的特点是：</p><ul>\n<li>数据处理简洁明快，Perl的替代品；</li>\n<li>各种数据平台driver都支持；</li>\n<li>支持各种挖掘算法库；</li>\n<li>支持流式计算框架。</li>\n</ul><p>这时候整体系统平台就会分成了三部分：数据存储数据库、数据处理和调度以及数据展示工具。</p><ul>\n<li><strong>数据存储数据库</strong>。可以是前面介绍的SQL Server，也可以是IBM的DB2、Oracle、Teradata、Greenplum、ClickHouse这些工具，目标是将数据存储到数据库里进行相关的调用。</li>\n<li><strong>数据处理</strong>。到这个部分，简单桌面版的Power BI就不够用了，这个时候得是商业版本的Power BI、商业版的Informatica、IBM Datastage，也可以是开源免费的Apache Dolphin Scheduler、Kettle。</li>\n<li><strong>数据展示</strong>。有了数据处理和存储，如何来做整体的数据处理展示呢？简单的Excel和Power BI也不够了，你可以购买商业版本的 Qlik Sense/Tablau/Cognos/BO或者开源的Superset、ReDash。</li>\n</ul><p>下图是一个完整的数据仓库系统，它可以帮助企业从各种各样的内部系统里面抽取数据，最终转换成企业所用的目标，也给各位数据分析师提供坚实的基础。<br>\n<img src=\"https://static001.geekbang.org/resource/image/10/5e/1018927915ea1fcb84f0f55e17dc7f5e.jpg?wh=1756x1027\" alt=\"\"></p><h2>大学</h2><p><strong>典型场景：</strong>中大型传统企业，500+人规模民营企业</p><p><strong>数据团队规模：</strong>人数20+</p><p><strong>关键词：</strong>Apache、Hadoop、Spark、HBase、ClickHouse、Presto、Hive、Kafka、Apache DolphinScheduler、数据挖掘、R、SPSS、SAS、Python MLlib</p><p>到这个阶段一般是中大型企业、小型银行、政府机构以及大部分的传统企业，一般这些企业里都会有20到30个数据工程师或者数据分析专职人员来控制数据。这些企业不满足于只有数据仓库的形式提供结构化数据分析，还会有大量的非结构化数据进入到企业。</p><p>这个时候企业就需要上大数据平台了，因为大部分使用的都是开源组件，一般大数据平台的维护需要3到5个专人维护平台和稳定性。</p><p>提到大数据平台肯定离不开世界顶级的Apache基金会，这是世界顶级的开源组织，现在市面上几乎所有的大数据组件都来自Apache基金会。只要属于Apache基金会的组件你就可以放心免费下载使用，当然，这些项目也有各自的商业版本来减少你的人工投入或者提供更好的功能。</p><p>这个时候数据的来源就更加复杂了，它除了过去企业内部的小数据，还会有用户和企业在互联网上操作的各种各样的大数据（例如网页和App互动日志，采集的视频、语音，网上的各种舆论新闻等）。</p><p>所以这个阶段的数据结构会相当复杂，我在下面给出了在这个阶段的大数据架构图，你可以参考一下。</p><p><img src=\"https://static001.geekbang.org/resource/image/a5/96/a5e778213bab281cc80e3999967e1996.jpg?wh=2000x1125\" alt=\"\"></p><p>这个阶段因为数据的增加，数据源变得越来越复杂，数据的大小也都是Tb级以上的内容。你需要增加对于数据本身的管理（也叫数据治理），比如主数据的管理（也就是到底哪个数据是唯一有效的数据），还有各种各样元数据的管理，这些系统的出现都是为了更好管理内部各种各样复杂系统。</p><p>数据量大了之后，除了我们前面简单的数据展示之外，开始有数据算法基础那一章讲的数据挖掘的应用了。这些数据挖掘应用你可以使用开源的库例如PythonMLlib或者是R，也可以使用一些收费软件例如SPSS、SAS或者云上的一些算法服务。</p><h2>博士</h2><p><strong>典型场景：</strong>超大型传统企业，大型互联网公司</p><p><strong>数据团队规模：</strong>人数100+</p><p><strong>关键词：</strong>融合框架、融合算法、自建开源社区</p><p>到这个阶段一般是超大型的传统企业或者大型的互联网公司，他们将数据贯彻到企业业务过程当中，已经完全融合了数据驱动的思路。内部从事数据的工程师和分析人员规模从一百人到上千人不等，分工明细，从数据平台工程师、数据处理工程师、数据质量部门到数据科学家、数据分析师再到数据运营等岗位一应俱全。</p><p>这个阶段一般公司都会建设内部的数据中台，自主研发自己的展示工具，自己建立自己的推荐算法引擎。它的特点就是针对每一个公司自己的特色和业务，采用自建和外采的混合模式建设自主的数据系统，不会采用某一种技术、某一个厂商来全面覆盖自己企业的需求。</p><h2>小结</h2><p>在本节课里，每一张架构图里会有各种各样的数据组件，我把这些大数据组件的名词解释列在了附录里，你如果有不清楚的地方，可以到附录里对照参考看一下，丰富自己的知识储备。</p><p>这节课讲到这里其实已经把全球最先进的科技技术分享给你了。最后我们还是回到这门课的初衷：数据分析不是为炫技而生。</p><p><strong>不要追求在企业小学阶段的时候就要用博士的方法来解决问题。克制住对最新技术的冲动，在合适的场景用合适的工具，才能够创造最大数据驱动的价值。</strong>真正数据分析的高手往往是心中有剑，手中无剑，用一个Excel也可以分析出惊世骇俗的数据结论。</p><p>不要只是追求手中工具技术的先进性而忘掉了数据分析思维，外行看的都是数据工具的热闹，内行其实看的是数据分析思维里面的这些门道。</p><p>数据给你一双看透本质的眼睛，数据分析思维是无招胜有招。</p><h2>课后思考</h2><p>你还遇到过哪些比较好用的数据分析组件？分享出来，我们一起提高。</p><h2>附录：数据组件名词解释表</h2><p><strong>Excel</strong>： 微软Office套件里面专门针对数据处理的组件，有云同步的Office  365和本地的Office版本。（<a href=\"https://www.office.com/\">https://www.office.com/</a>）</p><p><strong>SQL Server</strong>：微软的数据库系统，在阿里云、腾讯云以及微软的云上都有按时和按需购买的实例。（<a href=\"https://www.microsoft.com/en-in/sql-server/\">https://www.microsoft.com/en-in/sql-server/</a>）</p><p><strong>云</strong>：不用安装软件直接订阅使用相关的公有云服务，典型的有AWS、Azure、阿里云、腾讯云、华为云。</p><p><strong>Power</strong>  <strong>BI</strong>：微软的数据处理和数据展示套装，桌面版是免费的，云版和服务器端是收费的。（<a href=\"https://powerbi.microsoft.com/cn\">https://powerbi.microsoft.com/cn</a>）</p><p><strong>数据仓库</strong>：传统数据存储的小数据比较集中的地方，将企业内部所有的格式化数据全都聚集到一起，方便数据分析师和内部决策者进行辅助决策。</p><p><strong>MySQL</strong>： Oracle公司免费的小型的数据库系统。(<a href=\"https://www.mysql.com/\">https://www.mysql.com/</a>)</p><p><strong>Oracle</strong>：Oracle公司大型的数据存储和数据库系统，也提供Oracle的云上服务。（<a href=\"https://www.oracle.com/in/index.html\">https://www.oracle.com/in/index.html</a>）</p><p><strong>Greenplum</strong>：Pivotal公司的开源的数据仓库、存储系统。（<a href=\"https://greenplum.org/\">https://greenplum.org/</a>）</p><p><strong>Teradata</strong>：收费的软件和硬件一体化的数据仓库系统。（<a href=\"https://www.teradata.com/\">https://www.teradata.com/</a>）</p><p><strong>Informatica</strong>：收费的数据处理和数据调度系统。（<a href=\"https://www.informatica.com/\">https://www.informatica.com/</a>）</p><p><strong>Datastage</strong>： IBM公司收费的数据处理和数据调度系统。（<a href=\"https://www.ibm.com/in-en/products/datastage\">https://www.ibm.com/in-en/products/datastage</a>）</p><p><strong>Apache</strong>：全球顶级的开源基金会，旗下所有的软件都是开源可以免费使用，大部分大数据组件都是来自这家开源基金会的组建。（<a href=\"https://Apache.org\">https://Apache.org</a>）</p><p><strong>Apache DolphinScheduler</strong>：中国人贡献的阿帕奇基金会的免费可视化大数据调度系统，可加微信Leonard-ds进入社区。（<a href=\"https://dolphinscheduler.apache.org/\">https://dolphinscheduler.apache.org/</a> ）</p><p><strong>Kettle</strong>：免费的可视化数据调度系统。（<a href=\"https://github.com/pentaho/pentaho-kettle\">https://github.com/pentaho/pentaho-kettle</a>）</p><p><strong>BO</strong>： SAP公司收费的BI数据展示系统。（<a href=\"https://www.sap.com/india/products/bi-platform.html\">https://www.sap.com/india/products/bi-platform.html</a>）</p><p><strong>Cognos</strong>： IBM公司收费的BI数据展示系统。（<a href=\"https://www.ibm.com/products/cognos-analytics\">https://www.ibm.com/products/cognos-analytics</a>）</p><p><strong>Tableau</strong>：收费的BI展示系统。（<a href=\"https://www.tableau.com/\">https://www.tableau.com/</a>）</p><p><strong>QlikTech</strong>：收费的BI展示系统。（<a href=\"https://www.qlik.com/us/\">https://www.qlik.com/us/</a>）</p><p><strong>Hadoop</strong>：开源免费的大数据存储和处理系统。（<a href=\"https://hadoop.apache.org/\">https://hadoop.apache.org/</a>）</p><p><strong>Spark</strong>：开源免费的新一代大数据处理系统框架。(<a href=\"https://spark.apache.org/\">https://spark.apache.org/</a>)</p><p><strong>HBase</strong>：免费开源的大数据列存储的系统。(<a href=\"https://hbase.apache.org/\">https://hbase.apache.org/</a>)</p><p><strong>ClickHouse</strong>：开源免费的数据即时查询系统，单表性能全球最佳，可加微信ClickHouseC进入社区。（<a href=\"https://clickhouse.tech/\">https://clickhouse.tech/</a>）</p><p><strong>Presto</strong>：开源免费的数据即时查询系统(<a href=\"https://prestodb.io/\">https://prestodb.io/</a>,<a href=\"https://trino.io/\">https://trino.io/</a>)</p><p><strong>Kafka</strong>：开源免费的消息、中间件系统。(<a href=\"https://kafka.apache.org/\">https://kafka.apache.org/</a>)</p><p><strong>R</strong>：开源免费的数据挖掘算法系统。(<a href=\"https://www.r-project.org/\">https://www.r-project.org/</a>)</p><p><strong>SPSS</strong>：IBM收费的数据挖掘及数据处理系统。(<a href=\"https://www.ibm.com/products/spss-statistics\">https://www.ibm.com/products/spss-statistics</a>)</p><p><strong>SAS</strong>：收费的数据挖掘系统。(<a href=\"https://www.sas.com/zh_cn/home.html\">https://www.sas.com/zh_cn/home.html</a>)</p><p><strong>MLlib</strong>：免费的开源的数据挖掘算法库。(<a href=\"https://spark.apache.org/mllib/\">https://spark.apache.org/mllib/</a>)</p>",
                "article_title": "27 |  我常用的数据分析工具图谱"
            },
            {
                "title": "28 | 让你数据分析瞬间提效的18个基础功法（上）",
                "id": 425246,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>上一节课给你讲了最新的数据科技技术，你会不会感觉已经跃跃欲试了？其实在我们日常的工作和生活当中，往往你需要基于小数据快速做出一些决策和分析，所以我们使用最频繁的不是这些高深的大数据平台或者算法平台，而是Excel这个数据分析的神器。</p><p>我原来以为很多人对这个东西应该非常熟悉，但后来我和我的数据分析团队算法工程师以及管理团队交流时，才发现大家对这个工具的使用方法还停留在最简单的输入和简单计算阶段，很难发挥出它在实际数据分析中的真正实力，这在某种程度上也会造成我们管理、开发效率低下。</p><p>所以在接下来的这几节课里，我准备专门针对Excel的功能给你做一下普及，把我最常用的一些技巧和我认为无论你是做管理或者做数据分析都有必要学的一些知识点梳理出来。相信你学习完以后就会事半功倍，让Excel成为你数据分析的神器。</p><p>为了让你能快速掌握，这几节课我都准备用视频辅助讲解的方式来进行。我会在文字稿中把使用的场景和大概的技巧简单给你介绍一下，具体如何使用，请你看下我给你录制好的手把手视频，保证你一看就会，一试就通。那话不多说，我们直接开始吧！</p><h3>1.我常用的快捷键</h3><!-- [[[read_end]]] --><p>首先给你介绍一下我常用的Excel里的快捷方式。我知道这方面的文章特别多，往往能够介绍好几十种快捷方式，但其实真正常用的就是我在下面要给你介绍的这4种，记住这几个快捷键，他们可以帮助你快速提高你的工作效率。</p><ul>\n<li>下拉自动填充：多种双击自动填充的方法；</li>\n<li>单元格里如何换行：Alt+Enter；</li>\n<li>自动重复上一个动作的快捷键：F4；</li>\n<li>去除科学计数法的符号：单引号。</li>\n</ul><p>我来给你演示一下。</p><p><video poster=\"https://media001.geekbang.org/6afdeed0520b4ca498e0d54b9223d544/snapshots/6630d0f9aaa7406fb5ae85fcf95a076c-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/48c530a3-17c68f2f4e0-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/8bfa917199954b65bde619311ce97c3f/68891c438efd4ae5b9f8b489653a5d5d-dee3aaf48247fdc566c5b4312a42cf85-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>2.多选重复录入</h3><p>很多时候我们在做Excel的时候，只知道选择某一个单元格来做处理，其实Excel有非常强大的选择能力，能够选择某些同样类型的单元格，然后统一输入某些公式或者数字，比如我们会把一些空的单元格输入某个数字或者公式。</p><p>这件事情怎么来做呢？我们可以用F5和Ctrl+Enter来解决这方面的问题，详情我来给你演示一下。</p><p><video poster=\"https://media001.geekbang.org/764b80bf133646b4b0da4b98703b069d/snapshots/4d636d77d0874b919e5ea0c32ce5aefc-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/46e35974-17c68f2f1bb-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/da9b9e94faac46d893e14358de9061ee/b0d61e09f513483b98dcf70fdb42f236-9c673a450fafaff485fe6c72c5641e3a-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>3.神奇的智能填充</h3><p>我们经常会需要去拆分一些有规律的格式，比如说我们想从身份证号来拆成出生日期，或者把一堆内容加上书名号或者引号，这个时候怎么办呢？</p><p>程序员肯定告诉你要么就得一个一个往里敲，要么就得通过复杂的字符串公式才行。但其实Excel有一个非常方便的方法叫智能填充（使用 Ctrl+E），它可以非常方便地寻找到前面的字符规律，自动给你填充进去。</p><p>你可以看一下我视频当中的这个例子，你会惊奇地发现原来Excel这么智能，当然如果这种规律Excel无法发现的时候，你就要用我们下节课会讲到的第15种技巧字符串函数来处理了。</p><p><video poster=\"https://media001.geekbang.org/23ffaf6a4406406788157c0903cc4e3f/snapshots/759def8d61764c68ad12d7f88674e08c-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/60e05b03-17c68f2ed05-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/313fc733d1064dcabce67dee2639db67/136d1e49c4da4e9cad313d018f711427-49293b1dadf056e47056d1c4b5674bd0-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>4.相对位置、绝对位置</h3><p>你在使用Excel公式的时候，经常会在里面写一个公式，然后在单元格里面加一个等号，去选择某几个单元格相加或者使用某种公式计算。这时候你使用的是相对位置，也就是它会随着你的单元格变化，里面的单元格引用公式也会发生变化。</p><p>在这种情况下，计算某些汇率、单价到总价的时候就很麻烦，怎么办呢？你可以使用绝对位置来解决这些特殊的情况的问题，你可以参考一下这段视频。</p><p><video poster=\"https://media001.geekbang.org/6f3e97d0f5a14e4f8658005de8be7496/snapshots/43edc2c1765742d693e468f396bb5fb0-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/20125137-17c68f2e6f3-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/a78be336a52146ce807e6fe78d2698f8/974b28d3a8164107a80ce62bf545014f-3afc0d8034cb8ece7e75726f5271d18a-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>5.单元格合并、解除合并自动填充</h3><p>我们经常会拿到一些中国式报表的数据，里边有各种各样合并单元格的数据，但是我们在使用公式和其他进行计算的时候，这些合并的单元格反而影响了我们的整个计算过程（因为它们除了第一个单元格有数值，其它都是空的）。怎么样能把这些合并的单元格全都把它填上数据呢？这里面就有一个非常有意思的技巧，你可以看看下面的这个视频。</p><p><video poster=\"https://media001.geekbang.org/32b4ba0ea43c4ca4af0fa86cb92bc49c/snapshots/6538d29cdc714480b44c15b4f7c4f903-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/5d65cb65-17c68f2e298-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/ae81651cb3bf4ea6885776982d114591/ffad74828c5d4d92a48e0b45cb929e6e-06ddd98ed7b6492ea248d0cd68fcfa7f-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>6.自动分列</h3><p>我们经常会拿到一些数据，这些数据不是所谓的csv格式（也就是逗号分隔的），而是有一些奇怪的分隔符号，有的是Tab符号，有的是竖线。我们现在希望是最后拆完以后变成每一列可以做数据处理的样子，这里就会用到Excel分列的功能，具体我来给你演示一下。</p><p><video poster=\"https://media001.geekbang.org/cfd4e165cb81464f817347e1dc120afd/snapshots/ca360367f1774e9a83d81391bf03fd48-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/12a71093-17c68f67bd5-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/f8d781a6b11646cd81e85c748646fed9/520b34be2d4b4a5e826b03b65f799396-f628038c758be0ac7f2e9eae0d20e931-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>7.求和技巧</h3><p>接下来给你讲讲求和技巧。你可能会说求和谁不会，你现在已经不用一个个单元格去加了，直接会用SUM这个函数求和。但其实我要和你说，这个技巧也过时了。</p><p>其实，你直接选择要加和的单元用Alt+=，就能把这个问题解决了，而且加上我们上面讲的第2个技巧，你可以快速解决多个小计的求和问题，绝对是求和公式里的战斗机。下面我来给你演示一下高手的求和是怎么做的。</p><p><video poster=\"https://media001.geekbang.org/103925fbf8f646f0b6313af4ca468aa3/snapshots/be8edfe0fd084e23a77fd25fe013ae0d-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/5b8ad7dc-17c68f6783e-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/ea968e9d5a334f5985bbcc96c7460e7d/114b5f96152746279ee20d828709850a-f62296aafdc24a7302f5fbfe7715490b-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>8.数据过滤和排序</h3><p>很多小伙伴会用数据过滤，也就是筛选一下某几个特定值相对应的行进行统计和分析。但其实Excel的数据过滤里面有非常复杂的条件逻辑，例如大于某一个数值、包含某一个单词，或者你可以有好几个条件把它相互进行合并。</p><p>而排序也不单单局限于简单的针对某一列的排序，你可以有主排序的列以及第二排序序列和第三排序序列。在一些数据有重复值的时候，你可以非常方便去找到合适的排名，具体方法我来给你演示一下。</p><p><video poster=\"https://media001.geekbang.org/affd16f6d1424d61af85dffa85bc7343/snapshots/79b50157d0ca4ad08eddac49c4aafec9-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/20d1b562-17c68f6729f-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/287bfa5be940416b9032ad22816727c5/6cc2f91f7a0f43329c3ad8347fc31c4a-6ee0c07bb744ac1c479666549f070748-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>9.最大值、最小值、次大值、次小值</h3><p>想要找到一个列里面的最大值和最小值是有专门的函数能直接得出的，这并不稀奇。但其实你可能并不知道，Excel能非常方便地取得这个列里面的第n个次大值或者第n个次小值，也就是它不仅仅可以帮你找到冠军，还可以帮你找到亚军、季军。怎么样才能够去实现呢？我来给你演示一下。</p><p><video poster=\"https://media001.geekbang.org/6cdd5a11a6d94bcc8ca6985c0d090368/snapshots/db4aaa6dc2f44de1bd62b63ad4e593cb-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/5d0eac80-17c68f66f86-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/b98d267a94b94e0cb611fd0ced10c5e0/ca5949f94e60438c9c132358ff254754-ff1582a97f927f0544c58b1a0bf6e9ff-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>10.选择性粘贴</h3><p>说到复制粘贴我们都不陌生，这太简单了，就是Ctrl+C加Ctrl+V。但其实在Excel里面，复制粘贴有非常复杂的一些用法。你可以只复制公式过去，也可以只复制数值过去，甚至你可以通过选择性粘贴，把一个横表转成纵表，我来给你演示一下。</p><p><video poster=\"https://media001.geekbang.org/1ac71786bb854f3fbf80912e8ebeb315/snapshots/9bc0a492acfb498ba874986fef59cf6c-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/4efe1650-17c68f66ada-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/d8d3973e4ceb4e4d8639c1fbccb86e36/15e55f7c2c194756ab64cfe8a9537724-35f4719b5fd74069a8ff8f015545f763-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>11.保留某几位小数</h3><p>说到某个数值（例如金额）保留到几位小数，你可能第一个感觉会是使用Excel里面的单元格格式去设定一下小数位，但是这种方法会在使用计算公式的时候会出现一些偏差。比如你显示的是两位小数，但其实背后它是一个10位的小数，那么你在进行其他计算的时候，它会按10位小数计算，就出现一些细微数据不准确的情况。</p><p>所以为了避免这种情况发生，我们往往会通过公式把它变成最后只保留两位的形式。这种保留小数有两种方式，一种是直接去掉所有的小数向下取整，还一种是你常见的四舍五入，具体方法我在下面的视频会给你演示一下，希望你记住。</p><p><video poster=\"https://media001.geekbang.org/9edbfbb5724a48878e8ac55d0642f6d1/snapshots/7cfbf2e40a9442dab2674b24518560f1-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/aff3947-17c68fa0e36-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/300c85d3d22c482c8e277218910da533/7b162c809bab420d907aaa7ddbefdcbb-626484526b740aa0dec4e04c6b593790-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h2>小结</h2><p>这节课到这里，我相信即使你是文科生，学了这几个技巧，你也会发现原来复杂的数据处理也并不是理工科学生的专有特长，你也可以做一些快速的数据处理。而如果你是理科生，你会发现原来并不是所有事情都要编程序来实现的，Excel几个按键就可以代替你编一大段程序，所见即所得。</p><p>另外再小小预告一下，下节课我会给你介绍一些Excel更复杂的例子，基本上用了Excel，在它数据处理量级范围内，你可以忘记数据库编程了。套用一个网络用语，对，小数据分析神器Excel，它就是什么神奇！</p><p>数据给你一双看透本质的眼睛，想要快速处理数据的其实只有一句话：“无他，但手熟尔”。</p><h2>课后思考</h2><p>你还有哪些觉得比较好用的Excel快捷键和简单小技巧？分享出来，大家都觉得不错的，我会加到将来的加餐里。</p><h2>参考资料</h2><p>你可以点击<a href=\"https://pan.baidu.com/s/1DqC7GNgq9DYXOfo-U0BvwA\">这里</a>（提取码hnwf）获取我们这节课的Excel文件，方便你进一步学习。</p>",
                "article_title": "28 | 让你数据分析瞬间提效的18个基础功法（上）"
            },
            {
                "title": "29 | 让你数据分析瞬间提效的18个基础功法（下）",
                "id": 425765,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>上节课我给你讲了做Excel的初级技巧，你在日常使用中绝大部分都会用到。而如果你想要成为Excel高手，还要掌握下面的7种技巧。</p><p>从第12个技巧开始，这些就会是稍微复杂的Excel的公式使用方法了，这些方法可以帮助你在不使用数据库和编程序方法的情况下，使用Excel来处理非常复杂的一些计算逻辑，帮助你解决日常当中遇到的一些复杂问题。</p><p>不要担心，这些并不是Excel里最复杂的“宏编程”，不需要你掌握复杂的编程知识，我用的都是比较简单的例子和方式，让你一看就会一学就懂，通过学习很少量的技巧，助你快速成为一个Excel专家。</p><h3>12.条件分支计算</h3><p>我们在日常工作当中经常会遇到某一些数据在某种情况下我们按照这种方法计算，在其他条件下又按另一种方法计算。比如对于计算销售提成来说，大多数公司都是在某一个价格范围里是按照一个销售提成计算，在另一个价格范围里，按照别的销售提成计算。这个时候怎么在Excel里面去处理呢？这就用到了Excel的条件分支计算。使用起来很简单，把逻辑直接写在Excel单元格的公式里就可以。</p><p>有时你在进行Excel计算的时候，还会遇到一些数据出现错误表示#ERROR、或者是出现空值#NA的情况，这时候再进行求和、求平均值等复杂公式计算的时候，你经常会因为这一个数字把一群数字的值都无法计算出来，这样就非常的讨厌。我告诉你，你也可以通过条件分支的情况把这个问题解决掉，具体解决的方法我给你演示下。</p><!-- [[[read_end]]] --><p><video poster=\"https://media001.geekbang.org/47c052469dfa4c33991a99f45bfa61d6/snapshots/8275ecf2a10149c1839546d16f9bb325-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/ff9492-17c7256c746-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/16b42f757fbb4176b00edb5a6dd99270/2697ce8ea744492da2393c2a75384c65-57378820f8d2f1ed960bc93925be5804-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>13.统计个数</h3><p>我们经常会统计某一个时间段里的数量是多少，比如我们进行正态分布曲线统计的时候，你就要分片分段来统计不同分段里面的数据分布情况，又或者你去统计某一个班里面不同分数学生的整体情况，也要计算不同分数段不同学生的占比。这个时候我们就会使用统计个数的函数FREQUENCY，使用方法可以参考我给你演示的视频。</p><p><video poster=\"https://media001.geekbang.org/02f8c8a964aa4e7a90da193f4432818e/snapshots/0a3e9e0a9d5c45b28fa1a43993c9af36-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/58e8e588-17c7256c227-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/173570cdb30f4101b6be80adc97684ac/6ec10af6c55144b7b0ca0e7c847ceed1-682ca470476d0dac7e6fdd8d9f1595b2-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>14.去除重复值</h3><p>在使用数据的时候，我们经常会发现给的数据里面有一些重复数据，那么在进行数据统计的时候，我们要做一些去重的处理。有的时候这些去重的处理还不是简单地把重复数据都去掉，而是把一些姓名、身份证号相同，但是可能其它某些列属性不同的数据，按照一定规则分别去重。</p><p>这个时候我们就会有简单和复杂的两种去重方法，下面这个视频就是给你介绍这两种去重方法的，对，在Excel里的去重要比数据库里的Distinct还强大。</p><p><video poster=\"https://media001.geekbang.org/160ec6cd89c04b86b2de204c49741ccc/snapshots/48f17fc157004935bc71d62bdcf8d7e5-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/46846d28-17c7256bc26-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/164b86d3fa724022b031dc81a90cced2/b16ebeeaf8ff4cee9280570bf5616de2-1f4cea3dd1433791becea8a38ca8eb5f-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>15.字符串处理函数</h3><p>前面给你讲过一个自动填充的技巧，它可以帮助我们找到一些字符之间的关系，然后自动帮你做填充，但是在某些复杂的情况下的时候，Excel无法找到比较好的规律能够自动填充。这个时候你就需要掌握一些基本的字符串的处理函数来帮你去做一些复杂的字符处理。</p><p>例如我们想把手机号码当中的4位变成星号其他位不变，以确保我们的隐私保护，这个时候你就可以使用字符串的函数来方便地解决这个问题。具体方法可以看一下我这个演示，我把最常见的几种字符串使用的函数用比较简单的方法给你讲解了一下。</p><p><video poster=\"https://media001.geekbang.org/2bfbaf83bd44454ab7a39add4a5037f7/snapshots/4382e21e004d4ced9c552ef90aae2547-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/19cf1845-17c7256b50c-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/eb8e186ea7084f329c3a0a2af9e4d6d1/c48ac82904d74d99af3026848c075009-65b26d2e1080a57f7d03a83d5748bd3d-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>16.数据匹配函数-VLOOKUP</h3><p>VLOOKUP这个函数是在Excel里面区别普通使用者和高级使用者的一个重要函数，它可以帮助我们在大量数据当中取得我们想要找的相关数据。</p><p>有时候我们也把这个函数用来做数据的比对，例如有两列，我们看看到底这两列中间哪些数据是两边都有的，哪些数据是没有的，我们会使用这个函数来做一下检查。在数据库编程里，我们叫做“关联”。Excel里用这个函数要简单得多，你看了我这个演示，一定可以把它记牢、使用好。</p><p><video poster=\"https://media001.geekbang.org/c62ae24fc15b4fd5bbea39d0b2fd92f0/snapshots/097312625bcd48bc98763962c470eeb4-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/14e0b1b-17c7256ad1d-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/deb06865f5c14a1da48803fe58468b92/33472032f70640a18ea8674ab3de056f-492e6a9969c9d0ac845f798e9a54aafd-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>17.分类汇总和统计</h3><p>我们经常会遇到要在某些分组里做统计，例如从省的维度来统计各城市的销售汇总以及销售的个数，或者是从全国的角度看各省汇总的情况。如果你会SQL，那你就知道我们可以使用数据库里一个叫做GroupBy的方法来取得这些明细数据的分组汇总值。</p><p>其实你不用把数据放到数据库里，在Excel里也可以快速获得这些汇总值，而且公式使用起来也相对简单，具体我来给你演示一下。</p><p><video poster=\"https://media001.geekbang.org/626401eedb394467a4cf842106ef5e08/snapshots/82cb09a101fc49c08b7be42d327bce0e-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/5d9f6e04-17c725c5a16-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/bff1a803396e4f228eea88c3af682baa/0a67d61bf86b4559b5a9ca424b5b0544-255fe31951d49edf7c2aa10d0e489704-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h3>18.数据透视表（图）</h3><p>在Excel里我们经常会面对一个非常明细的数据，想看到它分门别类的汇总或者是基于时间线的一些趋势，从而来做一些数据探索。</p><p>这时候我们就需要既可以分层汇总，还可以去过滤某些条件来针对某些情况下的一些数据进行深入探索，同时我们还希望能够用到Excel的柱状图、折线图、饼图等一些方便的图形辅助我们进行深度的数据探索。</p><p>这种情况下，数据透视表和数据透视图就应运而生了，它可以帮助我们在明细数据里面快速建立一套简单的数据分析视图，能够让你通过简单的拖拉拽快速进行数据探索和图表的生成，从而帮助发现这些数据当中隐含的规律。具体使用方法，你可以参考我这个视频当中的讲解。</p><p><video poster=\"https://media001.geekbang.org/d59ab9a5312d4a8c88634d122c368499/snapshots/920afac6cbcf43c8a39bd2e3f38e400c-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/4918d823-17c725b04ae-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/fd1b92e39a484b48bf9ad8954be12b88/a82b78477744402bb9e397afcfeef77c-72cf4e808c000306cbdb12d0b5b91ad3-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h2>小结</h2><p>到这里，我就把我自己最常用的18种Excel使用技巧教给你了。不知道你发现没有，我们没有像很多Excel课程一样，事无巨细地把所有技巧全都罗列出来，因为我觉得在日常数据分析当中，并不需要记住所有的Excel功能，并且这也是不现实的。</p><p>我介绍的这18种技巧是我和团队在做数据分析的时候，最常用的18种技巧，真的希望你可以通过视频的讲解深深记住。18种其实并不多，我相信你只要花点时间，用心记一记，一定可以掌握。如果你掌握了这18种技巧，在你工作和生活中真正使用的时候，你会发现它可以在你的数据分析、日常管理、自己个人财务分析等诸多方面有非常大的帮助。</p><p>数据给你一双看透本质的眼睛，熟练掌握一种得心用手的数据分析工具，比你只是“会”10种数据分析工具要强大得多。</p><h2>课后思考</h2><p>还有哪些Excel函数你常用的？使用场景是什么呢？分享出来，我们一起提高！</p><h2>参考资料</h2><p>你可以点击<a href=\"https://pan.baidu.com/s/1DqC7GNgq9DYXOfo-U0BvwA\">这里</a>（提取码hnwf）获取我们这节课的Excel文件，方便你进一步学习。</p>",
                "article_title": "29 | 让你数据分析瞬间提效的18个基础功法（下）"
            },
            {
                "title": "30 | 快速实现数据分析基础课中的分析模型",
                "id": 426662,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>数据分析思维课不仅是讲理论，我们还要实践。所以这节课我们来把前两节课讲过的18个技巧再进行一下实操，我们回到前面课程里的实例，看看这些技巧在真正实践当中是怎样使用的。</p><h2>实践1：平均值</h2><p>首先回到我们的<a href=\"https://time.geekbang.org/column/article/400764\">平均值</a>这节课，你能看到课程里面有这样的一张图，这张图由若干个柱状图和一条平均线组成，其中柱状图的平均线是由Excel自动计算出来的。那么我们怎样用Excel来实现呢？你可以看一下我视频当中的操作方法。</p><p><img src=\"https://static001.geekbang.org/resource/image/ca/cc/cab04b2d4f07677f92e380dd2bf092cc.png?wh=1460x929\" alt=\"\"></p><p>视频演示：</p><p><video poster=\"https://media001.geekbang.org/cad78a8e28034a17a5d6abe13676b8a3/snapshots/830b35679e3f49a4a2e646203af04837-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/1c54415e-17c7df18cf7-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/83972a73f3ff49999a5e47b18d0661a5/77617331f3b143d0b2d50351a06d3ade-54ba9fa1658bac699e90d62f64224683-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>你要注意，在画这个图时要注意以下几个重点：</p><ul>\n<li>所有的柱状图的间距都是要调整的，否则每个柱状图都会变成豆芽菜的形状，非常难看；</li>\n<li>数据标注时一定要做颜色位置调整；</li>\n<li>平均线其实Excel是无法自动计算出来的，所以我们需要用组合图的方式把平均线通过折线图加入进来。</li>\n</ul><h2>实践2：直方图与幂分布</h2><p>我们接下来看第2个实践案例：画直方图。你可以看到<a href=\"https://time.geekbang.org/column/article/404779\">第5节课</a>的数据图形是下面这个样子的。</p><p><img src=\"https://static001.geekbang.org/resource/image/ab/70/abf6c16bdb3c8dbda520a62b373de970.png?wh=632x441\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/27/a4/27c7768186433dbc5ffa74fb79b2a1a4.png?wh=1164x706\" alt=\"\"></p><p>这两张图其实都是由柱状图组成的。第一个直方图是我们使用的是事后统计出来的数据，所以不能用Excel自带的直方图进行绘制。</p><p>第二个图是网上的大量数据先通过Excel的数据透视图，再选择相应的指标维度并进行排序，最后找到相关的趋势线就完成了。我在视频里的操作其实是非常快的，这是因为这些技巧我已经非常熟悉了，当然，你不妨参照我的视频一步一步做一遍，你也一定可以和我一样熟悉这些技巧。</p><!-- [[[read_end]]] --><p>视频教学：</p><p><video poster=\"https://media001.geekbang.org/a7772cc6f0944bb5a517ee97251bfdbd/snapshots/63b5fd92b5f6423ba2c6e90ad306c521-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/16156ffb-17c7df3c9db-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/9ad0a00fb5294358b31f75dcf1418687/f52eccc5ba044c4c8fdda63224f7fa73-f17b9dcdc7789652db7e7bf79e71bd67-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>其中重点有这样两个：</p><ul>\n<li>直方图的图距进行了调整，才可以调成我们图中的这个样子；</li>\n<li>数据透视图要选好计算指标，同时在图中可以利用排序和调整图形属性来变成直方图。</li>\n</ul><h2>实践3：数据分布</h2><p>紧接着我们来看一个比较复杂的例子：<a href=\"https://time.geekbang.org/column/article/405241\">第6节课</a>数据分布里面的正态分布曲线。 Excel不能自动生成正态曲线，它需要通过组合图的方式把计算出来的直方图和模拟出来的正态曲线，放在一个图里面进行比对，才可以完成下图当中这个样子。</p><p><img src=\"https://static001.geekbang.org/resource/image/27/52/2739517d5a74cf6f404938cbb8726a52.png?wh=718x437\" alt=\"\"></p><p>你可以看我在视频里面给你做的演示：</p><p><video poster=\"https://media001.geekbang.org/312338c7ef514147b056cf5b908005d8/snapshots/d3fff8386c2d4c3886b1f893a66f08d6-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/247a2fc8-17c7df3a536-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/b3690675c417496e8897d4b17eb48341/c2e238a5eede44f1b0303bdcd0e64b4a-84f21e382ab9d7f8c8f21c48809a7676-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>重点有这样几个：</p><ul>\n<li>使用前面的复杂公式统一填写模式；</li>\n<li>使用拖拽自动生成序号和copy的模式；</li>\n<li>使用Tab键自动填充公式关键字；</li>\n<li>使用复杂的FREQUENCY和标准差、正态分布函数。</li>\n</ul><p>你看我在视频当中操作的过程也是非常快的，你以后在做相关数据分析的时候，也要以这样的速度来处理，这样你的手速才会跟上你的思路，更快更好地做好数据分析。</p><h2>实践4：散点图和相关性</h2><p>我们在<a href=\"https://time.geekbang.org/column/article/406706\">第7节课</a>的时候讲过，Excel不仅可以非常方便地画出散点图，还可以在Excel里面给出相应的趋势线预测。</p><p><img src=\"https://static001.geekbang.org/resource/image/50/d4/50f15f6b7d8b41b59b68627426b3f2d4.png?wh=1385x971\" alt=\"\"></p><p>在下面的视频演示中，我会给你讲一讲上面这个散点图是怎么在Excel里绘制出来的，同时我还会和你分享如何去选择一个比较好的趋势线来说明这些散点的大方向和趋势。你看完这个视频就会发现，Excel在做小数据分析的时候真的非常方便，从趋势线的模型选择到散点图的调整其实都已经帮你设置好了。</p><p>视频教学：</p><p><video poster=\"https://media001.geekbang.org/b32c484a74d14350b1085a99dab9e55f/snapshots/9dc9f26f87624586a5369c44be3ab712-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/d06920a-17c7df16dd6-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/107bf8ffe0a1429cbdad86c36ab66712/772de630b229400a8c20d7845d20a0c5-47c218b36040826585de96e80b211016-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>重点有这么几个：</p><ul>\n<li>散点图 X、Y变量设置；</li>\n<li>趋势线的选择；</li>\n<li>最后公式的比较。</li>\n</ul><h2>实践5：标准差</h2><p>在<a href=\"https://time.geekbang.org/column/article/407445\">第8节课</a>里，我们讲了标准差和标准误差这两个概念。标准差还可以叫做标准偏差，它可以在 Excel里快速计算出来。</p><p>在Excel里计算标准差时，有两个函数都可以计算出标准差。</p><ul>\n<li>一种是我们认为给出的标准差就是总体的标准差，这个时候我们就用STDEVP函数；</li>\n<li>另一种是用于计算样本估算的整体的标准差，也就是我默认去拿出来的样本是抽样出来的一些数据，并不是我们拿到的整体的所有的人的样本量，也就是用STDEV函数。</li>\n</ul><p>是不是感觉有点绕？我给你举个例子。如果我们全组就5个人，我把所有人都计算进来，计算标准差，这个时候我们就可以用给定样本的总体标准差STDEVP计算公式；如果这一组是500人，我们只抽调了5个人来看看这500人之间的标准差可能是什么样子，我们就会使用估算的整体样本标准差STDEV进行计算。</p><p>具体方法你可以参考一下这个视频：</p><p><video poster=\"https://media001.geekbang.org/c8d83542daed4491b9a48a4ea0582ca7/snapshots/287a69a8e3b14d848471cc3b591e557e-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/33ec10eb-17c7df16996-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/13ed2343e7644e479d71947ee9c31e2f/14eb930a054f41a5bdb4650f98b8065f-fd4a16dad1d5247ffacd3efd92c9b0cf-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>在这个例子里我们的重点是区分来自抽样数据还是全部数据，选择不同的标准差公式。</p><p>通过跟着视频做这些之前课程的案例你能感觉到，虽然我们在前面讲了很多的基础理论和知识点，但这还是不够的。到真正上手实践的时候，你还要区分出来具体的业务场景是什么，然后使用合适的相关的公式才能得到正确的数据，这就是数据分析思维的严谨性所在。</p><h2>小结</h2><p>这节课主要是用Excel来实践一下我们之前课程里的例子，也是二次磨合锻炼一下前面两节课的一些技巧。其实数据分析并不难，但如果你想要快速做数据探查，给出各种各样的数据分析结果，前面介绍的这些技巧你一定要掌握好。否则可能两三分钟演示出来的一个实例，你自己没有很好掌握的情况下，花半个小时都做不出来。</p><p>我们对工具的熟练可以让你的手速跟上你的“脑速”，这也就是为什么我没有用其他的工具，一定要给你讲解Excel的原因。<strong>我们使用大数据算法的时候，往往会把注意力都放到编程当中而忽视了数据本身。我们在做管理决策的时候，往往不是在大数据里面做决策，而是在我们的小数据里。</strong></p><p>这个时候我们要是有一个得心应手的数据分析工具，就可以帮助我们在工作和生活当中得到更好的分析数据结论，更好地贯彻我们的数据思维。影响我们最终决策的，往往是凝聚高信息熵的小数据，而Excel正是处理这方面数据的神器。同样，你可以点击<a href=\"https://pan.baidu.com/s/1DqC7GNgq9DYXOfo-U0BvwA\">这里</a>（提取码hnwf）获取我们这节课的Excel文件，方便你进一步学习。</p><p>数据给你一双看透本质的眼睛，我希望你学完这门课之后，不仅能成长为数据分析的理论高手，更要成为数据分析的实践能手。</p><h2>课后思考</h2><p>我给你介绍这些案例的实践方法只是若干种实践方法之一，你还有没有更聪明的做法？分享出来我们一起提高。</p>",
                "article_title": "30 | 快速实现数据分析基础课中的分析模型"
            },
            {
                "title": "31 |  最先进的数据分析工具展望",
                "id": 427344,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>在第<a href=\"https://time.geekbang.org/column/article/424564\">27节课</a>里，我给你分享了我常用的数据分析工具图谱，我们今天再进一步来看看，到底这些工具图谱里最新的技术工具长什么样子？</p><p>在这节课里我会给你介绍2021年企业里最常用的比较先进的工具，等将来出现了更好的工具，我会在后续的加餐里再做更新。</p><p>整个大数据分析框架离不开三个基础技术部分：数据存储、数据处理和数据展示。接下来我就根据这三个基础技术，选三个比较新的开源免费的工具与你分享，我们一块来看看最新的技术可以达到什么的样子。</p><h2>数据存储与分析引擎——ClickHouse</h2><p>在数据存储的部分，我给你介绍一下现在全球最流行的专门针对数据分析打造的引擎：ClickHouse。</p><p>ClickHouse专门为数据分析师打造。为什么这么讲呢？</p><p><strong>第一，它使用的不是非常复杂的NoSQL编程语言，而是用的很简单的SQL语言，</strong>这样数据分析师、产品经理和运营人员都会非常熟悉。</p><p><strong>第二，它的宽表查询速度非常快，全球第一。</strong>我们做最后数据分析1公里的时候，大多数情况都可以用一个或者几个大宽表来解决问题。传统的大数据工具因为要适配各种情况，经常在数据量增大时，整体数据处理的速度变得非常慢。你往往是要填写一个需求单给数据开发和工程部门，让他们转化成复杂的编程语言，或者在大数据平台上面提交一个任务才行。这样一来少则半个小时，多则数天你才可以拿到你想要的结果。</p><!-- [[[read_end]]] --><p>而ClickHouse这个引擎数秒之内就可以针对百亿条的数据进行复杂的SQL查询。无论是我们需要做分组聚合、明细过滤还是基于文本的条件筛选，它的速度都是秒甚至毫秒级别出结果。这样你在做数据分析的时候，就可以不停地快速进行数据探查，不会打断你的数据分析思路。而不是在提交各种各样的任务后，喝杯咖啡甚至休息几小时之后再看到结果。</p><p><strong>第三，ClickHouse整体部署和维护安装比较简单，在数据量不是特别大的时候，一台服务器就可以搞定，普通的运维人员就可以维护。</strong>对于更复杂的情况，你可以使用集群版或者相关的商业版本来提高维护效率。所以ClickHouse这个数据引擎特别适合做数据分析，现在已经成为互联网公司的标配数据分析引擎了，下图的这些公司都在使用ClickHouse作为它的分析引擎来分析数据。</p><p><img src=\"https://static001.geekbang.org/resource/image/63/de/63fe0d040e134ae247cc1dcd7194e5de.png?wh=1579x620\" alt=\"\"></p><p>那ClickHouse到底怎么来用的呢？我这里举三个公司对外分享的实例，给你分享一下ClickHouse都能干什么。</p><p>首先是喜马拉雅的例子，这是2019年喜马拉雅Alex黄在ClickHouse Meetup的时候分享的案例。你能看到在喜马拉雅，ClickHouse作为一个典型的数据查询平台来使用，它既做用户行为分析，也就是我们网上的各种各样的APP和网络日志的查询；也做用户画像的数据分析，你可以对不同用户画像标签的圈选人群进行人群探查、投放效果预测；它还可以用于各种服务器日志的监控报警，当服务出现问题的时候管理可以快速找到相关问题的原因，整体架构图可以参考下面这个样子。</p><p><img src=\"https://static001.geekbang.org/resource/image/57/d1/57eeeb609bfd89b64966fc7c4ac8e1d1.png?wh=1267x685\" alt=\"\" title=\"喜马拉雅 Alex，Huang 2019.10.27 ClickHouse Shanghai Meetup\"></p><p>下面一个例子我们来看看腾讯音乐是怎么使用ClickHouse的。</p><p>腾讯音乐把ClickHouse作为了实时分析数据仓库，你在使用腾讯音乐的推荐和点击的时候，背后的大数据平台就是ClickHouse来提供的。</p><p>腾讯把数据放到消息队列里，然后通过一个叫做Flink的工具实时装载到ClickHouse当中，同时把一些离线文件传入传统的数据仓库里。最终我们数据分析师使用的数据，看到的是实时的数据，既可以看到上一秒的系统情况，还可以做各种自定义的SQL查询，数据还是秒回。这样帮助腾讯音乐自助进行汇总、筛选查询，也能快速地响应各种各样的原始数据变更。</p><p>其实所有互联网大厂里使用ClickHouse都可以实现针对数据用户日志的秒级查询，不再需要数据运营和产品团队自己跑复杂的脚本任务和处理了。</p><p><img src=\"https://static001.geekbang.org/resource/image/4d/a1/4dc5a8d704f393b1391ec027c4ea88a1.png?wh=1618x728\" alt=\"\" title=\"腾讯音乐 吴泽君 2021.2.6 On-line Meetup\"></p><p>最后一个例子我们来看看新浪。ClickHouse在新浪用于监控整个数据平台。这个例子有意思的地方是新浪每天有300亿条的数据直接进入到ClickHouse平台里，而新浪在做监控的时候是通过算法来进行监控和处理的，每日有800万次的查询，每次几乎是毫秒级返回。</p><p>这就像前面数据算法基础这一章提到的，开始时还是用人在做分析，当技术发展到一定程度，我们就可以通过算法和机器来进行分析。现在的数据底层的技术可以已经可以非常容易地做到用算法取代人工，最终高效地实现整体的数据分析和告警。</p><p><img src=\"https://static001.geekbang.org/resource/image/91/eb/912c91062d4baee0536e7486e37da1eb.png?wh=1366x689\" alt=\"\" title=\"新浪 JackGao 2019.10.27 ClickHouse Beijing Meetup\"></p><p>数据存储还有很多各种各样的引擎，比如Spark SQL、Presto、Impala等等，这些引擎都可以很好地处理数据分析，我只是介绍其中的一种让你体验下最新的数据存储技术是什么样子。</p><p>每个数据分析师可以根据自己数据团队的情况选择最合适自己公司的开源产品来使用，我录了一个视频，让你体会下ClickHouse到底有多快，一台机器，10亿条数据复杂查询4秒就出结果，而同样的数据Presto集群（若干台机器）还要40秒才可以出结果，你要是感兴趣可以关注ClickHouseGroup微信号来看到最新的ClickHouse中国社区 Meetup信息和中文材料。</p><p><video poster=\"https://media001.geekbang.org/396aab910bb4477fa422b9ed339aa67c/snapshots/63283157570044cea76dee6f65ea4a83-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/602a6e4b-17c8cda2d89-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/a9e1e77ef2124ee7b2f40d360b8c0174/78ea006ba8904412908ca831237ab74e-fcbc9982bce42fecaa4e80390deefe80-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><h2>数据处理与调度平台——Apache DolphinScheduler</h2><p>数据我们都已经存储好了，SQL你也写好了，如果这是一个日常都要做的任务，你肯定不希望每次都需要人来运行，它要可以自动调度把数据处理到我们目标的数据表里才是最好。这个时候就需要数据运营平台的数据调度和处理引擎了。</p><p>这里我给你介绍一个我当年主导开源的数据处理与调度平台，它也是一个Apache顶级项目：Apache DolphinScheduler。</p><p>它源于我上一家公司易观给内部数据分析师和数据开发人员使用的调度工具。它的优点是全部是可视化的配置（数据分析师最爱），而且超级稳定易扩展。在数据平台人员安装完成之后，你不需要懂得服务器脚本或任何的大数据平台语言，你只需要拖拽把你熟悉的SQL脚本放到这个调度平台里，把这些表之间的逻辑关系通过连线把它连起来，你就可以得到一个非常方便使用的大数据调度处理流程了。</p><p>底层它采用的是云原生的技术，扩展性和稳定性都是非常优秀的，所以它也是Apache基金会的顶级项目。它在我们数据逻辑脚本比较清晰的情况下，可以不用写代码直接配置。我在下面这个视频演示了几个复杂的脚本之间有逻辑关系，怎么样可以不用编程序来快速实现自动化调度启停。</p><p><video poster=\"https://media001.geekbang.org/eccc1d539e2d45cb894d045066423c38/snapshots/562c007d5a4340ccb188a63f8dd52bf0-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/82ed36c-17c8cdc6e1a-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/ea1a62afbfc842aabb89d590b4b2deba/df90ae702f6244d59cd1321d8ec48f74-acf56dbe3bd231e2b8ed5e2611348fef-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>Apache DolphinScheduler也得到了很多的用户使用。</p><p><img src=\"https://static001.geekbang.org/resource/image/94/c3/94a02de86590a9byy6d7b5eca64a1ac3.png?wh=1330x680\" alt=\"\"></p><p>其中一个互联网用户叫做“奇安信”，他是这样反馈的：Apache DolphinScheduler是一个可视化非常好的工具，无需代码就可以调度任务。降低使用门槛；它底层用了分布式、易扩展的方式实现了集群高可用；所有的资源文件都是在线的，不用登陆带服务器就可以看到日志错误调试脚本、管理上传的脚本文件；同时它的支持多租户也支持权限管理分给不同部门使用。</p><p>总之Apache DolphinScheduler是一个非常好的数据处理与调度工具，你要是感兴趣可以访问<a href=\"http://DolphinScheduler.Apache.Org\">官网</a>来看最新的信息。</p><p><img src=\"https://static001.geekbang.org/resource/image/a3/fa/a3846147968a65b47ae9058846d460fa.png?wh=1123x586\" alt=\"\"><br>\n除了Apache DolphinScheduler，类似的还有美国AirB&amp;B开源的Apache Airflow和Cloudera 开源的Apache OOzie等等，这些都还需要编一部分代码来执行相关的任务，所以<strong>你可以根据自己的情况去测试一下哪个工具最适合你的场景，最后通过数据平台部门来帮你实现。</strong></p><h2>数据展示工具——EChart</h2><p>数据存储好了也处理好了，最后还需要非常方便地展示出来，这就不得不提国内的最牛的数据展示工具——Apache ECharts。在前面的课程里我们看过Excel各种展示图形的方式，如果你觉得还不够，你可以看一下ECharts这个图形展示工具，它是目前市面上最全的展示工具之一。</p><p>只不过如果它要变成具体可使用的界面，还需要你请前端小伙伴编一些程序，不过看下图这么酷炫的展示，我觉得你还是值得去要一些前端开发资源的。</p><p><img src=\"https://static001.geekbang.org/resource/image/5a/1f/5accc7942155fe13baf53da519a4301f.png?wh=1293x1097\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/af/66/af3faa0dc67dcd4176cf9b58102f0866.png?wh=1408x1225\" alt=\"\"></p><p><img src=\"https://static001.geekbang.org/resource/image/e6/69/e66ab175735551064ca1672aefeb6069.png?wh=1419x1098\" alt=\"\"></p><p>我在下面这个视频里面给你介绍一下所有ECharts支持的图像，你能看到非常全面，几乎你所用数据想要的结果在这里都可以找到。而且它大部分图形支持手机演示，也就是你的数据可以在手机上给所有相关人员展示。同样，你如果感兴趣可以点击<a href=\"https://echarts.apache.org/zh/index.html\">这里</a>，访问官网了解更多信息。</p><p><video poster=\"https://media001.geekbang.org/b95fc72b04414f609452a62ad0333bae/snapshots/30ed039d4723448b974e920b94f41ec0-00005.jpg\" preload=\"none\" controls=\"\"><source src=\"https://media001.geekbang.org/customerTrans/7e27d07d27d407ebcc195a0e78395f55/2daa9f19-17c8cda1b5a-0000-0000-01d-dbacd.mp4\" type=\"video/mp4\"><source src=\" https://media001.geekbang.org/123b35b88e2d4e70a534de5e5effd828/71fc1f39764c4e19b96d21edbf842e8e-0f9d6e2fa6dc1cd45a9146442592292a-sd.m3u8\" type=\"application/x-mpegURL\"></video></p><p>当然类似像Echarts这样的工具，海外还有D3或者是一些其他的收费工具，数据分析最后的颜面还是要找一个漂亮的图形让更多人喜爱。</p><h2>小结</h2><p>今天给你介绍了几个比较先进的数据分析工具，你应该能感觉到现在的技术已经非常发达了，只有你想不到，没有做不到的技术工具——无论是单机版实时数据分析引擎，还是无代码的数据逻辑工作流，或是动态酷炫的数据效果，现在都可以通过比较简单的程序化方式实现。</p><p>我们现在需要做的是用第三章<a href=\"https://time.geekbang.org/column/article/418334\">如何用数据说话</a>的方法捋好自己的数据分析思路和内容，用我们第二章讲到的<a href=\"https://time.geekbang.org/column/article/410422\">数据算法基础</a>扩展数据结论，同时你要注意第一章<a href=\"https://time.geekbang.org/column/article/400764\">数据分析基础</a>的内容，不要错用数据分析基础知识。最终，你就可以通过这些工具展现一个完整的动态数据分析系统，给公司老板和大多数的用户一起来使用。</p><p>基于正确的数据分析思路，使用这些工具打造的数据平台就像一个放大器，可以帮我们快速推广想法，能够帮你将已成型的数据分析思维放大给更多的人迅速使用。</p><p>需要注意的是，我们不要沉浸在先进的工具里不能自拔，工具永远只是我们拓展数据实践半径让更多的人认可数据思维的手段，所以你会发现在工具这一部分，我没有给你推荐非常多酷炫的工具，因为我觉得<strong>对数据分析思维来说，最重要的还是思维。具体用什么武器，其实只要顺手，它哪怕是一个小小的Excel，也可以使出非常好的数据分析效果来。</strong>如果你没有好的数据分析思维，你的展示再酷炫也是没有意义的。</p><p>数据给你一双看透本质的眼睛，数据分析核心在思维，酷炫的工具就像是美颜滤镜，底子好不好，见到真人还是要原形毕露的，所以多花心思在数据分析思路上。</p><h2>课后思考</h2><p>你还看到过什么顺手的数据分析工具？分享出来我们一起提高。</p>",
                "article_title": "31 |  最先进的数据分析工具展望"
            }
        ]
    },
    {
        "chapterTitle": "结束语",
        "children": [
            {
                "title": "结束语 | 我们不是神：数据分析既是天使也是魔鬼",
                "id": 428069,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>不知不觉已经进入到这个课程的最后一课了，看到这个标题，你可能会奇怪，我们当然不是神了，我们就是普通的人啊。但我在这里要和你强调一下，学完这门课，在收获了如此多的工具及理论后，你很容易会有一种“无所不能”的感觉，但这种无所不能的感觉是种假象。</p><p>我希望这个课程能够让你更加“清醒”，能够更深层次地去思考当下的生活，既认识到数据分析天使的一面（提升效率、思维框架），也能看到数据分析魔鬼的另一面（各种数据陷阱），从而能够更加从容地去工作与生活。</p><p>所以接下来不要嫌我唠叨，我还是要嘱咐你几点。</p><p><strong>在做人方面</strong>，数据分析思维一定要尊重客观事实，全面完整地通过数据来反映现实世界。既不要被类似辛普森悖论的情况所欺骗，也不要用这样的方法去欺骗别人。客观、坦诚、智慧是我们每一个数据分析思维人最重要的特质。</p><p><strong>在实践方面</strong>，利用数据思维分析做实践的时候，你要知道理想和现实永远是有偏差的，你在做预测的时候一定要适度留出震荡的空间。现实往往没有你想的那么好，当然也往往没有你想得这么差。根据数据分析结果执行的时候，不要太理想主义，毕竟你很难把所有的因素全都考虑清楚。</p><p>我们都说“谋事在人成事在天”，在用数据分析思维的话来讲，你的实践很可能会出现墨菲定律，也可能取得的胜利其实就是幸存者偏差。你要用一颗平常心，做好万全的准备，不断迭代尝试，根据大数定律的趋势，才能利用数据分析思维最终得到你想要的结果。</p><!-- [[[read_end]]] --><p><strong>在决策方面</strong>，数据驱动最终的目标是解决公司的经营问题，也就是通过整体环境的判断、经济形势的趋势预测以及行业赛道的变化观察，做出正确的方向性决策。如果做到了这些，其实你已经脱离数据分析师的岗位，走在了COO和CEO的道路上。</p><p>另外，用数据分析来决策，一定要敢于做不完美的决定，这不完美的决定背后就是学会断舍离。没有损失的决策，不是好决策。你要通过数据预测和执行调整，把损失控制在可预期的范围内。</p><p><strong>不管是做人、实践还是做决策，共性都是要有一颗开放的心。</strong>如果你只看到自己认为对的东西，那么你积累的不是自己的思想，而是你自己的偏见。</p><p>这个年代，我们被数据所包围，也被数据所困扰。我们不缺乏数据和相关的算法工具，而是缺乏坚持数据分析的理念和思维，然后把这些数据变成有用的信息并支持决策的人。我们的目标是从纷繁复杂的数据中化繁为简，利用算法、数据框架把大数据最终变成小数据，最终再为人进行服务和决策。</p><p>现在所有的企业已经不再考虑“要不要数字化转型”了，时代要求我们去考虑“如何进行数字化转型”。这样一来，数据分析乃至数据分析思维就非常重要。我曾经见过很多企业，规划一个“宏大”的数字化升级项目，投入大量的资金、人力，但大多数不到3年就偃旗息鼓了。究其原因，其实是在数字化升级和转型当中到底从哪里下手，如何规划、落地，如果没有数据分析思维的驱动，没有数据思维的实践方法，往往会摸不着门路。</p><p>数字化时代需要用数据来分析解决问题，而不是像过去的根据经验一拍脑袋就决策。转化变革的时候，也要用“精益”的方法，根据数据反馈快速迭代，不要武断地认为大方向正确资源到位，砸人砸钱就可以了。</p><p>我看到更多的企业（哪怕是互联网企业），数据驱动和数据分析思维只停留在了某几个高管或者某几个部门当中，很难形成公司统一的“数据思维价值观”，这样在推动数据驱动和数据变革的时候，往往会花费非常多的时间。<strong>数据思维企业在数字化升级和转型的过程中，扮演着非常重要的角色，希望你不仅能够自己掌握数据分析思维，更能够自己消化吸收并分享给更多的人。</strong></p><p>当然，任何思维都有它的局限性，数据分析思维也是如此。喜欢使用数据思维的人更像是军师，因为可以把很多事情看得非常全面和透彻。但因为要深入探查和理解，所以往往容易纠结于细节。</p><p>如果你不仅仅想做军师，还想进一步提升去做元帅，这中间就差了一个杀伐决断去落地的勇气和执行力。我相信，当年看到互联网大潮来临，无论是王兴、张一鸣还是李彦宏，和他们想法类似的人有很多，但是真正有魄力的人去扛这大风大浪的人，很少。</p><p>你要知道，通过数据分析思维出来的创新的点子不如关键的行为。我们中国人是很聪明的，你想的点子，别人早就想到了，而真正能做成事的人，是做对了关键行为。所以如果你的志向是想做大事的话，数据分析思维只能是你的左右手当中的一只手，另一只手是你的杀伐决断的领导力，你要是感兴趣，可以看看我的这篇<a href=\"https://zhuanlan.zhihu.com/p/69301776\">《怎样做技术管理者——关于管理和领导力的学习笔记》</a>。</p><p>说到底，我们这个课还只是一个入门课，数据思维和数据分析其实有非常广阔和深厚的空间，从数学理论到人工智能算法，从行业分析到经营管理数据决策，每个维度都可以展开N次元的空间。</p><p>所以我无法把所有的东西都事无巨细地交付给你，我想给你打开一扇窗，把枯燥的数学理论、数据算法变成简单容易理解的生活例子，让你充分感觉到数据分析的魅力，从而把数据思维变成你工作和生活决策过程当中的一部分。愿你在未来你某个决策的时刻，忽然想起课程当中的某个例子或者知识点，这样就不算白学了。</p><p>很多人会有这样一种“执念”：对于人生的终极目标，一定要自己先找到一个正确答案，然后才算是真正开始自己的生活。美国哲学家麦金泰尔说过这样一句话：“美好的人生就是一生都在追求美好人生的人生。”这样来看，<strong>我们的人生其实是“边想边做”，并且想和做是分不开的。</strong></p><p>对于很多“终极”的问题（比如人生意义），到现在也没有一个终极的答案，但我们一直都“在路上”，我想，这应该也是这个终极问题答案本身的一部分。学完这门课程，其实也只是你数据分析的起点。</p><p>人们常说想法产生行动，行动养成习惯，习惯变成性格，性格决定命运。这门课程已经在你头脑里种下了数据分析的一颗种子，希望你多给它浇浇水，落实到行动上，就算在实践中不断碰壁，那也是苦口的良药，只有这样才能真正让数据分析思维为你所用。</p><p>数据分析思维是一个要求你不断往前跑的思维，我在<a href=\"https://time.geekbang.org/column/article/424348\">加餐</a>里和你分享了我的个人经历，也是希望激励你不要甘于平庸。“人生就是转瞬即逝的鸟鸣”，动听而曲折，嘹亮而短暂。<strong>我们应该拼命热爱，珍惜经历的一切，不论是开心还是痛苦。</strong></p><p>所以在这里，我建议你在选择工作机会的时候，去挑战那些有陡峭学习曲线和艰苦磨练机会的工作，只有不断突破自己的极限，才能够不断提升自己。</p><p>最后，再次感谢你的一路相伴，我和你一样，也成长了很多。细心的你应该发现了，截至这篇结束语发布的时候，我们额外增加了五篇的加餐，这些加餐也会是动态的，比如<a href=\"https://time.geekbang.org/column/article/423939\">书单推荐</a>这篇，我还会不断完善附录当中的参考书。此外，我在最后给你留了一个小小的问卷调查，希望你花两分钟的时间填写一下，比如你后续还想看到什么主题的加餐，以及对这门课程还有什么想法，我们一起交流。</p><p>数据，给你一双看透本质的眼睛。希望你可以通过这门课重新看待你自己的工作和生活，也欢迎你在遇到决策困难的时候常回来看看，我们留言区见。</p><p><a href=\"https://jinshuju.net/f/Hm0OkE\"><img src=\"https://static001.geekbang.org/resource/image/7e/46/7e1601c7dce3a61322a8069833609746.jpg?wh=1142x801\" alt=\"\"></a></p>",
                "article_title": "结束语 | 我们不是神：数据分析既是天使也是魔鬼"
            },
            {
                "title": "期末测试｜来赴一场满分之约！",
                "id": 487729,
                "content": "<p>你好，我是郭炜。</p><p>咱们的专栏《数据分析思维课》已经结课一段时间了，非常感谢你一直以来的认真学习和支持！</p><p>为了帮你检验自己的学习效果，我特意给你准备了一套结课测试题（可以重复答题）。这套测试题一共有 10 道题（包含单选和多选），考点都来自我们前面讲到的重要知识。</p><p>点击下面按钮开始测试吧！</p><p><a href=\"http://time.geekbang.org/quiz/intro?act_id=1627&exam_id=4008\"><img src=\"https://static001.geekbang.org/resource/image/28/a4/28d1be62669b4f3cc01c36466bf811a4.png?wh=1142*201\" alt=\"\"></a></p><!-- [[[read_end]]] -->",
                "article_title": "期末测试｜来赴一场满分之约！"
            }
        ]
    },
    {
        "chapterTitle": "特别放送",
        "children": [
            {
                "title": "编辑手记 | 让生活多一些科学，少一些神学",
                "id": 411210,
                "content": "<p>你好，我是《数据分析思维课》的专栏编辑和音频导演正霖。看到这个标题，不知道你会不会觉得这个编辑有些神神叨叨的，别急，我先给你分享一个故事。</p><p>我最近看了一本叫做<a href=\"https://book.douban.com/subject/5384622/\">《阿赞德人的巫术、魔法与神谕》</a>的书，当时我是看到这本书的名字里带个“巫术”，抱着猎奇的心理去读了读。书里确实讲了不少阿赞德人如何使用巫术、制作“魔药”的例子，但是最颠覆我的认知的，还是阿赞德人的世界观：<strong>阿赞德人把一切不幸归结于巫术，并且只会在不幸发生的时候才会去思考不幸。</strong></p><p>举个例子，一个阿赞德人来到了现代社会，他今天很“水逆”：上班路上一路红灯，到了公司还被领导同事刁难，中午点的外卖还被别人给拿走了，晚上回家打游戏结果一直输……这时他会怎么想呢？他会想，自己今天一定是被别人给下了巫术了。然后他会采取一系列的措施，试图去解除巫术。</p><p>如果是你，经历了不幸的一天，你会归结于什么呢？郭炜老师这门《数据分析思维课》给了我另外一个直面生活中不幸的理由：<strong>我们的生活可以用数据来科学地解释。</strong>这让我不会去怪是不是别人给我下了巫术，不再怪老天就是让我今天不顺，也不再怪自己。这是我目前做这门课最大的收获，也是标题的由来。</p><p>当然，这只是我个人的收获，欢迎你在评论区留言，和小伙伴们分享《数据分析思维课》给你带来的认知上的提升。我写这篇编辑手记其实重点在于，我想站在一个编辑的角度，进一步和你分享一下我们是如何想到要做这样一门课程，又是怎样来设计这门课的。</p><!-- [[[read_end]]] --><h3>初心</h3><p>我们现在的生活充斥着各种各样的数据，但是绝大多数人都无法把握住数据，让数据真正为己所用。于是，也就有了我们这门课程的一个整体交付目标：<strong>提升用户对于数据的理解能力，帮助用户建立思考和分析数据的立体模型。</strong>换句话说，其实我们这门课尝试在给你交付一个“数据价值观”。</p><p>这个“数据价值观”有什么用？主要是以下四点：</p><ul>\n<li>让你有效规避工作生活里常见的数据分析误区，培养数据分析思维；</li>\n<li>让你能够抽丝剥茧，理解算法的逻辑，并且能够用算法思想来指导生活；</li>\n<li>掌握常见的分析模型与理论后，你还能够用数据思维去启发他人、影响他人；</li>\n<li>你还会收获很多即学即用的工具，为工作和生活提速。</li>\n</ul><p>不知道你发现没有，其实我们就是根据以上这四点，把我们的整个课程划分为了数据分析基础、数据算法基础、如何用数据说话以及分析工具四大模块。</p><p>在数据基础与数据算法的章节，大部分标题都是以“核心交付点+贴合生活的痛点问题”形式出现，为什么会这样设计呢？其实还是为我们的课程范式服务。我们这门课的课程范式大概是下面这个样子。</p><h3>课程范式</h3><p><strong>开篇</strong>：提出一个或多个贴近我们生活的痛点问题，引出这一讲需要讲解的重点知识，让你重点关注，并在下面正文内容的学习中找到答案。这其实也是<a href=\"https://book.douban.com/subject/10567712/\">理想剧本创作模式</a>中“三幕戏结构”的第一幕：引出问题。</p><p><strong>正文</strong>：在正文部分，图文并茂，有逻辑、衔接自然地讲解各部分知识，也就是线性递进的思路。同时，我们要注意用通俗易懂的例子来解答开篇提出的痛点问题。这是我们的第二幕和第三幕戏：主人公踏上了征途，为了解决一开始的那个问题，他又遇上了一连串的问题。经过一系列的努力，最后主人公找到了一个解决终极困境的方法。</p><p><strong>总结</strong>：带领你回顾和梳理重点知识，并结合知识点，给出老师的操作建议或注意事项。此外，我们还会基于这节课所讲的内容，对交付的知识点做进一步的升华。不知道你对“<a href=\"https://time.geekbang.org/column/article/401316\">慎始敬终</a>”或者“<a href=\"https://time.geekbang.org/column/article/408750\">种树的小故事</a>”还有印象吗？这其实是峰终定律的体现：一场体验的好坏基本取决于两个时刻，一个是最高峰，一个是结尾，并且结尾部分会直接影响用户的记忆和观感。我们在每节课的结尾处都设置了类似的拔高，当然也期待你的总结。</p><p><strong>课后思考</strong>：每讲留一道思考题，让你可以有效思考所学知识或进行延伸扩展。在这一个部分，我和郭老师都非常开心，看到同学们提出了非常多有观点、有态度的思考。另外在部分内容的最后，我们还添加了附录部分，如果你爱动手计算，附录部分的内容不容错过。</p><p>看完课程范式你会发现，其实“问题”对于学习这门课来说非常重要，希望你在学习的时候，也能够带着自己工作或生活里的问题进行学习。</p><h3>人群定位</h3><p>在课程核心的人群的定位上，其实我们内部有过不小的争论。一开始我们想要把用户主体定位为不懂数据分析的程序员，把课程路径放在每个程序员、产品经理都应该有数据分析思维上。后来我们发现，单拿数据分析这件事来说，很多人都会觉得难，认为数据分析就是“数据分析师”之类的角色干的活，但其实数据分析不仅仅是一种专业能力，更是一种底层能力。</p><p>我们的开篇词标题“数据给你一双看透本质的眼睛”，这个看透本质的眼睛不仅仅是数据分析师才能拥有，而是我们每一个人都需要透过数据看到本质，去伪存真，把握住数据背后的大势，这样才能更好地生活。</p><p>我们把课程取名为“数据分析思维课”，也是想要告诉你，我们会站在一个普世的角度，给你交付这种对于数据的洞察、理解、应用能力。所以我们的核心人群做了进一步的扩展，并不是仅面向开发、运营或者专业的数据分析师，而是所有致力于扩宽舒适圈，想要探索新事物的小伙伴。</p><p>功利一点来说，这种数据分析能力能够为你的工作与生活提效，避免你落入一些常见的数据陷阱。诗意一点来说，数据、算法其实蕴含着非常多的哲理，不局限于具体的某件事，会在你彷徨的时候，给你一个更为理性的人生指导。</p><p>到这里，整个课程的交付思路就给你汇报完毕啦。其实上面的内容我是基于课程设计文档做了一个二次解读，你要是感兴趣，可以点击<a href=\"https://shimo.im/docs/xSksZiqNZ6kuxtI1/\">这里</a>，查看表格版的课程设计文档。</p><h3>我是如何学习这门课的</h3><p>最后，我想再和你分享一下我关于学习这门课程的小小心得，与你共勉。</p><p>我越来越觉得，知识浩如烟海，数据更是无穷无尽。很多时候，<strong>成功的原因不在于你知道多少事情，而是在于你知道在无知的时候该怎么做。</strong>作为编辑，其实我相当于这门课程的第一个用户，我在学习这门课程的时候，会去重点关注两条线：一条生活线，一条工作线。在学习每一节课的时候我都会去想，郭老师举的这些例子里如果是我，我会怎么办？然后用这个问题去探寻究竟郭老师有哪些成事的原则。</p><p>比如在平均值那节课里，原则就是“抓大放小”；在大数定律那节课里，原则就是“长期主义”；在标准差那节课里，原则就是“严于律己，宽以待人”……这些原则其实构成了郭老师行动的基础，我可以想象，当郭老师遇到生活中很多难以预料的事情，必须孤立地做出反应时，这些原则一定是可以帮助他更好地进行决策的。那么相应地，我们也可以去参考郭老师的原则，再根据自己的目标和性格总结出自己的原则。</p><p>就在刚更新不久的<a href=\"https://time.geekbang.org/column/article/409828\">因果倒置</a>那节课里，我得出了一个结论：<strong>要独立并批判性地思考</strong>。之前这句话我经常听到，耳朵都快起茧了。但是真正学完这节课后，我自己再总结出这个结论，感觉真的很不一样，我能够顺着这个结论去深入思考：我想要什么、事实是什么、我在什么情况下容易被欺骗、我应该以一个什么样的态度去看待我长期目标……你也可以试试，说不定你已经有了很多生活的原则，只是没有通过“聚类”“分类”把它们显现出来。</p><p>这就是我对于这门课的一点学习心得，简单来说，就是“找原则”的方法。关于工作和生活的原则，我还邀请了郭老师专门做一篇加餐，不讲具体的知识点，就聊聊他是怎么用数据思维来做开源、做管理、激励家人。敬请期待！</p><p>作为本课程的音频导演，我<strong>建议你在学习的时候搭配音频一块学习</strong>，效果更佳。此外，如果你还想要看到什么类型的加餐，欢迎在下方留言，我们后续会不定时更新加餐，让这门课程持续成长。数据分析思维让我们的生活更多一些科学，咱们留言区见！</p>",
                "article_title": "编辑手记 | 让生活多一些科学，少一些神学"
            },
            {
                "title": "中秋放送 | 数据分析基础回顾",
                "id": 420203,
                "content": "<p>你好，我是这门课程的编辑正霖，我又来了。</p><p>明天就是中秋节啦，在这里提前祝你中秋节快乐！不知道你有没有复习的习惯呢？课程更新到现在，你应该也能感受到，到了“如何用数据说话”这一章，对之前知识点的综合运用更多了。</p><p>基于此，我为你准备了两篇复习回顾（分别回顾数据分析基础以及数据算法基础）。我会把前两章每一讲画出一个思维导图并加上这一讲的金句（重点关键句），如果你对这节课所讲的内容感觉很模糊，可以点击对应的超链接去复习一下。好了，那我们今天就从“数据分析基础”这一章开始吧！</p><p><a href=\"https://time.geekbang.org/column/article/400764\">01 | 平均值：不要被骗了，它不能代表整体水平</a></p><p><img src=\"https://static001.geekbang.org/resource/image/6e/94/6e1a9a5a07eeb6513bc65abb2b27d994.jpg?wh=862x396\" alt=\"\"></p><p>拆开来看，“质”与“量”是不等价的。平均值和辛普森悖论告诉我们要抓大放小，不要因为某一个单项优势就洋洋得意，也不要因为局部失败就一蹶不振。生活，要有一颗平常心，我们的目标是让我们这一生的“人生平均值”逐步提高。</p><p><a href=\"https://time.geekbang.org/column/article/401316\">02 | 大数定律与小数陷阱：生活是随机还是有定数的？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/70/5a/70cd42ba043549cf162436378eeyy95a.jpg?wh=908x470\" alt=\"\"></p><p>生活里最难的就是如何辨别什么是偶然，什么是必然。我们期待把生活全部变成必然，但其实你会发现人的一生很短暂，我们一生的经历很难都是必然。站在数据分析的角度来看，生活本来就充满着各种不确定性，你如果不去努力，那经历的样本就太少了，你经历的可能就会是各种偶然的极端情况（比如一路上老是遇上红灯）。</p><!-- [[[read_end]]] --><p><a href=\"https://time.geekbang.org/column/article/402945\">03 | 数据的期望值：为什么你坐的飞机总是晚点？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/27/73/2795786816a522ff3bb6e7c631007973.jpg?wh=864x432\" alt=\"\"></p><p>“为大概率坚持，为小概率备份”、“已知的是成本，未知的才是风险”、“项目风险控制”、“生活中的风险控制”、“平衡预期”、“未雨绸缪”都是这节课的关键词。同时，01、02、03建议放在一起统一进行复习：没有事情可以一蹴而就（平均值），我们需要努力足够多的次数（大数定律），学会规避风险（期望值），你的生活才会越来越有掌控感。</p><p><a href=\"https://time.geekbang.org/column/article/403845\">04 | 随机对照试验：章鱼保罗真的是“预言帝”么？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/4b/24/4b492d46fae70abd0791c57cf0548e24.jpg?wh=986x390\" alt=\"\"></p><p>在我们工作和生活当中，一定要注意不能犯同样的“错误”——采用非随机的结果来证明我们的观点，更不能用幸存者偏差——用结果倒推原因来解释我们的一些结论。</p><p>注意自己“不犯错”是一方面，另一方面我们也要学会“发现错误”，学习前人失败的经验教训。当别人和你兜售一些貌似合理论调时，希望你对“沉默的数据”留一个心眼，在看向那些闪闪发光的成功数据时，也要意识到有很多“话少”甚至“不说话”的数据存在。</p><p><a href=\"https://time.geekbang.org/column/article/404779\">05 | 直方图与幂分布：为什么全世界1%的人掌握着50%的财富？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/b5/93/b5e531ff42179059b9eedbe21e518a93.jpg?wh=1030x570\" alt=\"\"></p><p>我们身处的世界是赢者通吃的世界，开始时细微优势最终将带来无穷多的回报。反之，最初的细微劣势也将导致最终一无所有。那么，我们如果每天在自己的专业领域里面比其他人多成功1%，最终积累起来的竞争优势将使别人无法超越，你就会变成那个能够大声说“我全都要”的少数派。</p><p><a href=\"https://time.geekbang.org/column/article/405241\">06 | 数据分布：房子应该是买贵的还是买便宜的？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/5e/fd/5efccfcb494077c0a1a4dc22362a20fd.jpg?wh=902x412\" alt=\"\"></p><p>无论在什么场景下做数据分析，数据的分布应该能贴合地描述我们社会上的“大势”，所以当你面临生活中的决策时，而不能就数据套数据、为了算法而算法，领域背后的知识对于我们更加重要。</p><p>正态分布和拉普拉斯分布其实给我们的工作生活一个大的启示，那就是为什么会有“Work Hard, Play Hard”这样一句话的流行，因为这句话背后的含义其实是指当你要获得更多的自由的时候，你也要付出同等的甚至更多的自律（控制自己既能使劲玩也能使劲工作）。当今社会的人才分布是呈拉普拉斯分布的，我们要争取做顶尖，这样才会有更多的资源和机会。</p><p><a href=\"https://time.geekbang.org/column/article/406706\">07 | 散点图和相关性：怎样快速从数据当中找到规律？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/e3/02/e3aa4afdb79526c1e8baefe2d2ef4602.jpg?wh=2000x1221\" alt=\"\"></p><p>数据分析的艺术就在于通过数据分析和管理经验找到反U型最高点。</p><p>没有正确的数据验证，千万不要轻易下结论。我们要根据实际自己的业务领域知识以及算法模型找到接近事实的最佳解，这样才能够帮助你去预测这个世界，错误利用模型最后只会导致我们出现错误的决策。</p><p><a href=\"https://time.geekbang.org/column/article/407445\">08 | 标准差：这人是不是“靠谱”其实看标准差？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/5b/54/5b270a7675b2d8d95f4c261decfc1254.jpg?wh=960x460\" alt=\"\"></p><p>看一个人、一个企业、一个投资产品靠不靠谱，除了人办事情的成功率、企业收入平均值和产品的盈利率，你还要看它标准差是怎样的。有可能这个所谓的“成功人士”只成功了一次，赚了一大笔钱，但是其实别的事他都失败了，那说明这人的标准差很大，有可能他就是靠运气，不太靠谱。我们中国人其实是比较喜欢“中庸”的这种感觉，用标准差的视角来看，就是自己做事做人的标准差要小。</p><p>对标准误差来说，我送你一个成语，叫做“严于律己，宽以待人”。前半句是指我们在工作和生活中，要尽量少出错，甚至是不犯错，这样不仅做事漂亮，领导喜欢，而且这种不断追求完美的理念，会一直推着我们往前跑。你可以试试，把六西格玛的思想不仅用在工作中，也用在生活里，对自己高标准、严要求一段时间，相信你会获得更进一步的成长。后半句是说，躺平无罪，奋斗有理。我们可以用六个标准误差来要求自己，但是别人也有用一个标准误差要求自己的自由。</p><p>如果用一句话来概括，希望你尽量把自己做人做事的标准差变小，提高对自己的标准差预期。</p><p><a href=\"https://time.geekbang.org/column/article/408181\">09 | 数据抽样：大数据来了还需要抽样么？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/76/4d/76c12302ce6bcf8c32cfe3012b9ca94d.jpg?wh=822x396\" alt=\"\"></p><p>大数据其实不是数据抽样的终结者，无论是大数据还是小数据，它都无法逃离统计学、数学、集合论、数据结构等这些基础理论的约束。之前讲的数据分析的原理，也同样适用于大数据环境。</p><p>如果你能把数据抽样的这个“涡轮加速器”运用到你自己的工作和生活当中，那么你就可以事半而功倍，通过针对一小部分的人和事情的观察而看到整个事物的整体情况。古人说“管中窥豹，可见一斑”，对应到我们的数据分析上，说的就是合适的数据抽样算法能够由点及面地看到事物的全貌。</p><p><a href=\"https://time.geekbang.org/column/article/408750\">10 | 指数和KPI：智商是怎么计算出来的？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/27/d8/271ab9a7c800a439cc29a2ec68f4e9d8.jpg?wh=828x446\" alt=\"\"></p><p>在我们的生活和工作中，很多人往往会为了做一个可衡量的数字，不负责任地拍脑袋决策出一个结果。比如说我知道很多公司在做员工360度评估的时候，就是简单地套用一个标准公式，这样的评估往往是失败的。一定要基于细致的业务流程和实验，才能得到合理科学的结果。</p><p>一方面当你在衡量一个事物的时候，不要轻易地拍脑袋造出一组数字来代表它。另一方面，希望你能够更加坚定地相信，数字是可以衡量这个世间所有事物的。毕竟如此复杂的我们都可以用数字来衡量，还有什么不能衡量的呢？</p><p><a href=\"https://time.geekbang.org/column/article/409828\">11 | 因果倒置：星座真的可以判定你的性格吗？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/75/04/7593ce1ae67e58e09d15b062a26a5c04.jpg?wh=1688x1417\" alt=\"\"></p><p>打篮球真的能让人长高吗？这很有可能是因为长高的人都会去打篮球，而不是打篮球让人长高——因果倒置。</p><p>喝咖啡可以长寿？常喝咖啡的人一般都是白领阶级，他们的营养供给更高，所以他们可以长寿，而不是因为咖啡让他们长寿——相关性而非因果关系。</p><p>吃不吃早饭其实和你肥不肥胖没有什么关系，运动健康才和你的肥胖有关系——相关性而非因果关系。</p><p>爱笑的女孩子通常运气都不会太差？爱笑的女孩其实运气也有差的，最后她就不笑了，事实是因为运气好的女孩她们才会爱笑——因果倒置。</p><p>会撒娇的女人更好命？女人好不好命其实与另一半或者周围的人和环境更有关系，而不是和你会不会撒娇有关系——需要找到遗漏的X变量。</p><p><strong>数据分析基础部分整合版思维导图</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/75/96/752c81af7d8e1c6d6135aa3b0b1bdc96.jpg?wh=2622x2000\" alt=\"\"></p>",
                "article_title": "中秋放送 | 数据分析基础回顾"
            },
            {
                "title": "中秋放送 | 数据算法基础回顾",
                "id": 420417,
                "content": "<p>你好，我是这门课程的编辑正霖。</p><p>今天是收假回来的第一天，不知道你中秋节过得怎么样呢？上节课我带你重新梳理了一遍数据分析基础部分的脉络，我们今天继续来复习回顾数据算法基础部分。另外，如果你想看到其他任何形式的加餐，欢迎在评论区留下你的需求。</p><p>话不多说，我们直接开始吧！</p><p><a href=\"https://time.geekbang.org/column/article/410422\">12 | 精确率与置信区间：两种预测，你究竟应该相信哪一个？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/5f/54/5f7e01c8bbb7ba4d2b5b9d186783d654.jpg?wh=1000x462\" alt=\"\"></p><p>在具体场景里，没有十全十美的算法，总是要做一些取舍。这个时候我们就更要去理解这些指标背后的含义，做到“断舍离”，根据我们实际的业务场景去选择最优的算法。</p><p>生活和工作做决策的时候也是如此，现实世界里很少有“两好选其优”的机会，大部分都是“两害取其轻”。究竟哪个害处更大不可接受，我们要自己衡量好。这样才可以在我们自己的生活和工作当中逐步的优化自己生活工作的算法，提高我们自己生活的最终的精确率，召回率和置信区间。</p><p><a href=\"https://time.geekbang.org/column/article/412094\">13 | 趋势分析与回归：父母高，孩子一定高么？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/ac/f1/ac92780305a17df1c3eeb6c324af29f1.jpg?wh=850x400\" alt=\"\"></p><p>在生活和工作里，我们可以通过回归分析找到很多简单的规律，它们能够帮助我们去预测一些常见的数据问题。但是在真正使用的时候，我们也不能盲目相信算法模型推导出来的结果，因为现实要比我们预测出来更加的贴近于平庸：好的没有我们预测当中的那么好，差的也没预测当中的那么差。</p><!-- [[[read_end]]] --><p>所以对我们自己的工作和生活来讲，用一颗平常心不断去提高自己的平均线水平才是正确选择。人和人之间的差异没有那么大，不存在着优生学，也不存在着“龙生龙凤生凤，老鼠的儿子会打洞”这样的说法。</p><p><a href=\"https://time.geekbang.org/column/article/412828\">14 | 初识聚类算法：物以类聚，让复杂事物简单化</a></p><p><img src=\"https://static001.geekbang.org/resource/image/b3/b2/b313159dfaac355dc082a5ce7d3f8db2.jpg?wh=914x480\" alt=\"\"></p><p>物以类聚，这是我们天生就有的一种思维方式。不知道你会不会有这样一种感觉：总是每天很忙，全都深入在不同的生活、业务细节里，但一天忙下来，却不知道自己到底忙了些什么。</p><p>你不妨试试用类似聚类算法的思路，把你觉得纷纷扰扰的一些小事统一归到一个篮子里去，用一整块的时间或者类似通用的方法去解决它们，说不定会有奇效。因为多用聚类算法的方式去思考，可以把你的思维锻炼得更加结构化，助你更快理清琐碎的生活。</p><p><a href=\"https://time.geekbang.org/column/article/413734\">15 | 初识分类算法：分而治之，不断进化</a></p><p><img src=\"https://static001.geekbang.org/resource/image/a1/57/a1faa2a34d02cbf417fc746389b8a357.jpg?wh=956x532\" alt=\"\"></p><p>希望你能够学会用分类算法的视角去看待“复盘”这件事。</p><p>分类算法的核心就是在于经验不断积累，不断迭代自己的规则，从而得到最好的答案。而我们在工作和生活当中，其实就接触的场景和得到反馈的结果来说，要比电脑当中的分类算法多得多。但我们有像分类算法一样，把这些场景和反馈结果分类整理记录下来，然后下次遇到情况时再去优化么？其实我相信大多数的人都是没有的。</p><p>所以很多人会经历了很多事情后依然庸庸碌碌。我们需要让大脑这个超级分类器不仅去接收好结果、差结果，还要在结果之外找背后的原因来不断优化自己的算法。那些成功的人，就是通过不断地思考，不断地学习优化自己的思维，最终他们的大脑进化成为超级分类器当中的佼佼者，通过现象看到了本质。</p><p><a href=\"https://time.geekbang.org/column/article/414442\">16 | 关联规则：为什么啤酒和尿布一起卖？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/e1/ec/e12bb7bb732fb20639a06d28e3cf83ec.jpg?wh=846x494\" alt=\"\"></p><p>人的一生其实很短暂，我们会经历很多事情，感觉很多的事情有关联又不关联，就比如说眼皮跳真的和你今天的运气关联性很高吗？</p><p>我们要和关联算法一样，把和你关联关系最强的那些事情把握住，把关联不强的事情舍弃掉。你可以试试用关联算法的思想，盘一盘你现在手里的资源，看看能不能用“连坐”算法把整体无关的事务、人脉做到断舍离，留下精力把和你最强的关联关系的事情做好。</p><p>如果你分不清什么事情对你关联关系最强，什么事情对你无关紧要，你的生活很有可能变成一团毛线球，不知道从哪下功夫，就算发力也有可能忙活一些不痛不痒的小事。人的一生重要的事情和重要的人脉可能就这么几个，你抓住了，人生才能成功。</p><p><a href=\"https://time.geekbang.org/column/article/415120\">17 | 蒙特卡洛与拉斯维加斯：有限时间内如何获得最优解？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/9b/af/9b49dddbc3bef1536bbda44a030ab9af.jpg?wh=998x484\" alt=\"\"></p><p>我们要根据自己手里的资源、时间，灵活选择是使用蒙特卡罗式的方法还是拉斯维加斯式的方法来处理事情，毕竟人的一生时间和精力都是有限的。</p><p>我们每天都会面临到各种各样的问题，你可以仔细思考一下你现在手里哪些事情不达目的誓不罢休（拉斯维加斯式算法）；哪些事情需要精益的方法和思路，多次尝试不断修正，事情发展到一定程度见好就收（蒙特卡洛式算法）。</p><p>对于管理企业来说，我们要高维度思考，不要把我们的有限的时间和精力浪费在不必要的事情上，整体的做事思路是抓大放小。而重要的事情要用拉斯维加斯算法一通到底，任何细节都不要放过，确保随机事件的正确性。</p><p><a href=\"https://time.geekbang.org/column/article/415893\">18 | 马尔可夫链：你的未来，只取决于你当下做什么</a></p><p><img src=\"https://static001.geekbang.org/resource/image/be/dd/bef6b35fb5045224ec88be4f497c2fdd.jpg?wh=970x476\" alt=\"\"></p><p>在我们工作和日常生活当中也有很多“马尔可夫链”：你现在的状态其实大部分都是由你上一个状态决定，没有人会走背字一直失败，也没有人能幸运到一直成功。</p><p>你可以仔细想想，真正的失败，很多时候都是自己遇到失败后从此一蹶不振，走不出来失败的这个状态才造成的。“没有迈不过去的坎”这句话用马尔可夫链的视角来看，那就是现在自己的状态，只和自己上一个状态相关，和整体无关。所以吸取完教训后，调整好现在的心态，用现在去影响你的未来。</p><p>我特别喜欢《飘》电影结尾郝思嘉说的那句话，我觉得它诠释了“马尔可夫链”在生活哲学中的真谛：“Tomorrow is another day”——你的未来只取决于你当下在做什么，而不是过去你曾经做过什么，毕竟“明天，是新的一天”。</p><p><a href=\"https://time.geekbang.org/column/article/416739\">19 | 协同过滤：你看到的短视频都是集体智慧的结晶</a></p><p><img src=\"https://static001.geekbang.org/resource/image/ff/3e/ffd367bca773d039e70116f25571383e.jpg?wh=948x496\" alt=\"\"></p><p>首先，你自己的心态应该更加开放，不要一股脑地追主流，毕竟主流和大众的不一定是最适合自己的，我们的圈子当中应该有个性化的东西。</p><p>同样，我们的价值观也应该更加地开放，不能就沉浸在自己的小圈子里。因为协同过滤给我们的都是我们所喜欢的东西，它的价值观并不一定是最好的，我们应该开放心态去接受和尝试各种各样新的主流的非主流的物品，用我们自己的经历和人生去判断。</p><p>我们更不要沉浸在某些短视频或者网站根据我们兴趣推荐的碎片化文章里，因为它给我们带来的不只是推荐，还会束缚、固化我们的思维，让我们成为这个时代里的“井底之蛙”。毕竟我们要主导自己的人生，而不是让算法去主导我们的人生。</p><p><a href=\"https://time.geekbang.org/column/article/417460\">20 | 人工智能初探：阿尔法狗是怎样的一只“狗”？</a></p><p><img src=\"https://static001.geekbang.org/resource/image/a2/70/a259364b03fa6d0a2461553e7ba70270.jpg?wh=1024x466\" alt=\"\"></p><p>尽管人工智能算法可以在很多有规则的竞争里超过人类，甚至现在很多人对人类十分悲观，觉得总有一天人工智能会像电影里那样奴役人类，但我一直都不这样认为。因为人工智能算法是没有灵魂的，它所有的计算其实本质上还是一个分类模拟器。</p><p>人工智能算法是一个有监督的学习算法，无论通过什么样的方式去模拟，它都无法通过一个有规则的算法去适配当今无规则的现实世界，更无法去模拟人们的感情、灵感和创造力。所以我们不要“机械”地活着，要往生活里多注入一些热爱和创新才好。</p><p><strong>数据算法基础部分整合版思维导图</strong></p><p><img src=\"https://static001.geekbang.org/resource/image/14/2e/140742e1a3e67e1cab3781746f81412e.jpg?wh=2724x2000\" alt=\"\"></p>",
                "article_title": "中秋放送 | 数据算法基础回顾"
            },
            {
                "title": "国庆放送 | 书单推荐",
                "id": 423939,
                "content": "<p>你好，我是郭炜。今天是国庆节的第一天，在这里祝你假期玩得开心！</p><p>我看到留言区有同学问有没有数据分析思维相关的书单推荐，于是就有了这篇加餐。我重点挑选了几本看过觉得还不错的书籍，我会把我觉得很有感触的点列出来，希望你在假期休息之余，能够选到自己感兴趣的书来阅读一下。</p><h2>《精益数据分析》</h2><p>首先是我在之前也提到过的《精益数据分析》，这是一本当时让我惊艳的数据分析入门书籍。</p><p>“精益”是我非常认同的比较落地可行的创新实践思路。整体上我认为数据分析如果没有落地，那么本身是不具备任何价值的。这是我在过去的工作以及组织的开源社区、管理我的团队或和社区的用户交流中深刻体会到的。我想这也是每一个从事数据行业的人共同的梦想：让数据真的用起来。</p><p>《精益数据分析》这本书给出了非常实用的行业例子，从电子商务、SaaS、免费移动应用、媒体网站、用户生成内容、双边市场来分析需要落地的分析模式与指标。与其说是行业，不如说是商业模型，因为现在公司业务纷繁复杂，每个产品模块就是一种商业模型，所以衡量的指标也不同。</p><p>这本书里提到的“<strong>唯一关键指标</strong>”（One Metric That Matters）是我非常认同的观点，因为一个公司从管理上来说，看太多指标是很分散精力的，我们用“唯一关键指标”统一全公司的思路，从老板到员工每一个人都要对这个指标负责，这样才可以力出一孔，让公司整体业务增长起来。</p><!-- [[[read_end]]] --><p>我推荐这本书还有一个原因，是因为它不仅给出了你要去做什么，更给出了“底线”。也就是什么时候我们该停止，或者当哪些指标出现异常的时候我们需要重点关注。</p><p>我把这些指标叫做“卫生指标”，意思就是说如果这些指标做得好，就像一个房间卫生打扫得比较干净，大家不会觉得如何。但是如果这些数据表现很差，就好比屋子里脏乱差，那么你的用户、投资人都会离你而去。所以，这些指标并不是“唯一关键指标”但它们一旦出现问题，就代表公司整体趋势出现了比较严重的问题，这个时候一定要追查到底。</p><p>总之，如果我只推荐一本数据分析行业的入门书，《精益数据分析》非他莫属，推荐你假期有时间的话，一定要看一看。</p><h2>《刷新》</h2><p>数据驱动就是用结果说话，这句话说起来容易做起来难。其实每一个数据驱动的分析师、科学家甚至CDO（首席数据官）在内部推动变革时都会遇到各种各样的艰难险阻，每次我遇到挑战的时候，我就会想起《刷新》这本书。</p><p>《刷新》一书的作者是微软现任CEO萨提亚·纳德拉，书里面主要是他做CEO时的整体的经历，看似非常琐碎的一些记录背后，其实记录了他一个人如何撬动微软这头大象，将这么一个拥有众多天才的公司重新回到具有“生机”的创新公司轨道上。</p><p>他写这本书的意义也是在于把他的价值观和企业文化，传递给每一个微软以及和微软相关业务的人。这让我非常佩服，因为在同周期内，IBM依然徘徊在探寻新业务的轨道上，国内也有非常多的企业在面临类似的困境，一个强有力的推动者和合适的方法以及坚持是非常重要的，如果你在面临一些工作里的抉择，在推动某事遇到了瓶颈，不妨看看这本书。</p><blockquote>\n<p>在2014年2月被任命为微软第三任首席执行官时，我对公司员工表示，重塑企业文化将是我的首要任务。我告诉他们，我将不遗余力地清除创新障碍，让公司重新回到先前的轨道上：继续以改变世界为己任。当我们将个人热情与更广阔的目标结合起来时，微软就会处于最佳状态。</p>\n</blockquote><h2>《原则》《一网打尽》</h2><p>一个企业的没落往往根本原因不是具体业务的没落，而是企业文化的没落。所以，我们的使命是把数据分析的思维贯彻在企业每一个人心中，让它成为企业文化的一部分。这样，未来推动数据驱动实验才会得心应手。</p><p>在我喜欢的《原则》这本书里，也提到文化和人加上企业这个规则的机器，是构成企业的主要要素，我非常认同这一点。如果要改变一个企业，首先要从文化入手，如果人心无法聚拢，那只会变成一个员工没有使命感的企业，挣钱再多也只是一时，不能长久。数据驱动要落在人、文化、规则上才可以把一个企业变成数据驱动的企业。另外，《原则》这本书如果你没有入手，光看目录可能很容易让你觉得“原则”太多，我个人建议你可以看看导言部分再下结论。</p><p>同样，说到数据驱动的企业，不得不提亚马逊，《一网打尽》这本书采用的是传记式记录方法，每一个细节都追求真实和透明，你可以从这本书里身临其境地回到亚马逊决策的那个时代，体验当时亚马逊的艰难选择。</p><p>在书中我看到了亚马逊公司对人的尊重。AWS并非产自亚马逊的美国总部，而是亚马逊南非办事处。这怎么回事呢？在2004年末，亚马逊IT基础部总监 Chris Pinkham 想要陪家人想要回到祖国南非，普通公司可能只会是祝福，但亚马逊当时的CTO很尊重Chris这个人才，于是在南非开设了办事处，并建立了基于Xen的内部服务，最终演化成为了Ec2，然后是S3。当时这个办事处啊不过十几个人，在业务验证后迅速扩大了规模。如果没有对人才的尊重，世界上恐怕就没有AWS这个改变世界的王者了。</p><p>“一心为顾客着想”在亚马逊是一个核心价值观，亚马逊为此甚至不惜和供应商对簿公堂，得罪所有的出版商也要做出Kindle。但也正是这一举措，让亚马逊积累了大量的客户。</p><p>只有把对人的尊重贯彻到企业中，才会有源源不断的核心人才加入。我们做数据分析的时候也是如此，最终的目标和价值观是什么？<strong>我们是真的数据驱动，还是“驱动”数据完成老板要达成的业绩？很多时候，真实的数据分析是很得罪人的，但是只有真实才可以让整个企业真正进步。</strong></p><h2>《从优秀到卓越》</h2><p>我们现在耳熟能详的“飞轮效应”、“亚马逊的价值观”、“AWS”都不是Day0想出来的，这些模式都是由市场和需求驱动着人们去思考商业解决办法，然后二次整合总结出来。</p><p>其中“飞轮效应”其实是亚马逊在经过各种碰壁之后发现了可以增长的市场，事后由吉姆·科林斯在《从优秀到卓越》当中总结出来的。在这本书里你会看到，谨慎留下管理和技术债，在市场驱动下高速发展才是硬道理，不要预设模型去套现在的市场和自己的企业。</p><p>这和做数据分析思维一样，我给你讲的也只是数据分析思维的一种套路，数据分析思维留白是很多的，你不要拘泥于我所给出的方法。<strong>所有的招式都是在若干次成功之后总结出来的，是不是适合你的场景，并不一定。所以这需要你从这门课当中边学习边和同学讨论，还要多反思，最终希望你能够“无招胜有招”。</strong></p><h2>一点题外话</h2><p>我曾经和朋友吃饭时聊到，一个技术人的正常路线是技术架构-&gt;技术总监-&gt;技术VP-&gt;CTO。但如果你想转型做业务，还有一条路线更适合你，那就是技术开发-&gt;数据分析师-&gt;数据运营总监-&gt;CDO-&gt;COO-&gt;CEO。因为深入数据的过程其实是一个深入业务的过程，技术人员天然理解数据，有强大的数据分析和算法能力，你可以“跨界打击”。</p><p>但这就要求你在深入了解数据分析思维的同时，更理解业务。技术人员走上数据分析的岗位，会让你必须得深入理解业务背后的本质，更了解公司的商业模型，逐步走向业务运营的岗位。再加上你的管理技能，你的“码农”职业瓶颈就被打开了。在<a href=\"https://time.geekbang.org/column/article/418334\">21讲</a>的附录里，有这个职业发展路线，你要是记不清了，可以回过头去参考一下。</p><p>我在附录部分也给你放了一些数据方面的参考书，希望你在学习之余多阅读，多拓展自己的认知边界。另外，如果你有其他感觉不错的书，欢迎在留言区评论，我们一起互相丰富书单。</p><p>最后再次祝你节日快乐！</p><h2>附录</h2><p>《看穿一切数字的统计学》[日] 西内启</p><p>《统计数据会说谎》[美] 达莱尔·哈夫</p><p>《如何用数据解决实际问题》 [日] 柏木吉基</p><p>《简单统计学》[美] 加里· 史密斯</p><p>《魔鬼数学》[美] 乔丹·艾伦伯格</p><p>《黑天鹅：如何应对不可预知的未来》（升级版） [美] 纳西姆·尼古拉斯·塔勒布</p><p>《随机生存的智慧：黑天鹅语录》[美] 纳西姆·尼古拉斯·塔勒布</p><p>《反脆弱：从无序中受益》[美] 纳西姆·尼古拉斯·塔勒布</p><p>《终极算法：机器学习和人工智能如何重塑世界》[美] 佩德罗·多明戈斯</p><p>《怪诞行为学》（新版）[美]丹·艾瑞里</p>",
                "article_title": "国庆放送 | 书单推荐"
            },
            {
                "title": "加餐 | 升级头脑，用数据思维点亮生活",
                "id": 424348,
                "content": "<p>数据给你一双看透本质的眼睛，这里是《数据分析思维课》，我是郭炜。</p><p>在开课的时候我做了一次直播，分享了我自己的一些利用数据思维的经历，考虑到有的同学没有听过这场直播，我二次梳理整合了直播的内容，分享给你。</p><p>不知道你是否思考过中国文化这么博大精深，从老子、庄子、孔子提出哲学思想到四大发明，其实中国思想和科技一度是领先于全世界的，可为什么到近代中国科技却没有跟上时代的步伐呢？</p><p>在我看来，其中一个原因就是中国人非常善于思考，但是却不像西方人善于使用一些逻辑框架进行总结。中国人喜欢用中医的方式，也就是所谓的只可意会，不可言传。而西方的科学善于总结整个的思维框架和方式，一代一代传播的不仅仅是表面的知识，而是它一套思维框架和逻辑体系。</p><p>比如我们的中医在古代非常了得，讲究望闻问切这些经验性的知识。西医却根据人体现象，通过检验检测设计了一套逻辑框架，最后可以根据这个框架迭代自身，检验自身。我们不谈中医西医孰好孰坏，但是光从发展速度来看，西医现在确实在很多疾病的治疗效果上是超越中医的。</p><p>所以我们数据分析思维这门课，<strong>我不想只教你一些数据的基础知识和算法知识，更想要给你一套数据思维的思考框架，你可以把你过去生活工作当中的一些问题整理在一个框架里不停迭代，从而升级我们的头脑。</strong></p><!-- [[[read_end]]] --><h2>用框架升级你的头脑</h2><p>就拿我自己的经历来讲吧，我从北大本科研究生毕业后，和绝大多数毕业生一样，在很多事情上都是迷茫的。那时候我虽然立志做数据方面的研究实践，但是具体却不知道怎么样去提高自己。这个时候是数据思维的思考框架帮助了我，也就是先确定问题，然后细化采集数据，再整理思路最终在实践当中迭代（这其实也就是“<a href=\"https://time.geekbang.org/column/article/418334\">如何用数据说话</a>”这一章的内容）。</p><p>现在我自己大的方向定下来了，那就是我要做数据方面的工作，“数据是有灵魂的，我将用我的一生去追寻它”这句话是我的座右铭。在这个时候，我们就完成了“<strong>确定问题</strong>”这一步。但是数据方面有很多的职位都可以去做： CTO、技术总监、首席架构师、数据科学家等等。我并不了解我应该成为哪一种人，也不知道我要成为这样一种人我需要做哪些技能。</p><p>于是我紧接着就做了“<strong>采集数据</strong>”的工作。我找了很多师兄师长和一些当时我觉得比较厉害的人做了访谈。聊到一些应该提高的方面，我就把它们都逐条写了下来。随后我发现，如果我只是听大佬说，觉得很有道理然后记录，记录下的只是零碎的点，不成体系。</p><p>我在这个时候用了数据分析里的常见的雷达图，帮助我进一步思考。我把每次访谈后的结果总结在雷达图的维度里，不停<strong>迭代</strong>这个雷达图，最终形成了现在我自己管理理论里面的技术管理核心能力的五力模型（如下图）。然后我把这些技术都是顶尖的职位之间的能力差别进行了区分，结合自己的实际情况，选择了一条自己要走的路。</p><ul>\n<li>领导力——“成事”的能力；</li>\n<li>文化构造能力——“影响意识”的能力；</li>\n<li>人员管理能力：“人*100”的能力；</li>\n<li>体系搭建能力：“建巢、管事”的能力；</li>\n<li>技术实力：“技术肌肉”的实力。</li>\n</ul><p><img src=\"https://static001.geekbang.org/resource/image/aa/58/aac09161e4f32a7efa20b3a7bcf3f258.jpg?wh=1957x1149\" alt=\"\"></p><p>如果你想要进一步了解这个五力模型，你可以点击<a href=\"https://zhuanlan.zhihu.com/p/50527184\">这里</a>去进一步学习一下。通过这个图你会发现，CTO、技术VP、技术总监、首席架构师同样都是技术一把手，但这些职位他在图里面的能力是各不相同的，而你要成为哪一类的人，其实你就需要在这个能力的技能点上面多去投入时间去学习。</p><p>有了这个模型，就不用担心自己的技能树可能会点歪了。我当时的目标是将来要做CTO，我对比目标的五力模型，发现自己技术实力仅仅刚起步，管理技能基本为0，体系和文化更不用说了，几乎没有。</p><p>后来我就去选择增加自己管理能力的岗位，我从Teradata的数据模型架构师去做了当时的项目经理，后来跳槽到IBM做资深项目经理，到后来的中金、万达、联想从事高级总监、大数据部门总经理等岗位，其实都是根据雷达图在数据和管理方面加自己的技能点，直到最后做成CTO。当然，这个技术领导五力模型图也在不停地随着我的认知升级而升级。</p><p>如果我们每天只是学习眼前的东西，但是不去总结背后的底层逻辑，也就无法去升级我们的思维。这也是为什么我在课程里给你总结了<a href=\"https://time.geekbang.org/column/article/423163\">15种数据思维图</a>，就是想要引导你去培养一个时时思考的习惯。</p><p>努力很重要，但很多时候知道方向其实更重要。鸦片战争刚开始就注定失败，因为战区士兵和民众广泛流传着这样一句话“皇上要和洋人开战啦”，仗为谁打都搞错了，又怎么可能胜利呢？在自己努力开战之前，我觉得不妨分析一下自己要走向哪里，即使战败了，也可以不断迭代直至胜利。</p><h2>基础概念学以致用</h2><p>刚刚和你讲的是框架的重要性，但数据思维有了大的分析框架还不行，我们的基础得打牢。所以我们这个课程的一开始，我给你讲了很多耳熟能详的概念。</p><p>你可以回想一下当初学前面课程基础概念的时候，是不是概念都挺熟悉，但是大多数的概念都没有吃透、用起来。</p><p>我自己个人最喜欢的是<a href=\"https://time.geekbang.org/column/article/401316\">大数定律</a>，因为我的人生也是按照大数定律这个方式来迭代的。你最喜欢的是我们这门课程里的哪个概念呢？</p><p>大数定律是说当随机事件发生的次数足够多的时候，发生的频率才会接近预期的概率。</p><p>我一直在支持开源，是国内为数不多的Apache Foundation Member，也是  Apache 顶级项目Dolphin Scheduler和ClickHouse中国社区发起人。听起来是获得了一些成功，对吧？但做开源这一路其实很不容易，背后需要你若干年如一日地付出，经历很多开源失败，才最终看到你想要的结果。</p><p>举个例子，你可以看看下面这个图，这是我凌晨5点在等待我家孩子出生时，我还在外面拿着电脑参加美国Meetup的情况，所以我们家娃被叫做“开源小公主”（你可以关注抖音“郭大侠说开源”来看她，哈哈）。</p><p><img src=\"https://static001.geekbang.org/resource/image/48/a1/48bf5e34cc92de21deabe90a0131c5a1.jpg?wh=2000x1417\" alt=\"\"></p><p>我们Apache member每个周四晚上10:00到12:00都有例会。在中国996的这个情况下，做开源的人得是真的衷心相信开源是未来，才能支持下来。毕竟回到家之后都是10点的我们，在晚上10:00到12:00再去做开源的事情，这要是没有热爱和信念是很难坚持下来的。</p><p>所以你看，<strong>开源本身，它就是一个大数定律的事情，要想看到蓝天，屡战屡败又如何？我们屡败屡战。</strong>我有一个演讲叫<a href=\"https://zhuanlan.zhihu.com/p/331630657\">《开源不是天才的甜点，而是勤奋者的盛宴》</a>，你要是感兴趣，可以去看一下。</p><h2>用算法点亮你的生活</h2><p>光有基础知识和框架其实还不够，即使你不是数据出身，你也需要去了解一些算法。因为很多算法背后的哲理，很有指导意义。</p><p>比如说，这里面我很喜欢<a href=\"https://time.geekbang.org/column/article/414442\">关联分析</a>这个算法，它背后蕴含的一个更大含义是告诉我们，其实世间很多事情都有关联，我们的精力有限，选择哪条路很重要，要做好断舍离。</p><p>对于我来讲，当时选择做技术还是做管理，就像你可以在食草和食肉动物里二选一。你如果选择吃草，你每天都可以安安静静地低头吃草，不会饿肚子，但是你一天到晚也只能低头吃草。吃肉的话，你可能就会饿肚子，并且在狩猎过程中如果你跑得不够快，那你可能就会饿死，但是一次狩猎成功一周的肉就会有着落。</p><p>每个选择都有优劣，做好自己的断舍离。我很喜欢王兴的这句话：“人生，和谁一起在路上，看什么风景。”</p><p>在算法里，对我帮助最大的就是<a href=\"https://time.geekbang.org/column/article/415893\">马尔可夫链</a>这一节。我最近生活里出现了蛮大变化，一方面幸运的是我小女儿出生了，另一方面很不幸的是我的岳父被诊断为渐冻症的晚期。渐冻症会先是无法吞咽，紧接着到四肢无法控制，甚至连呼吸都无法自主进行，最后人还是清醒的，但只能眼睛在动（就像霍金一样）。</p><p>初为父母，本身就会比较焦虑，岳父突然确诊，再正好赶上我自己工作有一些变动。这个挑战可想而知。怎么办呢？唉呀，每天都非常的愁。在我每天跑步的时候，有几天跑步跑两步就要扶着树休息一下，上不来气，这感觉就是自己沉到水里，四肢乱蹬却呼吸不到空气，那是一种窒息的感觉，我想我肯定抑郁了。</p><p>正好那两天正在写算法当中的马尔可夫链，马尔可夫链是说下一状态的概率分布，只由当前的状态决定，在时间序列中，它前面的事件均与它无关。这个事情一下就启发了我。我们要把每一天当前的事情做好，明天才会更好。如果每天我们都在焦虑，没有做该做的事情，明天一定不会变得更好。<strong>问题和挑战是上天化了妆的祝福，一旦你内心恐惧了，很多本可以做的事情你也做不到了。</strong></p><p>我也是这么去劝我岳父的，渐冻症本身并不可怕，它的发展需要一定的过程，可怕的是你对它的恐惧。与其我们在消极的过程中失败，不如在我们热爱的生活和事业里拼搏。</p><p>我特别喜欢飘的电影里边的那一句台词：“Tomorrow is another day.”电影当中女主角郝思佳经历了非常多的苦难，但是你发现她一直都是非常乐观，什么困难都没能将她击倒。她在电影最后说“明天是新的一天”，其实我猜也你曾经想过，有一天是不是可以重来过，但是只有过好现在的每一天，未来才会更加美好。</p><p>很多人都说郭大侠非常幽默。如果你今天看到我，我依然是笑口常开，和我相处的朋友们都非常开心和快乐。一个朋友的这句话我特别认同：“幽默的人通常都是这样诞生的，他们自己经历许许多多苦难后，决定让其他人不再像自己这般难受，这份血淋淋的乐观，人们称它为幽默。”</p><h2>小结</h2><p>今天其实主要和你分享了我怎么样去用数据分析思维来规划自己的生活和人生，来处理自己人生当中遇到的各种挑战。</p><p>回到我开设这门课的初心，我相信每一个人都有自己丰富多彩的阅历，但要去升华和总结自己的人生总需要一套方法。特别是对国内善于思考的我们来说，我们缺的不是观点，而是缺了一套思维方法的框架。</p><p>数据分析思维课这门课其实设立的初心就是给你以数据思维的方式，提出一个整体的框架。让你把生活当中的自己思维的收获、悟到的道理，通过一套框架和体系把它整理起来，不断提高自己的人生的品质，升级自己的头脑。</p><p>数据给你一双看透本质的眼睛，让我们通过数据思维打开我们的认知边界。</p>",
                "article_title": "加餐 | 升级头脑，用数据思维点亮生活"
            }
        ]
    }
]